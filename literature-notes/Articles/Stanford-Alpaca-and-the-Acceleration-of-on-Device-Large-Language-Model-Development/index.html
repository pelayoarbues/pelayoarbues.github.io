<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Stanford Alpaca, and the Acceleration of on-Device Large Language Model Development  Metadata  Author: [[simonwillison.net]] Full Title: Stanford Alpaca, and the Acceleration of on-Device Large Language Model Development Category: #articles URL: https://simonwillison."><title>Stanford Alpaca, and the Acceleration of on-Device Large Language Model Development</title><meta name=viewport content="width=device-width,initial-scale=1"><script defer src=https://unpkg.com/@tinybirdco/flock.js data-host=https://api.tinybird.co data-token=p.eyJ1IjogIjFhYTEyN2VjLWI0MTEtNDdjNS1iNWQzLTA5OGE2NDZjMWZhYSIsICJpZCI6ICI5YzFhNzE4Zi0xNjA1LTRmMTUtOGQ3Yy05NzliMDBjNWVmNTcifQ.-aCZYTIrTPiQCDYC_zS0dH0IVOXqI9ThnK39DMDgY7c></script><link rel="shortcut icon" type=image/png href=https://pelayoarbues.github.io//icon.png><link href=https://pelayoarbues.github.io/styles.23ddc3ecf7e887d89acd50af3b520de2.min.css rel=stylesheet><link href=https://pelayoarbues.github.io/styles/_light_syntax.32359fa0e4ad5c5b354cb209e7fa1b22.min.css rel=stylesheet id=theme-link><script src=https://pelayoarbues.github.io/js/darkmode.d1ab992b86a0866f970f82ef4d95b010.min.js></script>
<script src=https://pelayoarbues.github.io/js/util.ba89ec55faeebabb6b4bf288cd40f6da.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script async src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script async src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script async src=https://pelayoarbues.github.io/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://pelayoarbues.github.io/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://pelayoarbues.github.io/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script>const isReducedMotion=window.matchMedia("(prefers-reduced-motion: reduce)").matches,lastVisit=localStorage.getItem("lastVisitTime"),now=Date.now();let show="true";if(lastVisit){document.documentElement.setAttribute("visited","true");const e=Math.ceil((now-parseInt(lastVisit))/(1e3*60));show=!isReducedMotion&&e>5?"true":"false"}document.documentElement.setAttribute("show-animation",show),localStorage.setItem("lastVisitTime",`${now}`);const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://pelayoarbues.github.io/",fetchData=Promise.all([fetch("https://pelayoarbues.github.io/indices/linkIndex.522f61ac700d26ac7fdf540cf3e57d1b.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://pelayoarbues.github.io/indices/contentIndex.3f7663bdb509a7e1b23d0f91a7175422.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),initPopover("https://pelayoarbues.github.io",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://pelayoarbues.github.io",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:.8,opacityScale:3,repelForce:2,scale:1})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/pelayoarbues.github.io\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=pelayoarbues.github.io src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://pelayoarbues.github.io/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div id=cursor-chat-layer><input type=text id=cursor-chat-box></div><script type=module>
  import { initCursorChat } from 'https://esm.sh/cursor-chat'
  initCursorChat("jzhao.xyz")
</script><div class=singlePage><header class="delay t-3"><h1 id=page-title><a class=root-title href=https://pelayoarbues.github.io/>Pelayo Arbués</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>Stanford Alpaca, and the Acceleration of on-Device Large Language Model Development</h1><p class=meta>Last updated
Mar 17, 2023</p><ul class=tags><li><a href=https://pelayoarbues.github.io/tags/articles/>Articles</a></li><li><a href=https://pelayoarbues.github.io/tags/literature-note/>Literature Note</a></li></ul><a href=#stanford-alpaca-and-the-acceleration-of-on-device-large-language-model-development><h1 id=stanford-alpaca-and-the-acceleration-of-on-device-large-language-model-development><span class=hanchor arialabel=Anchor># </span>Stanford Alpaca, and the Acceleration of on-Device Large Language Model Development</h1></a><p><img src=https://static.simonwillison.net/static/2023/alpaca-email.png width=auto alt=rw-book-cover></p><a href=#metadata><h2 id=metadata><span class=hanchor arialabel=Anchor># </span>Metadata</h2></a><ul><li>Author: <a class="internal-link broken">simonwillison.net</a></li><li>Full Title: Stanford Alpaca, and the Acceleration of on-Device Large Language Model Development</li><li>Category: #articles</li><li>URL:
<a href=https://simonwillison.net/2023/Mar/13/alpaca/ rel=noopener>https://simonwillison.net/2023/Mar/13/alpaca/</a></li></ul><a href=#highlights><h2 id=highlights><span class=hanchor arialabel=Anchor># </span>Highlights</h2></a><ul><li>We introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. Alpaca behaves similarly to OpenAI’s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (&lt;600$) (
<a href=https://read.readwise.io/read/01gvfn3vbfxx2g9xtqr0shj0ae rel=noopener>View Highlight</a>)</li><li>One of the great innovations from OpenAI was their application of
<a href=https://openai.com/research/instruction-following rel=noopener>instruction tuning</a> to GPT-3: (
<a href=https://read.readwise.io/read/01gvfn4pc6nn1kf1tr59at6cse rel=noopener>View Highlight</a>)</li><li>On prompts submitted by our customers to the API, our labelers provide demonstrations of the desired model behavior, and rank several outputs from our models. We then use this data to fine-tune GPT-3. (
<a href=https://read.readwise.io/read/01gvfn4jqsraz7caj723k84mjr rel=noopener>View Highlight</a>)</li><li>Prior to this, you had to think very carefully about how to construct your prompts. Thanks to instruction tuning you can be a lot more, well, human in the way you interact with the model. (
<a href=https://read.readwise.io/read/01gvfn55vkwrjkgp4tevpwkbnh rel=noopener>View Highlight</a>)</li><li>Keep in mind these models are not finetuned for question answering. As such, they should be prompted so that the expected answer is the natural continuation of the prompt. (
<a href=https://read.readwise.io/read/01gvfn5gd6vc0hebd37hqzbssg rel=noopener>View Highlight</a>)</li><li>Thanks to the team at Stanford we now have an answer: 52,000 training samples and $100 of training compute! From their blog post: (
<a href=https://read.readwise.io/read/01gvfn5t8e7k7apcqkagy5e7k6 rel=noopener>View Highlight</a>)</li><li>Something that stuns me about Alpaca is the quality they claim to be able to get from the 7B model—the smallest of the LLaMA models, and the one which has been seen running (albeit glacially slowly) on a RaspberryPi and a mobile phone! Here’s one example from their announcement: (
<a href=https://read.readwise.io/read/01gvfn65p90ytzbzjevhzecz0p rel=noopener>View Highlight</a>)</li><li>We emphasize that Alpaca is intended <strong>only for academic research</strong> and any <strong>commercial use is prohibited</strong>. There are three factors in this decision: First, Alpaca is based on LLaMA, which has a non-commercial
<a href=https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform rel=noopener>license</a>, so we necessarily inherit this decision. Second, the instruction data is based OpenAI’s text-davinci-003, whose
<a href=https://openai.com/policies/terms-of-use rel=noopener>terms of use</a> prohibit developing models that compete with OpenAI. Finally, we have not designed adequate safety measures, so Alpaca is not ready to be deployed for general use. (
<a href=https://read.readwise.io/read/01gvfn6w4rm489rw619dz4njv3 rel=noopener>View Highlight</a>)</li><li>Those 52,000 samples they used to fine-tune the model? Those were the result of a prompt they ran against GPT-3 itself! Here’s
<a href=https://github.com/tatsu-lab/stanford_alpaca/blob/da37bb2ecab37cae022dd07aa3ff861c446fb614/prompt.txt rel=noopener>the prompt</a> they used: (
<a href=https://read.readwise.io/read/01gvfn8yar4jb3t3n2rnfq9m5z rel=noopener>View Highlight</a>)</li><li>Then they include three random example instructions from
<a href=https://github.com/tatsu-lab/stanford_alpaca/blob/da37bb2ecab37cae022dd07aa3ff861c446fb614/seed_tasks.jsonl rel=noopener>a list of 175</a> they had prepared by hand. The completed prompt sent to OpenAI would include the above instructions followed by something like this (
<a href=https://read.readwise.io/read/01gvfn9c4ta3hh5q2gdnezbt19 rel=noopener>View Highlight</a>)</li><li>They spent $500 on OpenAI credits to assemble the 52,000 examples they used to fine-tune their model. (
<a href=https://read.readwise.io/read/01gvfna517kgrt5t2d1jve66s5 rel=noopener>View Highlight</a>)</li><li>There’s a related concept to this called
<a href=https://ssg.aalto.fi/research/projects/mlsec/model-extraction/ rel=noopener>Model Extraction</a>, where people build new models that emulate the behaviour of others by firing large numbers of examples through the other model and training a new one based on the results. (
<a href=https://read.readwise.io/read/01gvfnackbeacwwz9b32agyaq3 rel=noopener>View Highlight</a>)</li></ul><a href=#new-highlights-added-march-17-2023-at-301-pm><h2 id=new-highlights-added-march-17-2023-at-301-pm><span class=hanchor arialabel=Anchor># </span>New highlights added March 17, 2023 at 3:01 PM</h2></a><ul><li>On Saturday 11th March I wrote about how
<a href=https://simonwillison.net/2023/Mar/11/llama/ rel=noopener>Large language models are having their Stable Diffusion moment</a>. Today is Monday. Let’s look at what’s happened in the past three days. (
<a href=https://read.readwise.io/read/01gvqx6adskeg5jkbdndjgz9zy rel=noopener>View Highlight</a>)<ul><li>Note: In the past three days since the release of an article about the increasing relevance of large language models, the development of on-device language models has been rapidly accelerating, with Stanford Alpaca being the most recent development. Stanford Alpaca is a toolkit designed to help developers and machine learning practitioners develop and deploy large language models on mobile and other edge devices.</li></ul></li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://pelayoarbues.github.io/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Pelayo Arbués using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://pelayoarbues.github.io/>Home</a></li><li><a href=https://twitter.com/pelayoarbues>Twitter</a></li><li><a href=https://sigmoid.social/@pelayoarbues>Mastodon</a></li><li><a href=https://www.linkedin.com/in/pelayoarbues/>Linkedin</a></li><li><a href="https://scholar.google.com/citations?user=WaC-GcIAAAAJ&hl">Scholar</a></li><li><a href=https://www.flickr.com/photos/wonderfulhorriblelife/>Flickr</a></li><li><a href=https://github.com/pelayoarbues>GitHub</a></li></ul></footer></div></div></body></html>