---
title: Stable Diffusion technicalities
date: 2023-10-05
tags:
  - permanent-note
  - stablediffusion
---

![](notes/attachments/Pasted%20image%2020231005105602.png)
 [Source](https://www.reddit.com/r/StableDiffusion/comments/10cgxrx/wellresearched_comparison_of_training_techniques/)

If you need further info on how Stable Diffusion works, I suggest you to read my notes on [LoRA](notes/LoRA.%20Low-Rank%20Adaptation%20of%20LLMs.md) and also the following links:

- LoRa paper: [Hu, E. J.,et al.Â (2021).Â LoRA: Low-Rank Adaptation of Large Language Models.](https://arxiv.org/abs/2106.09685)
- A HuggingFace post indicating why you should use LoRa. [Using LoRA for Efficient Stable Diffusion Fine-Tuning](https://huggingface.co/blog/lora)
- Tuning an LLM with LoRa, somehow related to images: [Parameter-Efficient LLM Finetuning With Low-Rank Adaptation (LoRA)](https://sebastianraschka.com/blog/2023/llm-finetuning-lora.html)
- Intuition behind Unet: [You Canâ€™t Spell Diffusion without U | by Sairam Sundaresan | Towards Data Science](https://towardsdatascience.com/you-cant-spell-diffusion-without-u-60635f569579)


Different Stable Diffusion techniques you should learn about:
- [ðŸ˜•LoRA vs Dreambooth vs Textual Inversion vs Hypernetworks - YouTube](https://www.youtube.com/watch?v=dVjMiJsuR5o)
- [What is LyCORIS and how to use them in Stable Diffusion - Stable Diffusion Art](https://stable-diffusion-art.com/lycoris/)



