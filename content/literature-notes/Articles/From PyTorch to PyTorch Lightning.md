---
author: [[Avi Chawla]]
title: "From PyTorch to PyTorch Lightning"
date: 2024-03-14
tags: 
- articles
- literature-note
---
![rw-book-cover](https://substack-post-media.s3.amazonaws.com/public/images/7d644225-a696-4953-b8cd-07bdf7edf80a_2320x1500.png)

## Metadata
- Author: [[Avi Chawla]]
- Full Title: From PyTorch to PyTorch Lightning
- URL: https://www.blog.dailydoseofds.com/p/from-pytorch-to-pytorch-lightning

## Highlights
- One of the most significant issues with PyTorch is that one has to manually write its long training loops shown below, which is primarily boilerplate code. ([View Highlight](https://read.readwise.io/read/01hrz7y0c0n3rgah9x6wh6ytz8))
- You can think of PyTorch Lightning as a lightweight wrapper around PyTorch. ([View Highlight](https://read.readwise.io/read/01hrz7yp0ctxecv88sw8na2f1k))
- Just like Keras is a wrapper on TensorFlow, PyTorch lightning is a wrapper on PyTorch, but one that makes it much more efficient than the traditional way of training the model. ([View Highlight](https://read.readwise.io/read/01hrz7yrkng003chjr8bn5h0jq))
- PyTorch Lightning:
  • Abstracts away the boilerplate code, which we typically write with PyTorch
  • Provides elegant and one-liner support for mixed precision training.
  • Works seamlessly in a distributed setting, again, with just a few lines of code.
  • Comes with built-in logging and profiling capabilities, and much more. ([View Highlight](https://read.readwise.io/read/01hrz7z9rd0h7x7bs2h458fw1a))
