---
author: [[Superhuman AI]]
title: "ðŸŒŒ AI Drones Are Paving the Way for Autonomous Spaceflight"
date: 2024-07-17
tags: 
- articles
- literature-note
---
![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png)

## Metadata
- Author: [[Superhuman AI]]
- Full Title: ðŸŒŒ AI Drones Are Paving the Way for Autonomous Spaceflight

## Highlights
- If youâ€™ve used LLMs long enough, youâ€™ve probably come up against a pesky problem: Suddenly, your go-to prompt for completing a certain task no longer works. Or, maybe youâ€™re trying out someone elseâ€™s prompt and you find that their method gives you a completely different result. ([View Highlight](https://read.readwise.io/read/01j3123f7p5v1azpx3721nprnd))
- **In many cases, updates are to blame for those inconsistencies:** Developers fine-tune their models to cut down on hallucinations, glitches, and other problems. But every time thereâ€™s an update, some of that work gets undone. As a result, an LLM might struggle with certain things â€” from reasoning problems to writing tasks â€” that it previously excelled at. ([View Highlight](https://read.readwise.io/read/01j3123j6sre76r9v7av62aq97))
- **What can we do about it?** Apple researchers are trying to figure out a way to make the [transition](https://link.mail.beehiiv.com/ss/c/u001.zEtKbyME9NCWhmYYa-Fvv0akQuX9uJgkDhwDkXINFUv3qHeHQx01_-YONBI_Q21Jdq0Y9rz95n9s_o1Rdtw5KkPiIsIASsATJi8SfKnuhj1XLae3OPYB_8njyw5KJcMYSjh1ZiP1KX7GzPu984XoOOfAMzzOpQRx5YmULS_PEUcKiRsvZw6P3Sa-JRKC1gUAB3mzhn8J7-OUKdnapcQBoQ/484/UhNMxfkmRWKAChcB9BZeLw/h1/h001.tVOEQPcSVXG4TSmdX60MKoheXVGjrF20uGSatGkM5iA) between old and new models easier to adjust to. Itâ€™s a tricky problem because negative flips â€” when an AI model gets wrong what it previously got right â€” are common even when an LLMâ€™s training methods are kept exactly the same across generations. ([View Highlight](https://read.readwise.io/read/01j3123v35k1eqynm55dzhkjcm))
- **How does it work?** The researchers created a set of metrics that can be used to spot differences between each version of an LLM â€” in this case, Metaâ€™s open-source Llama 1 and Llama 2. Then, using that data, they taught a specialized LLM known as a compatibility model how to flag discrepancies on its own. This approach slashed inconsistencies by about 40%. ([View Highlight](https://read.readwise.io/read/01j31249sm7gam1gk4a9v9ezpt))
- **What it means for you:** Whenever thereâ€™s a new update, we often focus on a modelâ€™s number of parameters and tokens â€” or its performance across different benchmarks. But just as important is the experience of actually using that LLM. Appleâ€™s research shows that tech companies are paying closer attention to the inconsistency problem and want to cut down on it. ([View Highlight](https://read.readwise.io/read/01j3124mz9p3d6q9r9c47pnck9))
