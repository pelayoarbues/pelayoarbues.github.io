---
author: [[Nathan Lambert]]
title: "Model Commoditization and Product Moats"
date: 2024-03-14
tags: 
- articles
- literature-note
---
![rw-book-cover](https://substack-post-media.s3.amazonaws.com/public/images/29ef41f3-6ec9-4d8b-874d-91a190af5ece_3200x1800.png)

## Metadata
- Author: [[Nathan Lambert]]
- Full Title: Model Commoditization and Product Moats
- URL: https://www.interconnects.ai/p/gpt4-commoditization-and-moats

## Highlights
- GPT4’s level of performance has been replicated within multiple organizations. GPT3’s level of performance has been reproduced by many. GPT2 level models can be trained by almost everyone ([probably on the order of $1k to do in a few hours](https://www.databricks.com/blog/gpt-3-quality-for-500k)). The early idea that models could maybe be moats has been so resoundingly defeated that *people don’t expect language model providers to have **any** moats.* ([View Highlight](https://read.readwise.io/read/01hrz84003apar3ejw3jsawfhd))
- In this era of massive investment into AI, the land grab phase, we’ll see the most providers trying to enter the space. It has turned out that many of these providers have reached largely similar tiers of capabilities, which may not always be the case as scaling costs get even higher (and future technical challenges emerge). Market share distributions will be defined by who can create sticky user behavior. To set the stage, I’m bringing up this image I [Tweeted](https://twitter.com/natolambert/status/1765779714252451971) last week. It shows that since Gemini 1.5 Pro on February 15th, we’ve seen 4 GPT4 class models in Gemini, Claude 3 (GPT4 turbo tier, actually), Mistral Large, and Inflection 2.5. ([View Highlight](https://read.readwise.io/read/01hrz84basrq9zqj7pvkgfxcn2))
- I expected to have Llama 3 by now, but it seems the scope of what they’re doing is constantly changing. I have heard credible rumors that it is done training and credible rumors that multiple teams are trying different things and the best one wins. So, who knows when we’ll get this model? ([View Highlight](https://read.readwise.io/read/01hrz8508kbanvqhzdfgq5vz42))
- These broadly available GPT4 class models are very rapidly going to create a high-entropy situation in the next few months — prices will fluctuate, companies will fight for usage, and narratives will shift fast. This fluctuation is the organizations trying to find a competitive advantage and a moat. ([View Highlight](https://read.readwise.io/read/01hrz853sgeg4hbgdpbw4rkj76))
- The companies that have users interacting with their models consistently have moats through data and habits. The models themselves are not a moat, as I discussed at the end of last year when I tried to [predict machine learning moats](https://www.interconnects.ai/p/ml-moats), but there are things in the modern large language model (LLM) space that open-source will really struggle to replicate. Concretely, that difference is access to quality and diverse training prompts for fine-tuning. While I want open-source to win out for personal philosophical and financial factors, this obviously is not a walk in the park for the open-source community. It'll be a siege of a castle with, you guessed it, a moat. We'll see if the moat holds. ([View Highlight](https://read.readwise.io/read/01hrz8609tjs9641cy2vf9c6zc))
- Having the best *cheap* model could be another way to create a moat. While the companies creating [openly trained and permissive-ish usage](https://www.interconnects.ai/p/an-open-source-llm) don’t normally have the economies of scale to drive down inference costs, those of Google, Anthropic (a borderline inclusion on capital assets), and OpenAI will probably use it as a loss leader. We need more **data on the paid versus free tier usage** of the various applications, and especially conversion numbers. We likely won’t get this data, so don’t buy into the PR narratives you hear too much. ([View Highlight](https://read.readwise.io/read/01hrz86a86153q1f7287nn001f))
- The model I’m expecting to test this hypothesis is Claude 3 Sonnet. Can they get many users to unsubscribe for a better free model? Unlikely. Can they bring more people in from OpenAI’s free tier, probably? Both Anthropic and OpenAI probably have no chance of winning an inference price competition versus Google, though. ([View Highlight](https://read.readwise.io/read/01hrz86tbp79cncchj838pysad))
- In some ways, Claude 3’s timing seems like their last shot to get a consumer footprint (with GPT4.5-Turbo around the corner). Google’s recent [“ship it” attitude](https://www.interconnects.ai/p/gemma-google-ships-it?r=68gy5&utm_campaign=post&utm_medium=web) and OpenAI’s larger consumer footprint will be extremely hard to beat. In some ways, I don’t even expect the Claude 3 step to matter much for paid users. Disruption theory on the internet has long been driven by the need to have a dramatically better experience or price, not just marginal gains. ([View Highlight](https://read.readwise.io/read/01hrz87af90pwjatebfddg4avy))
