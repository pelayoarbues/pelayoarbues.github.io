---
author: [[WFH Brian]]
title: "Revolutionizing Search: How Hypothetical Document Embeddings (HyDE) Can Save Time and Increase Productivity"
tags: 
- articles
- literature-note
---
# Revolutionizing Search: How Hypothetical Document Embeddings (HyDE) Can Save Time and Increase Productivity

![rw-book-cover](https://wfhbrian.com/wp-content/uploads/sites/26/2023/01/AI-HyDE-workflow.excalidraw.png)

## Metadata
- Author: [[WFH Brian]]
- Full Title: Revolutionizing Search: How Hypothetical Document Embeddings (HyDE) Can Save Time and Increase Productivity
- URL: https://wfhbrian.com/revolutionizing-search-how-hypothetical-document-embeddings-hyde-can-save-time-and-increase-productivity/

## Highlights
- The HyDE hypothesis is that the document search would yield better results using hypothetical answers than the question itself. ([View Highlight](https://read.readwise.io/read/01h4h5zgggy0xadcjqkyn66zkt))
- The HyDE method is a way to find information in a large set of documents using artificial intelligence. It starts by having a Large Language Model (LLM), like ChatGPT, create a document based on a specific question or topic. This document may contain some false information, but it also has relevant patterns that can be used to find similar documents in a trusted knowledge base. ([View Highlight](https://read.readwise.io/read/01h4h5zybmyj8h721vdy79wtmb))
- Next, another AI model is used to turn the created document into an embedding vector, which is then used to find other documents similar to the one the AI model created. ([View Highlight](https://read.readwise.io/read/01h4h6003v0h7wnm6stfth6z7p))
- HyDE can enable language models in more sensitive applications since the search results are returned directly from a trusted source. This process prevents “hallucinations” by the LLM from being returned to the user. This can be useful in cases where exact measurements are necessary or incorrect answers could prove catastrophic, like in medicine. ([View Highlight](https://read.readwise.io/read/01h4h605der386zttrjhewdnc3))
