---
author: [[stephenwolfram.com]]
title: "ChatGPT Gets Its “Wolfram Superpowers”!"
tags: 
- articles
- literature-note
---
# ChatGPT Gets Its “Wolfram Superpowers”!

![rw-book-cover](https://content.wolfram.com/uploads/sites/43/2023/03/gpt-plugin-hero6.png)

## Metadata
- Author: [[stephenwolfram.com]]
- Full Title: ChatGPT Gets Its “Wolfram Superpowers”!
- URL: https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/

## Highlights
- ChatGPT can now call on Wolfram|Alpha—and [Wolfram Language](https://www.wolfram.com/language/) as well—to give it what we might think of as “computational superpowers”. It’s still very early days for all of this, but it’s already very impressive—and one can begin to see how amazingly powerful (and perhaps even revolutionary) what we can call “ChatGPT + Wolfram” can be. ([View Highlight](https://read.readwise.io/read/01gwkttk557r6v8a1zqxzn5rts))
- How did this work? Under the hood, ChatGPT is formulating a query for Wolfram|Alpha—then [sending it to Wolfram|Alpha for computation](https://www.wolfram.com/resources/tools-for-AIs/), and then “deciding what to say” based on reading the results it got back ([View Highlight](https://read.readwise.io/read/01gwktvp63h8c97r03119y6ysr))
- Since [ChatGPT uses randomness](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/) in generating its responses, different things can happen even when you ask it the exact same question (even in a fresh session). It feels “very human”. But different from the solid “right-answer-and-it-doesn’t-change-if-you-ask-it-again” experience that one gets in Wolfram|Alpha and Wolfram Language. ([View Highlight](https://read.readwise.io/read/01gwktxgzwcyrpyatz7k3hwefd))
- we’re acting much more like a true “brain implant” for ChatGPT—where it asks us things whenever it needs to, and we give responses that it can weave back into whatever it’s doing. It’s rather impressive to see in action. And—although there’s definitely much more polishing to be done—what’s already there goes a long way towards (among other things) giving ChatGPT the ability to deliver accurate, curated knowledge and data—as well as correct, nontrivial computations. ([View Highlight](https://read.readwise.io/read/01gwmqrz8r07tm2pv44p5kbg4d))
- Wolfram Language, on the other hand, is set up to be precise and well defined—and capable of being used to build arbitrarily sophisticated towers of computation. Inside Wolfram|Alpha, what it’s doing is to translate natural language to precise Wolfram Language. In effect it’s catching the “imprecise natural language” and “funneling it” into precise Wolfram Language. ([View Highlight](https://read.readwise.io/read/01gwmrhdgh7yar8dvm0m8ta4qr))
- Sometimes we’ve found we have to be quite insistent (note the all caps): “When writing Wolfram Language code, NEVER use snake case for variable names; ALWAYS use camel case for variable names.” And even with that insistence, ChatGPT will still sometimes do the wrong thing. The whole process of “prompt engineering” feels a bit like animal wrangling: you’re trying to get ChatGPT to do what you want, but it’s hard to know just what it will take to achieve that. ([View Highlight](https://read.readwise.io/read/01gwmrm5v1zkk0vj89h20zzye3))
- Well, here’s the issue. Traditional programming languages are centered around telling a computer what to do in the computer’s terms: set this variable, test that condition, etc. But it doesn’t have to be that way. And instead one can start from the other end: take things people naturally think in terms of, then try to represent these computationally—and effectively automate the process of getting them actually implemented on a computer ([View Highlight](https://read.readwise.io/read/01gwms9jb55zmpa6b29tpdjmkz))
