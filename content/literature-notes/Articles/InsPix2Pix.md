---
author: [[mllm-ie.github.io]]
title: "InsPix2Pix"
date: 2023-10-10
tags: 
- articles
- literature-note
---
![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article2.74d541386bbf.png)

## Metadata
- Author: [[mllm-ie.github.io]]
- Full Title: InsPix2Pix
- URL: https://mllm-ie.github.io/

## Highlights
- Instruction-based image editing improves the controllability and flexibility of image manipulation via natural commands without elaborate descriptions or regional masks. However, human instructions are sometimes too brief for current methods to capture and follow. Multimodal large language models (MLLMs) show promising capabilities in cross-modal understanding and visual-aware response generation via LMs. ([View Highlight](https://read.readwise.io/read/01hcc730wngsmcnq0k2zwyxn3w))
