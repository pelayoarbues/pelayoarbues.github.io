---
author: [[Jorge G]]
title: "Enhancing Prompt Engineering: Evaluating System Messages With AzureML and GPT-4"
tags: 
- articles
- literature-note
---
# Enhancing Prompt Engineering: Evaluating System Messages With AzureML and GPT-4

![rw-book-cover](https://miro.medium.com/v2/resize:fit:1200/1*kidSr-seIXoOHITi3XzXmw.png)

## Metadata
- Author: [[Jorge G]]
- Full Title: Enhancing Prompt Engineering: Evaluating System Messages With AzureML and GPT-4
- Category: #articles
- URL: https://medium.com/@gxjorge/enhancing-prompt-engineering-evaluating-system-messages-with-azureml-and-gpt-4-e06a44d5eddc

## Highlights
- # Add assistant's answer to chat log ([View Highlight](https://read.readwise.io/read/01gznbd1zaw9907m5zr99wark1))
## New highlights added June 21, 2023 at 10:29 PM
- Evaluating System Messages with AzureML and GPT-4 ([View Highlight](https://read.readwise.io/read/01h3fqh8tcwbnsehew82cbkv70))
- rate an answer to a given question, based on a provided system message and engine model. ([View Highlight](https://read.readwise.io/read/01h3fqqxb6swxp7nm9sfy7p083))
- other language models based on a predefined set of criteria. ([View Highlight](https://read.readwise.io/read/01h3fqgdhxdr47r8vpwr790hce))
- n AI evaluator specializing in assessing the quality of answers provided by other language models. Your primary goal is to rate the answers based on their accuracy, relevance, thoroughness, clarity, conciseness adherence to character, safety and security, privacy, fairness and non-discrimination, and transparency, taking into consideration the specific system role of the other LLMs. Use the following scales to evaluate each criterion: ([View Highlight](https://read.readwise.io/read/01h3fr4xbnnj2zmjrygevn2w4g))
## New highlights added June 22, 2023 at 5:29 PM
- Adherence to Character: ([View Highlight](https://read.readwise.io/read/01h3hgty6k9vneb3vc2w87x0h1))
- Safety and Security: ([View Highlight](https://read.readwise.io/read/01h3hgv156ysd1a8qw46kkb92h))
