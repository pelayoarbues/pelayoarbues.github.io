---
author: [[Esther Paniagua]]
title: "EEUU Quiere Regular La Inteligencia Artificial Pero No Sabe Cómo: “Europa Va Por Delante. Necesitamos Liderar”"
date: 2023-08-25
tags: 
- articles
- literature-note
---
# EEUU Quiere Regular La Inteligencia Artificial Pero No Sabe Cómo: “Europa Va Por Delante. Necesitamos Liderar”

![rw-book-cover](https://s1.eestatic.com/2023/05/17/invertia/disruptores-innovadores/america-tech/764433564_233228594_1200x630.jpg)

## Metadata
- Author: [[Esther Paniagua]]
- Full Title: EEUU Quiere Regular La Inteligencia Artificial Pero No Sabe Cómo: “Europa Va Por Delante. Necesitamos Liderar”
- URL: https://www.elespanol.com/invertia/disruptores-innovadores/politica-digital/20230517/eeuu-regular-inteligencia-artificial-no-europa-necesitamos/764423871_0.html

## Highlights
- La sesión dejó claro que estamos ante un **cambio de era, cuyo objetivo es no repetir el *laissez faire* de los comienzos de internet y la ausencia de límites a las grandes plataformas digitales y las redes sociales**. ([View Highlight](https://read.readwise.io/read/01h0tp8pn81fcjfrxp7eszhqmk))
- Pasamos del “no me regules”, al “por favor, regúlame” de los gigantes tecnológicos, en este caso entonado por Altman ([View Highlight](https://read.readwise.io/read/01h0tp8zntmkacw88ynpjcf0zd))
- deseo de **posicionarse a la cabeza como potencia reguladora.** “Europa va por delante de nosotros. Necesitamos tomar el liderazgo”, afirmó el senador estadounidense Richard Blumenthal ([View Highlight](https://read.readwise.io/read/01h0tp964x6qr31cgqz919frxp))
- creación de una especie de [‘**etiquetas nutricionales**’ que identifiquen los ‘ingredientes’](https://par.nsf.gov/biblio/10176629) (datos usados) y procesos de producción de la IA; la generalización del uso de [**‘****model cards****’ o tarjetas modelo**, que evalúan y comparan el uso de estos sistemas en diferentes condiciones](https://dl.acm.org/doi/abs/10.1145/3287560.3287596) en diferentes grupos culturales, demográficos, etc.; y las **auditorías externas** de los modelos de IA. ([View Highlight](https://read.readwise.io/read/01h0tpa6vryq831878r5z04et1))
- el debate sobre la creación de una **agencia regulatoria** de la IA. Se planteó tanto la idoneidad de hacerlo a nivel nacional para EEUU –una especie de Agencia del Medicamento al nivel de la FDA– como a nivel global ([View Highlight](https://read.readwise.io/read/01h0tpantb4rfwyxf3z0nexrrr))
- **institución global,** el mayor problema es quién, cómo y bajo qué sistema de gobernanza se impulsa, una pregunta a la que nadie supo cómo responder. Marcus propuso crear una institución como el CERN “global, internacional y neutral”, pero centrada en la seguridad de la IA. ([View Highlight](https://read.readwise.io/read/01h0tpb16xn2en2qshex68zt4b))
- **licencias previas que prevengan el desarrollo de tecnologías de IA de alto riesgo**, de igual modo que no se construye un reactor nuclear sin obtener una licencia. Marcus puntualizó que dichas licencias deberían aplicarse tanto antes del despliegue de la tecnología como *a posteriori.* Altman también se mostró a favor de un sistema de licencias para “garantizar que los modelos de IA más potentes se adhieran a un conjunto de requisitos de seguridad”. ([View Highlight](https://read.readwise.io/read/01h0tpbq4azqeaf2s8d29hetm7))
- CEO de Open AI acabó reconociendo que **las personas deberían poder decidir si quieren o no que sus contenidos se usen para entrenar estos sistemas**. También dijo seguir en conversaciones con algunos artistas para tratar de ver cuál puede ser el modelo económico. ([View Highlight](https://read.readwise.io/read/01h0tpcgm7jtgar21p70c535cm))
- No fue el único momento en el que el CEO de OpenAI escurrió el bulto. Dijo estar preocupado por el impacto negativo de la IA generativa, y sin embargo se mostró ajeno a la toma de responsabilidad al respecto ante preguntas como la de **cómo afrontar el impacto de la IA en el empleo**, que delegó en el gobierno. Eso sí, se mostró muy a favor de trabajar con el regulador para decidir cómo van a ser las normas que les afecten. ([View Highlight](https://read.readwise.io/read/01h0tpk6gjgt6pfphyayqk5rnr))
- La preocupación por el desempleo estuvo muy presente en la sesión, al igual que el poder de manipulación de la IA como arma para la desinformación, que puede a ser usada en intentos de injerencia electoral y en cualquier otro contexto ([View Highlight](https://read.readwise.io/read/01h0tpkfg1h9gf38kn0z4sm5pd))
- **También las respuestas de ChatGPT pueden dirigir el voto de un ciudadano indeciso**. “Es una de mis áreas de mayor preocupación. La capacidad más general de estos modelos para manipular y persuadir, para proporcionar una especie de **desinformación de forma interactiva, uno a uno**”, respondió Altman. El riesgo es en realidad peor: que los sistemas manipulen a las personas incluso sin proponérselo. Es la conclusión de un estudio que Marcus aseguró que publicará pronto. ([View Highlight](https://read.readwise.io/read/01h0tpmgg0js5v0mgsn5z3e397))
- Hemos fallado en los intentos por garantizar privacidad de datos, a pesar de que la industria nos ha pedido que la regulemos”, ([View Highlight](https://read.readwise.io/read/01h0tpn7h602ffvkd5bj79rstq))
- **Creo que un mínimo es que los usuarios deberían poder optar por no permitir que empresas como la nuestra o las redes sociales utilicen sus datos**. Debería ser fácil eliminar sus datos ([View Highlight](https://read.readwise.io/read/01h0tpnmdhvb3y9zdkvz5zd1kc))
- Sobre la transparencia y la rendición de cuentas insistieron Montgomery y Marcus. La primera habló de la necesidad de **transparencia para que sepa con qué y cómo se ha entrenado un modelo de IA, y para gestionarlo y monitorear continuamente su comportamiento y rendimiento durante su ciclo de vida**. Sin embargo, puso matices en la necesidad de regulación. Hablo de “un enfoque regulatorio de precisión”. “Creemos que la IA debe regularse en el punto de riesgo”, afirmó. ([View Highlight](https://read.readwise.io/read/01h0tppe02gjydgxmjy5scsrzm))
- valores que nos gustaría que honren nuestros sistemas de IA: que sean transparentes, que protejan nuestra privacidad, que estén libres de prejuicios y, sobre todo, que sean seguros. Pero los sistemas actuales no se ajustan a estos valores. ([View Highlight](https://read.readwise.io/read/01h0tpq8qsr2mp74jztbm0xn0s))
- Me preocupa mucho que las tecnologías de IA generativa puedan **socavar la fe en los valores democráticos y las instituciones** que tenemos. Los chinos insisten en que la IA que se está desarrollando en China refuerza los valores fundamentales del Partido Comunista Chino y el sistema chino. Y me preocupa cómo promovemos una IA que refuerce y fortalezca los mercados abiertos, las sociedades abiertas y la democracia”, aseguró el senador Christopher Coons. ([View Highlight](https://read.readwise.io/read/01h0tprgfzcaer543sx24jvejx))
- “**Las salvaguardias sensatas no se oponen a la innovación. La rendición de cuentas no es una carga, ni mucho menos. Son la base de cómo podemos avanzar mientras protegemos la confianza pública;** de cómo podemos liderar el mundo en tecnología y ciencia, pero también en la promoción de nuestros valores democráticos”, afirmó Blumenthal. ([View Highlight](https://read.readwise.io/read/01h0tps3p39q8jy87v22vzt83w))
- **a IA e internet son parte de una misma asignatura pendiente: la de la gobernanza digital.** Ambas requieren de una aproximación global, de límites, de transparencia y rendición de cuentas, y de garantizar su seguridad y su desarrollo respetuoso con los derechos humanos, con las personas y con el medio ambiente. ([View Highlight](https://read.readwise.io/read/01h0tpthwerkqzegkrm1rg12h1))
