---
author: [[Noor Al-Sibai]]
title: "Sam Altman Replaces OpenAI’s Fired Safety Team With Himself and His Cronies"
date: 2024-05-30
tags: 
- articles
- literature-note
---
![rw-book-cover](https://wp-assets.futurism.com/2024/05/sam-altman-openai-safety-team-replacement.jpg)

## Metadata
- Author: [[Noor Al-Sibai]]
- Full Title: Sam Altman Replaces OpenAI’s Fired Safety Team With Himself and His Cronies
- URL: https://futurism.com/the-byte/sam-altman-openai-safety-team-replacement

## Highlights
- Less than ten days after [dissolving its safety-oriented Superalignment team](https://www.wired.com/story/openai-superalignment-team-disbanded/), OpenAI has announced a new safety board — with embattled CEO Sam Altman at its helm. ([View Highlight](https://read.readwise.io/read/01hz2xxv0nvcvz1b182hnztx0k))
- In a statement, [OpenAI announced](https://openai.com/index/openai-board-forms-safety-and-security-committee/) that it was creating a new "safety and security committee," an offshoot of its [now-infamous board of directors](https://futurism.com/the-byte/openai-board-altman-history) that along with Altman includes the body's chair, Bret Taylor, Quora CEO and cofounder Adam D’Angelo, and corporate attorney Nicole Seligman. ([View Highlight](https://read.readwise.io/read/01hz2xy1094nev0g169d5jb4qv))
- The original Superalignment team, which had been [announced less than a year ago](https://openai.com/index/introducing-superalignment/), was meant to "steer and control AI systems much smarter than us," but was dissolved earlier this month. ([View Highlight](https://read.readwise.io/read/01hz2xy6x9c1mhh6m1e8fh0vw1))
- This new team's creation also comes after the exits of several prominent OpenAI executives, including Superalignment chief Jan Leike — who just announced that he's [joining his fellow company expats](https://x.com/janleike/status/1795497960509448617) at Anthropic — and team cofounder Ilya Sutskever. ([View Highlight](https://read.readwise.io/read/01hz2xyfy298ee4p8czepggn8v))
- Leike had previously accused OpenAI of abandoning its responsibilities in a series of posts earlier this month, with safety taking a "[backseat to shiny products](https://apnews.com/article/openai-jan-leike-safety-ilya-8a7ba341e06a66e9a7935bb06214edcb)." ([View Highlight](https://read.readwise.io/read/01hz2y016h40641zc4b21x59yd))
- In the latest announcement, meanwhile, OpenAI teased that it has "recently begun training its next frontier model," though there's no word yet [whether that model is GPT-5](https://www.theverge.com/2024/5/28/24166076/ready-for-gpt-5), the much-anticipated update to the large language model that undergirds ChatGPT. ([View Highlight](https://read.readwise.io/read/01hz2y05s5fpkw44whbd7sqm3j))
- Unlike the debacle last fall that saw Altman fired and promptly reinstated — affectionately referred to as the "[turkey-shoot clusterfuck](https://futurism.com/the-byte/microsoft-openai-drama-name)" — we don't know what's going on behind the scenes at OpenAI. ([View Highlight](https://read.readwise.io/read/01hz2y0e1kqpfqwdz8e22468t6))
- We still can't say why the Superalignment team was dissolved and replaced in such a manner. Was it a cost-cutting measure or was the team's dissolution the result of internal disagreements? Was it both? ([View Highlight](https://read.readwise.io/read/01hz2y0kqa5d2yna8ar8stkd5f))
- Given that Altman is leading the new one and the person who ran its predecessor is now at a rival firm, we know one thing for certain: there's likely *plenty* of drama. ([View Highlight](https://read.readwise.io/read/01hz2y0qx46maahg3b3p35gys9))
