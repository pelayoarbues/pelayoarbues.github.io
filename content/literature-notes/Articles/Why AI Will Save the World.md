---
author: [[Marc Andreessen]]
title: "Why AI Will Save the World"
date: 2023-09-04
tags: 
- articles
- literature-note
---
![rw-book-cover](https://a16z.com/wp-content/uploads/2023/06/AI-Saves-The-World_Yoast-FB.jpg)

## Metadata
- Author: [[Marc Andreessen]]
- Full Title: Why AI Will Save the World
- URL: https://a16z.com/2023/06/06/ai-will-save-the-world/

## Highlights
- AI will not destroy the world, and in fact may save it ([View Highlight](https://read.readwise.io/read/01h9g2jrtnc32h85sgxshhsy53))
- What AI offers us is the opportunity to profoundly *augment* human intelligence to make all of these outcomes of intelligence ([View Highlight](https://read.readwise.io/read/01h9g2kndwhtgmqpcxyem6my9j))
- Every child will have an AI tutor that is infinitely patient, infinitely compassionate, infinitely knowledgeable, infinitely helpful. ([View Highlight](https://read.readwise.io/read/01h9g2m15chbzvr9jr0rmcfjp7))
- Every person will have an AI assistant/coach/mentor/trainer/advisor/therapist that is infinitely patient, infinitely compassionate, infinitely knowledgeable, and infinitely helpful. ([View Highlight](https://read.readwise.io/read/01h9g2m89nsbwmyhcmy4tkygv4))
- Every scientist will have an AI assistant/collaborator/partner that will greatly expand their scope of scientific research and achievement. ([View Highlight](https://read.readwise.io/read/01h9g2mdcg85za1mp1gjh22x8w))
- Every leader of people – CEO, government official, nonprofit president, athletic coach, teacher – will have the same. The magnification effects of better decisions by leaders across the people they lead are enormous, so this intelligence augmentation may be the most important of all. ([View Highlight](https://read.readwise.io/read/01h9g2mnwv686qbc5cc1npzf8h))
- The creative arts will enter a golden age, as AI-augmented artists, musicians, writers, and filmmakers gain the ability to realize their visions far faster and at greater scale than ever before. ([View Highlight](https://read.readwise.io/read/01h9g2n2trpenaktzard2xf99e))
- military commanders and political leaders will have AI advisors that will help them make much better strategic and tactical decisions, minimizing risk, error, and unnecessary bloodshed. ([View Highlight](https://read.readwise.io/read/01h9g2nj9r57p9x9vt3a07d8vq))
## New highlights added September 5, 2023 at 4:52 PM
- Historically, every new technology that matters, from electric lighting to automobiles to radio to the Internet, has sparked a *moral panic* – a [social contagion](https://en.wikipedia.org/wiki/Moral_panic) that convinces people the new technology is going to destroy the world, or society, or both. The fine folks at [Pessimists Archive](https://pessimistsarchive.org/) have documented these technology-driven moral panics over the decades; their history makes the pattern vividly clear. It turns out this present panic is [not even the first for AI](https://newsletter.pessimistsarchive.org/p/the-original-ai-doomer-dr-norbert). ([View Highlight](https://read.readwise.io/read/01h9jwch1qx173g1fnre9tdv9f))
- Economists have observed a [longstanding pattern](https://en.wikipedia.org/wiki/Bootleggers_and_Baptists) in reform movements of this kind. The actors within movements like these fall into two categories – “Baptists” and “Bootleggers” – drawing on the historical example of the [prohibition of alcohol in the United States in the 1920’s](https://en.wikipedia.org/wiki/Prohibition_in_the_United_States):
  • “Baptists” are the true believer social reformers who legitimately feel – deeply and emotionally, if not rationally – that new restrictions, regulations, and laws are required to prevent societal disaster. For alcohol prohibition, these actors were often literally [devout Christians](https://en.wikipedia.org/wiki/Carrie_Nation) who felt that alcohol was destroying the moral fabric of society. For AI risk, these actors are true believers that AI presents one or another existential risks – strap them to a polygraph, they really mean it.
  • “Bootleggers” are the self-interested opportunists who stand to financially profit by the imposition of new restrictions, regulations, and laws that insulate them from competitors. For alcohol prohibition, these were the [literal bootleggers](https://en.wikipedia.org/wiki/Category:Bootleggers) who made a fortune selling illicit alcohol to Americans when legitimate alcohol sales were banned. For AI risk, these are CEOs who stand to make more money if regulatory barriers are erected that form a cartel of government-blessed AI vendors protected from new startup and open source competition – the software version of “too big to fail” banks. ([View Highlight](https://read.readwise.io/read/01h9jwggcc5rqrqkpz1barj6ep))
- A cynic would suggest that some of the apparent Baptists are also Bootleggers – specifically the ones paid to attack AI by their [universities](https://hai.stanford.edu/news/new-report-assesses-progress-and-risks-artificial-intelligence), [think tanks](https://www.brookings.edu/blog/up-front/2023/05/22/the-us-government-should-regulate-ai/), [activist groups](https://www.humanetech.com/podcast/the-ai-dilemma), and [media outlets](https://www.washingtonpost.com/opinions/2023/05/26/ai-regulation-congress-risk/). If you are [paid a salary](https://projects.propublica.org/nonprofits/organizations/582565917) or [receive grants](https://www.fhi.ox.ac.uk/grant-announcement/) to foster AI panic…you are probably a Bootlegger. ([View Highlight](https://read.readwise.io/read/01h9jwh67gv85v2t1dw5xdhyaz))
- The problem with the Bootleggers is that they *win*. The Baptists are naive ideologues, the Bootleggers are cynical operators, and so the result of reform movements like these is often that the Bootleggers get what they want – regulatory capture, insulation from competition, the formation of a cartel – and the Baptists are left wondering where their drive for social improvement went so wrong. ([View Highlight](https://read.readwise.io/read/01h9jwhgfxdd0c0e71r1ebeytn))
- We just lived through a stunning example of this – banking reform after the 2008 global financial crisis. The Baptists told us that we needed new laws and regulations to break up the “too big to fail” banks to prevent such a crisis from ever happening again. So Congress passed the Dodd-Frank Act of 2010, which was marketed as satisfying the Baptists’ goal, but in reality was coopted by the Bootleggers – the big banks. The result is that the same banks that were “too big to fail” in 2008 are *much, much larger* now. ([View Highlight](https://read.readwise.io/read/01h9jwj2m6q9qymazbhhvv6a90))
- So in practice, even when the Baptists are genuine – and even when the Baptists are *right* – they are used as cover by manipulative and venal Bootleggers to benefit themselves. ([View Highlight](https://read.readwise.io/read/01h9jwj7638se8dqqgf8f9ccwa))
- The fear that technology of our own creation will rise up and destroy us is deeply coded into our culture. The Greeks expressed this fear in the Prometheus Myth – Prometheus brought the destructive power of fire, and more generally technology (“techne”), to man, for which Prometheus was condemned to perpetual torture by the gods. Later, Mary Shelley gave us moderns our own version of this myth in her novel *Frankenstein, or, The Modern Prometheus*, in which we develop the technology for eternal life, which then rises up and seeks to destroy us. And of course, no AI panic newspaper story is complete without a still image of a gleaming red-eyed killer robot from James Cameron’s *Terminator* films. ([View Highlight](https://read.readwise.io/read/01h9jx7x78zty0cemg6vznw6wb))
- The presumed evolutionary purpose of this mythology is to motivate us to seriously consider potential risks of new technologies – fire, after all, can indeed be used to burn down entire cities. But just as fire was also the foundation of modern civilization as used to keep us warm and safe in a cold and hostile world, this mythology ignores the far greater upside of most – all? – new technologies, and in practice inflames destructive emotion rather than reasoned analysis. Just because premodern man freaked out like this doesn’t mean we have to; we can apply rationality instead. ([View Highlight](https://read.readwise.io/read/01h9jx8yk8neyfqnfgghff9b2n))
## New highlights added September 5, 2023 at 5:52 PM
- AI is not a living being that has been primed by billions of years of evolution to participate in the battle for the survival of the fittest, as animals are, and as we are. It is math – code – computers, built by people, owned by people, used by people, controlled by people. The idea that it will at some point develop a mind of its own and decide that it has motivations that lead it to try to kill us is a superstitious handwave. ([View Highlight](https://read.readwise.io/read/01h9jxa4rrbvq040mmjq5dtb0d))
- In short, AI doesn’t *want*, it doesn’t have *goals*, it doesn’t want to *kill you*, because it’s not *alive*. And AI is a machine – is not going to come alive any more than your toaster will. ([View Highlight](https://read.readwise.io/read/01h9jxagnnbc2g9w8h34nb4w0j))
- Now, obviously, there are true believers in killer AI – Baptists – who are gaining a suddenly stratospheric amount of media coverage for their terrifying warnings, some of whom claim to have been studying the topic for decades and say they are now scared out of their minds by what they have learned. Some of these true believers are even [actual](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) [innovators](https://www.bbc.com/news/technology-65760449) of the technology. These actors are arguing for a variety of bizarre and extreme restrictions on AI ranging from a [ban on AI development](https://www.nytimes.com/2023/03/29/technology/ai-artificial-intelligence-musk-risks.html), all the way up to [military airstrikes on datacenters](https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/) and [nuclear war](https://mishtalk.com/economics/to-stop-ai-lunatics-are-willing-to-risk-a-global-nuclear-war). They argue that because people like me cannot rule out future catastrophic consequences of AI, that we must assume a [precautionary](https://en.wikipedia.org/wiki/Precautionary_principle) stance that may require large amounts of physical violence and death in order to prevent potential existential risk. ([View Highlight](https://read.readwise.io/read/01h9jxbjaf6e6tah77canf0qgr))
- John Von Neumann responded to Robert Oppenheimer’s famous hand-wringing about his role creating nuclear weapons – which helped end World War II and prevent World War III – with, “Some people confess guilt to claim credit for the sin.” What is the most dramatic way one can claim credit for the importance of one’s work without sounding overtly boastful? This explains the mismatch between the words and actions of the Baptists who are actually building and funding AI – watch their actions, not their words. ([View Highlight](https://read.readwise.io/read/01h9jxdd4k8cw8teab9rqxjf7k))
- some of the Baptists are actually Bootleggers. There is a whole profession of “AI safety expert”, “AI ethicist”, “AI risk researcher”. They are paid to be doomers, and their statements should be processed appropriately. ([View Highlight](https://read.readwise.io/read/01h9jxfcambd2n8gh3w7jmprzb))
- “AI risk” has [developed](https://studio.ribbonfarm.com/p/the-priest-in-the-arena) [into](https://twitter.com/QiaochuYuan/status/1542767419394912256) a [cult](https://www.lesswrong.com/posts/MnFqyPLqbiKL8nSR7/my-experience-at-and-around-miri-and-cfar-inspired-by-zoe), which has suddenly emerged into the daylight of global press attention and the public conversation. This cult has pulled in not just fringe characters, but also some actual industry experts and a not small number of wealthy donors – including, until recently, [Sam Bankman-Fried](https://fortune.com/2022/11/15/sam-bankman-fried-ftx-collapse-a-i-safety-research-effective-altruism-debacle/). And it’s developed a full panoply of cult behaviors and beliefs. ([View Highlight](https://read.readwise.io/read/01h9jxg64f7aknha7yyc51xvnv))
- This cult is why there are a set of AI risk doomers who [sound so extreme](https://www.youtube.com/watch?v=gA1sNLL6yg4) – it’s not that they actually have secret knowledge that make their extremism logical, it’s that they’ve whipped themselves into a frenzy and really are…extremely extreme. ([View Highlight](https://read.readwise.io/read/01h9jxgg41ngym17bg5kdf1eee))
- “Millenarianism is the belief by a group or movement [AI risk doomers] in a coming fundamental transformation of society [the arrival of AI], after which all things will be changed [AI utopia, dystopia, and/or end of the world]. Only dramatic events [AI bans, airstrikes on datacenters, nuclear strikes on unregulated AI] are seen as able to change the world [prevent AI] and the change is anticipated to be brought about, or survived, by a group of the devout and dedicated. In most millenarian scenarios, the disaster or battle to come [AI apocalypse, or its prevention] will be followed by a new, purified world [AI bans] in which the believers will be rewarded [or at least acknowledged to have been correct all along].” ([View Highlight](https://read.readwise.io/read/01h9jxk9w30t4bty8zpke9qfkk))
- The second widely mooted AI risk is that AI will ruin our society, by generating outputs that will be so “harmful”, to use the nomenclature of this kind of doomer, as to cause profound damage to humanity, even if we’re not literally killed. ([View Highlight](https://read.readwise.io/read/01h9jxmwg57tm6kdz4b6xa5389))
- Short version: If the murder robots don’t get us, the hate speech and misinformation will. ([View Highlight](https://read.readwise.io/read/01h9jxn0318xxrkxevezv69x71))
- the terminology of AI risk recently changed from “AI safety” – the term used by people who are worried that AI would literally kill us – to “AI alignment” – the term used by people who are worried about societal “harms”. The original AI safety people are frustrated by this shift, although they don’t know how to put it back in the box ([View Highlight](https://read.readwise.io/read/01h9jxnx9n4b02k6mkf2a8ng99))
- The tipoff to the nature of the AI societal risk claim is its own term, “AI alignment”. [Alignment with what?](https://futureoflife.org/ai/align-artificial-intelligence-with-human-values/) Human values. [Whose human values?](https://arxiv.org/pdf/2301.03740.pdf) Ah, that’s where things get tricky. ([View Highlight](https://read.readwise.io/read/01h9jxppz488svh7c3brmwngq0))
- s it happens, I have had a front row seat to an analogous situation – the social media “trust and safety” wars. As is [now](https://en.wikipedia.org/wiki/Twitter_Files) [obvious](https://twitter.com/AGAndrewBailey/status/1664286859344719872), social media services have been under massive pressure from governments and activists to ban, restrict, censor, and otherwise suppress a wide range of content for many years. And the same concerns of “hate speech” (and its mathematical counterpart, “algorithmic bias”) and “misinformation” are being [directly transferred](https://cyber.fsi.stanford.edu/io/news/forecasting-potential-misuses-language-models-disinformation-campaigns-and-how-reduce-risk) from the social media context to the new frontier of “AI alignment”. ([View Highlight](https://read.readwise.io/read/01h9jxq6cvemktr5e5gmd0dkcf))
- there is no absolutist free speech position. First, every country, including the United States, [makes at least some content illegal](https://en.wikipedia.org/wiki/United_States_free_speech_exceptions). Second, there are certain kinds of content, like child pornography and incitements to real world violence, that are nearly universally agreed to be off limits – legal or not – by virtually every society. So any technological platform that facilitates or generates content – speech – is going to have *some* restrictions. ([View Highlight](https://read.readwise.io/read/01h9jxr3476f38c0sgw3mv33hh))
- On the other hand, the slippery slope is not a fallacy, it’s an inevitability. Once a framework for restricting even egregiously terrible content is in place – for example, for hate speech, a specific hurtful word, or for misinformation, obviously false claims like “[the Pope is dead](https://www.americamagazine.org/politics-society/2022/07/12/pope-benedict-dead-fake-news-243347)” – a shockingly broad range of [government agencies](https://judiciary.house.gov/sites/evo-subsites/republicans-judiciary.house.gov/files/evo-media-document/2023-04-28-jdj-to-rubin-gec-subpoena-cover-letter.pdf) and [activist pressure groups](https://en.wikipedia.org/wiki/Color_of_Change) and [nongovernmental entities](https://cyber.fsi.stanford.edu/io) will kick into gear and demand ever greater levels of censorship and suppression of whatever speech they view as threatening to society and/or their own personal preferences. They will do this up to and including in ways that are nakedly [felony](https://www.law.cornell.edu/uscode/text/18/241) [crimes](https://www.law.cornell.edu/uscode/text/18/242). This cycle in practice can run apparently forever, with the enthusiastic support of authoritarian hall monitors installed throughout our elite power structures. This has been cascading for a decade in social media and with only [certain](https://twitter.com/home) [exceptions](https://substack.com/) continues to get more fervent all the time. ([View Highlight](https://read.readwise.io/read/01h9jxs59t8aaa54tt4y0q4chx))
- . Its proponents claim the wisdom to engineer AI-generated speech and thought that are good for society, and to ban AI-generated speech and thoughts that are bad for society. Its *opponents* claim that the thought police are breathtakingly arrogant and presumptuous ([View Highlight](https://read.readwise.io/read/01h9jxw2dgnqcw3a5se7hze917))
- As the proponents of both “trust and safety” and “AI alignment” are clustered into the very narrow slice of the global population that characterizes the American coastal elites – which includes many of the people who work in and write about the tech industry ([View Highlight](https://read.readwise.io/read/01h9jxx41z25x0rmbvxfqrp1jr))
- The fear of job loss due variously to mechanization, automation, computerization, or AI has been a recurring panic for hundreds of years, since the original onset of machinery such as the [mechanical loom](https://en.wikipedia.org/wiki/Luddite). Even though every new major technology has led to more jobs at higher wages throughout history, each wave of this panic is accompanied by claims that “this time is different” – *this* is the time it will finally happen, *this* is the technology that will finally deliver the hammer blow to human labor. And yet, it never happens. ([View Highlight](https://read.readwise.io/read/01h9jy01xpzq56sqwzh79ryjd6))
- we *finally* have the technology that’s going to take all the jobs and render human workers superfluous – *real* AI. Surely *this time* history won’t repeat, and AI will cause mass unemployment – and not rapid economic, job, and wage growth – right?
  No, that’s not going to happen – and in fact AI, if allowed to develop and proliferate throughout the economy, may cause the most dramatic and sustained economic boom of all time, with correspondingly record job and wage growth – the exact opposite of the fear. And here’s why. ([View Highlight](https://read.readwise.io/read/01h9jy1pwxrprmj9g8208rz0ta))
- [Lump Of Labor Fallacy](https://en.wikipedia.org/wiki/Lump_of_labour_fallacy). This fallacy is the incorrect notion that there is a fixed amount of labor to be done in the economy at any given time, and either machines do it or people do it – and if machines do it, there will be no work for people to do. ([View Highlight](https://read.readwise.io/read/01h9jy22zxj4rxkn5qxwqg4z63))
- The Lump Of Labor Fallacy flows naturally from naive intuition, but naive intuition here is wrong. When technology is applied to production, we get [*productivity growth*](https://en.wikipedia.org/wiki/Productivity) – an increase in output generated by a reduction in inputs. The result is *lower prices* for goods and services. As prices for goods and services fall, we pay less for them, meaning that we now have *extra spending power* with which to buy *other things*. This *increases demand* in the economy, which drives the creation of *new production* – including new products and new industries – which then creates new jobs for the people who were replaced by machines in prior jobs. The result is a larger economy with higher material prosperity, more industries, more products, and more jobs. ([View Highlight](https://read.readwise.io/read/01h9jy2wdnw2c0nsavk5cfc92s))
- e also get higher wages. This is because, at the level of the individual worker, the marketplace sets compensation as a function of the [*marginal productivity of the worker*](https://en.wikipedia.org/wiki/Marginal_revenue_productivity_theory_of_wages). A worker in a technology-infused business will be more productive than a worker in a traditional business. The employer will either pay that worker more money as he is now more productive, or another employer will, purely out of self interest. The result is that technology introduced into an industry generally not only increases the number of jobs in the industry but also raises wages. ([View Highlight](https://read.readwise.io/read/01h9jy3fkw821321ab2sqggn1q))
- technology empowers people to be more productive. This causes the prices for existing goods and services to fall, and for wages to rise. This in turn causes economic growth and job growth, while motivating the creation of new jobs and new industries. If a market economy is allowed to function normally and if technology is allowed to be introduced freely, this is a perpetual upward cycle that never ends. For, as Milton Friedman observed, “Human wants and needs are endless” – we always want more than we have. A technology-infused market economy is the way we get closer to delivering everything everyone could conceivably want, but never all the way there. [And that is why technology doesn’t destroy jobs and never will.](https://www.aeaweb.org/articles?id=10.1257/jep.29.3.3) ([View Highlight](https://read.readwise.io/read/01h9jy49zxk396grp0b8h80yzr))
- using the principles I described above, think of what it would mean for literally all existing human labor to be replaced by machines.
  It would mean a takeoff rate of economic productivity growth that would be absolutely stratospheric, far beyond any historical precedent. Prices of existing goods and services would drop across the board to virtually zero. Consumer welfare would skyrocket. Consumer spending power would skyrocket. New demand in the economy would explode. Entrepreneurs would create dizzying arrays of new industries, products, and services, and employ as many people *and* AI as they could as fast as possible to meet all the new demand. ([View Highlight](https://read.readwise.io/read/01h9jy6dx6rgqrsb0tdnzvsed6))
- e concern about AI taking jobs segues directly into the next claimed AI risk, which is, OK, Marc, suppose AI *does* take all the jobs, either for bad or for good. Won’t that result in massive and crippling wealth inequality, as the owners of AI reap all the economic rewards and regular people get nothing?
  As it happens, this was a central claim of Marxism, that the owners of the means of production – the bourgeoisie – would inevitably steal all societal wealth from the people who do the actual work – the proletariat. This is another fallacy that simply will not die no matter how often it’s disproved by reality. ([View Highlight](https://read.readwise.io/read/01h9jy7gnqaqaf9asxb175hq04))
- The flaw in this theory is that, as the owner of a piece of technology, it’s not in your own interest to keep it to yourself – in fact the opposite, it’s in your own interest to sell it to as many customers as possible. The largest market in the world for any product is the entire world, all 8 billion of us. And so in reality, every new technology – even ones that start by selling to the rarefied air of high-paying big companies or wealthy consumers – rapidly proliferates until it’s in the hands of the largest possible mass market, ultimately everyone on the planet. ([View Highlight](https://read.readwise.io/read/01h9jy82x5yrt0498aajs7nx4h))
- everyone gets the thing – as we saw in the past with not just cars but also electricity, radio, computers, the Internet, mobile phones, and search engines. The makers of such technologies are highly motivated to drive down their prices until everyone on the planet can afford them. This is precisely what is already happening in AI – it’s why you can use state of the art generative AI not just at low cost but even *for free* today in the form of Microsoft Bing and Google Bard – and it is what will continue to happen. Not because such vendors are foolish or generous but precisely because they are greedy – they want to maximize the size of their market, which maximizes their profits. ([View Highlight](https://read.readwise.io/read/01h9jy99v37cmz8gg753qn69fd))
