---
author: [[Philipp Schmid]]
title: "Fine-Tune BERT for Text Classification on AWS Trainium"
tags: 
- articles
- literature-note
---
# Fine-Tune BERT for Text Classification on AWS Trainium

![rw-book-cover](https://www.philschmid.de/static/blog/getting-started-trainium/thumbnail.jpg)

## Metadata
- Author: [[Philipp Schmid]]
- Full Title: Fine-Tune BERT for Text Classification on AWS Trainium
- Category: #articles
- URL: https://www.philschmid.de/getting-started-trainium

## Highlights
- rainium is the successor of [AWS Inferentia](https://aws.amazon.com/ec2/instance-types/inf1/?nc1=h_ls) focused on high-performance training workloads claiming up to 50% cost-to-train savings over comparable GPU-based instances.
  Trainium has been optimized for training natural language processing, computer vision, and recommender models used. The accelerator supports a wide range of data types, including FP32, TF32, BF16, FP16, UINT8, and configurable FP8. ([View Highlight](https://read.readwise.io/read/01h5q3c77kd0bnv2515h8aq107))
## New highlights added July 22, 2023 at 12:53 PM
- This tutorial will help you to get started with [AWS Trainium](https://aws.amazon.com/machine-learning/trainium/?nc1=h_ls) and Hugging Face Transformers. It will cover how to set up a Trainium instance on AWS, load & fine-tune a transformers model for text-classification ([View Highlight](https://read.readwise.io/read/01h5yhfrw1ns20g0hq454k58vm))
- Trainium is the successor of [AWS Inferentia](https://aws.amazon.com/ec2/instance-types/inf1/?nc1=h_ls) focused on high-performance training workloads claiming up to 50% cost-to-train savings over comparable GPU-based instances. ([View Highlight](https://read.readwise.io/read/01h5yhg5a3vg598afqjh7gd98c))
