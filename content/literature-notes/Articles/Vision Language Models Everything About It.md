---
author: [[Zamal]]
title: "Vision Language Models: Everything About It"
date: 2024-09-24
tags: 
- articles
- literature-note
---
![rw-book-cover](https://miro.medium.com/v2/resize:fit:902/1*9uuWHtogKdDB_eOEEhzp7w.png)

## Metadata
- Author: [[Zamal]]
- Full Title: Vision Language Models: Everything About It
- URL: https://medium.com/@zamalbabar/vision-language-models-everything-about-it-e642cb66055a

## Highlights
- 1. **Image Encoder**: Converts the image into a numerical format.
  2. **Multimodal Projector**: Aligns the image and text representations.
  3. **Text Decoder**: Generates text based on the combined image-text input.
  For example, the LLaVA model uses a CLIP image encoder, a multimodal projector, and a Vicuna text decoder. The model learns to align images and text by comparing its output to ground truth captions. ([View Highlight](https://read.readwise.io/read/01j8hy5x7pnr0hmj3pka5g91m7))
- With TRL’s SFTTrainer, you can customize a VLM for your specific needs. ([View Highlight](https://read.readwise.io/read/01j8hy6c2wq8zmr4ph9pq92sdh))
- VLM Superpowers
  VLMs can do a lot of nifty things:
  • **Image Captioning**: Describe what’s happening in a picture.
  • **Visual Question Answering**: Answer questions about images.
  • **Image Recognition**: Identify objects or scenes in images based on instructions.
  • **Document Understanding**: Make sense of text within images, like scanned documents.
  • **Spatial Understanding**: Detect and segment objects in an image, even telling their positions. ([View Highlight](https://read.readwise.io/read/01j8hy5382tjhtevrjwn3t0rqx))
- Choosing a VLM can feel like picking a new gadget. Here’s how to make it easier:
  1. **Vision Arena**: Think of it as a friendly competition where users submit images and prompts, and then vote on the best model output. The leaderboard here is based purely on human preferences.
  2. **Open VLM Leaderboard**: Models are ranked based on various metrics. You can filter models by size, license type, and performance on specific tasks.
  3. **VLMEvalKit**: A toolkit to benchmark VLMs, powering the Open VLM Leaderboard.
  These resources help you find the perfect model for your needs, whether it’s chatting about images or performing complex visual tasks. ([View Highlight](https://read.readwise.io/read/01j8hy5dvyqt6jc5bahkar8tss))
