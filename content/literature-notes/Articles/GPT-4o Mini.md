---
author: [[Simon Willison's Weblog]]
title: "GPT-4o Mini"
date: 2024-07-19
tags: 
- articles
- literature-note
---
![rw-book-cover](https://simonwillison.net/favicon.ico)

## Metadata
- Author: [[Simon Willison's Weblog]]
- Full Title: GPT-4o Mini
- URL: https://simonwillison.net/2024/Jul/18/gpt-4o-mini/#atom-everything

## Highlights
- GPT-4o mini is *exactly* what I've been looking forward to.
  It supports 128,000 input tokens (both images and text) and an impressive 16,000 output tokens. Most other models are still 4,000, and Claude 3.5 Sonnet got an upgrade to 8,000 [just a few days ago](https://simonwillison.net/2024/Jul/15/alex-albert/). This makes it a good fit for translation and transformation tasks where the expected output more closely matches the size of the input. ([View Highlight](https://read.readwise.io/read/01j33rk13pcnm260mcdv4wwh84))
- GPT-4o mini is 15 cents per millions input tokens and 60 cents per million output tokens - a 60% discount on GPT-3.5, and cheaper than Claude 3 Haiku's 25c/125c and Gemini 1.5 Flash's 35c/70c. Or you can use the OpenAI [batch API](https://platform.openai.com/docs/guides/batch) for 50% off again, in exchange for up-to-24-hours of delay in getting the results. ([View Highlight](https://read.readwise.io/read/01j33rkhvcw48670mhxepqssjp))
- OpenAI point out that "the cost per token of GPT-4o mini has dropped by 99% since text-davinci-003, a less capable model introduced in 2022." ([View Highlight](https://read.readwise.io/read/01j33rkpep67vgqdg3m1923qmn))
- GPT-4o mini in the API is the first model to apply our [instruction hierarchy(opens in a new window)](https://arxiv.org/abs/2404.13208) method, which helps to improve the model's ability to resist jailbreaks, prompt injections, and system prompt extractions. ([View Highlight](https://read.readwise.io/read/01j33rm1cfwmj0rvzgee3hsg55))
