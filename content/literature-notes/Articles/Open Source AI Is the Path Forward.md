---
author: [[Mark Zuckerberg]]
title: "Open Source AI Is the Path Forward"
date: 2024-07-25
tags: 
- articles
- literature-note
---
![rw-book-cover](https://about.fb.com/wp-content/uploads/2024/07/MZ-Open-Letter-AI_Social-Share.jpg?w=1200)

## Metadata
- Author: [[Mark Zuckerberg]]
- Full Title: Open Source AI Is the Path Forward
- URL: https://about.fb.com/news/2024/07/open-source-ai-is-the-path-forward/

## Highlights
- In the early days of high-performance computing, the major tech companies of the day each invested heavily in developing their own closed source versions of Unix. It was hard to imagine at the time that any other approach could develop such advanced software. Eventually though, open source Linux gained popularity – initially because it allowed developers to modify its code however they wanted and was more affordable, and over time because it became more advanced, more secure, and had a broader ecosystem supporting more capabilities than any closed Unix. Today, Linux is the industry standard foundation for both cloud computing and the operating systems that run most mobile devices – and we all benefit from superior products because of it. ([View Highlight](https://read.readwise.io/read/01j3m8esexk9768zr39agvwy87))
- I believe that AI will develop in a similar way. Today, several tech companies are developing leading closed models. But open source is quickly closing the gap. Last year, Llama 2 was only comparable to an older generation of models behind the frontier. This year, Llama 3 is competitive with the most advanced models and leading in some areas. Starting next year, we expect future Llama models to become the most advanced in the industry. But even before that, Llama is already leading on openness, modifiability, and cost efficiency. ([View Highlight](https://read.readwise.io/read/01j3m8f6ccp4pa29gp94c1rsm9))
- **We need to train, fine-tune, and distill our own models.** Every organization has different needs that are best met with models of different sizes that are trained or fine-tuned with their specific data. On-device tasks and classification tasks require small models, while more complicated tasks require larger models. Now you’ll be able to take the most advanced Llama models, continue training them with your own data and then distill them down to a model of your optimal size – without us or anyone else seeing your data. ([View Highlight](https://read.readwise.io/read/01j3m8h05225n4fnng9ehmp57b))
- **We need to control our own destiny and not get locked into a closed vendor.** Many organizations don’t want to depend on models they cannot run and control themselves. They don’t want closed model providers to be able to change their model, alter their terms of use, or even stop serving them entirely. They also don’t want to get locked into a single cloud that has exclusive rights to a model. Open source enables a broad ecosystem of companies with compatible toolchains that you can move between easily. ([View Highlight](https://read.readwise.io/read/01j3m8hfm6c3g12jv99fvhhpzv))
- **We need to protect our data.** Many organizations handle sensitive data that they need to secure and can’t send to closed models over cloud APIs. Other organizations simply don’t trust the closed model providers with their data. Open source addresses these issues by enabling you to run the models wherever you want. It is well-accepted that open source software tends to be more secure because it is developed more transparently. ([View Highlight](https://read.readwise.io/read/01j3m8hxyy8njk7kpzrwswmcyh))
- **We need a model that is efficient and affordable to run.** Developers can run inference on Llama 3.1 405B on their own infra at roughly 50% the cost of using closed models like GPT-4o, for both user-facing and offline inference tasks. ([View Highlight](https://read.readwise.io/read/01j3m8jf89smv0cfb6z85bf34z))
- **We want to invest in the ecosystem that’s going to be the standard for the long term.** Lots of people see that open source is advancing at a faster rate than closed models, and they want to build their systems on the architecture that will give them the greatest advantage long term. ([View Highlight](https://read.readwise.io/read/01j3m8jneh6ch7tstd93t7svjc))
- Meta’s business model is about building the best experiences and services for people. To do this, we must ensure that we always have access to the best technology, and that we’re not locking into a competitor’s closed ecosystem where they can restrict what we build. ([View Highlight](https://read.readwise.io/read/01j3m8kbnp8xqn6empe4jrz8w4))
- One of my formative experiences has been building our services constrained by what Apple will let us build on their platforms. Between the way they tax developers, the arbitrary rules they apply, and all the product innovations they block from shipping, it’s clear that Meta and many other companies would be freed up to build much better services for people if we could build the best versions of our products and competitors were not able to constrain what we could build. On a philosophical level, this is a major reason why I believe so strongly in building open ecosystems in AI and AR/VR for the next generation of computing. ([View Highlight](https://read.readwise.io/read/01j3m8kr9yqyea0vhvzcp6f4mv))
- First, to ensure that we have access to the best technology and aren’t locked into a closed ecosystem over the long term, Llama needs to develop into a full ecosystem of tools, efficiency improvements, silicon optimizations, and other integrations. If we were the only company using Llama, this ecosystem wouldn’t develop and we’d fare no better than the closed variants of Unix. ([View Highlight](https://read.readwise.io/read/01j3m8mfev9a4e9wyayr5ew6y9))
- Second, I expect AI development will continue to be very competitive, which means that open sourcing any given model isn’t giving away a massive advantage over the next best models at that point in time. The path for Llama to become the industry standard is by being consistently competitive, efficient, and open generation after generation. ([View Highlight](https://read.readwise.io/read/01j3m8mqxp835d6kcczm2xyq06))
- Third, a key difference between Meta and closed model providers is that selling access to AI models isn’t our business model. That means openly releasing Llama doesn’t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers. (This is one reason several closed providers consistently lobby governments against open source.) ([View Highlight](https://read.readwise.io/read/01j3m8na612q03syjqt3qs3z52))
- Finally, Meta has a long history of open source projects and successes. We’ve saved billions of dollars by releasing our server, network, and data center designs with Open Compute Project and having supply chains standardize on our designs. We benefited from the ecosystem’s innovations by open sourcing leading tools like PyTorch, React, and many more tools. This approach has consistently worked for us when we stick with it over the long term. ([View Highlight](https://read.readwise.io/read/01j3m8nwbn8173wjnsvjy4421p))
- I believe that open source is necessary for a positive AI future. AI has more potential than any other modern technology to increase human productivity, creativity, and quality of life – and to accelerate economic growth while unlocking progress in medical and scientific research. Open source will ensure that more people around the world have access to the benefits and opportunities of AI, that power isn’t concentrated in the hands of a small number of companies, and that the technology can be deployed more evenly and safely across society. ([View Highlight](https://read.readwise.io/read/01j3m8pc0epxkges9nt3n8gp4j))
- There is an ongoing debate about the safety of open source AI models, and my view is that open source AI will be safer than the alternatives. I think governments will conclude it’s in their interest to support open source because it will make the world more prosperous and safer. ([View Highlight](https://read.readwise.io/read/01j3m8phnmq9gtq5rpr9y03sa1))
- My framework for understanding safety is that we need to protect against two categories of harm: unintentional and intentional. Unintentional harm is when an AI system may cause harm even when it was not the intent of those running it to do so. For example, modern AI models may inadvertently give bad health advice. Or, in more futuristic scenarios, some worry that models may unintentionally self-replicate or hyper-optimize goals to the detriment of humanity. Intentional harm is when a bad actor uses an AI model with the goal of causing harm. ([View Highlight](https://read.readwise.io/read/01j3m8ptv2xc7hvr3sd716a0fm))
- It’s worth noting that unintentional harm covers the majority of concerns people have around AI – ranging from what influence AI systems will have on the billions of people who will use them to most of the truly catastrophic science fiction scenarios for humanity. On this front, open source should be significantly safer since the systems are more transparent and can be widely scrutinized. Historically, open source software has been more secure for this reason. Similarly, using Llama with its safety systems like Llama Guard will likely be safer and more secure than closed models. For this reason, most conversations around open source AI safety focus on intentional harm. ([View Highlight](https://read.readwise.io/read/01j3m8qdb6aftfv9yz5t9wqx1m))
- Our safety process includes rigorous testing and red-teaming to assess whether our models are capable of meaningful harm, with the goal of mitigating risks before release. Since the models are open, anyone is capable of testing for themselves as well. We must keep in mind that these models are trained by information that’s already on the internet, so the starting point when considering harm should be whether a model can facilitate more harm than information that can quickly be retrieved from Google or other search results. ([View Highlight](https://read.readwise.io/read/01j3m8qp1y3tmnx6m312bv5m7f))
- At some point in the future, individual bad actors may be able to use the intelligence of AI models to fabricate entirely new harms from the information available on the internet. At this point, the balance of power will be critical to AI safety. I think it will be better to live in a world where AI is widely deployed so that larger actors can check the power of smaller bad actors. This is how we’ve managed security on our social networks – our more robust AI systems identify and stop threats from less sophisticated actors who often use smaller scale AI systems. More broadly, larger institutions deploying AI at scale will promote security and stability across society. As long as everyone has access to similar generations of models – which open source promotes – then governments and institutions with more compute resources will be able to check bad actors with less compute. ([View Highlight](https://read.readwise.io/read/01j3m8r95fjbsg5sv3s09h5029))
- The next question is how the US and democratic nations should handle the threat of states with massive resources like China. The United States’ advantage is decentralized and open innovation. Some people argue that we must close our models to prevent China from gaining access to them, but my view is that this will not work and will only disadvantage the US and its allies. Our adversaries are great at espionage, stealing models that fit on a thumb drive is relatively easy, and most tech companies are far from operating in a way that would make this more difficult. It seems most likely that a world of only closed models results in a small number of big companies plus our geopolitical adversaries having access to leading models, while startups, universities, and small businesses miss out on opportunities. Plus, constraining American innovation to closed development increases the chance that we don’t lead at all. Instead, I think our best strategy is to build a robust open ecosystem and have our leading companies work closely with our government and allies to ensure they can best take advantage of the latest advances and achieve a sustainable first-mover advantage over the long term. ([View Highlight](https://read.readwise.io/read/01j3m8s1h0t45dqyn9xv7yxgh1))
- When you consider the opportunities ahead, remember that most of today’s leading tech companies and scientific research are built on open source software. The next generation of companies and research will use open source AI if we collectively invest in it. That includes startups just getting off the ground as well as people in universities and countries that may not have the resources to develop their own state-of-the-art AI from scratch. ([View Highlight](https://read.readwise.io/read/01j3m8smkajezgpyjt5fa4hb5c))
