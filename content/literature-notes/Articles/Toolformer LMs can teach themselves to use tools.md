---
author: [[arxiv.org]]
title: "Toolformer: LMs can teach themselves to use tools"
tags: 
- articles
- literature-note
---
# Toolformer: LMs can teach themselves to use tools

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png)

## Metadata
- Author: [[arxiv.org]]
- Full Title: Toolformer: LMs can teach themselves to use tools
- Category: #articles
- URL: https://arxiv.org/pdf/2302.04761v1.pdf

## Highlights
- Toolformer: Language Models Can Teach Themselves to Use Tools ([View Highlight](https://read.readwise.io/read/01gs56zjwr4x67myv3mm7x66k9))
- we show that
  LMs can teach themselves to use external tools
  via simple APIs ([View Highlight](https://read.readwise.io/read/01gs55kwd9kr4vas1cdfwhs26p))
- Toolformer, a model
  trained to decide which APIs to call, when to
  call them, what arguments to pass, and how to
  best incorporate the results into future token
  prediction. ([View Highlight](https://read.readwise.io/read/01gs55m3606zentxqprj1gp7b9))
- . This is done in a self-supervised
  way, requiring nothing more than a handful of
  demonstrations for each API. We incorporate
  a range of tools, including a calculator, a Q&A
  system, a search engine, a translation system,
  and a calendar. Toolformer achieves substan-
  tially improved zero-shot performance across
  a variety of downstream tasks, often competi-
  tive with much larger models, without sacriﬁc-
  ing its core language modeling abilities. ([View Highlight](https://read.readwise.io/read/01gs55mpwycfyp44pg4gjc83aj))
- , existing ap-
  proaches either rely on large amounts of human
  annotations (Komeili et al., 2022; Thoppilan et al.,
  2022) or limit tool use to task-speciﬁc settings only
  (e.g., Gao et al., 2022; Parisi et al., 2022), ([View Highlight](https://read.readwise.io/read/01gs55pa95z2zj3cpb168ekntk))
- limitations include an inability to access
  up-to-date information on recent events ([View Highlight](https://read.readwise.io/read/01gs55n8qrc91eer80fc74w9sj))
- tendency to hallucinate
  facts ( ([View Highlight](https://read.readwise.io/read/01gs55nb745dh6nn5gfg88k9pb))
- difﬁcul-
  ties in understanding low-resource languages ([View Highlight](https://read.readwise.io/read/01gs55ndxva4tqsbw3e9qt4b5y))
- a lack of mathematical skills to per-
  form precise calculations ([View Highlight](https://read.readwise.io/read/01gs55ngp7a4x9j123mfx7h8rt))
- ) and an
  unawareness of the progression of time ([View Highlight](https://read.readwise.io/read/01gs55nk10e7szqrk6ybnmzfbk))
- The use of tools should be learned in a
  self-supervised way without requiring large
  amounts of human annotations. ([View Highlight](https://read.readwise.io/read/01gs55qqchkt3x8ygg1xj5r9p4))
- The LM should not lose any of its generality
  and should be able to decide for itself when
  and how to use which tool. ([View Highlight](https://read.readwise.io/read/01gs55qz0f2332adm14jdjtmq2))
- Our aim is to equip a language model M with the
  ability to use different tools by means of API calls.
  We require that inputs and outputs for each API
  can be represented as text sequences. This allows
  seamless insertion of API calls into any given text,
  using special tokens to mark the start and end of
  each such call. ([View Highlight](https://read.readwise.io/read/01gs56404drd4dzfjjj903bs74))
- using large LMs with in-
  context learning (Brown et al., 2020) to generate
  entire datasets from scratch ([View Highlight](https://read.readwise.io/read/01gs5627sh3h78gknv00rwshbc))
- Given just a handful of human-written examples
  of how an API can be used, we let a LM annotate
  a huge language modeling dataset with potential
  API calls. We then use a self-supervised loss to
  determine which of these API calls actually help
  the model in predicting future tokens. Finally, we
  ﬁnetune the LM itself on the API calls that it con-
  siders useful. ([View Highlight](https://read.readwise.io/read/01gs562vsakc7e6gm4tkvz0mh2))
- As a next step, we execute
  all API calls generated by M to obtain the corre-
  sponding results. How this is done depends entirely
  on the API itself – for example, it can involve call-
  ing another neural network, executing a Python
  script or using a retrieval system to perform search
  over a large corpus ([View Highlight](https://read.readwise.io/read/01gs5651fp2zbjy5s11ykxtfxy))
- For each API, we write a
  prompt P(x) that encourages the LM to anno-
  tate an example x = x1, . . . , xn with API calls. ([View Highlight](https://read.readwise.io/read/01gs564marcfgazs5b5j98hch2))
- Model Finetuning After sampling and ﬁltering
  calls for all APIs, we ﬁnally merge the remaining
  API calls and interleave them with the original
  inputs ([View Highlight](https://read.readwise.io/read/01gs565q74k49z4vr8xkm484jt))
- One such limi-
  tation is the inability of Toolformer to use tools in a
  chain (i.e., using the output of one tool as an input
  for another tool). This is due to the fact that API
  calls for each tool are generated independently; as a
  consequence, there are no examples of chained tool
  use in the ﬁnetuning dataset ([View Highlight](https://read.readwise.io/read/01gs567xjvjtxnzbkz1py92r28))
- we found models
  trained with Toolformer to often be sensitive to the
  exact wording of their input when deciding whether
  or not to call an API; this is perhaps unsurprising
  given that LMs are known to be very sensitive to
  the prompt they are provided with in both zero-
  and few-shot settings ([View Highlight](https://read.readwise.io/read/01gs568afsvrq89wf0zcx1c268))
---
author: [[arxiv.org]]
title: "Toolformer: LMs can teach themselves to use tools"
tags: 
- articles
- literature-note
---
# Toolformer: LMs can teach themselves to use tools

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png)

## Metadata
- Author: [[arxiv.org]]
- Full Title: Toolformer: LMs can teach themselves to use tools
- Category: #articles
- URL: https://arxiv.org/pdf/2302.04761v1.pdf

## Highlights
- Toolformer: Language Models Can Teach Themselves to Use Tools ([View Highlight](https://read.readwise.io/read/01gs56zjwr4x67myv3mm7x66k9))
- we show that
  LMs can teach themselves to use external tools
  via simple APIs ([View Highlight](https://read.readwise.io/read/01gs55kwd9kr4vas1cdfwhs26p))
- Toolformer, a model
  trained to decide which APIs to call, when to
  call them, what arguments to pass, and how to
  best incorporate the results into future token
  prediction. ([View Highlight](https://read.readwise.io/read/01gs55m3606zentxqprj1gp7b9))
- . This is done in a self-supervised
  way, requiring nothing more than a handful of
  demonstrations for each API. We incorporate
  a range of tools, including a calculator, a Q&A
  system, a search engine, a translation system,
  and a calendar. Toolformer achieves substan-
  tially improved zero-shot performance across
  a variety of downstream tasks, often competi-
  tive with much larger models, without sacriﬁc-
  ing its core language modeling abilities. ([View Highlight](https://read.readwise.io/read/01gs55mpwycfyp44pg4gjc83aj))
- , existing ap-
  proaches either rely on large amounts of human
  annotations (Komeili et al., 2022; Thoppilan et al.,
  2022) or limit tool use to task-speciﬁc settings only
  (e.g., Gao et al., 2022; Parisi et al., 2022), ([View Highlight](https://read.readwise.io/read/01gs55pa95z2zj3cpb168ekntk))
- limitations include an inability to access
  up-to-date information on recent events ([View Highlight](https://read.readwise.io/read/01gs55n8qrc91eer80fc74w9sj))
- tendency to hallucinate
  facts ( ([View Highlight](https://read.readwise.io/read/01gs55nb745dh6nn5gfg88k9pb))
- difﬁcul-
  ties in understanding low-resource languages ([View Highlight](https://read.readwise.io/read/01gs55ndxva4tqsbw3e9qt4b5y))
- a lack of mathematical skills to per-
  form precise calculations ([View Highlight](https://read.readwise.io/read/01gs55ngp7a4x9j123mfx7h8rt))
- ) and an
  unawareness of the progression of time ([View Highlight](https://read.readwise.io/read/01gs55nk10e7szqrk6ybnmzfbk))
- The use of tools should be learned in a
  self-supervised way without requiring large
  amounts of human annotations. ([View Highlight](https://read.readwise.io/read/01gs55qqchkt3x8ygg1xj5r9p4))
- The LM should not lose any of its generality
  and should be able to decide for itself when
  and how to use which tool. ([View Highlight](https://read.readwise.io/read/01gs55qz0f2332adm14jdjtmq2))
- Our aim is to equip a language model M with the
  ability to use different tools by means of API calls.
  We require that inputs and outputs for each API
  can be represented as text sequences. This allows
  seamless insertion of API calls into any given text,
  using special tokens to mark the start and end of
  each such call. ([View Highlight](https://read.readwise.io/read/01gs56404drd4dzfjjj903bs74))
- using large LMs with in-
  context learning (Brown et al., 2020) to generate
  entire datasets from scratch ([View Highlight](https://read.readwise.io/read/01gs5627sh3h78gknv00rwshbc))
- Given just a handful of human-written examples
  of how an API can be used, we let a LM annotate
  a huge language modeling dataset with potential
  API calls. We then use a self-supervised loss to
  determine which of these API calls actually help
  the model in predicting future tokens. Finally, we
  ﬁnetune the LM itself on the API calls that it con-
  siders useful. ([View Highlight](https://read.readwise.io/read/01gs562vsakc7e6gm4tkvz0mh2))
- As a next step, we execute
  all API calls generated by M to obtain the corre-
  sponding results. How this is done depends entirely
  on the API itself – for example, it can involve call-
  ing another neural network, executing a Python
  script or using a retrieval system to perform search
  over a large corpus ([View Highlight](https://read.readwise.io/read/01gs5651fp2zbjy5s11ykxtfxy))
- For each API, we write a
  prompt P(x) that encourages the LM to anno-
  tate an example x = x1, . . . , xn with API calls. ([View Highlight](https://read.readwise.io/read/01gs564marcfgazs5b5j98hch2))
- Model Finetuning After sampling and ﬁltering
  calls for all APIs, we ﬁnally merge the remaining
  API calls and interleave them with the original
  inputs ([View Highlight](https://read.readwise.io/read/01gs565q74k49z4vr8xkm484jt))
- One such limi-
  tation is the inability of Toolformer to use tools in a
  chain (i.e., using the output of one tool as an input
  for another tool). This is due to the fact that API
  calls for each tool are generated independently; as a
  consequence, there are no examples of chained tool
  use in the ﬁnetuning dataset ([View Highlight](https://read.readwise.io/read/01gs567xjvjtxnzbkz1py92r28))
- we found models
  trained with Toolformer to often be sensitive to the
  exact wording of their input when deciding whether
  or not to call an API; this is perhaps unsurprising
  given that LMs are known to be very sensitive to
  the prompt they are provided with in both zero-
  and few-shot settings ([View Highlight](https://read.readwise.io/read/01gs568afsvrq89wf0zcx1c268))
---
author: [[arxiv.org]]
title: "Toolformer: LMs can teach themselves to use tools"
tags: 
- articles
- literature-note
---
# Toolformer: LMs can teach themselves to use tools

![rw-book-cover](https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png)

## Metadata
- Author: [[arxiv.org]]
- Full Title: Toolformer: LMs can teach themselves to use tools
- Category: #articles
- URL: https://arxiv.org/pdf/2302.04761v1.pdf

## Highlights
- Toolformer: Language Models Can Teach Themselves to Use Tools ([View Highlight](https://read.readwise.io/read/01gs56zjwr4x67myv3mm7x66k9))
- we show that
  LMs can teach themselves to use external tools
  via simple APIs ([View Highlight](https://read.readwise.io/read/01gs55kwd9kr4vas1cdfwhs26p))
- Toolformer, a model
  trained to decide which APIs to call, when to
  call them, what arguments to pass, and how to
  best incorporate the results into future token
  prediction. ([View Highlight](https://read.readwise.io/read/01gs55m3606zentxqprj1gp7b9))
- . This is done in a self-supervised
  way, requiring nothing more than a handful of
  demonstrations for each API. We incorporate
  a range of tools, including a calculator, a Q&A
  system, a search engine, a translation system,
  and a calendar. Toolformer achieves substan-
  tially improved zero-shot performance across
  a variety of downstream tasks, often competi-
  tive with much larger models, without sacriﬁc-
  ing its core language modeling abilities. ([View Highlight](https://read.readwise.io/read/01gs55mpwycfyp44pg4gjc83aj))
- , existing ap-
  proaches either rely on large amounts of human
  annotations (Komeili et al., 2022; Thoppilan et al.,
  2022) or limit tool use to task-speciﬁc settings only
  (e.g., Gao et al., 2022; Parisi et al., 2022), ([View Highlight](https://read.readwise.io/read/01gs55pa95z2zj3cpb168ekntk))
- limitations include an inability to access
  up-to-date information on recent events ([View Highlight](https://read.readwise.io/read/01gs55n8qrc91eer80fc74w9sj))
- tendency to hallucinate
  facts ( ([View Highlight](https://read.readwise.io/read/01gs55nb745dh6nn5gfg88k9pb))
- difﬁcul-
  ties in understanding low-resource languages ([View Highlight](https://read.readwise.io/read/01gs55ndxva4tqsbw3e9qt4b5y))
- a lack of mathematical skills to per-
  form precise calculations ([View Highlight](https://read.readwise.io/read/01gs55ngp7a4x9j123mfx7h8rt))
- ) and an
  unawareness of the progression of time ([View Highlight](https://read.readwise.io/read/01gs55nk10e7szqrk6ybnmzfbk))
- The use of tools should be learned in a
  self-supervised way without requiring large
  amounts of human annotations. ([View Highlight](https://read.readwise.io/read/01gs55qqchkt3x8ygg1xj5r9p4))
- The LM should not lose any of its generality
  and should be able to decide for itself when
  and how to use which tool. ([View Highlight](https://read.readwise.io/read/01gs55qz0f2332adm14jdjtmq2))
- Our aim is to equip a language model M with the
  ability to use different tools by means of API calls.
  We require that inputs and outputs for each API
  can be represented as text sequences. This allows
  seamless insertion of API calls into any given text,
  using special tokens to mark the start and end of
  each such call. ([View Highlight](https://read.readwise.io/read/01gs56404drd4dzfjjj903bs74))
- using large LMs with in-
  context learning (Brown et al., 2020) to generate
  entire datasets from scratch ([View Highlight](https://read.readwise.io/read/01gs5627sh3h78gknv00rwshbc))
- Given just a handful of human-written examples
  of how an API can be used, we let a LM annotate
  a huge language modeling dataset with potential
  API calls. We then use a self-supervised loss to
  determine which of these API calls actually help
  the model in predicting future tokens. Finally, we
  ﬁnetune the LM itself on the API calls that it con-
  siders useful. ([View Highlight](https://read.readwise.io/read/01gs562vsakc7e6gm4tkvz0mh2))
- As a next step, we execute
  all API calls generated by M to obtain the corre-
  sponding results. How this is done depends entirely
  on the API itself – for example, it can involve call-
  ing another neural network, executing a Python
  script or using a retrieval system to perform search
  over a large corpus ([View Highlight](https://read.readwise.io/read/01gs5651fp2zbjy5s11ykxtfxy))
- For each API, we write a
  prompt P(x) that encourages the LM to anno-
  tate an example x = x1, . . . , xn with API calls. ([View Highlight](https://read.readwise.io/read/01gs564marcfgazs5b5j98hch2))
- Model Finetuning After sampling and ﬁltering
  calls for all APIs, we ﬁnally merge the remaining
  API calls and interleave them with the original
  inputs ([View Highlight](https://read.readwise.io/read/01gs565q74k49z4vr8xkm484jt))
- One such limi-
  tation is the inability of Toolformer to use tools in a
  chain (i.e., using the output of one tool as an input
  for another tool). This is due to the fact that API
  calls for each tool are generated independently; as a
  consequence, there are no examples of chained tool
  use in the ﬁnetuning dataset ([View Highlight](https://read.readwise.io/read/01gs567xjvjtxnzbkz1py92r28))
- we found models
  trained with Toolformer to often be sensitive to the
  exact wording of their input when deciding whether
  or not to call an API; this is perhaps unsurprising
  given that LMs are known to be very sensitive to
  the prompt they are provided with in both zero-
  and few-shot settings ([View Highlight](https://read.readwise.io/read/01gs568afsvrq89wf0zcx1c268))
