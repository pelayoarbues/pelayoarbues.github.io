---
author: [[Eric Schmidt]]
title: "Mapping AI’s Rapid Advance"
date: 2024-08-23
tags: 
- articles
- literature-note
---
![rw-book-cover](https://noemamag.imgix.net/2024/05/NOEMA_DOTS_2x1.jpg?fit=crop&fm=pjpg&h=628&ixlib=php-3.3.1&w=1200&wpsize=noema-social-facebook&s=268770120f5b9276a8488d2717fbf9d1)

## Metadata
- Author: [[Eric Schmidt]]
- Full Title: Mapping AI’s Rapid Advance
- URL: https://www.noemamag.com/mapping-ais-rapid-advance/

## Highlights
- The first pertains to the question of the “[context window](https://www.zdnet.com/article/what-does-a-long-context-window-mean-for-an-ai-model-like-gemini/).” For non-technical people, the context window is the prompt that you ask. That context window can have a [million](https://www.forbes.com/sites/moorinsights/2024/05/01/anthropic-dethroned-by-gemini-15-pros-1-million-token-context-window/?sh=303a78ba351f) words in it. And this year, people are inventing a context window that is [infinitely](https://venturebeat.com/ai/googles-new-technique-gives-llms-infinite-context/) long. This is very important because it means that you can take the answer from the system and feed it back in and ask it another question. ([View Highlight](https://read.readwise.io/read/01j6006qwxf1kgv8dh3xsfpe1p))
- The second thing going on presently is [enhanced agency](https://www.axios.com/2024/04/19/ai-agents-assistants-ethics-alignment-google). An agent can be understood as a large language model that can learn something new. An example would be that an agent can read all of chemistry, learn something about it, have a bunch of hypotheses about the chemistry, run some tests in a lab and then add that knowledge to what it knows. ([View Highlight](https://read.readwise.io/read/01j6007s9k7tdtghmt2pdm75wy))
- These agents are going to be really powerful, and it’s reasonable to expect that there will be millions of them out there. So, there will be lots and lots of agents running around and available to you. ([View Highlight](https://read.readwise.io/read/01j6007yrh3hehhkhvyg0x3ce2))
- The third development already beginning to happen, which to me is the most profound, is called “text to action.” You might say to AI, “Write me a piece of software to do X” and it does. You just say it and it transpires. Can you imagine having programmers that actually do what you say you want? And they do it 24 hours a day? These systems are good at writing code, such as languages like Python. ([View Highlight](https://read.readwise.io/read/01j60085n88vdjc1tayrmsbpb7))
- Put all that together, and you’ve got, (a) an [infinite context window](https://arxiv.org/abs/2404.07143), (b) [chain of thought reasoning in agents](https://arxiv.org/abs/2201.11903) and then (c) the text-to-action [capacity](https://aibusiness.com/nlp/ai-code-generation-models-the-big-list) for programming. ([View Highlight](https://read.readwise.io/read/01j6008ajnvzaqc81yc5hnp46k))
- What happens then poses a lot of issues. Here we get into the questions raised by science fiction. What I’ve described is what is happening already. But at some point, these systems will get powerful enough that the agents will start to work together. So your agent, my agent, her agent and his agent will all combine to solve a new problem. ([View Highlight](https://read.readwise.io/read/01j6008grf94xznmz18460bsj4))
- Some believe that these agents will develop their own language to [communicate](https://www.livescience.com/technology/artificial-intelligence/scientists-create-ai-models-that-can-talk-to-each-other-and-pass-on-skills-with-limited-human-input) with each other. And that’s the point when we won’t understand what the models are doing. What should we do? Pull the plug? Literally unplug the computer? It will really be a problem when agents start to communicate and do things in ways that we as humans do not understand. That’s the limit, in my view. ([View Highlight](https://read.readwise.io/read/01j6008q43m3y9b0x7aw7ba910))
