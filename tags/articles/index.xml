<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>articles on</title><link>https://pelayoarbues.github.io/tags/articles/</link><description>Recent content in articles on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://pelayoarbues.github.io/tags/articles/index.xml" rel="self" type="application/rss+xml"/><item><title>1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con...</title><link>https://pelayoarbues.github.io/literature-notes/Articles/1-La-Mayor%C3%ADa-De-Las-Empresas-Confunden-Eficiencia-Operativa-Con.../</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/1-La-Mayor%C3%ADa-De-Las-Empresas-Confunden-Eficiencia-Operativa-Con.../</guid><description>&lt;h1 id="1-la-mayoría-de-las-empresas-confunden-eficiencia-operativa-con">1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1492131334847823875/5fCHhO9P.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Arthur Cahuantzi]]&lt;/li>
&lt;li>Full Title: 1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Only the paranoid survive - Check Andrews Grove
In a digital company data pushes your competitive advantage.&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/ArthurCahuantzi/status/1614963374990807041" rel="noopener">https://twitter.com/ArthurCahuantzi/status/1614963374990807041&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Peter Drucker sintetizó con la lucidez que lo caracterizaba la esencia de la estrategia:
&amp;ldquo;No hay nada tan inútil como hacer con gran eficiencia algo que no debería hacerse en absoluto.&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqfp458gsapajstdn9s4bt60" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h4p2cbt056xxm51q47" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h6s6ehckjxt694mz07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las inversiones en empresas de bienes físicos se reflejan en su balance, CAPEX. En empresas intensivas en personal y conocimientos sus inversiones se reflejan en su estado de resultados, OPEX = gastos de venta, generales, administrativos y gastos en Investigación y Desarrollo (
&lt;a href="https://read.readwise.io/read/01gqfp7x7xa939szs3sag34kza" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el defecto del CAPEX para ponerse al día, es su baja rentabilidad. A medida que P se pone al día, el líder del sector no se queda quieto y en el momento en que lo alcanza donde estaba, él ya no está allí, y seguirá siendo el proveedor favorito de los clientes (
&lt;a href="https://read.readwise.io/read/01gqfpa83pxk7edf86p3neb7dh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd77kf147m05gn0rvsk0v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd78gvrp51a20aaj2hzvc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia es un acto creativo, enfocado a diseñar aquello que aún no existe; se ocupa en resolver problemas no estandarizados. Los enfoques analíticos, de investigación y centrados en datos solo miran hacia atrás: no son aptos para innovar y crear un futuro alternativo: (
&lt;a href="https://read.readwise.io/read/01gqfpkc0198dv3hvgjwggt11y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia debe definir una teoría convincente y clara de cómo un negocio será mejor que sus competidores en el mercado elegido. Para tener un foso amplio y profundo significa NO invertir solo para ponerse al día, la clave es tener 1 teoría de dónde y cómo jugar para ganar (
&lt;a href="https://read.readwise.io/read/01gqfpkxsedsmqxf15vnq3b2rh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La diferenciación atrae y retiene talento, ayuda a los empleados a unirse en torno a una misión; y atrae a cierto tipo de colaborador, el apasionado por resolver problemas. (
&lt;a href="https://read.readwise.io/read/01gqfpp09177hjzqfsn9rrrz5e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Es más fácil, incluso divertido, hacer algo difícil cuando crees que estás haciendo algo que nadie más puede hacer, como G. (
&lt;a href="https://read.readwise.io/read/01gqfppanqg7gktems3cyf676r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Arthur Cahuantzi]]
title: &amp;ldquo;1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="1-la-mayoría-de-las-empresas-confunden-eficiencia-operativa-con-1">1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1492131334847823875/5fCHhO9P.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Arthur Cahuantzi]]&lt;/li>
&lt;li>Full Title: 1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Only the paranoid survive - Check Andrews Grove
In a digital company data pushes your competitive advantage.&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/ArthurCahuantzi/status/1614963374990807041" rel="noopener">https://twitter.com/ArthurCahuantzi/status/1614963374990807041&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Peter Drucker sintetizó con la lucidez que lo caracterizaba la esencia de la estrategia:
&amp;ldquo;No hay nada tan inútil como hacer con gran eficiencia algo que no debería hacerse en absoluto.&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqfp458gsapajstdn9s4bt60" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h4p2cbt056xxm51q47" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h6s6ehckjxt694mz07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las inversiones en empresas de bienes físicos se reflejan en su balance, CAPEX. En empresas intensivas en personal y conocimientos sus inversiones se reflejan en su estado de resultados, OPEX = gastos de venta, generales, administrativos y gastos en Investigación y Desarrollo (
&lt;a href="https://read.readwise.io/read/01gqfp7x7xa939szs3sag34kza" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el defecto del CAPEX para ponerse al día, es su baja rentabilidad. A medida que P se pone al día, el líder del sector no se queda quieto y en el momento en que lo alcanza donde estaba, él ya no está allí, y seguirá siendo el proveedor favorito de los clientes (
&lt;a href="https://read.readwise.io/read/01gqfpa83pxk7edf86p3neb7dh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd77kf147m05gn0rvsk0v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd78gvrp51a20aaj2hzvc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia es un acto creativo, enfocado a diseñar aquello que aún no existe; se ocupa en resolver problemas no estandarizados. Los enfoques analíticos, de investigación y centrados en datos solo miran hacia atrás: no son aptos para innovar y crear un futuro alternativo: (
&lt;a href="https://read.readwise.io/read/01gqfpkc0198dv3hvgjwggt11y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia debe definir una teoría convincente y clara de cómo un negocio será mejor que sus competidores en el mercado elegido. Para tener un foso amplio y profundo significa NO invertir solo para ponerse al día, la clave es tener 1 teoría de dónde y cómo jugar para ganar (
&lt;a href="https://read.readwise.io/read/01gqfpkxsedsmqxf15vnq3b2rh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La diferenciación atrae y retiene talento, ayuda a los empleados a unirse en torno a una misión; y atrae a cierto tipo de colaborador, el apasionado por resolver problemas. (
&lt;a href="https://read.readwise.io/read/01gqfpp09177hjzqfsn9rrrz5e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Es más fácil, incluso divertido, hacer algo difícil cuando crees que estás haciendo algo que nadie más puede hacer, como G. (
&lt;a href="https://read.readwise.io/read/01gqfppanqg7gktems3cyf676r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Arthur Cahuantzi]]
title: &amp;ldquo;1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="1-la-mayoría-de-las-empresas-confunden-eficiencia-operativa-con-2">1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1492131334847823875/5fCHhO9P.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Arthur Cahuantzi]]&lt;/li>
&lt;li>Full Title: 1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Only the paranoid survive - Check Andrews Grove
In a digital company data pushes your competitive advantage.&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/ArthurCahuantzi/status/1614963374990807041" rel="noopener">https://twitter.com/ArthurCahuantzi/status/1614963374990807041&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Peter Drucker sintetizó con la lucidez que lo caracterizaba la esencia de la estrategia:
&amp;ldquo;No hay nada tan inútil como hacer con gran eficiencia algo que no debería hacerse en absoluto.&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqfp458gsapajstdn9s4bt60" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h4p2cbt056xxm51q47" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h6s6ehckjxt694mz07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las inversiones en empresas de bienes físicos se reflejan en su balance, CAPEX. En empresas intensivas en personal y conocimientos sus inversiones se reflejan en su estado de resultados, OPEX = gastos de venta, generales, administrativos y gastos en Investigación y Desarrollo (
&lt;a href="https://read.readwise.io/read/01gqfp7x7xa939szs3sag34kza" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el defecto del CAPEX para ponerse al día, es su baja rentabilidad. A medida que P se pone al día, el líder del sector no se queda quieto y en el momento en que lo alcanza donde estaba, él ya no está allí, y seguirá siendo el proveedor favorito de los clientes (
&lt;a href="https://read.readwise.io/read/01gqfpa83pxk7edf86p3neb7dh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd77kf147m05gn0rvsk0v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd78gvrp51a20aaj2hzvc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia es un acto creativo, enfocado a diseñar aquello que aún no existe; se ocupa en resolver problemas no estandarizados. Los enfoques analíticos, de investigación y centrados en datos solo miran hacia atrás: no son aptos para innovar y crear un futuro alternativo: (
&lt;a href="https://read.readwise.io/read/01gqfpkc0198dv3hvgjwggt11y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia debe definir una teoría convincente y clara de cómo un negocio será mejor que sus competidores en el mercado elegido. Para tener un foso amplio y profundo significa NO invertir solo para ponerse al día, la clave es tener 1 teoría de dónde y cómo jugar para ganar (
&lt;a href="https://read.readwise.io/read/01gqfpkxsedsmqxf15vnq3b2rh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La diferenciación atrae y retiene talento, ayuda a los empleados a unirse en torno a una misión; y atrae a cierto tipo de colaborador, el apasionado por resolver problemas. (
&lt;a href="https://read.readwise.io/read/01gqfpp09177hjzqfsn9rrrz5e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Es más fácil, incluso divertido, hacer algo difícil cuando crees que estás haciendo algo que nadie más puede hacer, como G. (
&lt;a href="https://read.readwise.io/read/01gqfppanqg7gktems3cyf676r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Arthur Cahuantzi]]
title: &amp;ldquo;1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="1-la-mayoría-de-las-empresas-confunden-eficiencia-operativa-con-3">1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1492131334847823875/5fCHhO9P.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Arthur Cahuantzi]]&lt;/li>
&lt;li>Full Title: 1/ La Mayoría De Las Empresas Confunden Eficiencia Operativa Con&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Only the paranoid survive - Check Andrews Grove
In a digital company data pushes your competitive advantage.&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/ArthurCahuantzi/status/1614963374990807041" rel="noopener">https://twitter.com/ArthurCahuantzi/status/1614963374990807041&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Peter Drucker sintetizó con la lucidez que lo caracterizaba la esencia de la estrategia:
&amp;ldquo;No hay nada tan inútil como hacer con gran eficiencia algo que no debería hacerse en absoluto.&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqfp458gsapajstdn9s4bt60" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h4p2cbt056xxm51q47" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmCRQ8akAIPAq-.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfp50h6s6ehckjxt694mz07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las inversiones en empresas de bienes físicos se reflejan en su balance, CAPEX. En empresas intensivas en personal y conocimientos sus inversiones se reflejan en su estado de resultados, OPEX = gastos de venta, generales, administrativos y gastos en Investigación y Desarrollo (
&lt;a href="https://read.readwise.io/read/01gqfp7x7xa939szs3sag34kza" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el defecto del CAPEX para ponerse al día, es su baja rentabilidad. A medida que P se pone al día, el líder del sector no se queda quieto y en el momento en que lo alcanza donde estaba, él ya no está allí, y seguirá siendo el proveedor favorito de los clientes (
&lt;a href="https://read.readwise.io/read/01gqfpa83pxk7edf86p3neb7dh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd77kf147m05gn0rvsk0v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://pbs.twimg.com/media/FmmOHVHaUAEWMDP.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqfpd78gvrp51a20aaj2hzvc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia es un acto creativo, enfocado a diseñar aquello que aún no existe; se ocupa en resolver problemas no estandarizados. Los enfoques analíticos, de investigación y centrados en datos solo miran hacia atrás: no son aptos para innovar y crear un futuro alternativo: (
&lt;a href="https://read.readwise.io/read/01gqfpkc0198dv3hvgjwggt11y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La estrategia debe definir una teoría convincente y clara de cómo un negocio será mejor que sus competidores en el mercado elegido. Para tener un foso amplio y profundo significa NO invertir solo para ponerse al día, la clave es tener 1 teoría de dónde y cómo jugar para ganar (
&lt;a href="https://read.readwise.io/read/01gqfpkxsedsmqxf15vnq3b2rh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La diferenciación atrae y retiene talento, ayuda a los empleados a unirse en torno a una misión; y atrae a cierto tipo de colaborador, el apasionado por resolver problemas. (
&lt;a href="https://read.readwise.io/read/01gqfpp09177hjzqfsn9rrrz5e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Es más fácil, incluso divertido, hacer algo difícil cuando crees que estás haciendo algo que nadie más puede hacer, como G. (
&lt;a href="https://read.readwise.io/read/01gqfppanqg7gktems3cyf676r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>2022 Recap: Every Random Idea I Had</title><link>https://pelayoarbues.github.io/literature-notes/Articles/2022-Recap-Every-Random-Idea-I-Had/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/2022-Recap-Every-Random-Idea-I-Had/</guid><description>&lt;h1 id="2022-recap-every-random-idea-i-had">2022 Recap: Every Random Idea I Had&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a7d450-26bb-4b07-b113-dfc6b964db1f_906x354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Pedram Navid]]&lt;/li>
&lt;li>Full Title: 2022 Recap: Every Random Idea I Had&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pedram.substack.com/i/93416609/on-talking-about-the-work" rel="noopener">https://pedram.substack.com/i/93416609/on-talking-about-the-work&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>There’s no magic trick, secret cabal, or mysterious meetings. I talk to people I’m genuinely interested in, meet them in person when I can, and treat them as well as I can. If we like each other, we become friends, and if we’re friends, we’ll help each other. That’s all networking is. (
&lt;a href="https://read.readwise.io/read/01gqdmhn9bz558bwmg7gnjzawc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Pedram Navid]]
title: &amp;ldquo;2022 Recap: Every Random Idea I Had&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="2022-recap-every-random-idea-i-had-1">2022 Recap: Every Random Idea I Had&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a7d450-26bb-4b07-b113-dfc6b964db1f_906x354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Pedram Navid]]&lt;/li>
&lt;li>Full Title: 2022 Recap: Every Random Idea I Had&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pedram.substack.com/i/93416609/on-talking-about-the-work" rel="noopener">https://pedram.substack.com/i/93416609/on-talking-about-the-work&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>There’s no magic trick, secret cabal, or mysterious meetings. I talk to people I’m genuinely interested in, meet them in person when I can, and treat them as well as I can. If we like each other, we become friends, and if we’re friends, we’ll help each other. That’s all networking is. (
&lt;a href="https://read.readwise.io/read/01gqdmhn9bz558bwmg7gnjzawc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Pedram Navid]]
title: &amp;ldquo;2022 Recap: Every Random Idea I Had&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="2022-recap-every-random-idea-i-had-2">2022 Recap: Every Random Idea I Had&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a7d450-26bb-4b07-b113-dfc6b964db1f_906x354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Pedram Navid]]&lt;/li>
&lt;li>Full Title: 2022 Recap: Every Random Idea I Had&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pedram.substack.com/i/93416609/on-talking-about-the-work" rel="noopener">https://pedram.substack.com/i/93416609/on-talking-about-the-work&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>There’s no magic trick, secret cabal, or mysterious meetings. I talk to people I’m genuinely interested in, meet them in person when I can, and treat them as well as I can. If we like each other, we become friends, and if we’re friends, we’ll help each other. That’s all networking is. (
&lt;a href="https://read.readwise.io/read/01gqdmhn9bz558bwmg7gnjzawc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Pedram Navid]]
title: &amp;ldquo;2022 Recap: Every Random Idea I Had&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="2022-recap-every-random-idea-i-had-3">2022 Recap: Every Random Idea I Had&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0a7d450-26bb-4b07-b113-dfc6b964db1f_906x354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Pedram Navid]]&lt;/li>
&lt;li>Full Title: 2022 Recap: Every Random Idea I Had&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pedram.substack.com/i/93416609/on-talking-about-the-work" rel="noopener">https://pedram.substack.com/i/93416609/on-talking-about-the-work&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>There’s no magic trick, secret cabal, or mysterious meetings. I talk to people I’m genuinely interested in, meet them in person when I can, and treat them as well as I can. If we like each other, we become friends, and if we’re friends, we’ll help each other. That’s all networking is. (
&lt;a href="https://read.readwise.io/read/01gqdmhn9bz558bwmg7gnjzawc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%</title><link>https://pelayoarbues.github.io/literature-notes/Articles/3-2-1-Healthy-Self-Esteem-How-to-Build-an-Exercise-Habit-and-Improving-by-1/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/3-2-1-Healthy-Self-Esteem-How-to-Build-an-Exercise-Habit-and-Improving-by-1/</guid><description>&lt;h1 id="3-2-1-healthy-self-esteem-how-to-build-an-exercise-habit-and-improving-by-1">3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/h1>
&lt;p>
&lt;img src="https://jamesclear.com/wp-content/uploads/2020/11/cropped-icon-270x270.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[3-2-1 Thursday newsletter - James Clear]]&lt;/li>
&lt;li>Full Title: 3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jamesclear.com/3-2-1/january-26-2023" rel="noopener">https://jamesclear.com/3-2-1/january-26-2023&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Refocusing on exercising only for one’s own individual pleasure, as slowly as one prefers, and only at intensities that are pleasurable, is more likely to motivate repeat and habitual exercising. At that point, the enjoyment of exercise pleasure can build on itself, motivating longer and longer intervals of experiencing the pleasure.” (
&lt;a href="https://read.readwise.io/read/01gqvyk8zyavkgpah8tj9s8ck9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[3-2-1 Thursday newsletter - James Clear]]
title: &amp;ldquo;3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="3-2-1-healthy-self-esteem-how-to-build-an-exercise-habit-and-improving-by-1-1">3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/h1>
&lt;p>
&lt;img src="https://jamesclear.com/wp-content/uploads/2020/11/cropped-icon-270x270.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[3-2-1 Thursday newsletter - James Clear]]&lt;/li>
&lt;li>Full Title: 3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jamesclear.com/3-2-1/january-26-2023" rel="noopener">https://jamesclear.com/3-2-1/january-26-2023&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Refocusing on exercising only for one’s own individual pleasure, as slowly as one prefers, and only at intensities that are pleasurable, is more likely to motivate repeat and habitual exercising. At that point, the enjoyment of exercise pleasure can build on itself, motivating longer and longer intervals of experiencing the pleasure.” (
&lt;a href="https://read.readwise.io/read/01gqvyk8zyavkgpah8tj9s8ck9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[3-2-1 Thursday newsletter - James Clear]]
title: &amp;ldquo;3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="3-2-1-healthy-self-esteem-how-to-build-an-exercise-habit-and-improving-by-1-2">3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/h1>
&lt;p>
&lt;img src="https://jamesclear.com/wp-content/uploads/2020/11/cropped-icon-270x270.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[3-2-1 Thursday newsletter - James Clear]]&lt;/li>
&lt;li>Full Title: 3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jamesclear.com/3-2-1/january-26-2023" rel="noopener">https://jamesclear.com/3-2-1/january-26-2023&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Refocusing on exercising only for one’s own individual pleasure, as slowly as one prefers, and only at intensities that are pleasurable, is more likely to motivate repeat and habitual exercising. At that point, the enjoyment of exercise pleasure can build on itself, motivating longer and longer intervals of experiencing the pleasure.” (
&lt;a href="https://read.readwise.io/read/01gqvyk8zyavkgpah8tj9s8ck9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[3-2-1 Thursday newsletter - James Clear]]
title: &amp;ldquo;3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="3-2-1-healthy-self-esteem-how-to-build-an-exercise-habit-and-improving-by-1-3">3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/h1>
&lt;p>
&lt;img src="https://jamesclear.com/wp-content/uploads/2020/11/cropped-icon-270x270.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[3-2-1 Thursday newsletter - James Clear]]&lt;/li>
&lt;li>Full Title: 3-2-1: Healthy Self-Esteem, How to Build an Exercise Habit, and Improving by 1%&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jamesclear.com/3-2-1/january-26-2023" rel="noopener">https://jamesclear.com/3-2-1/january-26-2023&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Refocusing on exercising only for one’s own individual pleasure, as slowly as one prefers, and only at intensities that are pleasurable, is more likely to motivate repeat and habitual exercising. At that point, the enjoyment of exercise pleasure can build on itself, motivating longer and longer intervals of experiencing the pleasure.” (
&lt;a href="https://read.readwise.io/read/01gqvyk8zyavkgpah8tj9s8ck9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>About nownownow.com</title><link>https://pelayoarbues.github.io/literature-notes/Articles/About-nownownow.com/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/About-nownownow.com/</guid><description>&lt;h1 id="about-nownownowcom">About nownownow.com&lt;/h1>
&lt;p>
&lt;img src="http://nownownow.com/images/nowclock.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Derek Sivers]]&lt;/li>
&lt;li>Full Title: About nownownow.com&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nownownow.com/about" rel="noopener">https://nownownow.com/about&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>So a website with a link that says “&lt;strong>now&lt;/strong>” goes to a page that tells you &lt;strong>what this person is focused on at this point in their life.&lt;/strong> For short, we call it a “now page (
&lt;a href="https://read.readwise.io/read/01gs6akf4zjpkcgwparqqszn81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Besides answering the common question, “What are you up to these days?”, those who have a now page say it’s a good reminder of their priorities. By publicly showing what you are focused on now, it helps you say no to other requests (
&lt;a href="https://read.readwise.io/read/01gs6ana7rk25wm3z7sm5yf2sr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Derek Sivers]]
title: &amp;ldquo;About nownownow.com&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="about-nownownowcom-1">About nownownow.com&lt;/h1>
&lt;p>
&lt;img src="http://nownownow.com/images/nowclock.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Derek Sivers]]&lt;/li>
&lt;li>Full Title: About nownownow.com&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nownownow.com/about" rel="noopener">https://nownownow.com/about&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>So a website with a link that says “&lt;strong>now&lt;/strong>” goes to a page that tells you &lt;strong>what this person is focused on at this point in their life.&lt;/strong> For short, we call it a “now page (
&lt;a href="https://read.readwise.io/read/01gs6akf4zjpkcgwparqqszn81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Besides answering the common question, “What are you up to these days?”, those who have a now page say it’s a good reminder of their priorities. By publicly showing what you are focused on now, it helps you say no to other requests (
&lt;a href="https://read.readwise.io/read/01gs6ana7rk25wm3z7sm5yf2sr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Derek Sivers]]
title: &amp;ldquo;About nownownow.com&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="about-nownownowcom-2">About nownownow.com&lt;/h1>
&lt;p>
&lt;img src="http://nownownow.com/images/nowclock.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Derek Sivers]]&lt;/li>
&lt;li>Full Title: About nownownow.com&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nownownow.com/about" rel="noopener">https://nownownow.com/about&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>So a website with a link that says “&lt;strong>now&lt;/strong>” goes to a page that tells you &lt;strong>what this person is focused on at this point in their life.&lt;/strong> For short, we call it a “now page (
&lt;a href="https://read.readwise.io/read/01gs6akf4zjpkcgwparqqszn81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Besides answering the common question, “What are you up to these days?”, those who have a now page say it’s a good reminder of their priorities. By publicly showing what you are focused on now, it helps you say no to other requests (
&lt;a href="https://read.readwise.io/read/01gs6ana7rk25wm3z7sm5yf2sr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Derek Sivers]]
title: &amp;ldquo;About nownownow.com&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="about-nownownowcom-3">About nownownow.com&lt;/h1>
&lt;p>
&lt;img src="http://nownownow.com/images/nowclock.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Derek Sivers]]&lt;/li>
&lt;li>Full Title: About nownownow.com&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nownownow.com/about" rel="noopener">https://nownownow.com/about&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>So a website with a link that says “&lt;strong>now&lt;/strong>” goes to a page that tells you &lt;strong>what this person is focused on at this point in their life.&lt;/strong> For short, we call it a “now page (
&lt;a href="https://read.readwise.io/read/01gs6akf4zjpkcgwparqqszn81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Besides answering the common question, “What are you up to these days?”, those who have a now page say it’s a good reminder of their priorities. By publicly showing what you are focused on now, it helps you say no to other requests (
&lt;a href="https://read.readwise.io/read/01gs6ana7rk25wm3z7sm5yf2sr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Balancing the Weight of Variables in a Decision Tree</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Balancing-the-Weight-of-Variables-in-a-Decision-Tree/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Balancing-the-Weight-of-Variables-in-a-Decision-Tree/</guid><description>&lt;h1 id="balancing-the-weight-of-variables-in-a-decision-tree">Balancing the Weight of Variables in a Decision Tree&lt;/h1>
&lt;p>
&lt;img src="https://www.bbvaaifactory.com/wp-content/uploads/GettyImages-923622818-1.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[BBVA AI Factory]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Balancing the Weight of Variables in a Decision Tree&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: In industrialised process where the output of the model is used to take decisions it is a bad practice to over-rely on a low number of variables due to fail to be reported or technical failure. For this reason it might be important to dillute the importance of a variable to make the model more robust.
In linear regression models we may impose penalties or constraints on the magnitude of the coefficients but this is not possible in decission trees.
Different workarounds include: introduce noise to the data or to use the more important variables in the last steps of the decission.
Proposed solution, extended trees: We fit a base tree without most important variables, then extend the leaves of previous trees with variable left out.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/" rel="noopener">https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sometimes, when facing the challenge of modelling the operation of a process where different variables are involved, we find that some of them dominate over the others. These variables will thus exert greater influence compared to the rest. (
&lt;a href="https://read.readwise.io/read/01gs3nwk5fzcynbadezjb6ef7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an industrialised process where the output of a model is used to make decisions, it is generally bad practice to over-rely on a low number of variables as these might fail to be reported (or may be misreported) due to technical failure. (
&lt;a href="https://read.readwise.io/read/01gs3nww75w1btw22y1w2hrq7c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[BBVA AI Factory]]
title: &amp;ldquo;Balancing the Weight of Variables in a Decision Tree&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="balancing-the-weight-of-variables-in-a-decision-tree-1">Balancing the Weight of Variables in a Decision Tree&lt;/h1>
&lt;p>
&lt;img src="https://www.bbvaaifactory.com/wp-content/uploads/GettyImages-923622818-1.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[BBVA AI Factory]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Balancing the Weight of Variables in a Decision Tree&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: In industrialised process where the output of the model is used to take decisions it is a bad practice to over-rely on a low number of variables due to fail to be reported or technical failure. For this reason it might be important to dillute the importance of a variable to make the model more robust.
In linear regression models we may impose penalties or constraints on the magnitude of the coefficients but this is not possible in decission trees.
Different workarounds include: introduce noise to the data or to use the more important variables in the last steps of the decission.
Proposed solution, extended trees: We fit a base tree without most important variables, then extend the leaves of previous trees with variable left out.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/" rel="noopener">https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sometimes, when facing the challenge of modelling the operation of a process where different variables are involved, we find that some of them dominate over the others. These variables will thus exert greater influence compared to the rest. (
&lt;a href="https://read.readwise.io/read/01gs3nwk5fzcynbadezjb6ef7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an industrialised process where the output of a model is used to make decisions, it is generally bad practice to over-rely on a low number of variables as these might fail to be reported (or may be misreported) due to technical failure. (
&lt;a href="https://read.readwise.io/read/01gs3nww75w1btw22y1w2hrq7c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[BBVA AI Factory]]
title: &amp;ldquo;Balancing the Weight of Variables in a Decision Tree&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="balancing-the-weight-of-variables-in-a-decision-tree-2">Balancing the Weight of Variables in a Decision Tree&lt;/h1>
&lt;p>
&lt;img src="https://www.bbvaaifactory.com/wp-content/uploads/GettyImages-923622818-1.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[BBVA AI Factory]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Balancing the Weight of Variables in a Decision Tree&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: In industrialised process where the output of the model is used to take decisions it is a bad practice to over-rely on a low number of variables due to fail to be reported or technical failure. For this reason it might be important to dillute the importance of a variable to make the model more robust.
In linear regression models we may impose penalties or constraints on the magnitude of the coefficients but this is not possible in decission trees.
Different workarounds include: introduce noise to the data or to use the more important variables in the last steps of the decission.
Proposed solution, extended trees: We fit a base tree without most important variables, then extend the leaves of previous trees with variable left out.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/" rel="noopener">https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sometimes, when facing the challenge of modelling the operation of a process where different variables are involved, we find that some of them dominate over the others. These variables will thus exert greater influence compared to the rest. (
&lt;a href="https://read.readwise.io/read/01gs3nwk5fzcynbadezjb6ef7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an industrialised process where the output of a model is used to make decisions, it is generally bad practice to over-rely on a low number of variables as these might fail to be reported (or may be misreported) due to technical failure. (
&lt;a href="https://read.readwise.io/read/01gs3nww75w1btw22y1w2hrq7c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[BBVA AI Factory]]
title: &amp;ldquo;Balancing the Weight of Variables in a Decision Tree&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="balancing-the-weight-of-variables-in-a-decision-tree-3">Balancing the Weight of Variables in a Decision Tree&lt;/h1>
&lt;p>
&lt;img src="https://www.bbvaaifactory.com/wp-content/uploads/GettyImages-923622818-1.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[BBVA AI Factory]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Balancing the Weight of Variables in a Decision Tree&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: In industrialised process where the output of the model is used to take decisions it is a bad practice to over-rely on a low number of variables due to fail to be reported or technical failure. For this reason it might be important to dillute the importance of a variable to make the model more robust.
In linear regression models we may impose penalties or constraints on the magnitude of the coefficients but this is not possible in decission trees.
Different workarounds include: introduce noise to the data or to use the more important variables in the last steps of the decission.
Proposed solution, extended trees: We fit a base tree without most important variables, then extend the leaves of previous trees with variable left out.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/" rel="noopener">https://www.bbvaaifactory.com/balancing-the-weight-of-variables-in-a-decision-tree/&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sometimes, when facing the challenge of modelling the operation of a process where different variables are involved, we find that some of them dominate over the others. These variables will thus exert greater influence compared to the rest. (
&lt;a href="https://read.readwise.io/read/01gs3nwk5fzcynbadezjb6ef7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an industrialised process where the output of a model is used to make decisions, it is generally bad practice to over-rely on a low number of variables as these might fail to be reported (or may be misreported) due to technical failure. (
&lt;a href="https://read.readwise.io/read/01gs3nww75w1btw22y1w2hrq7c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>BBRR Programa investigo</title><link>https://pelayoarbues.github.io/literature-notes/Articles/BBRR-Programa-investigo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/BBRR-Programa-investigo/</guid><description>&lt;h1 id="bbrr-programa-investigo">BBRR Programa investigo&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[MINISTERIO DE TRABAJO Y ECONOMÍA SOCIAL]]&lt;/li>
&lt;li>Full Title: BBRR Programa investigo&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://readwise.io/reader/document_raw_content/28917847" rel="noopener">https://readwise.io/reader/document_raw_content/28917847&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>cuya finalidad es la
contratación de personas jóvenes, mayores de 16 y menores de 30 años, investigadoras,
tecnólogas, personal técnico y otros perfiles profesionales en I+D+i, así como, en su
caso, el personal de apoyo a la investigación, en organismos públicos de investigación y
difusión del conocimiento, universidades públicas, centros tecnológicos, parques
científicos y tecnológicos, entidades públicas sujetas a derecho privado y entidades
privadas sin ánimo de lucro, como fundaciones, junto con empresas que inviertan en
investigación e innovación. (
&lt;a href="https://read.readwise.io/read/01gqf5jhjzax4cyyagxhwzw6pa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>la digitalización de servicios
e ingeniería de datos o science data (
&lt;a href="https://read.readwise.io/read/01gqf5k2aqxqx6p52cfj6qfaaz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las
subvenciones objeto de esta orden se tramitarán según el procedimiento de concurrencia
no competitiva (
&lt;a href="https://read.readwise.io/read/01gqf5p37c644xfx1dekhh0k7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>cuyo objeto es financiar actuaciones concretas que no requieren de
valoración comparativa con otras propuestas, por lo que las resoluciones de concesión
se dictarán por orden de presentación de solicitudes, una vez realizadas las
comprobaciones de concurrencia de la actuación subvencionable y el cumplimiento del
resto de requisitos exigidos, hasta el agotamiento del crédito presupuestario asignado en
la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5pew8mdf4758s57f11e9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>l «Programa Investigo»,
cuyo objeto serán las subvenciones reguladas en la presente norma, para la contratación
de personas jóvenes demandantes de empleo, de 16 o más años y que no hayan
cumplido treinta años en el momento de comenzar la relación contractual, por los
organismos de investigación y difusión de conocimientos, universidades públicas,
centros tecnológicos, parques científicos y tecnológicos, entidades públicas sujetas a
derecho privado y entidades privadas sin ánimo de lucro, junto con empresas que estén
invirtiendo en investigación e innovación pertenecientes al sector público o privado, en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5qfbd5e7cymg94yymb8f0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Empresas pertenecientes al sector público o privado, que estén invirtiendo en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5w4jd3bngfw187v3d5me6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las subvenciones a otorgar para la contratación se destinarán a la financiación
de los costes laborales y salariales, incluyendo la cotización por todos los conceptos a la
Seguridad Social, de las personas jóvenes (
&lt;a href="https://read.readwise.io/read/01gqf5wh606esp30t1s9hct45x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Los contratos objeto de subvención, que habrán de ser a tiempo completo, se
realizarán conforme a la normativa laboral. No se podrán contratar personas jóvenes que
hayan desempeñado cualquier tipo de puesto de investigación en la misma entidad,
empresa o grupo de empresas en el plazo de 6 meses inmediatamente anteriores. (
&lt;a href="https://read.readwise.io/read/01gqf5wwbdgrw8he2ajajmh5pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Costes laborales y salariales, incluyendo la cotización por todos los conceptos a
la Seguridad Social. (
&lt;a href="https://read.readwise.io/read/01gqf5x3f017e8efk4aky60e37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Ayudas al desplazamiento, por importe de 1.000 euros por año a tanto alzado
por persona contratada, cuando estas tengan residencia en provincia o isla diferente de
donde van a desempeñar su puesto de trabajo, que serán de aplicación a un máximo
del 50 por ciento de las personas contratadas, hasta agotar el crédito disponible a tal fin.
Una vez seleccionadas las personas trabajadoras para ocupar los puestos objeto de la
subvención, las entidades y centros beneficiarios podrán formalizar una solicitud
adicional en la forma que se establezca en la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5xxn4bpgryp34zs2znjm3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>grupos de
cotización de la Seguridad Social (
&lt;a href="https://read.readwise.io/read/01gr1m5mmggdhhtt22wmtgwhvp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el importe de esta subvención se calculará en función de las
previsiones recogidas en el proyecto presentado del número de personas a contratar, los años (o meses en su caso) de contratación de cada una de ellas y el módulo según el grupo de cotización de la Seguridad Social que corresponda. (
&lt;a href="https://read.readwise.io/read/01gqfq6aq5p1zw3cnhxgr35v79" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Mayor adecuación entre la formación académica de la persona joven en relación al programa de investigación que se desea llevar a cabo. b) Disponer de estudios específicos relacionados con la materia a desarrollar, tales
como másteres, grados o/y cualesquiera que, estando homologados por el Ministerio de Educación y Formación Profesional o el Ministerio de Universidades, les otorguen mayores capacidades y competencias para llevar a cabo el programa de investigación. Este criterio no será de aplicación para los puestos de apoyo. c) La valoración curricular y de las personas candidatas deberá realizarse mediante
el uso de curriculum vitae ciego, garantizando el principio de no discriminación por ninguna razón. d) Las convocatorias deberán recoger las medidas que la entidad tenga ya implementadas a fecha de la solicitud para favorecer la conciliación entre la vida laboral, familiar, personal y la igualdad de género. e) En las convocatorias las administraciones competentes podrán incluir otros
criterios que se consideren relevantes en función de su normativa propia o que se correspondan con la realidad del colectivo. (
&lt;a href="https://read.readwise.io/read/01gqfqan2s4k3tsc38rgz52pbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las solicitudes de concesión de subvenciones se dirigirán a la Dirección General
del Servicio Público de Empleo Estatal o al órgano competente de la comunidad autónoma, según el ámbito de la convocatoria (
&lt;a href="https://read.readwise.io/read/01gqfqc05gtd6pk3g87d8kdj4t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Junto con la solicitud se presentará una memoria con la descripción de los puestos
de trabajo a cubrir, características de las actividades a realizar y duración y número de contratos; así como las previsiones de los costes del programa, distinguiendo entre subvención solicitada y, en su caso, aportación de la entidad beneficiaria. (
&lt;a href="https://read.readwise.io/read/01gqfqdhm2c6bjtmap7sd9gf9p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las personas participantes serán seleccionadas por la entidad beneficiaria o el
servicio público de empleo correspondiente, con un mes de antelación, al menos, al inicio previsto de los contratos. Se deberán publicar las ofertas de los puestos a cubrir, en el Portal Único de Empleo «EMPLÉATE» para las convocatorias de ámbito estatal. Las convocatorias de alcance autonómico podrán requerir la publicación de ofertas en el portal de empleo en su ámbito de competencia. (
&lt;a href="https://read.readwise.io/read/01gqfqg6bz5n5jxv3x8dzv4anq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) Una memoria económica justificativa del coste de las actividades realizadas en
función de los resultados obtenidos, que contendrá, como mínimo los siguientes extremos (
&lt;a href="https://read.readwise.io/read/01gqfqntkbke0tf9wrkq02337b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[MINISTERIO DE TRABAJO Y ECONOMÍA SOCIAL]]
title: &amp;ldquo;BBRR Programa investigo&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="bbrr-programa-investigo-1">BBRR Programa investigo&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[MINISTERIO DE TRABAJO Y ECONOMÍA SOCIAL]]&lt;/li>
&lt;li>Full Title: BBRR Programa investigo&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://readwise.io/reader/document_raw_content/28917847" rel="noopener">https://readwise.io/reader/document_raw_content/28917847&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>cuya finalidad es la
contratación de personas jóvenes, mayores de 16 y menores de 30 años, investigadoras,
tecnólogas, personal técnico y otros perfiles profesionales en I+D+i, así como, en su
caso, el personal de apoyo a la investigación, en organismos públicos de investigación y
difusión del conocimiento, universidades públicas, centros tecnológicos, parques
científicos y tecnológicos, entidades públicas sujetas a derecho privado y entidades
privadas sin ánimo de lucro, como fundaciones, junto con empresas que inviertan en
investigación e innovación. (
&lt;a href="https://read.readwise.io/read/01gqf5jhjzax4cyyagxhwzw6pa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>la digitalización de servicios
e ingeniería de datos o science data (
&lt;a href="https://read.readwise.io/read/01gqf5k2aqxqx6p52cfj6qfaaz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las
subvenciones objeto de esta orden se tramitarán según el procedimiento de concurrencia
no competitiva (
&lt;a href="https://read.readwise.io/read/01gqf5p37c644xfx1dekhh0k7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>cuyo objeto es financiar actuaciones concretas que no requieren de
valoración comparativa con otras propuestas, por lo que las resoluciones de concesión
se dictarán por orden de presentación de solicitudes, una vez realizadas las
comprobaciones de concurrencia de la actuación subvencionable y el cumplimiento del
resto de requisitos exigidos, hasta el agotamiento del crédito presupuestario asignado en
la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5pew8mdf4758s57f11e9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>l «Programa Investigo»,
cuyo objeto serán las subvenciones reguladas en la presente norma, para la contratación
de personas jóvenes demandantes de empleo, de 16 o más años y que no hayan
cumplido treinta años en el momento de comenzar la relación contractual, por los
organismos de investigación y difusión de conocimientos, universidades públicas,
centros tecnológicos, parques científicos y tecnológicos, entidades públicas sujetas a
derecho privado y entidades privadas sin ánimo de lucro, junto con empresas que estén
invirtiendo en investigación e innovación pertenecientes al sector público o privado, en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5qfbd5e7cymg94yymb8f0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Empresas pertenecientes al sector público o privado, que estén invirtiendo en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5w4jd3bngfw187v3d5me6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las subvenciones a otorgar para la contratación se destinarán a la financiación
de los costes laborales y salariales, incluyendo la cotización por todos los conceptos a la
Seguridad Social, de las personas jóvenes (
&lt;a href="https://read.readwise.io/read/01gqf5wh606esp30t1s9hct45x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Los contratos objeto de subvención, que habrán de ser a tiempo completo, se
realizarán conforme a la normativa laboral. No se podrán contratar personas jóvenes que
hayan desempeñado cualquier tipo de puesto de investigación en la misma entidad,
empresa o grupo de empresas en el plazo de 6 meses inmediatamente anteriores. (
&lt;a href="https://read.readwise.io/read/01gqf5wwbdgrw8he2ajajmh5pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Costes laborales y salariales, incluyendo la cotización por todos los conceptos a
la Seguridad Social. (
&lt;a href="https://read.readwise.io/read/01gqf5x3f017e8efk4aky60e37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Ayudas al desplazamiento, por importe de 1.000 euros por año a tanto alzado
por persona contratada, cuando estas tengan residencia en provincia o isla diferente de
donde van a desempeñar su puesto de trabajo, que serán de aplicación a un máximo
del 50 por ciento de las personas contratadas, hasta agotar el crédito disponible a tal fin.
Una vez seleccionadas las personas trabajadoras para ocupar los puestos objeto de la
subvención, las entidades y centros beneficiarios podrán formalizar una solicitud
adicional en la forma que se establezca en la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5xxn4bpgryp34zs2znjm3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>grupos de
cotización de la Seguridad Social (
&lt;a href="https://read.readwise.io/read/01gr1m5mmggdhhtt22wmtgwhvp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el importe de esta subvención se calculará en función de las
previsiones recogidas en el proyecto presentado del número de personas a contratar, los años (o meses en su caso) de contratación de cada una de ellas y el módulo según el grupo de cotización de la Seguridad Social que corresponda. (
&lt;a href="https://read.readwise.io/read/01gqfq6aq5p1zw3cnhxgr35v79" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Mayor adecuación entre la formación académica de la persona joven en relación al programa de investigación que se desea llevar a cabo. b) Disponer de estudios específicos relacionados con la materia a desarrollar, tales
como másteres, grados o/y cualesquiera que, estando homologados por el Ministerio de Educación y Formación Profesional o el Ministerio de Universidades, les otorguen mayores capacidades y competencias para llevar a cabo el programa de investigación. Este criterio no será de aplicación para los puestos de apoyo. c) La valoración curricular y de las personas candidatas deberá realizarse mediante
el uso de curriculum vitae ciego, garantizando el principio de no discriminación por ninguna razón. d) Las convocatorias deberán recoger las medidas que la entidad tenga ya implementadas a fecha de la solicitud para favorecer la conciliación entre la vida laboral, familiar, personal y la igualdad de género. e) En las convocatorias las administraciones competentes podrán incluir otros
criterios que se consideren relevantes en función de su normativa propia o que se correspondan con la realidad del colectivo. (
&lt;a href="https://read.readwise.io/read/01gqfqan2s4k3tsc38rgz52pbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las solicitudes de concesión de subvenciones se dirigirán a la Dirección General
del Servicio Público de Empleo Estatal o al órgano competente de la comunidad autónoma, según el ámbito de la convocatoria (
&lt;a href="https://read.readwise.io/read/01gqfqc05gtd6pk3g87d8kdj4t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Junto con la solicitud se presentará una memoria con la descripción de los puestos
de trabajo a cubrir, características de las actividades a realizar y duración y número de contratos; así como las previsiones de los costes del programa, distinguiendo entre subvención solicitada y, en su caso, aportación de la entidad beneficiaria. (
&lt;a href="https://read.readwise.io/read/01gqfqdhm2c6bjtmap7sd9gf9p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las personas participantes serán seleccionadas por la entidad beneficiaria o el
servicio público de empleo correspondiente, con un mes de antelación, al menos, al inicio previsto de los contratos. Se deberán publicar las ofertas de los puestos a cubrir, en el Portal Único de Empleo «EMPLÉATE» para las convocatorias de ámbito estatal. Las convocatorias de alcance autonómico podrán requerir la publicación de ofertas en el portal de empleo en su ámbito de competencia. (
&lt;a href="https://read.readwise.io/read/01gqfqg6bz5n5jxv3x8dzv4anq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) Una memoria económica justificativa del coste de las actividades realizadas en
función de los resultados obtenidos, que contendrá, como mínimo los siguientes extremos (
&lt;a href="https://read.readwise.io/read/01gqfqntkbke0tf9wrkq02337b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[MINISTERIO DE TRABAJO Y ECONOMÍA SOCIAL]]
title: &amp;ldquo;BBRR Programa investigo&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="bbrr-programa-investigo-2">BBRR Programa investigo&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[MINISTERIO DE TRABAJO Y ECONOMÍA SOCIAL]]&lt;/li>
&lt;li>Full Title: BBRR Programa investigo&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://readwise.io/reader/document_raw_content/28917847" rel="noopener">https://readwise.io/reader/document_raw_content/28917847&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>cuya finalidad es la
contratación de personas jóvenes, mayores de 16 y menores de 30 años, investigadoras,
tecnólogas, personal técnico y otros perfiles profesionales en I+D+i, así como, en su
caso, el personal de apoyo a la investigación, en organismos públicos de investigación y
difusión del conocimiento, universidades públicas, centros tecnológicos, parques
científicos y tecnológicos, entidades públicas sujetas a derecho privado y entidades
privadas sin ánimo de lucro, como fundaciones, junto con empresas que inviertan en
investigación e innovación. (
&lt;a href="https://read.readwise.io/read/01gqf5jhjzax4cyyagxhwzw6pa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>la digitalización de servicios
e ingeniería de datos o science data (
&lt;a href="https://read.readwise.io/read/01gqf5k2aqxqx6p52cfj6qfaaz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las
subvenciones objeto de esta orden se tramitarán según el procedimiento de concurrencia
no competitiva (
&lt;a href="https://read.readwise.io/read/01gqf5p37c644xfx1dekhh0k7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>cuyo objeto es financiar actuaciones concretas que no requieren de
valoración comparativa con otras propuestas, por lo que las resoluciones de concesión
se dictarán por orden de presentación de solicitudes, una vez realizadas las
comprobaciones de concurrencia de la actuación subvencionable y el cumplimiento del
resto de requisitos exigidos, hasta el agotamiento del crédito presupuestario asignado en
la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5pew8mdf4758s57f11e9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>l «Programa Investigo»,
cuyo objeto serán las subvenciones reguladas en la presente norma, para la contratación
de personas jóvenes demandantes de empleo, de 16 o más años y que no hayan
cumplido treinta años en el momento de comenzar la relación contractual, por los
organismos de investigación y difusión de conocimientos, universidades públicas,
centros tecnológicos, parques científicos y tecnológicos, entidades públicas sujetas a
derecho privado y entidades privadas sin ánimo de lucro, junto con empresas que estén
invirtiendo en investigación e innovación pertenecientes al sector público o privado, en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5qfbd5e7cymg94yymb8f0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Empresas pertenecientes al sector público o privado, que estén invirtiendo en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5w4jd3bngfw187v3d5me6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las subvenciones a otorgar para la contratación se destinarán a la financiación
de los costes laborales y salariales, incluyendo la cotización por todos los conceptos a la
Seguridad Social, de las personas jóvenes (
&lt;a href="https://read.readwise.io/read/01gqf5wh606esp30t1s9hct45x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Los contratos objeto de subvención, que habrán de ser a tiempo completo, se
realizarán conforme a la normativa laboral. No se podrán contratar personas jóvenes que
hayan desempeñado cualquier tipo de puesto de investigación en la misma entidad,
empresa o grupo de empresas en el plazo de 6 meses inmediatamente anteriores. (
&lt;a href="https://read.readwise.io/read/01gqf5wwbdgrw8he2ajajmh5pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Costes laborales y salariales, incluyendo la cotización por todos los conceptos a
la Seguridad Social. (
&lt;a href="https://read.readwise.io/read/01gqf5x3f017e8efk4aky60e37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Ayudas al desplazamiento, por importe de 1.000 euros por año a tanto alzado
por persona contratada, cuando estas tengan residencia en provincia o isla diferente de
donde van a desempeñar su puesto de trabajo, que serán de aplicación a un máximo
del 50 por ciento de las personas contratadas, hasta agotar el crédito disponible a tal fin.
Una vez seleccionadas las personas trabajadoras para ocupar los puestos objeto de la
subvención, las entidades y centros beneficiarios podrán formalizar una solicitud
adicional en la forma que se establezca en la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5xxn4bpgryp34zs2znjm3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>grupos de
cotización de la Seguridad Social (
&lt;a href="https://read.readwise.io/read/01gr1m5mmggdhhtt22wmtgwhvp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el importe de esta subvención se calculará en función de las
previsiones recogidas en el proyecto presentado del número de personas a contratar, los años (o meses en su caso) de contratación de cada una de ellas y el módulo según el grupo de cotización de la Seguridad Social que corresponda. (
&lt;a href="https://read.readwise.io/read/01gqfq6aq5p1zw3cnhxgr35v79" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Mayor adecuación entre la formación académica de la persona joven en relación al programa de investigación que se desea llevar a cabo. b) Disponer de estudios específicos relacionados con la materia a desarrollar, tales
como másteres, grados o/y cualesquiera que, estando homologados por el Ministerio de Educación y Formación Profesional o el Ministerio de Universidades, les otorguen mayores capacidades y competencias para llevar a cabo el programa de investigación. Este criterio no será de aplicación para los puestos de apoyo. c) La valoración curricular y de las personas candidatas deberá realizarse mediante
el uso de curriculum vitae ciego, garantizando el principio de no discriminación por ninguna razón. d) Las convocatorias deberán recoger las medidas que la entidad tenga ya implementadas a fecha de la solicitud para favorecer la conciliación entre la vida laboral, familiar, personal y la igualdad de género. e) En las convocatorias las administraciones competentes podrán incluir otros
criterios que se consideren relevantes en función de su normativa propia o que se correspondan con la realidad del colectivo. (
&lt;a href="https://read.readwise.io/read/01gqfqan2s4k3tsc38rgz52pbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las solicitudes de concesión de subvenciones se dirigirán a la Dirección General
del Servicio Público de Empleo Estatal o al órgano competente de la comunidad autónoma, según el ámbito de la convocatoria (
&lt;a href="https://read.readwise.io/read/01gqfqc05gtd6pk3g87d8kdj4t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Junto con la solicitud se presentará una memoria con la descripción de los puestos
de trabajo a cubrir, características de las actividades a realizar y duración y número de contratos; así como las previsiones de los costes del programa, distinguiendo entre subvención solicitada y, en su caso, aportación de la entidad beneficiaria. (
&lt;a href="https://read.readwise.io/read/01gqfqdhm2c6bjtmap7sd9gf9p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las personas participantes serán seleccionadas por la entidad beneficiaria o el
servicio público de empleo correspondiente, con un mes de antelación, al menos, al inicio previsto de los contratos. Se deberán publicar las ofertas de los puestos a cubrir, en el Portal Único de Empleo «EMPLÉATE» para las convocatorias de ámbito estatal. Las convocatorias de alcance autonómico podrán requerir la publicación de ofertas en el portal de empleo en su ámbito de competencia. (
&lt;a href="https://read.readwise.io/read/01gqfqg6bz5n5jxv3x8dzv4anq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) Una memoria económica justificativa del coste de las actividades realizadas en
función de los resultados obtenidos, que contendrá, como mínimo los siguientes extremos (
&lt;a href="https://read.readwise.io/read/01gqfqntkbke0tf9wrkq02337b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[MINISTERIO DE TRABAJO Y ECONOMÍA SOCIAL]]
title: &amp;ldquo;BBRR Programa investigo&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="bbrr-programa-investigo-3">BBRR Programa investigo&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[MINISTERIO DE TRABAJO Y ECONOMÍA SOCIAL]]&lt;/li>
&lt;li>Full Title: BBRR Programa investigo&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://readwise.io/reader/document_raw_content/28917847" rel="noopener">https://readwise.io/reader/document_raw_content/28917847&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>cuya finalidad es la
contratación de personas jóvenes, mayores de 16 y menores de 30 años, investigadoras,
tecnólogas, personal técnico y otros perfiles profesionales en I+D+i, así como, en su
caso, el personal de apoyo a la investigación, en organismos públicos de investigación y
difusión del conocimiento, universidades públicas, centros tecnológicos, parques
científicos y tecnológicos, entidades públicas sujetas a derecho privado y entidades
privadas sin ánimo de lucro, como fundaciones, junto con empresas que inviertan en
investigación e innovación. (
&lt;a href="https://read.readwise.io/read/01gqf5jhjzax4cyyagxhwzw6pa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>la digitalización de servicios
e ingeniería de datos o science data (
&lt;a href="https://read.readwise.io/read/01gqf5k2aqxqx6p52cfj6qfaaz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las
subvenciones objeto de esta orden se tramitarán según el procedimiento de concurrencia
no competitiva (
&lt;a href="https://read.readwise.io/read/01gqf5p37c644xfx1dekhh0k7j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>cuyo objeto es financiar actuaciones concretas que no requieren de
valoración comparativa con otras propuestas, por lo que las resoluciones de concesión
se dictarán por orden de presentación de solicitudes, una vez realizadas las
comprobaciones de concurrencia de la actuación subvencionable y el cumplimiento del
resto de requisitos exigidos, hasta el agotamiento del crédito presupuestario asignado en
la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5pew8mdf4758s57f11e9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>l «Programa Investigo»,
cuyo objeto serán las subvenciones reguladas en la presente norma, para la contratación
de personas jóvenes demandantes de empleo, de 16 o más años y que no hayan
cumplido treinta años en el momento de comenzar la relación contractual, por los
organismos de investigación y difusión de conocimientos, universidades públicas,
centros tecnológicos, parques científicos y tecnológicos, entidades públicas sujetas a
derecho privado y entidades privadas sin ánimo de lucro, junto con empresas que estén
invirtiendo en investigación e innovación pertenecientes al sector público o privado, en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5qfbd5e7cymg94yymb8f0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Empresas pertenecientes al sector público o privado, que estén invirtiendo en la
realización de iniciativas de investigación e innovación contempladas en esta norma. (
&lt;a href="https://read.readwise.io/read/01gqf5w4jd3bngfw187v3d5me6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las subvenciones a otorgar para la contratación se destinarán a la financiación
de los costes laborales y salariales, incluyendo la cotización por todos los conceptos a la
Seguridad Social, de las personas jóvenes (
&lt;a href="https://read.readwise.io/read/01gqf5wh606esp30t1s9hct45x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Los contratos objeto de subvención, que habrán de ser a tiempo completo, se
realizarán conforme a la normativa laboral. No se podrán contratar personas jóvenes que
hayan desempeñado cualquier tipo de puesto de investigación en la misma entidad,
empresa o grupo de empresas en el plazo de 6 meses inmediatamente anteriores. (
&lt;a href="https://read.readwise.io/read/01gqf5wwbdgrw8he2ajajmh5pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Costes laborales y salariales, incluyendo la cotización por todos los conceptos a
la Seguridad Social. (
&lt;a href="https://read.readwise.io/read/01gqf5x3f017e8efk4aky60e37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Ayudas al desplazamiento, por importe de 1.000 euros por año a tanto alzado
por persona contratada, cuando estas tengan residencia en provincia o isla diferente de
donde van a desempeñar su puesto de trabajo, que serán de aplicación a un máximo
del 50 por ciento de las personas contratadas, hasta agotar el crédito disponible a tal fin.
Una vez seleccionadas las personas trabajadoras para ocupar los puestos objeto de la
subvención, las entidades y centros beneficiarios podrán formalizar una solicitud
adicional en la forma que se establezca en la convocatoria. (
&lt;a href="https://read.readwise.io/read/01gqf5xxn4bpgryp34zs2znjm3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>grupos de
cotización de la Seguridad Social (
&lt;a href="https://read.readwise.io/read/01gr1m5mmggdhhtt22wmtgwhvp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>el importe de esta subvención se calculará en función de las
previsiones recogidas en el proyecto presentado del número de personas a contratar, los años (o meses en su caso) de contratación de cada una de ellas y el módulo según el grupo de cotización de la Seguridad Social que corresponda. (
&lt;a href="https://read.readwise.io/read/01gqfq6aq5p1zw3cnhxgr35v79" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Mayor adecuación entre la formación académica de la persona joven en relación al programa de investigación que se desea llevar a cabo. b) Disponer de estudios específicos relacionados con la materia a desarrollar, tales
como másteres, grados o/y cualesquiera que, estando homologados por el Ministerio de Educación y Formación Profesional o el Ministerio de Universidades, les otorguen mayores capacidades y competencias para llevar a cabo el programa de investigación. Este criterio no será de aplicación para los puestos de apoyo. c) La valoración curricular y de las personas candidatas deberá realizarse mediante
el uso de curriculum vitae ciego, garantizando el principio de no discriminación por ninguna razón. d) Las convocatorias deberán recoger las medidas que la entidad tenga ya implementadas a fecha de la solicitud para favorecer la conciliación entre la vida laboral, familiar, personal y la igualdad de género. e) En las convocatorias las administraciones competentes podrán incluir otros
criterios que se consideren relevantes en función de su normativa propia o que se correspondan con la realidad del colectivo. (
&lt;a href="https://read.readwise.io/read/01gqfqan2s4k3tsc38rgz52pbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las solicitudes de concesión de subvenciones se dirigirán a la Dirección General
del Servicio Público de Empleo Estatal o al órgano competente de la comunidad autónoma, según el ámbito de la convocatoria (
&lt;a href="https://read.readwise.io/read/01gqfqc05gtd6pk3g87d8kdj4t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Junto con la solicitud se presentará una memoria con la descripción de los puestos
de trabajo a cubrir, características de las actividades a realizar y duración y número de contratos; así como las previsiones de los costes del programa, distinguiendo entre subvención solicitada y, en su caso, aportación de la entidad beneficiaria. (
&lt;a href="https://read.readwise.io/read/01gqfqdhm2c6bjtmap7sd9gf9p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las personas participantes serán seleccionadas por la entidad beneficiaria o el
servicio público de empleo correspondiente, con un mes de antelación, al menos, al inicio previsto de los contratos. Se deberán publicar las ofertas de los puestos a cubrir, en el Portal Único de Empleo «EMPLÉATE» para las convocatorias de ámbito estatal. Las convocatorias de alcance autonómico podrán requerir la publicación de ofertas en el portal de empleo en su ámbito de competencia. (
&lt;a href="https://read.readwise.io/read/01gqfqg6bz5n5jxv3x8dzv4anq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) Una memoria económica justificativa del coste de las actividades realizadas en
función de los resultados obtenidos, que contendrá, como mínimo los siguientes extremos (
&lt;a href="https://read.readwise.io/read/01gqfqntkbke0tf9wrkq02337b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Benzodiacepinas-La-Adicci%C3%B3n-Camuflada-Del-Consumo-De-Ansiol%C3%ADticos-en-Espa%C3%B1a/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Benzodiacepinas-La-Adicci%C3%B3n-Camuflada-Del-Consumo-De-Ansiol%C3%ADticos-en-Espa%C3%B1a/</guid><description>&lt;h1 id="benzodiacepinas-la-adicción-camuflada-del-consumo-de-ansiolíticos-en-españa">Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/h1>
&lt;p>
&lt;img src="https://static.nationalgeographic.es/files/styles/image_3200/public/benzos2.jpg?w=400&amp;amp;h=400&amp;amp;q=75" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[National Geographic]]&lt;/li>
&lt;li>Full Title: Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana" rel="noopener">https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>En 2021, un promedio de 110 españoles por cada mil habitantes consumió al menos una dosis de benzodiacepinas al día. (
&lt;a href="https://read.readwise.io/read/01gqzmwpm24r9f7fc915a8nhb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Reconoce que tiene pacientes que necesitan un ingreso para poder desintoxicarse de benzodiacepinas, un fármaco que, al generar tolerancia, presenta síntomas de abstinencia similares a los de otras droga como el cannabis o la heroína: (
&lt;a href="https://read.readwise.io/read/01gqzn45mc27zke0hs4m1br2mc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La gente se cree que esto es una broma y que es como tomarse un ibuprofeno; el síndrome de abstinencia de las benzodiacepinas es muchísimo peor que el de la heroína. Te entran dolores, espasmos o incluso ataques epilépticos (
&lt;a href="https://read.readwise.io/read/01gqzn8zpjkkhwte1qvf9m1gby" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[National Geographic]]
title: &amp;ldquo;Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="benzodiacepinas-la-adicción-camuflada-del-consumo-de-ansiolíticos-en-españa-1">Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/h1>
&lt;p>
&lt;img src="https://static.nationalgeographic.es/files/styles/image_3200/public/benzos2.jpg?w=400&amp;amp;h=400&amp;amp;q=75" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[National Geographic]]&lt;/li>
&lt;li>Full Title: Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana" rel="noopener">https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>En 2021, un promedio de 110 españoles por cada mil habitantes consumió al menos una dosis de benzodiacepinas al día. (
&lt;a href="https://read.readwise.io/read/01gqzmwpm24r9f7fc915a8nhb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Reconoce que tiene pacientes que necesitan un ingreso para poder desintoxicarse de benzodiacepinas, un fármaco que, al generar tolerancia, presenta síntomas de abstinencia similares a los de otras droga como el cannabis o la heroína: (
&lt;a href="https://read.readwise.io/read/01gqzn45mc27zke0hs4m1br2mc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La gente se cree que esto es una broma y que es como tomarse un ibuprofeno; el síndrome de abstinencia de las benzodiacepinas es muchísimo peor que el de la heroína. Te entran dolores, espasmos o incluso ataques epilépticos (
&lt;a href="https://read.readwise.io/read/01gqzn8zpjkkhwte1qvf9m1gby" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[National Geographic]]
title: &amp;ldquo;Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="benzodiacepinas-la-adicción-camuflada-del-consumo-de-ansiolíticos-en-españa-2">Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/h1>
&lt;p>
&lt;img src="https://static.nationalgeographic.es/files/styles/image_3200/public/benzos2.jpg?w=400&amp;amp;h=400&amp;amp;q=75" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[National Geographic]]&lt;/li>
&lt;li>Full Title: Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana" rel="noopener">https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>En 2021, un promedio de 110 españoles por cada mil habitantes consumió al menos una dosis de benzodiacepinas al día. (
&lt;a href="https://read.readwise.io/read/01gqzmwpm24r9f7fc915a8nhb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Reconoce que tiene pacientes que necesitan un ingreso para poder desintoxicarse de benzodiacepinas, un fármaco que, al generar tolerancia, presenta síntomas de abstinencia similares a los de otras droga como el cannabis o la heroína: (
&lt;a href="https://read.readwise.io/read/01gqzn45mc27zke0hs4m1br2mc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La gente se cree que esto es una broma y que es como tomarse un ibuprofeno; el síndrome de abstinencia de las benzodiacepinas es muchísimo peor que el de la heroína. Te entran dolores, espasmos o incluso ataques epilépticos (
&lt;a href="https://read.readwise.io/read/01gqzn8zpjkkhwte1qvf9m1gby" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[National Geographic]]
title: &amp;ldquo;Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="benzodiacepinas-la-adicción-camuflada-del-consumo-de-ansiolíticos-en-españa-3">Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/h1>
&lt;p>
&lt;img src="https://static.nationalgeographic.es/files/styles/image_3200/public/benzos2.jpg?w=400&amp;amp;h=400&amp;amp;q=75" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[National Geographic]]&lt;/li>
&lt;li>Full Title: Benzodiacepinas: La Adicción Camuflada Del Consumo De Ansiolíticos en España&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana" rel="noopener">https://www.nationalgeographic.es/ciencia/2022/12/benzodiacepinas-la-adiccion-camuflada-del-consumo-de-ansioliticos-en-espana&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>En 2021, un promedio de 110 españoles por cada mil habitantes consumió al menos una dosis de benzodiacepinas al día. (
&lt;a href="https://read.readwise.io/read/01gqzmwpm24r9f7fc915a8nhb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Reconoce que tiene pacientes que necesitan un ingreso para poder desintoxicarse de benzodiacepinas, un fármaco que, al generar tolerancia, presenta síntomas de abstinencia similares a los de otras droga como el cannabis o la heroína: (
&lt;a href="https://read.readwise.io/read/01gqzn45mc27zke0hs4m1br2mc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>La gente se cree que esto es una broma y que es como tomarse un ibuprofeno; el síndrome de abstinencia de las benzodiacepinas es muchísimo peor que el de la heroína. Te entran dolores, espasmos o incluso ataques epilépticos (
&lt;a href="https://read.readwise.io/read/01gqzn8zpjkkhwte1qvf9m1gby" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Beware-the-Data-Science-Pin-Factory-The-Power-of-the-Full-Stack-Data-Science-Generalist-and-the-Perils-of-Division-of-Labor-Through-Function/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Beware-the-Data-Science-Pin-Factory-The-Power-of-the-Full-Stack-Data-Science-Generalist-and-the-Perils-of-Division-of-Labor-Through-Function/</guid><description>&lt;h1 id="beware-the-data-science-pin-factory-the-power-of-the-full-stack-data-science-generalist-and-the-perils-of-division-of-labor-through-function">Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/posts/2019-03-11-FullStackDS-Generalists/image1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like and more can’t be designed up-front. They need to be learned. There are no blueprints to follow; these are novel capabilities with inherent uncertainty. &lt;strong>With data science, you learn as you go, not before you go&lt;/strong>.
The generalist moves fluidly between functions, extending the data pipeline to add more data, trying new features in the model, deploying new versions to production for causal measurement, and repeating the steps as quickly as new ideas come to her.
Key ideas
&lt;ul>
&lt;li>Dysfunctional relationship between DS and DE is common in the industry. &amp;gt; What is your experience here?&lt;/li>
&lt;li>Unless you have tons of people you get that sort of relationship. But that is not very efficient&lt;/li>
&lt;li>Generalists able to use platform is the answer&lt;/li>
&lt;li>Change mindshit to autonomous doers. Engineers work horizontally, DS vertically&lt;/li>
&lt;li>How to make platform engieers to stay ahead of DS teams? &amp;gt; My proposal is to involve them in our decisions&lt;/li>
&lt;li>We are sacrificing technical efficiency for velocity and autonomy. It is important to recognize this as a deliberate trade off.&lt;/li>
&lt;li>DS they are well equipped to make trade offs between technical and support costs vs. requirements.&lt;/li>
&lt;li>Algorithmic products and services like and more can’t be designed up-front. They need to be learned&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/" rel="noopener">https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>This division of labor by function is so ingrained in us even today that we are quick to organize our teams accordingly. Data science is no exception (
&lt;a href="https://read.readwise.io/read/01gs3p24sanjpfaej8v54dnzp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las, we should not be optimizing our data science teams for productivity gains; that is what you do when you know what it is you’re producing—pins or otherwise—and are merely seeking incremental efficiencies. (
&lt;a href="https://read.readwise.io/read/01gs3p2hddvnezjk7j7919a91p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like
&lt;a href="https://multithreaded.stitchfix.com/blog/2015/07/14/glmms/" rel="noopener">recommendations systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/11/08/bandits/" rel="noopener">client engagement bandits&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/06/28/latent-style/" rel="noopener">style preference classification&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2017/12/13/latentsize/" rel="noopener">size matching&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/14/data-driven-fashion-design/" rel="noopener">fashion design systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/21/skynet-salesman/" rel="noopener">logistics optimizers&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/08/23/seasonal-trends/" rel="noopener">seasonal trend detection&lt;/a>, and more can’t be designed up-front. They need to be learned. (
&lt;a href="https://read.readwise.io/read/01gs3p2rte7kqrjzj2387bva4h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>With data science, you learn as you go, not before you go&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p2xtmesn58vq2t2qs5skj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stitchfix.com]]
title: &amp;ldquo;Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="beware-the-data-science-pin-factory-the-power-of-the-full-stack-data-science-generalist-and-the-perils-of-division-of-labor-through-function-1">Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/posts/2019-03-11-FullStackDS-Generalists/image1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like and more can’t be designed up-front. They need to be learned. There are no blueprints to follow; these are novel capabilities with inherent uncertainty. &lt;strong>With data science, you learn as you go, not before you go&lt;/strong>.
The generalist moves fluidly between functions, extending the data pipeline to add more data, trying new features in the model, deploying new versions to production for causal measurement, and repeating the steps as quickly as new ideas come to her.
Key ideas
&lt;ul>
&lt;li>Dysfunctional relationship between DS and DE is common in the industry. &amp;gt; What is your experience here?&lt;/li>
&lt;li>Unless you have tons of people you get that sort of relationship. But that is not very efficient&lt;/li>
&lt;li>Generalists able to use platform is the answer&lt;/li>
&lt;li>Change mindshit to autonomous doers. Engineers work horizontally, DS vertically&lt;/li>
&lt;li>How to make platform engieers to stay ahead of DS teams? &amp;gt; My proposal is to involve them in our decisions&lt;/li>
&lt;li>We are sacrificing technical efficiency for velocity and autonomy. It is important to recognize this as a deliberate trade off.&lt;/li>
&lt;li>DS they are well equipped to make trade offs between technical and support costs vs. requirements.&lt;/li>
&lt;li>Algorithmic products and services like and more can’t be designed up-front. They need to be learned&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/" rel="noopener">https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>This division of labor by function is so ingrained in us even today that we are quick to organize our teams accordingly. Data science is no exception (
&lt;a href="https://read.readwise.io/read/01gs3p24sanjpfaej8v54dnzp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las, we should not be optimizing our data science teams for productivity gains; that is what you do when you know what it is you’re producing—pins or otherwise—and are merely seeking incremental efficiencies. (
&lt;a href="https://read.readwise.io/read/01gs3p2hddvnezjk7j7919a91p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like
&lt;a href="https://multithreaded.stitchfix.com/blog/2015/07/14/glmms/" rel="noopener">recommendations systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/11/08/bandits/" rel="noopener">client engagement bandits&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/06/28/latent-style/" rel="noopener">style preference classification&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2017/12/13/latentsize/" rel="noopener">size matching&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/14/data-driven-fashion-design/" rel="noopener">fashion design systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/21/skynet-salesman/" rel="noopener">logistics optimizers&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/08/23/seasonal-trends/" rel="noopener">seasonal trend detection&lt;/a>, and more can’t be designed up-front. They need to be learned. (
&lt;a href="https://read.readwise.io/read/01gs3p2rte7kqrjzj2387bva4h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>With data science, you learn as you go, not before you go&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p2xtmesn58vq2t2qs5skj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stitchfix.com]]
title: &amp;ldquo;Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="beware-the-data-science-pin-factory-the-power-of-the-full-stack-data-science-generalist-and-the-perils-of-division-of-labor-through-function-2">Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/posts/2019-03-11-FullStackDS-Generalists/image1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like and more can’t be designed up-front. They need to be learned. There are no blueprints to follow; these are novel capabilities with inherent uncertainty. &lt;strong>With data science, you learn as you go, not before you go&lt;/strong>.
The generalist moves fluidly between functions, extending the data pipeline to add more data, trying new features in the model, deploying new versions to production for causal measurement, and repeating the steps as quickly as new ideas come to her.
Key ideas
&lt;ul>
&lt;li>Dysfunctional relationship between DS and DE is common in the industry. &amp;gt; What is your experience here?&lt;/li>
&lt;li>Unless you have tons of people you get that sort of relationship. But that is not very efficient&lt;/li>
&lt;li>Generalists able to use platform is the answer&lt;/li>
&lt;li>Change mindshit to autonomous doers. Engineers work horizontally, DS vertically&lt;/li>
&lt;li>How to make platform engieers to stay ahead of DS teams? &amp;gt; My proposal is to involve them in our decisions&lt;/li>
&lt;li>We are sacrificing technical efficiency for velocity and autonomy. It is important to recognize this as a deliberate trade off.&lt;/li>
&lt;li>DS they are well equipped to make trade offs between technical and support costs vs. requirements.&lt;/li>
&lt;li>Algorithmic products and services like and more can’t be designed up-front. They need to be learned&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/" rel="noopener">https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>This division of labor by function is so ingrained in us even today that we are quick to organize our teams accordingly. Data science is no exception (
&lt;a href="https://read.readwise.io/read/01gs3p24sanjpfaej8v54dnzp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las, we should not be optimizing our data science teams for productivity gains; that is what you do when you know what it is you’re producing—pins or otherwise—and are merely seeking incremental efficiencies. (
&lt;a href="https://read.readwise.io/read/01gs3p2hddvnezjk7j7919a91p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like
&lt;a href="https://multithreaded.stitchfix.com/blog/2015/07/14/glmms/" rel="noopener">recommendations systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/11/08/bandits/" rel="noopener">client engagement bandits&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/06/28/latent-style/" rel="noopener">style preference classification&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2017/12/13/latentsize/" rel="noopener">size matching&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/14/data-driven-fashion-design/" rel="noopener">fashion design systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/21/skynet-salesman/" rel="noopener">logistics optimizers&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/08/23/seasonal-trends/" rel="noopener">seasonal trend detection&lt;/a>, and more can’t be designed up-front. They need to be learned. (
&lt;a href="https://read.readwise.io/read/01gs3p2rte7kqrjzj2387bva4h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>With data science, you learn as you go, not before you go&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p2xtmesn58vq2t2qs5skj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stitchfix.com]]
title: &amp;ldquo;Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="beware-the-data-science-pin-factory-the-power-of-the-full-stack-data-science-generalist-and-the-perils-of-division-of-labor-through-function-3">Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/posts/2019-03-11-FullStackDS-Generalists/image1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Beware the Data Science Pin Factory: The Power of the Full-Stack Data Science Generalist and the Perils of Division of Labor Through Function&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like and more can’t be designed up-front. They need to be learned. There are no blueprints to follow; these are novel capabilities with inherent uncertainty. &lt;strong>With data science, you learn as you go, not before you go&lt;/strong>.
The generalist moves fluidly between functions, extending the data pipeline to add more data, trying new features in the model, deploying new versions to production for causal measurement, and repeating the steps as quickly as new ideas come to her.
Key ideas
&lt;ul>
&lt;li>Dysfunctional relationship between DS and DE is common in the industry. &amp;gt; What is your experience here?&lt;/li>
&lt;li>Unless you have tons of people you get that sort of relationship. But that is not very efficient&lt;/li>
&lt;li>Generalists able to use platform is the answer&lt;/li>
&lt;li>Change mindshit to autonomous doers. Engineers work horizontally, DS vertically&lt;/li>
&lt;li>How to make platform engieers to stay ahead of DS teams? &amp;gt; My proposal is to involve them in our decisions&lt;/li>
&lt;li>We are sacrificing technical efficiency for velocity and autonomy. It is important to recognize this as a deliberate trade off.&lt;/li>
&lt;li>DS they are well equipped to make trade offs between technical and support costs vs. requirements.&lt;/li>
&lt;li>Algorithmic products and services like and more can’t be designed up-front. They need to be learned&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/" rel="noopener">https://multithreaded.stitchfix.com/blog/2019/03/11/FullStackDS-Generalists/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>This division of labor by function is so ingrained in us even today that we are quick to organize our teams accordingly. Data science is no exception (
&lt;a href="https://read.readwise.io/read/01gs3p24sanjpfaej8v54dnzp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>las, we should not be optimizing our data science teams for productivity gains; that is what you do when you know what it is you’re producing—pins or otherwise—and are merely seeking incremental efficiencies. (
&lt;a href="https://read.readwise.io/read/01gs3p2hddvnezjk7j7919a91p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But the goal of data science is not to execute. Rather, the goal is to learn and develop profound new business capabilities. Algorithmic products and services like
&lt;a href="https://multithreaded.stitchfix.com/blog/2015/07/14/glmms/" rel="noopener">recommendations systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/11/08/bandits/" rel="noopener">client engagement bandits&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2018/06/28/latent-style/" rel="noopener">style preference classification&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2017/12/13/latentsize/" rel="noopener">size matching&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/14/data-driven-fashion-design/" rel="noopener">fashion design systems&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/07/21/skynet-salesman/" rel="noopener">logistics optimizers&lt;/a>,
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/08/23/seasonal-trends/" rel="noopener">seasonal trend detection&lt;/a>, and more can’t be designed up-front. They need to be learned. (
&lt;a href="https://read.readwise.io/read/01gs3p2rte7kqrjzj2387bva4h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>With data science, you learn as you go, not before you go&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p2xtmesn58vq2t2qs5skj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Brain Food: Listening to Win</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Brain-Food-Listening-to-Win/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Brain-Food-Listening-to-Win/</guid><description>&lt;h1 id="brain-food-listening-to-win">Brain Food: Listening to Win&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[FS (Farnam Street)]]&lt;/li>
&lt;li>Full Title: Brain Food: Listening to Win&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>“One sign that determination matters more than talent: there are lots of talented people who never achieve anything, but not that many determined people who don&amp;rsquo;t.”
— Paul Graham (
&lt;a href="https://read.readwise.io/read/01gqzj1ynmr2yf7vwp8p51ce5m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[FS (Farnam Street)]]
title: &amp;ldquo;Brain Food: Listening to Win&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="brain-food-listening-to-win-1">Brain Food: Listening to Win&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[FS (Farnam Street)]]&lt;/li>
&lt;li>Full Title: Brain Food: Listening to Win&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>“One sign that determination matters more than talent: there are lots of talented people who never achieve anything, but not that many determined people who don&amp;rsquo;t.”
— Paul Graham (
&lt;a href="https://read.readwise.io/read/01gqzj1ynmr2yf7vwp8p51ce5m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[FS (Farnam Street)]]
title: &amp;ldquo;Brain Food: Listening to Win&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="brain-food-listening-to-win-2">Brain Food: Listening to Win&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[FS (Farnam Street)]]&lt;/li>
&lt;li>Full Title: Brain Food: Listening to Win&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>“One sign that determination matters more than talent: there are lots of talented people who never achieve anything, but not that many determined people who don&amp;rsquo;t.”
— Paul Graham (
&lt;a href="https://read.readwise.io/read/01gqzj1ynmr2yf7vwp8p51ce5m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[FS (Farnam Street)]]
title: &amp;ldquo;Brain Food: Listening to Win&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="brain-food-listening-to-win-3">Brain Food: Listening to Win&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[FS (Farnam Street)]]&lt;/li>
&lt;li>Full Title: Brain Food: Listening to Win&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>“One sign that determination matters more than talent: there are lots of talented people who never achieve anything, but not that many determined people who don&amp;rsquo;t.”
— Paul Graham (
&lt;a href="https://read.readwise.io/read/01gqzj1ynmr2yf7vwp8p51ce5m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Building a First Team Mindset</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Building-a-First-Team-Mindset/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Building-a-First-Team-Mindset/</guid><description>&lt;h1 id="building-a-first-team-mindset">Building a First Team Mindset&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[attack-gecko.net]]&lt;/li>
&lt;li>Full Title: Building a First Team Mindset&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/" rel="noopener">https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>A First Team mindset is the idea that leaders prioritize supporting their fellow leaders over supporting their direct reports—that they are responsible to their peers more than they are to their individual teams (
&lt;a href="https://read.readwise.io/read/01grsjmkgbwaczxx7kd1ggaxkd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When your leaders have built trust with each other it becomes significantly easier to manage change, exhibit vulnerability, and solve problems together. (
&lt;a href="https://read.readwise.io/read/01grsjng150xbvksve0ry3vzk3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The more explicit you are about the behaviors you expect from your leaders the better off you’ll be. I make sure I’m clear with my managers about their responsibility to one another (
&lt;a href="https://read.readwise.io/read/01grsk3shtpq2d75fdg0yc1td6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In my day-to-day. I encourage interdependence and normalization of help seeking amongst team members. I constantly encourage my team to talk to one another about their problems, and refer them to each other for help. (
&lt;a href="https://read.readwise.io/read/01grsk57eserk4n4h6s0rdaqnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Manager roundtables are a great way to achieve this as they are spaces specifically designed to share and solve problems collaboratively. (
&lt;a href="https://read.readwise.io/read/01grsk6yjr5reczpdy9hnmbewr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[attack-gecko.net]]
title: &amp;ldquo;Building a First Team Mindset&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="building-a-first-team-mindset-1">Building a First Team Mindset&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[attack-gecko.net]]&lt;/li>
&lt;li>Full Title: Building a First Team Mindset&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/" rel="noopener">https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>A First Team mindset is the idea that leaders prioritize supporting their fellow leaders over supporting their direct reports—that they are responsible to their peers more than they are to their individual teams (
&lt;a href="https://read.readwise.io/read/01grsjmkgbwaczxx7kd1ggaxkd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When your leaders have built trust with each other it becomes significantly easier to manage change, exhibit vulnerability, and solve problems together. (
&lt;a href="https://read.readwise.io/read/01grsjng150xbvksve0ry3vzk3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The more explicit you are about the behaviors you expect from your leaders the better off you’ll be. I make sure I’m clear with my managers about their responsibility to one another (
&lt;a href="https://read.readwise.io/read/01grsk3shtpq2d75fdg0yc1td6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In my day-to-day. I encourage interdependence and normalization of help seeking amongst team members. I constantly encourage my team to talk to one another about their problems, and refer them to each other for help. (
&lt;a href="https://read.readwise.io/read/01grsk57eserk4n4h6s0rdaqnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Manager roundtables are a great way to achieve this as they are spaces specifically designed to share and solve problems collaboratively. (
&lt;a href="https://read.readwise.io/read/01grsk6yjr5reczpdy9hnmbewr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[attack-gecko.net]]
title: &amp;ldquo;Building a First Team Mindset&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="building-a-first-team-mindset-2">Building a First Team Mindset&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[attack-gecko.net]]&lt;/li>
&lt;li>Full Title: Building a First Team Mindset&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/" rel="noopener">https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>A First Team mindset is the idea that leaders prioritize supporting their fellow leaders over supporting their direct reports—that they are responsible to their peers more than they are to their individual teams (
&lt;a href="https://read.readwise.io/read/01grsjmkgbwaczxx7kd1ggaxkd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When your leaders have built trust with each other it becomes significantly easier to manage change, exhibit vulnerability, and solve problems together. (
&lt;a href="https://read.readwise.io/read/01grsjng150xbvksve0ry3vzk3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The more explicit you are about the behaviors you expect from your leaders the better off you’ll be. I make sure I’m clear with my managers about their responsibility to one another (
&lt;a href="https://read.readwise.io/read/01grsk3shtpq2d75fdg0yc1td6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In my day-to-day. I encourage interdependence and normalization of help seeking amongst team members. I constantly encourage my team to talk to one another about their problems, and refer them to each other for help. (
&lt;a href="https://read.readwise.io/read/01grsk57eserk4n4h6s0rdaqnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Manager roundtables are a great way to achieve this as they are spaces specifically designed to share and solve problems collaboratively. (
&lt;a href="https://read.readwise.io/read/01grsk6yjr5reczpdy9hnmbewr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[attack-gecko.net]]
title: &amp;ldquo;Building a First Team Mindset&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="building-a-first-team-mindset-3">Building a First Team Mindset&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[attack-gecko.net]]&lt;/li>
&lt;li>Full Title: Building a First Team Mindset&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/" rel="noopener">https://www.attack-gecko.net/2018/06/25/building-a-first-team-mindset/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>A First Team mindset is the idea that leaders prioritize supporting their fellow leaders over supporting their direct reports—that they are responsible to their peers more than they are to their individual teams (
&lt;a href="https://read.readwise.io/read/01grsjmkgbwaczxx7kd1ggaxkd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When your leaders have built trust with each other it becomes significantly easier to manage change, exhibit vulnerability, and solve problems together. (
&lt;a href="https://read.readwise.io/read/01grsjng150xbvksve0ry3vzk3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The more explicit you are about the behaviors you expect from your leaders the better off you’ll be. I make sure I’m clear with my managers about their responsibility to one another (
&lt;a href="https://read.readwise.io/read/01grsk3shtpq2d75fdg0yc1td6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In my day-to-day. I encourage interdependence and normalization of help seeking amongst team members. I constantly encourage my team to talk to one another about their problems, and refer them to each other for help. (
&lt;a href="https://read.readwise.io/read/01grsk57eserk4n4h6s0rdaqnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Manager roundtables are a great way to achieve this as they are spaces specifically designed to share and solve problems collaboratively. (
&lt;a href="https://read.readwise.io/read/01grsk6yjr5reczpdy9hnmbewr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Ciencia De Datos Con R</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Ciencia-De-Datos-Con-R/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Ciencia-De-Datos-Con-R/</guid><description>&lt;h1 id="ciencia-de-datos-con-r">Ciencia De Datos Con R&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Gema Fernández-Avilés y José-María Montero]]&lt;/li>
&lt;li>Full Title: Ciencia De Datos Con R&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://readwise.io/reader/document_raw_content/29455725" rel="noopener">https://readwise.io/reader/document_raw_content/29455725&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>).Esta (
&lt;a href="https://read.readwise.io/read/01gqn3fqj29d7ke2qkhc6k31z6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) (
&lt;a href="https://read.readwise.io/read/01gqn3g1pf4k36dsyneqe11pba" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>as( (
&lt;a href="https://read.readwise.io/read/01gqn3g9f4myfyzf18df84k7xj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>trar (
&lt;a href="https://read.readwise.io/read/01gqn3gqhcmq3fnsb2e69vdjn8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>un (
&lt;a href="https://read.readwise.io/read/01gqn3gyjd9hjzqfp3gtb6j4fw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>difinir (
&lt;a href="https://read.readwise.io/read/01gqn3k3mgzrnrwte0re524krq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Figura ?? (
&lt;a href="https://read.readwise.io/read/01gqn43zpz7ndxd87wmbpwydex" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>@ref{fig:moranplot} (
&lt;a href="https://read.readwise.io/read/01gqn41ytdq95y531r6f20hrwp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>nos( (
&lt;a href="https://read.readwise.io/read/01gqn45nxq3vm7tvd8wkw0dgk3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>heteroscedasticidad (
&lt;a href="https://read.readwise.io/read/01gqn49sqzrp3masj0vyt7f5d7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>muerta l (
&lt;a href="https://read.readwise.io/read/01gqn4bf9n3f7tnwzzdngvvbnz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Create Capacity Rather Than Capture It.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Create-Capacity-Rather-Than-Capture-It./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Create-Capacity-Rather-Than-Capture-It./</guid><description>&lt;h1 id="create-capacity-rather-than-capture-it">Create Capacity Rather Than Capture It.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Create Capacity Rather Than Capture It.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/create-capacity/" rel="noopener">https://lethain.com/create-capacity/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;em>within a large company, it’s more effective to capture existing capacity than to create new capacity&lt;/em>, &lt;em>but the opposite is true in startup and growth companies&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsjcdzc8nxzw1bwknepg5g7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• If you need more headcount, then convince leadership to require every team to send a volunteer to work on your project
• If you’re missing a key leader, oblige a leader on a peer team to move to yours
• Hiring is slow and restrictive, bypass that by recruiting internally instead (
&lt;a href="https://read.readwise.io/read/01grsjem8bkr4nbamww451r6t0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>whereas large companies anticipate a meaningful fraction of projects will fail, growth and startup companies depend on almost all projects succeeding. (
&lt;a href="https://read.readwise.io/read/01grsjg1hb14xge8n3yxxpytxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Create Capacity Rather Than Capture It.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="create-capacity-rather-than-capture-it-1">Create Capacity Rather Than Capture It.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Create Capacity Rather Than Capture It.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/create-capacity/" rel="noopener">https://lethain.com/create-capacity/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;em>within a large company, it’s more effective to capture existing capacity than to create new capacity&lt;/em>, &lt;em>but the opposite is true in startup and growth companies&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsjcdzc8nxzw1bwknepg5g7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• If you need more headcount, then convince leadership to require every team to send a volunteer to work on your project
• If you’re missing a key leader, oblige a leader on a peer team to move to yours
• Hiring is slow and restrictive, bypass that by recruiting internally instead (
&lt;a href="https://read.readwise.io/read/01grsjem8bkr4nbamww451r6t0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>whereas large companies anticipate a meaningful fraction of projects will fail, growth and startup companies depend on almost all projects succeeding. (
&lt;a href="https://read.readwise.io/read/01grsjg1hb14xge8n3yxxpytxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Create Capacity Rather Than Capture It.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="create-capacity-rather-than-capture-it-2">Create Capacity Rather Than Capture It.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Create Capacity Rather Than Capture It.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/create-capacity/" rel="noopener">https://lethain.com/create-capacity/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;em>within a large company, it’s more effective to capture existing capacity than to create new capacity&lt;/em>, &lt;em>but the opposite is true in startup and growth companies&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsjcdzc8nxzw1bwknepg5g7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• If you need more headcount, then convince leadership to require every team to send a volunteer to work on your project
• If you’re missing a key leader, oblige a leader on a peer team to move to yours
• Hiring is slow and restrictive, bypass that by recruiting internally instead (
&lt;a href="https://read.readwise.io/read/01grsjem8bkr4nbamww451r6t0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>whereas large companies anticipate a meaningful fraction of projects will fail, growth and startup companies depend on almost all projects succeeding. (
&lt;a href="https://read.readwise.io/read/01grsjg1hb14xge8n3yxxpytxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Create Capacity Rather Than Capture It.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="create-capacity-rather-than-capture-it-3">Create Capacity Rather Than Capture It.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Create Capacity Rather Than Capture It.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/create-capacity/" rel="noopener">https://lethain.com/create-capacity/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;em>within a large company, it’s more effective to capture existing capacity than to create new capacity&lt;/em>, &lt;em>but the opposite is true in startup and growth companies&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsjcdzc8nxzw1bwknepg5g7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• If you need more headcount, then convince leadership to require every team to send a volunteer to work on your project
• If you’re missing a key leader, oblige a leader on a peer team to move to yours
• Hiring is slow and restrictive, bypass that by recruiting internally instead (
&lt;a href="https://read.readwise.io/read/01grsjem8bkr4nbamww451r6t0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>whereas large companies anticipate a meaningful fraction of projects will fail, growth and startup companies depend on almost all projects succeeding. (
&lt;a href="https://read.readwise.io/read/01grsjg1hb14xge8n3yxxpytxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Data as a Product vs Data Products. What Are the Differences?</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Data-as-a-Product-vs-Data-Products.-What-Are-the-Differences/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Data-as-a-Product-vs-Data-Products.-What-Are-the-Differences/</guid><description>&lt;h1 id="data-as-a-product-vs-data-products-what-are-the-differences">Data as a Product vs Data Products. What Are the Differences?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1000/0*XeHjlfiKO2_w6KYk" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Xavier Gumara Rigol]]&lt;/li>
&lt;li>Full Title: Data as a Product vs Data Products. What Are the Differences?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123" rel="noopener">https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://twitter.com/dpatil" rel="noopener">DJ Patil&lt;/a>, former United States Chief Data Scientist, defined a data product as “a product that facilitates an end goal through the use of data” (from his book &lt;em>Data Jujitsu: The Art of Turning Data into Product,&lt;/em> 2012 (
&lt;a href="https://read.readwise.io/read/01gqcqcr9ry9wz5kdf7mfbp4cq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://twitter.com/Simon_O_Regan" rel="noopener">Simon O’Regan&lt;/a> published an article called
&lt;a href="https://towardsdatascience.com/designing-data-products-b6b93edf3d23" rel="noopener">Designing Data Products&lt;/a> that lists very clear examples of data products and groups them by type: raw data, derived data, algorithms, decision support and automated decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcqdfawncc7ra4yct15swyh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One of the principles of the data mesh paradigm is to consider
&lt;a href="https://martinfowler.com/articles/data-mesh-principles.html#DataAsAProduct" rel="noopener">data as a product&lt;/a>. Sometimes this principle has been abbreviated to “data products”, hence the confusion (
&lt;a href="https://read.readwise.io/read/01gqcqj5ydrpa54rqtq4apfk4m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Xavier Gumara Rigol]]
title: &amp;ldquo;Data as a Product vs Data Products. What Are the Differences?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="data-as-a-product-vs-data-products-what-are-the-differences-1">Data as a Product vs Data Products. What Are the Differences?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1000/0*XeHjlfiKO2_w6KYk" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Xavier Gumara Rigol]]&lt;/li>
&lt;li>Full Title: Data as a Product vs Data Products. What Are the Differences?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123" rel="noopener">https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://twitter.com/dpatil" rel="noopener">DJ Patil&lt;/a>, former United States Chief Data Scientist, defined a data product as “a product that facilitates an end goal through the use of data” (from his book &lt;em>Data Jujitsu: The Art of Turning Data into Product,&lt;/em> 2012 (
&lt;a href="https://read.readwise.io/read/01gqcqcr9ry9wz5kdf7mfbp4cq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://twitter.com/Simon_O_Regan" rel="noopener">Simon O’Regan&lt;/a> published an article called
&lt;a href="https://towardsdatascience.com/designing-data-products-b6b93edf3d23" rel="noopener">Designing Data Products&lt;/a> that lists very clear examples of data products and groups them by type: raw data, derived data, algorithms, decision support and automated decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcqdfawncc7ra4yct15swyh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One of the principles of the data mesh paradigm is to consider
&lt;a href="https://martinfowler.com/articles/data-mesh-principles.html#DataAsAProduct" rel="noopener">data as a product&lt;/a>. Sometimes this principle has been abbreviated to “data products”, hence the confusion (
&lt;a href="https://read.readwise.io/read/01gqcqj5ydrpa54rqtq4apfk4m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Xavier Gumara Rigol]]
title: &amp;ldquo;Data as a Product vs Data Products. What Are the Differences?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="data-as-a-product-vs-data-products-what-are-the-differences-2">Data as a Product vs Data Products. What Are the Differences?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1000/0*XeHjlfiKO2_w6KYk" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Xavier Gumara Rigol]]&lt;/li>
&lt;li>Full Title: Data as a Product vs Data Products. What Are the Differences?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123" rel="noopener">https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://twitter.com/dpatil" rel="noopener">DJ Patil&lt;/a>, former United States Chief Data Scientist, defined a data product as “a product that facilitates an end goal through the use of data” (from his book &lt;em>Data Jujitsu: The Art of Turning Data into Product,&lt;/em> 2012 (
&lt;a href="https://read.readwise.io/read/01gqcqcr9ry9wz5kdf7mfbp4cq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://twitter.com/Simon_O_Regan" rel="noopener">Simon O’Regan&lt;/a> published an article called
&lt;a href="https://towardsdatascience.com/designing-data-products-b6b93edf3d23" rel="noopener">Designing Data Products&lt;/a> that lists very clear examples of data products and groups them by type: raw data, derived data, algorithms, decision support and automated decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcqdfawncc7ra4yct15swyh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One of the principles of the data mesh paradigm is to consider
&lt;a href="https://martinfowler.com/articles/data-mesh-principles.html#DataAsAProduct" rel="noopener">data as a product&lt;/a>. Sometimes this principle has been abbreviated to “data products”, hence the confusion (
&lt;a href="https://read.readwise.io/read/01gqcqj5ydrpa54rqtq4apfk4m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Xavier Gumara Rigol]]
title: &amp;ldquo;Data as a Product vs Data Products. What Are the Differences?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="data-as-a-product-vs-data-products-what-are-the-differences-3">Data as a Product vs Data Products. What Are the Differences?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1000/0*XeHjlfiKO2_w6KYk" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Xavier Gumara Rigol]]&lt;/li>
&lt;li>Full Title: Data as a Product vs Data Products. What Are the Differences?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123" rel="noopener">https://towardsdatascience.com/data-as-a-product-vs-data-products-what-are-the-differences-b43ddbb0f123&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://twitter.com/dpatil" rel="noopener">DJ Patil&lt;/a>, former United States Chief Data Scientist, defined a data product as “a product that facilitates an end goal through the use of data” (from his book &lt;em>Data Jujitsu: The Art of Turning Data into Product,&lt;/em> 2012 (
&lt;a href="https://read.readwise.io/read/01gqcqcr9ry9wz5kdf7mfbp4cq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://twitter.com/Simon_O_Regan" rel="noopener">Simon O’Regan&lt;/a> published an article called
&lt;a href="https://towardsdatascience.com/designing-data-products-b6b93edf3d23" rel="noopener">Designing Data Products&lt;/a> that lists very clear examples of data products and groups them by type: raw data, derived data, algorithms, decision support and automated decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcqdfawncc7ra4yct15swyh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One of the principles of the data mesh paradigm is to consider
&lt;a href="https://martinfowler.com/articles/data-mesh-principles.html#DataAsAProduct" rel="noopener">data as a product&lt;/a>. Sometimes this principle has been abbreviated to “data products”, hence the confusion (
&lt;a href="https://read.readwise.io/read/01gqcqj5ydrpa54rqtq4apfk4m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Data Scientists Work Alone and That&amp;#39;s Bad</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Data-Scientists-Work-Alone-and-Thats-Bad/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Data-Scientists-Work-Alone-and-Thats-Bad/</guid><description>&lt;h1 id="data-scientists-work-alone-and-thats-bad">Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/h1>
&lt;p>
&lt;img src="https://www.ethanrosenthal.com/favicon.ico" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ethan Rosenthal]]&lt;/li>
&lt;li>Full Title: Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This essay discusses the importance of code review in software engineering and the challenges of data science, where the norm is for data scientists to work alone. The author highlights the benefits of code review and collaboration, such as receiving feedback and learning more quickly, and explains the risks of data scientists working alone, such as the difficulty of collaborating and maintenance becoming a massive burden. The author also proposes solutions to make data science more collaborative, such as sharing Jupyter notebooks or setting up regular pair programming sessions.&lt;/li>
&lt;li>URL:
&lt;a href="https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/" rel="noopener">https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>many data scientists like myself who start with scientific programming and then find their way into software engineering are particularly dangerous. We have the ability to pretty much program whatever we want. This makes us prolific which is a terrible trait to combine with sloppy code. (
&lt;a href="https://read.readwise.io/read/01gr4vay0fj50sskzbpca2a5h1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The norm is that of a lonely life for the data scientist. Whether they lie near analytics, machine learning, or elsewhere in the large latent space that spans this ill-defined role, just like in the curse of high-dimensionality, they are likely alone. (
&lt;a href="https://read.readwise.io/read/01gr4vc56f1k5v4jqxb6a9x3fe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Analyses, models, one-off-scripts: all of these endeavors are usually built solo. It’s just hard to collaborate on training a machine learning model. And so, we often work alone. Each project is a
&lt;a href="https://en.wikipedia.org/wiki/Bus_factor" rel="noopener">one-bus&lt;/a> project. Beyond the inherent business risks that this represents, this kinda sucks for learning and development. (
&lt;a href="https://read.readwise.io/read/01gr4vcme5pksbqhdj4fw0sqfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Ethan Rosenthal]]
title: &amp;ldquo;Data Scientists Work Alone and That's Bad&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="data-scientists-work-alone-and-thats-bad-1">Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/h1>
&lt;p>
&lt;img src="https://www.ethanrosenthal.com/favicon.ico" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ethan Rosenthal]]&lt;/li>
&lt;li>Full Title: Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This essay discusses the importance of code review in software engineering and the challenges of data science, where the norm is for data scientists to work alone. The author highlights the benefits of code review and collaboration, such as receiving feedback and learning more quickly, and explains the risks of data scientists working alone, such as the difficulty of collaborating and maintenance becoming a massive burden. The author also proposes solutions to make data science more collaborative, such as sharing Jupyter notebooks or setting up regular pair programming sessions.&lt;/li>
&lt;li>URL:
&lt;a href="https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/" rel="noopener">https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>many data scientists like myself who start with scientific programming and then find their way into software engineering are particularly dangerous. We have the ability to pretty much program whatever we want. This makes us prolific which is a terrible trait to combine with sloppy code. (
&lt;a href="https://read.readwise.io/read/01gr4vay0fj50sskzbpca2a5h1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The norm is that of a lonely life for the data scientist. Whether they lie near analytics, machine learning, or elsewhere in the large latent space that spans this ill-defined role, just like in the curse of high-dimensionality, they are likely alone. (
&lt;a href="https://read.readwise.io/read/01gr4vc56f1k5v4jqxb6a9x3fe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Analyses, models, one-off-scripts: all of these endeavors are usually built solo. It’s just hard to collaborate on training a machine learning model. And so, we often work alone. Each project is a
&lt;a href="https://en.wikipedia.org/wiki/Bus_factor" rel="noopener">one-bus&lt;/a> project. Beyond the inherent business risks that this represents, this kinda sucks for learning and development. (
&lt;a href="https://read.readwise.io/read/01gr4vcme5pksbqhdj4fw0sqfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Ethan Rosenthal]]
title: &amp;ldquo;Data Scientists Work Alone and That's Bad&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="data-scientists-work-alone-and-thats-bad-2">Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/h1>
&lt;p>
&lt;img src="https://www.ethanrosenthal.com/favicon.ico" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ethan Rosenthal]]&lt;/li>
&lt;li>Full Title: Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This essay discusses the importance of code review in software engineering and the challenges of data science, where the norm is for data scientists to work alone. The author highlights the benefits of code review and collaboration, such as receiving feedback and learning more quickly, and explains the risks of data scientists working alone, such as the difficulty of collaborating and maintenance becoming a massive burden. The author also proposes solutions to make data science more collaborative, such as sharing Jupyter notebooks or setting up regular pair programming sessions.&lt;/li>
&lt;li>URL:
&lt;a href="https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/" rel="noopener">https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>many data scientists like myself who start with scientific programming and then find their way into software engineering are particularly dangerous. We have the ability to pretty much program whatever we want. This makes us prolific which is a terrible trait to combine with sloppy code. (
&lt;a href="https://read.readwise.io/read/01gr4vay0fj50sskzbpca2a5h1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The norm is that of a lonely life for the data scientist. Whether they lie near analytics, machine learning, or elsewhere in the large latent space that spans this ill-defined role, just like in the curse of high-dimensionality, they are likely alone. (
&lt;a href="https://read.readwise.io/read/01gr4vc56f1k5v4jqxb6a9x3fe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Analyses, models, one-off-scripts: all of these endeavors are usually built solo. It’s just hard to collaborate on training a machine learning model. And so, we often work alone. Each project is a
&lt;a href="https://en.wikipedia.org/wiki/Bus_factor" rel="noopener">one-bus&lt;/a> project. Beyond the inherent business risks that this represents, this kinda sucks for learning and development. (
&lt;a href="https://read.readwise.io/read/01gr4vcme5pksbqhdj4fw0sqfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Ethan Rosenthal]]
title: &amp;ldquo;Data Scientists Work Alone and That's Bad&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="data-scientists-work-alone-and-thats-bad-3">Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/h1>
&lt;p>
&lt;img src="https://www.ethanrosenthal.com/favicon.ico" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ethan Rosenthal]]&lt;/li>
&lt;li>Full Title: Data Scientists Work Alone and That&amp;rsquo;s Bad&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This essay discusses the importance of code review in software engineering and the challenges of data science, where the norm is for data scientists to work alone. The author highlights the benefits of code review and collaboration, such as receiving feedback and learning more quickly, and explains the risks of data scientists working alone, such as the difficulty of collaborating and maintenance becoming a massive burden. The author also proposes solutions to make data science more collaborative, such as sharing Jupyter notebooks or setting up regular pair programming sessions.&lt;/li>
&lt;li>URL:
&lt;a href="https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/" rel="noopener">https://www.ethanrosenthal.com/2023/01/10/data-scientists-alone/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>many data scientists like myself who start with scientific programming and then find their way into software engineering are particularly dangerous. We have the ability to pretty much program whatever we want. This makes us prolific which is a terrible trait to combine with sloppy code. (
&lt;a href="https://read.readwise.io/read/01gr4vay0fj50sskzbpca2a5h1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The norm is that of a lonely life for the data scientist. Whether they lie near analytics, machine learning, or elsewhere in the large latent space that spans this ill-defined role, just like in the curse of high-dimensionality, they are likely alone. (
&lt;a href="https://read.readwise.io/read/01gr4vc56f1k5v4jqxb6a9x3fe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Analyses, models, one-off-scripts: all of these endeavors are usually built solo. It’s just hard to collaborate on training a machine learning model. And so, we often work alone. Each project is a
&lt;a href="https://en.wikipedia.org/wiki/Bus_factor" rel="noopener">one-bus&lt;/a> project. Beyond the inherent business risks that this represents, this kinda sucks for learning and development. (
&lt;a href="https://read.readwise.io/read/01gr4vcme5pksbqhdj4fw0sqfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Dear Stakeholder</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Dear-Stakeholder/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Dear-Stakeholder/</guid><description>&lt;h1 id="dear-stakeholder">Dear Stakeholder&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6db2c91c-f476-4828-aed3-4814666c2c2e_1969x947.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Jayatillake]]&lt;/li>
&lt;li>Full Title: Dear Stakeholder&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://davidsj.substack.com/p/dear-stakeholder" rel="noopener">https://davidsj.substack.com/p/dear-stakeholder&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>When you ask us for help, tell us what you’re trying to achieve.&lt;/strong> Don’t just say “I need this piece of data”… tell us that you’re trying to achieve this higher level goal that you believe will be enhanced or achieved by X outcome, where you could use data to make a more optimal decision or enrich your product. (
&lt;a href="https://read.readwise.io/read/01gqb84kc1kkxh97qa2pfgqq06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>-serve data is, by nature, meant to deal with relatively simple requests - if the question you are trying to answer in one table or graph is beyond &lt;em>“I want to see this metric/s split by these dimensions, possibly with some table calculations on top like running totals”&lt;/em>, then the chances are you need help, where we will build you something more advanced. (
&lt;a href="https://read.readwise.io/read/01gqb87tf515q4h4s3sb932ndy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Not every data person knows the business like you do - they have to know a lot of other things.&lt;/strong> Some Data Analysts and Analytics Engineers may know some parts of the business very well, perhaps as well as you, but it’s rare for any data person to know their whole business to a great degree of detail. Data folks are trying to align the world in the data systems AND the actual world, this is rarely (read never) straightforward (
&lt;a href="https://read.readwise.io/read/01gqb892jt7ye7d8m2ss6g9b2w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Question whether the work you are asking for is worth the total cost.&lt;/strong> Data resource is scarce, and often what you think may be a low cost piece of work is actually much higher. Be clear about whether this is a one-off piece of work or something that will need to live on. (
&lt;a href="https://read.readwise.io/read/01gqb8b5ntf4fvtdhh535nbg1w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Data infra work can, should and often does have a long-term positive ROI in being a multiplier on future capacity or capability.&lt;/strong> It also increases work satisfaction in the data team - in my experience, data folks are neat creatures… they want their repos and workspaces to be as clean as possible. Ignoring data infra work for the long-term is perilous, as it results in lower efficiency, lower satisfaction in the data team… a recipe for turnover and failure. (
&lt;a href="https://read.readwise.io/read/01gqb8g5tjezfh0zxgva3s64xd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[David Jayatillake]]
title: &amp;ldquo;Dear Stakeholder&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="dear-stakeholder-1">Dear Stakeholder&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6db2c91c-f476-4828-aed3-4814666c2c2e_1969x947.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Jayatillake]]&lt;/li>
&lt;li>Full Title: Dear Stakeholder&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://davidsj.substack.com/p/dear-stakeholder" rel="noopener">https://davidsj.substack.com/p/dear-stakeholder&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>When you ask us for help, tell us what you’re trying to achieve.&lt;/strong> Don’t just say “I need this piece of data”… tell us that you’re trying to achieve this higher level goal that you believe will be enhanced or achieved by X outcome, where you could use data to make a more optimal decision or enrich your product. (
&lt;a href="https://read.readwise.io/read/01gqb84kc1kkxh97qa2pfgqq06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>-serve data is, by nature, meant to deal with relatively simple requests - if the question you are trying to answer in one table or graph is beyond &lt;em>“I want to see this metric/s split by these dimensions, possibly with some table calculations on top like running totals”&lt;/em>, then the chances are you need help, where we will build you something more advanced. (
&lt;a href="https://read.readwise.io/read/01gqb87tf515q4h4s3sb932ndy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Not every data person knows the business like you do - they have to know a lot of other things.&lt;/strong> Some Data Analysts and Analytics Engineers may know some parts of the business very well, perhaps as well as you, but it’s rare for any data person to know their whole business to a great degree of detail. Data folks are trying to align the world in the data systems AND the actual world, this is rarely (read never) straightforward (
&lt;a href="https://read.readwise.io/read/01gqb892jt7ye7d8m2ss6g9b2w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Question whether the work you are asking for is worth the total cost.&lt;/strong> Data resource is scarce, and often what you think may be a low cost piece of work is actually much higher. Be clear about whether this is a one-off piece of work or something that will need to live on. (
&lt;a href="https://read.readwise.io/read/01gqb8b5ntf4fvtdhh535nbg1w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Data infra work can, should and often does have a long-term positive ROI in being a multiplier on future capacity or capability.&lt;/strong> It also increases work satisfaction in the data team - in my experience, data folks are neat creatures… they want their repos and workspaces to be as clean as possible. Ignoring data infra work for the long-term is perilous, as it results in lower efficiency, lower satisfaction in the data team… a recipe for turnover and failure. (
&lt;a href="https://read.readwise.io/read/01gqb8g5tjezfh0zxgva3s64xd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[David Jayatillake]]
title: &amp;ldquo;Dear Stakeholder&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="dear-stakeholder-2">Dear Stakeholder&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6db2c91c-f476-4828-aed3-4814666c2c2e_1969x947.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Jayatillake]]&lt;/li>
&lt;li>Full Title: Dear Stakeholder&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://davidsj.substack.com/p/dear-stakeholder" rel="noopener">https://davidsj.substack.com/p/dear-stakeholder&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>When you ask us for help, tell us what you’re trying to achieve.&lt;/strong> Don’t just say “I need this piece of data”… tell us that you’re trying to achieve this higher level goal that you believe will be enhanced or achieved by X outcome, where you could use data to make a more optimal decision or enrich your product. (
&lt;a href="https://read.readwise.io/read/01gqb84kc1kkxh97qa2pfgqq06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>-serve data is, by nature, meant to deal with relatively simple requests - if the question you are trying to answer in one table or graph is beyond &lt;em>“I want to see this metric/s split by these dimensions, possibly with some table calculations on top like running totals”&lt;/em>, then the chances are you need help, where we will build you something more advanced. (
&lt;a href="https://read.readwise.io/read/01gqb87tf515q4h4s3sb932ndy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Not every data person knows the business like you do - they have to know a lot of other things.&lt;/strong> Some Data Analysts and Analytics Engineers may know some parts of the business very well, perhaps as well as you, but it’s rare for any data person to know their whole business to a great degree of detail. Data folks are trying to align the world in the data systems AND the actual world, this is rarely (read never) straightforward (
&lt;a href="https://read.readwise.io/read/01gqb892jt7ye7d8m2ss6g9b2w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Question whether the work you are asking for is worth the total cost.&lt;/strong> Data resource is scarce, and often what you think may be a low cost piece of work is actually much higher. Be clear about whether this is a one-off piece of work or something that will need to live on. (
&lt;a href="https://read.readwise.io/read/01gqb8b5ntf4fvtdhh535nbg1w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Data infra work can, should and often does have a long-term positive ROI in being a multiplier on future capacity or capability.&lt;/strong> It also increases work satisfaction in the data team - in my experience, data folks are neat creatures… they want their repos and workspaces to be as clean as possible. Ignoring data infra work for the long-term is perilous, as it results in lower efficiency, lower satisfaction in the data team… a recipe for turnover and failure. (
&lt;a href="https://read.readwise.io/read/01gqb8g5tjezfh0zxgva3s64xd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[David Jayatillake]]
title: &amp;ldquo;Dear Stakeholder&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="dear-stakeholder-3">Dear Stakeholder&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6db2c91c-f476-4828-aed3-4814666c2c2e_1969x947.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Jayatillake]]&lt;/li>
&lt;li>Full Title: Dear Stakeholder&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://davidsj.substack.com/p/dear-stakeholder" rel="noopener">https://davidsj.substack.com/p/dear-stakeholder&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>When you ask us for help, tell us what you’re trying to achieve.&lt;/strong> Don’t just say “I need this piece of data”… tell us that you’re trying to achieve this higher level goal that you believe will be enhanced or achieved by X outcome, where you could use data to make a more optimal decision or enrich your product. (
&lt;a href="https://read.readwise.io/read/01gqb84kc1kkxh97qa2pfgqq06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>-serve data is, by nature, meant to deal with relatively simple requests - if the question you are trying to answer in one table or graph is beyond &lt;em>“I want to see this metric/s split by these dimensions, possibly with some table calculations on top like running totals”&lt;/em>, then the chances are you need help, where we will build you something more advanced. (
&lt;a href="https://read.readwise.io/read/01gqb87tf515q4h4s3sb932ndy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Not every data person knows the business like you do - they have to know a lot of other things.&lt;/strong> Some Data Analysts and Analytics Engineers may know some parts of the business very well, perhaps as well as you, but it’s rare for any data person to know their whole business to a great degree of detail. Data folks are trying to align the world in the data systems AND the actual world, this is rarely (read never) straightforward (
&lt;a href="https://read.readwise.io/read/01gqb892jt7ye7d8m2ss6g9b2w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Question whether the work you are asking for is worth the total cost.&lt;/strong> Data resource is scarce, and often what you think may be a low cost piece of work is actually much higher. Be clear about whether this is a one-off piece of work or something that will need to live on. (
&lt;a href="https://read.readwise.io/read/01gqb8b5ntf4fvtdhh535nbg1w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Data infra work can, should and often does have a long-term positive ROI in being a multiplier on future capacity or capability.&lt;/strong> It also increases work satisfaction in the data team - in my experience, data folks are neat creatures… they want their repos and workspaces to be as clean as possible. Ignoring data infra work for the long-term is perilous, as it results in lower efficiency, lower satisfaction in the data team… a recipe for turnover and failure. (
&lt;a href="https://read.readwise.io/read/01gqb8g5tjezfh0zxgva3s64xd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Directly Responsible Individuals</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Directly-Responsible-Individuals/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Directly-Responsible-Individuals/</guid><description>&lt;h1 id="directly-responsible-individuals">Directly Responsible Individuals&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/296/1*W2RuZK6h6qAkMyyXGc7J7g.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Matthew Mamet]]&lt;/li>
&lt;li>Full Title: Directly Responsible Individuals&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4" rel="noopener">https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Fostering a culture of accountability within the team (people do what they say they will do) is key for effective product management over the long haul. (
&lt;a href="https://read.readwise.io/read/01grw0zdg1wpq21jvkkmgbavcd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When I’m the DRI on a task, it can sometimes come with a bit of apprehension (&lt;em>Gulp&lt;/em>, not 100% sure how I’m going to do that . . .but ok I’ll figure it out), or maybe with a bit of grumbling (oh man, I guess I gotta do that too), but being the DRI always comes with a sense of responsibility to the team. (
&lt;a href="https://read.readwise.io/read/01grw1477t6qncxnrnzcwym8qn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When sending email, we are more deliberate with the use of To: vs. CC: fields. The DRI(s) are in the To: list. Everyone else is CC’d. (
&lt;a href="https://read.readwise.io/read/01grw14m27rbbxsscnye1wj4gg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>am I understood by the team to be the DRI on this and should therefore take ownership of reply or resolution?” as opposed to thinking “someone else will probably handle this.” (
&lt;a href="https://read.readwise.io/read/01grw14yed0vgg1pgbhk385215" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When working on a new or particularly complex problem where the DRI is not yet known, we seek to establish the DRI early in the discussion. (
&lt;a href="https://read.readwise.io/read/01grw159yvytdzt4hm3pej9m5b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we gather in meetings, we always leave with action items or next steps. (
&lt;a href="https://read.readwise.io/read/01grw162fsm1q5x80a7mqe51j2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Matthew Mamet]]
title: &amp;ldquo;Directly Responsible Individuals&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="directly-responsible-individuals-1">Directly Responsible Individuals&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/296/1*W2RuZK6h6qAkMyyXGc7J7g.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Matthew Mamet]]&lt;/li>
&lt;li>Full Title: Directly Responsible Individuals&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4" rel="noopener">https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Fostering a culture of accountability within the team (people do what they say they will do) is key for effective product management over the long haul. (
&lt;a href="https://read.readwise.io/read/01grw0zdg1wpq21jvkkmgbavcd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When I’m the DRI on a task, it can sometimes come with a bit of apprehension (&lt;em>Gulp&lt;/em>, not 100% sure how I’m going to do that . . .but ok I’ll figure it out), or maybe with a bit of grumbling (oh man, I guess I gotta do that too), but being the DRI always comes with a sense of responsibility to the team. (
&lt;a href="https://read.readwise.io/read/01grw1477t6qncxnrnzcwym8qn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When sending email, we are more deliberate with the use of To: vs. CC: fields. The DRI(s) are in the To: list. Everyone else is CC’d. (
&lt;a href="https://read.readwise.io/read/01grw14m27rbbxsscnye1wj4gg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>am I understood by the team to be the DRI on this and should therefore take ownership of reply or resolution?” as opposed to thinking “someone else will probably handle this.” (
&lt;a href="https://read.readwise.io/read/01grw14yed0vgg1pgbhk385215" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When working on a new or particularly complex problem where the DRI is not yet known, we seek to establish the DRI early in the discussion. (
&lt;a href="https://read.readwise.io/read/01grw159yvytdzt4hm3pej9m5b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we gather in meetings, we always leave with action items or next steps. (
&lt;a href="https://read.readwise.io/read/01grw162fsm1q5x80a7mqe51j2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Matthew Mamet]]
title: &amp;ldquo;Directly Responsible Individuals&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="directly-responsible-individuals-2">Directly Responsible Individuals&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/296/1*W2RuZK6h6qAkMyyXGc7J7g.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Matthew Mamet]]&lt;/li>
&lt;li>Full Title: Directly Responsible Individuals&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4" rel="noopener">https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Fostering a culture of accountability within the team (people do what they say they will do) is key for effective product management over the long haul. (
&lt;a href="https://read.readwise.io/read/01grw0zdg1wpq21jvkkmgbavcd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When I’m the DRI on a task, it can sometimes come with a bit of apprehension (&lt;em>Gulp&lt;/em>, not 100% sure how I’m going to do that . . .but ok I’ll figure it out), or maybe with a bit of grumbling (oh man, I guess I gotta do that too), but being the DRI always comes with a sense of responsibility to the team. (
&lt;a href="https://read.readwise.io/read/01grw1477t6qncxnrnzcwym8qn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When sending email, we are more deliberate with the use of To: vs. CC: fields. The DRI(s) are in the To: list. Everyone else is CC’d. (
&lt;a href="https://read.readwise.io/read/01grw14m27rbbxsscnye1wj4gg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>am I understood by the team to be the DRI on this and should therefore take ownership of reply or resolution?” as opposed to thinking “someone else will probably handle this.” (
&lt;a href="https://read.readwise.io/read/01grw14yed0vgg1pgbhk385215" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When working on a new or particularly complex problem where the DRI is not yet known, we seek to establish the DRI early in the discussion. (
&lt;a href="https://read.readwise.io/read/01grw159yvytdzt4hm3pej9m5b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we gather in meetings, we always leave with action items or next steps. (
&lt;a href="https://read.readwise.io/read/01grw162fsm1q5x80a7mqe51j2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Matthew Mamet]]
title: &amp;ldquo;Directly Responsible Individuals&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="directly-responsible-individuals-3">Directly Responsible Individuals&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/296/1*W2RuZK6h6qAkMyyXGc7J7g.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Matthew Mamet]]&lt;/li>
&lt;li>Full Title: Directly Responsible Individuals&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4" rel="noopener">https://medium.com/@mmamet/directly-responsible-individuals-f5009f465da4&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Fostering a culture of accountability within the team (people do what they say they will do) is key for effective product management over the long haul. (
&lt;a href="https://read.readwise.io/read/01grw0zdg1wpq21jvkkmgbavcd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When I’m the DRI on a task, it can sometimes come with a bit of apprehension (&lt;em>Gulp&lt;/em>, not 100% sure how I’m going to do that . . .but ok I’ll figure it out), or maybe with a bit of grumbling (oh man, I guess I gotta do that too), but being the DRI always comes with a sense of responsibility to the team. (
&lt;a href="https://read.readwise.io/read/01grw1477t6qncxnrnzcwym8qn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When sending email, we are more deliberate with the use of To: vs. CC: fields. The DRI(s) are in the To: list. Everyone else is CC’d. (
&lt;a href="https://read.readwise.io/read/01grw14m27rbbxsscnye1wj4gg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>am I understood by the team to be the DRI on this and should therefore take ownership of reply or resolution?” as opposed to thinking “someone else will probably handle this.” (
&lt;a href="https://read.readwise.io/read/01grw14yed0vgg1pgbhk385215" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When working on a new or particularly complex problem where the DRI is not yet known, we seek to establish the DRI early in the discussion. (
&lt;a href="https://read.readwise.io/read/01grw159yvytdzt4hm3pej9m5b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we gather in meetings, we always leave with action items or next steps. (
&lt;a href="https://read.readwise.io/read/01grw162fsm1q5x80a7mqe51j2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Do Data Teams Have Product-Market Fit?</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Do-Data-Teams-Have-Product-Market-Fit/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Do-Data-Teams-Have-Product-Market-Fit/</guid><description>&lt;h1 id="do-data-teams-have-product-market-fit">Do Data Teams Have Product-Market Fit?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f7a7a28-ed5d-48e5-85f3-da4f47dba055_681x383.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Benn Stancil]]&lt;/li>
&lt;li>Full Title: Do Data Teams Have Product-Market Fit?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;amp;utm_medium=email" rel="noopener">https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;utm_medium=email&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Initial customers show up for unique reasons, and their interests aren’t representative of what other people want. The further the company gets from that group, the more it struggles to sell. (
&lt;a href="https://read.readwise.io/read/01gqafftwnza9k98wt409syref" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">Katie Bauer’s recent post&lt;/a> about data teams being left on the sidelines is excellent—and depressingly evergreen. Two years ago, Erik Bernhardsson
&lt;a href="https://erikbern.com/2021/07/07/the-data-team-a-short-story.html" rel="noopener">wrote a story&lt;/a> about navigating the same problems of being misunderstood, left out, and asked to do the wrong work (
&lt;a href="https://read.readwise.io/read/01gqafph785fh3qv9qjkc0j3qk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For as long as we&amp;rsquo;ve had analytics and BI teams, we&amp;rsquo;ve tried to create
&lt;a href="https://chartio.com/blog/3-steps-to-prioritizing-data-requests/" rel="noopener">good processes&lt;/a> for people to ask them questions. We’ve
&lt;a href="https://www.caitlinhudon.com/posts/2020/09/16/data-intake-form" rel="noopener">shared intake forms&lt;/a>. We’ve
&lt;a href="https://www.secoda.co/data-ticketing" rel="noopener">built products&lt;/a>. And yet, most data teams still can’t convince their business partners to regularly use them, and our most common ticket management system
&lt;a href="https://twitter.com/imightbemary/status/1614663474113806338" rel="noopener">is still Slack DMs&lt;/a>. We’ve put self-serve interfaces between us and everyone else, and declared it
&lt;a href="https://www.reddit.com/r/BusinessIntelligence/comments/9zjhm2/how_much_of_a_disaster_has_selfservice_bi_been_in/" rel="noopener">disaster&lt;/a>—no,
&lt;a href="https://www.businesswire.com/news/home/20220112005334/en/New-Report-Finds-Self-Service-Analytics-Are-Critical-to-Empowering-Frontline-Workers-with-Data-Driven-Decisions-and-Autonomy" rel="noopener">critical&lt;/a>—no,
&lt;a href="https://www.montecarlodata.com/blog-is-self-service-datas-biggest-lie/" rel="noopener">a lie&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqafqynzfq0t8ezm95gkrjg5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Products that have product-market fit
&lt;a href="https://a16z.com/2017/02/18/12-things-about-product-market-fit-2/#:~:text=%234-%E2%80%9CYou-can,Buck%E2%80%99s.%E2%80%9D-Marc-Andreessen" rel="noopener">are bought, not sold&lt;/a>. And as people’s responses to posts like those from Katie and Erik show, most data teams still have to do an awful lot of selling. (
&lt;a href="https://read.readwise.io/read/01gqafs2bxs3nj2fedjfkcmdkx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we want to be in the
&lt;a href="https://www.youtube.com/watch?v=qrkwgEUXyTU" rel="noopener">room where it happens&lt;/a>, we shouldn’t spend our time trying to sell an unnecessary service to a reluctant buyer; we should spend it figuring out what we can do that would make it necessary for us to be there. (
&lt;a href="https://read.readwise.io/read/01gqafvpvw7n9x8s2rpgtf4bk0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The corollary to both of these points is that we have to talk to our customers. We have to research them; understand them; put ourselves in their shoes and figure out why they do what they do. When they push us aside, we shouldn’t assume that we’re offering something valuable—strategic advice! Metrics and alignment! Experimentation and the scientific method!—and our job is to sell it; we should instead ask them why they don’t want it.
The answers may surprise us. Our advice might be bad.
&lt;a href="https://commoncog.com/goodharts-law-not-useful/" rel="noopener">Metrics might not be that useful.&lt;/a> We might create more disruption and doubt than we do agreement and alignment. If there’s a case to be made for
&lt;a href="https://twitter.com/imightbemary/status/1614663891501580292" rel="noopener">hiring a data PM&lt;/a>, this is it—to do
&lt;a href="https://www.gong.io/blog/what-is-a-discovery-call/" rel="noopener">discovery&lt;/a>, and figure out what people actually want from a data team. (
&lt;a href="https://read.readwise.io/read/01gqafy17kp5dd3zrzy5ambcrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Benn Stancil]]
title: &amp;ldquo;Do Data Teams Have Product-Market Fit?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="do-data-teams-have-product-market-fit-1">Do Data Teams Have Product-Market Fit?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f7a7a28-ed5d-48e5-85f3-da4f47dba055_681x383.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Benn Stancil]]&lt;/li>
&lt;li>Full Title: Do Data Teams Have Product-Market Fit?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;amp;utm_medium=email" rel="noopener">https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;utm_medium=email&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Initial customers show up for unique reasons, and their interests aren’t representative of what other people want. The further the company gets from that group, the more it struggles to sell. (
&lt;a href="https://read.readwise.io/read/01gqafftwnza9k98wt409syref" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">Katie Bauer’s recent post&lt;/a> about data teams being left on the sidelines is excellent—and depressingly evergreen. Two years ago, Erik Bernhardsson
&lt;a href="https://erikbern.com/2021/07/07/the-data-team-a-short-story.html" rel="noopener">wrote a story&lt;/a> about navigating the same problems of being misunderstood, left out, and asked to do the wrong work (
&lt;a href="https://read.readwise.io/read/01gqafph785fh3qv9qjkc0j3qk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For as long as we&amp;rsquo;ve had analytics and BI teams, we&amp;rsquo;ve tried to create
&lt;a href="https://chartio.com/blog/3-steps-to-prioritizing-data-requests/" rel="noopener">good processes&lt;/a> for people to ask them questions. We’ve
&lt;a href="https://www.caitlinhudon.com/posts/2020/09/16/data-intake-form" rel="noopener">shared intake forms&lt;/a>. We’ve
&lt;a href="https://www.secoda.co/data-ticketing" rel="noopener">built products&lt;/a>. And yet, most data teams still can’t convince their business partners to regularly use them, and our most common ticket management system
&lt;a href="https://twitter.com/imightbemary/status/1614663474113806338" rel="noopener">is still Slack DMs&lt;/a>. We’ve put self-serve interfaces between us and everyone else, and declared it
&lt;a href="https://www.reddit.com/r/BusinessIntelligence/comments/9zjhm2/how_much_of_a_disaster_has_selfservice_bi_been_in/" rel="noopener">disaster&lt;/a>—no,
&lt;a href="https://www.businesswire.com/news/home/20220112005334/en/New-Report-Finds-Self-Service-Analytics-Are-Critical-to-Empowering-Frontline-Workers-with-Data-Driven-Decisions-and-Autonomy" rel="noopener">critical&lt;/a>—no,
&lt;a href="https://www.montecarlodata.com/blog-is-self-service-datas-biggest-lie/" rel="noopener">a lie&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqafqynzfq0t8ezm95gkrjg5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Products that have product-market fit
&lt;a href="https://a16z.com/2017/02/18/12-things-about-product-market-fit-2/#:~:text=%234-%E2%80%9CYou-can,Buck%E2%80%99s.%E2%80%9D-Marc-Andreessen" rel="noopener">are bought, not sold&lt;/a>. And as people’s responses to posts like those from Katie and Erik show, most data teams still have to do an awful lot of selling. (
&lt;a href="https://read.readwise.io/read/01gqafs2bxs3nj2fedjfkcmdkx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we want to be in the
&lt;a href="https://www.youtube.com/watch?v=qrkwgEUXyTU" rel="noopener">room where it happens&lt;/a>, we shouldn’t spend our time trying to sell an unnecessary service to a reluctant buyer; we should spend it figuring out what we can do that would make it necessary for us to be there. (
&lt;a href="https://read.readwise.io/read/01gqafvpvw7n9x8s2rpgtf4bk0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The corollary to both of these points is that we have to talk to our customers. We have to research them; understand them; put ourselves in their shoes and figure out why they do what they do. When they push us aside, we shouldn’t assume that we’re offering something valuable—strategic advice! Metrics and alignment! Experimentation and the scientific method!—and our job is to sell it; we should instead ask them why they don’t want it.
The answers may surprise us. Our advice might be bad.
&lt;a href="https://commoncog.com/goodharts-law-not-useful/" rel="noopener">Metrics might not be that useful.&lt;/a> We might create more disruption and doubt than we do agreement and alignment. If there’s a case to be made for
&lt;a href="https://twitter.com/imightbemary/status/1614663891501580292" rel="noopener">hiring a data PM&lt;/a>, this is it—to do
&lt;a href="https://www.gong.io/blog/what-is-a-discovery-call/" rel="noopener">discovery&lt;/a>, and figure out what people actually want from a data team. (
&lt;a href="https://read.readwise.io/read/01gqafy17kp5dd3zrzy5ambcrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Benn Stancil]]
title: &amp;ldquo;Do Data Teams Have Product-Market Fit?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="do-data-teams-have-product-market-fit-2">Do Data Teams Have Product-Market Fit?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f7a7a28-ed5d-48e5-85f3-da4f47dba055_681x383.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Benn Stancil]]&lt;/li>
&lt;li>Full Title: Do Data Teams Have Product-Market Fit?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;amp;utm_medium=email" rel="noopener">https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;utm_medium=email&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Initial customers show up for unique reasons, and their interests aren’t representative of what other people want. The further the company gets from that group, the more it struggles to sell. (
&lt;a href="https://read.readwise.io/read/01gqafftwnza9k98wt409syref" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">Katie Bauer’s recent post&lt;/a> about data teams being left on the sidelines is excellent—and depressingly evergreen. Two years ago, Erik Bernhardsson
&lt;a href="https://erikbern.com/2021/07/07/the-data-team-a-short-story.html" rel="noopener">wrote a story&lt;/a> about navigating the same problems of being misunderstood, left out, and asked to do the wrong work (
&lt;a href="https://read.readwise.io/read/01gqafph785fh3qv9qjkc0j3qk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For as long as we&amp;rsquo;ve had analytics and BI teams, we&amp;rsquo;ve tried to create
&lt;a href="https://chartio.com/blog/3-steps-to-prioritizing-data-requests/" rel="noopener">good processes&lt;/a> for people to ask them questions. We’ve
&lt;a href="https://www.caitlinhudon.com/posts/2020/09/16/data-intake-form" rel="noopener">shared intake forms&lt;/a>. We’ve
&lt;a href="https://www.secoda.co/data-ticketing" rel="noopener">built products&lt;/a>. And yet, most data teams still can’t convince their business partners to regularly use them, and our most common ticket management system
&lt;a href="https://twitter.com/imightbemary/status/1614663474113806338" rel="noopener">is still Slack DMs&lt;/a>. We’ve put self-serve interfaces between us and everyone else, and declared it
&lt;a href="https://www.reddit.com/r/BusinessIntelligence/comments/9zjhm2/how_much_of_a_disaster_has_selfservice_bi_been_in/" rel="noopener">disaster&lt;/a>—no,
&lt;a href="https://www.businesswire.com/news/home/20220112005334/en/New-Report-Finds-Self-Service-Analytics-Are-Critical-to-Empowering-Frontline-Workers-with-Data-Driven-Decisions-and-Autonomy" rel="noopener">critical&lt;/a>—no,
&lt;a href="https://www.montecarlodata.com/blog-is-self-service-datas-biggest-lie/" rel="noopener">a lie&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqafqynzfq0t8ezm95gkrjg5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Products that have product-market fit
&lt;a href="https://a16z.com/2017/02/18/12-things-about-product-market-fit-2/#:~:text=%234-%E2%80%9CYou-can,Buck%E2%80%99s.%E2%80%9D-Marc-Andreessen" rel="noopener">are bought, not sold&lt;/a>. And as people’s responses to posts like those from Katie and Erik show, most data teams still have to do an awful lot of selling. (
&lt;a href="https://read.readwise.io/read/01gqafs2bxs3nj2fedjfkcmdkx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we want to be in the
&lt;a href="https://www.youtube.com/watch?v=qrkwgEUXyTU" rel="noopener">room where it happens&lt;/a>, we shouldn’t spend our time trying to sell an unnecessary service to a reluctant buyer; we should spend it figuring out what we can do that would make it necessary for us to be there. (
&lt;a href="https://read.readwise.io/read/01gqafvpvw7n9x8s2rpgtf4bk0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The corollary to both of these points is that we have to talk to our customers. We have to research them; understand them; put ourselves in their shoes and figure out why they do what they do. When they push us aside, we shouldn’t assume that we’re offering something valuable—strategic advice! Metrics and alignment! Experimentation and the scientific method!—and our job is to sell it; we should instead ask them why they don’t want it.
The answers may surprise us. Our advice might be bad.
&lt;a href="https://commoncog.com/goodharts-law-not-useful/" rel="noopener">Metrics might not be that useful.&lt;/a> We might create more disruption and doubt than we do agreement and alignment. If there’s a case to be made for
&lt;a href="https://twitter.com/imightbemary/status/1614663891501580292" rel="noopener">hiring a data PM&lt;/a>, this is it—to do
&lt;a href="https://www.gong.io/blog/what-is-a-discovery-call/" rel="noopener">discovery&lt;/a>, and figure out what people actually want from a data team. (
&lt;a href="https://read.readwise.io/read/01gqafy17kp5dd3zrzy5ambcrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Benn Stancil]]
title: &amp;ldquo;Do Data Teams Have Product-Market Fit?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="do-data-teams-have-product-market-fit-3">Do Data Teams Have Product-Market Fit?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f7a7a28-ed5d-48e5-85f3-da4f47dba055_681x383.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Benn Stancil]]&lt;/li>
&lt;li>Full Title: Do Data Teams Have Product-Market Fit?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;amp;utm_medium=email" rel="noopener">https://benn.substack.com/p/data-teams-product-market-fit?utm_source=substack&amp;utm_medium=email&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Initial customers show up for unique reasons, and their interests aren’t representative of what other people want. The further the company gets from that group, the more it struggles to sell. (
&lt;a href="https://read.readwise.io/read/01gqafftwnza9k98wt409syref" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">Katie Bauer’s recent post&lt;/a> about data teams being left on the sidelines is excellent—and depressingly evergreen. Two years ago, Erik Bernhardsson
&lt;a href="https://erikbern.com/2021/07/07/the-data-team-a-short-story.html" rel="noopener">wrote a story&lt;/a> about navigating the same problems of being misunderstood, left out, and asked to do the wrong work (
&lt;a href="https://read.readwise.io/read/01gqafph785fh3qv9qjkc0j3qk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For as long as we&amp;rsquo;ve had analytics and BI teams, we&amp;rsquo;ve tried to create
&lt;a href="https://chartio.com/blog/3-steps-to-prioritizing-data-requests/" rel="noopener">good processes&lt;/a> for people to ask them questions. We’ve
&lt;a href="https://www.caitlinhudon.com/posts/2020/09/16/data-intake-form" rel="noopener">shared intake forms&lt;/a>. We’ve
&lt;a href="https://www.secoda.co/data-ticketing" rel="noopener">built products&lt;/a>. And yet, most data teams still can’t convince their business partners to regularly use them, and our most common ticket management system
&lt;a href="https://twitter.com/imightbemary/status/1614663474113806338" rel="noopener">is still Slack DMs&lt;/a>. We’ve put self-serve interfaces between us and everyone else, and declared it
&lt;a href="https://www.reddit.com/r/BusinessIntelligence/comments/9zjhm2/how_much_of_a_disaster_has_selfservice_bi_been_in/" rel="noopener">disaster&lt;/a>—no,
&lt;a href="https://www.businesswire.com/news/home/20220112005334/en/New-Report-Finds-Self-Service-Analytics-Are-Critical-to-Empowering-Frontline-Workers-with-Data-Driven-Decisions-and-Autonomy" rel="noopener">critical&lt;/a>—no,
&lt;a href="https://www.montecarlodata.com/blog-is-self-service-datas-biggest-lie/" rel="noopener">a lie&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqafqynzfq0t8ezm95gkrjg5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Products that have product-market fit
&lt;a href="https://a16z.com/2017/02/18/12-things-about-product-market-fit-2/#:~:text=%234-%E2%80%9CYou-can,Buck%E2%80%99s.%E2%80%9D-Marc-Andreessen" rel="noopener">are bought, not sold&lt;/a>. And as people’s responses to posts like those from Katie and Erik show, most data teams still have to do an awful lot of selling. (
&lt;a href="https://read.readwise.io/read/01gqafs2bxs3nj2fedjfkcmdkx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we want to be in the
&lt;a href="https://www.youtube.com/watch?v=qrkwgEUXyTU" rel="noopener">room where it happens&lt;/a>, we shouldn’t spend our time trying to sell an unnecessary service to a reluctant buyer; we should spend it figuring out what we can do that would make it necessary for us to be there. (
&lt;a href="https://read.readwise.io/read/01gqafvpvw7n9x8s2rpgtf4bk0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The corollary to both of these points is that we have to talk to our customers. We have to research them; understand them; put ourselves in their shoes and figure out why they do what they do. When they push us aside, we shouldn’t assume that we’re offering something valuable—strategic advice! Metrics and alignment! Experimentation and the scientific method!—and our job is to sell it; we should instead ask them why they don’t want it.
The answers may surprise us. Our advice might be bad.
&lt;a href="https://commoncog.com/goodharts-law-not-useful/" rel="noopener">Metrics might not be that useful.&lt;/a> We might create more disruption and doubt than we do agreement and alignment. If there’s a case to be made for
&lt;a href="https://twitter.com/imightbemary/status/1614663891501580292" rel="noopener">hiring a data PM&lt;/a>, this is it—to do
&lt;a href="https://www.gong.io/blog/what-is-a-discovery-call/" rel="noopener">discovery&lt;/a>, and figure out what people actually want from a data team. (
&lt;a href="https://read.readwise.io/read/01gqafy17kp5dd3zrzy5ambcrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Ego Is the Enemy: The Legend of Genghis Khan</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Ego-Is-the-Enemy-The-Legend-of-Genghis-Khan/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Ego-Is-the-Enemy-The-Legend-of-Genghis-Khan/</guid><description>&lt;h1 id="ego-is-the-enemy-the-legend-of-genghis-khan">Ego Is the Enemy: The Legend of Genghis Khan&lt;/h1>
&lt;p>
&lt;img src="https://149664534.v2.pressablecdn.com/wp-content/uploads/2016/06/Genghis-Khan.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Farnam Street]]&lt;/li>
&lt;li>Full Title: Ego Is the Enemy: The Legend of Genghis Khan&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fs.blog/ego-is-the-enemy-genghis-khan/" rel="noopener">https://fs.blog/ego-is-the-enemy-genghis-khan/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Under Genghis Khan’s direction, the Mongols were as ruthless about stealing and absorbing the best of each culture they encountered as they were about conquest itself. (
&lt;a href="https://read.readwise.io/read/01gs90vyhrphc4a32n5mhbhmv9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Genghis Khan was not born a genius. Instead, as one biographer put it, his was “a persistent cycle of pragmatic learning, experimental adaptation, and constant revision driven by his uniquely disciplined and focused will.” (
&lt;a href="https://read.readwise.io/read/01gs90wb9b9mzs98jr144sfhmc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>He was the greatest conqueror the world ever knew because he was more open to learning than any other conqueror has ever been. (
&lt;a href="https://read.readwise.io/read/01gs90wnb5e046wr3vr6fsscer" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his campaigns against the Jurched, Khan learned the importance of winning hearts and minds. By working with the scholars and royal family of the lands he conquered, Khan was able to hold on to and manage these territories in ways that most empires could not. (
&lt;a href="https://read.readwise.io/read/01gs90y21hye32n33nagqerbv2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Mongol Empire was remarkable for its religious freedoms, and most of all, for its love of ideas and convergence of cultures. (
&lt;a href="https://read.readwise.io/read/01gs90z0ve4630sbper1m3db0d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As we first succeed, we will find ourselves in new situations, facing new problems. The freshly promoted soldier must learn the art of politics. The salesman, how to manage. The founder, how to delegate. The writer, how to edit others. The comedian, how to act. (
&lt;a href="https://read.readwise.io/read/01gs9107q8rdpkejhhxgdjxz3k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>as our island of knowledge grows, so does the shore of our ignorance.” In other words, each victory and advancement that made Khan smarter also bumped him against new situations he’d never encountered before. (
&lt;a href="https://read.readwise.io/read/01gs911mc7tr8tgbw99w4wnre4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With accomplishment comes a growing pressure to pretend that we know more than we do. To pretend we already know everything. Scientia infla (knowledge puffs up). (
&lt;a href="https://read.readwise.io/read/01gs912d4mxm1v4jp6p2wx2sj2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step and every juncture in life, there is the opportunity to learn—and even if the lesson is purely remedial, we must not let ego block us from hearing it again. (
&lt;a href="https://read.readwise.io/read/01gs914m9adcbph0axfwwarkbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An amateur is defensive. The professional finds learning (and even, occasionally, being shown up) to be enjoyable; they like being challenged and humbled, and engage in education as an ongoing and endless process. (
&lt;a href="https://read.readwise.io/read/01gs91643cfm33t3nca98vkamy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the theory of disruption, which posits that at some point in time, every industry will be disrupted by some trend or innovation that, despite all the resources in the world, the incumbent interests will be incapable of responding to. (
&lt;a href="https://read.readwise.io/read/01gs916zxycx0anbg86dtftrfs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Peter Drucker says that it’s not enough simply to want to learn. As people progress, they must also understand how they learn and then set up processes to facilitate this continual education. (
&lt;a href="https://read.readwise.io/read/01gs9186fsfecz7yhyash36abj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Farnam Street]]
title: &amp;ldquo;Ego Is the Enemy: The Legend of Genghis Khan&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="ego-is-the-enemy-the-legend-of-genghis-khan-1">Ego Is the Enemy: The Legend of Genghis Khan&lt;/h1>
&lt;p>
&lt;img src="https://149664534.v2.pressablecdn.com/wp-content/uploads/2016/06/Genghis-Khan.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Farnam Street]]&lt;/li>
&lt;li>Full Title: Ego Is the Enemy: The Legend of Genghis Khan&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fs.blog/ego-is-the-enemy-genghis-khan/" rel="noopener">https://fs.blog/ego-is-the-enemy-genghis-khan/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Under Genghis Khan’s direction, the Mongols were as ruthless about stealing and absorbing the best of each culture they encountered as they were about conquest itself. (
&lt;a href="https://read.readwise.io/read/01gs90vyhrphc4a32n5mhbhmv9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Genghis Khan was not born a genius. Instead, as one biographer put it, his was “a persistent cycle of pragmatic learning, experimental adaptation, and constant revision driven by his uniquely disciplined and focused will.” (
&lt;a href="https://read.readwise.io/read/01gs90wb9b9mzs98jr144sfhmc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>He was the greatest conqueror the world ever knew because he was more open to learning than any other conqueror has ever been. (
&lt;a href="https://read.readwise.io/read/01gs90wnb5e046wr3vr6fsscer" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his campaigns against the Jurched, Khan learned the importance of winning hearts and minds. By working with the scholars and royal family of the lands he conquered, Khan was able to hold on to and manage these territories in ways that most empires could not. (
&lt;a href="https://read.readwise.io/read/01gs90y21hye32n33nagqerbv2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Mongol Empire was remarkable for its religious freedoms, and most of all, for its love of ideas and convergence of cultures. (
&lt;a href="https://read.readwise.io/read/01gs90z0ve4630sbper1m3db0d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As we first succeed, we will find ourselves in new situations, facing new problems. The freshly promoted soldier must learn the art of politics. The salesman, how to manage. The founder, how to delegate. The writer, how to edit others. The comedian, how to act. (
&lt;a href="https://read.readwise.io/read/01gs9107q8rdpkejhhxgdjxz3k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>as our island of knowledge grows, so does the shore of our ignorance.” In other words, each victory and advancement that made Khan smarter also bumped him against new situations he’d never encountered before. (
&lt;a href="https://read.readwise.io/read/01gs911mc7tr8tgbw99w4wnre4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With accomplishment comes a growing pressure to pretend that we know more than we do. To pretend we already know everything. Scientia infla (knowledge puffs up). (
&lt;a href="https://read.readwise.io/read/01gs912d4mxm1v4jp6p2wx2sj2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step and every juncture in life, there is the opportunity to learn—and even if the lesson is purely remedial, we must not let ego block us from hearing it again. (
&lt;a href="https://read.readwise.io/read/01gs914m9adcbph0axfwwarkbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An amateur is defensive. The professional finds learning (and even, occasionally, being shown up) to be enjoyable; they like being challenged and humbled, and engage in education as an ongoing and endless process. (
&lt;a href="https://read.readwise.io/read/01gs91643cfm33t3nca98vkamy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the theory of disruption, which posits that at some point in time, every industry will be disrupted by some trend or innovation that, despite all the resources in the world, the incumbent interests will be incapable of responding to. (
&lt;a href="https://read.readwise.io/read/01gs916zxycx0anbg86dtftrfs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Peter Drucker says that it’s not enough simply to want to learn. As people progress, they must also understand how they learn and then set up processes to facilitate this continual education. (
&lt;a href="https://read.readwise.io/read/01gs9186fsfecz7yhyash36abj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Farnam Street]]
title: &amp;ldquo;Ego Is the Enemy: The Legend of Genghis Khan&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="ego-is-the-enemy-the-legend-of-genghis-khan-2">Ego Is the Enemy: The Legend of Genghis Khan&lt;/h1>
&lt;p>
&lt;img src="https://149664534.v2.pressablecdn.com/wp-content/uploads/2016/06/Genghis-Khan.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Farnam Street]]&lt;/li>
&lt;li>Full Title: Ego Is the Enemy: The Legend of Genghis Khan&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fs.blog/ego-is-the-enemy-genghis-khan/" rel="noopener">https://fs.blog/ego-is-the-enemy-genghis-khan/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Under Genghis Khan’s direction, the Mongols were as ruthless about stealing and absorbing the best of each culture they encountered as they were about conquest itself. (
&lt;a href="https://read.readwise.io/read/01gs90vyhrphc4a32n5mhbhmv9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Genghis Khan was not born a genius. Instead, as one biographer put it, his was “a persistent cycle of pragmatic learning, experimental adaptation, and constant revision driven by his uniquely disciplined and focused will.” (
&lt;a href="https://read.readwise.io/read/01gs90wb9b9mzs98jr144sfhmc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>He was the greatest conqueror the world ever knew because he was more open to learning than any other conqueror has ever been. (
&lt;a href="https://read.readwise.io/read/01gs90wnb5e046wr3vr6fsscer" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his campaigns against the Jurched, Khan learned the importance of winning hearts and minds. By working with the scholars and royal family of the lands he conquered, Khan was able to hold on to and manage these territories in ways that most empires could not. (
&lt;a href="https://read.readwise.io/read/01gs90y21hye32n33nagqerbv2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Mongol Empire was remarkable for its religious freedoms, and most of all, for its love of ideas and convergence of cultures. (
&lt;a href="https://read.readwise.io/read/01gs90z0ve4630sbper1m3db0d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As we first succeed, we will find ourselves in new situations, facing new problems. The freshly promoted soldier must learn the art of politics. The salesman, how to manage. The founder, how to delegate. The writer, how to edit others. The comedian, how to act. (
&lt;a href="https://read.readwise.io/read/01gs9107q8rdpkejhhxgdjxz3k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>as our island of knowledge grows, so does the shore of our ignorance.” In other words, each victory and advancement that made Khan smarter also bumped him against new situations he’d never encountered before. (
&lt;a href="https://read.readwise.io/read/01gs911mc7tr8tgbw99w4wnre4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With accomplishment comes a growing pressure to pretend that we know more than we do. To pretend we already know everything. Scientia infla (knowledge puffs up). (
&lt;a href="https://read.readwise.io/read/01gs912d4mxm1v4jp6p2wx2sj2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step and every juncture in life, there is the opportunity to learn—and even if the lesson is purely remedial, we must not let ego block us from hearing it again. (
&lt;a href="https://read.readwise.io/read/01gs914m9adcbph0axfwwarkbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An amateur is defensive. The professional finds learning (and even, occasionally, being shown up) to be enjoyable; they like being challenged and humbled, and engage in education as an ongoing and endless process. (
&lt;a href="https://read.readwise.io/read/01gs91643cfm33t3nca98vkamy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the theory of disruption, which posits that at some point in time, every industry will be disrupted by some trend or innovation that, despite all the resources in the world, the incumbent interests will be incapable of responding to. (
&lt;a href="https://read.readwise.io/read/01gs916zxycx0anbg86dtftrfs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Peter Drucker says that it’s not enough simply to want to learn. As people progress, they must also understand how they learn and then set up processes to facilitate this continual education. (
&lt;a href="https://read.readwise.io/read/01gs9186fsfecz7yhyash36abj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Farnam Street]]
title: &amp;ldquo;Ego Is the Enemy: The Legend of Genghis Khan&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="ego-is-the-enemy-the-legend-of-genghis-khan-3">Ego Is the Enemy: The Legend of Genghis Khan&lt;/h1>
&lt;p>
&lt;img src="https://149664534.v2.pressablecdn.com/wp-content/uploads/2016/06/Genghis-Khan.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Farnam Street]]&lt;/li>
&lt;li>Full Title: Ego Is the Enemy: The Legend of Genghis Khan&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fs.blog/ego-is-the-enemy-genghis-khan/" rel="noopener">https://fs.blog/ego-is-the-enemy-genghis-khan/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Under Genghis Khan’s direction, the Mongols were as ruthless about stealing and absorbing the best of each culture they encountered as they were about conquest itself. (
&lt;a href="https://read.readwise.io/read/01gs90vyhrphc4a32n5mhbhmv9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Genghis Khan was not born a genius. Instead, as one biographer put it, his was “a persistent cycle of pragmatic learning, experimental adaptation, and constant revision driven by his uniquely disciplined and focused will.” (
&lt;a href="https://read.readwise.io/read/01gs90wb9b9mzs98jr144sfhmc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>He was the greatest conqueror the world ever knew because he was more open to learning than any other conqueror has ever been. (
&lt;a href="https://read.readwise.io/read/01gs90wnb5e046wr3vr6fsscer" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his campaigns against the Jurched, Khan learned the importance of winning hearts and minds. By working with the scholars and royal family of the lands he conquered, Khan was able to hold on to and manage these territories in ways that most empires could not. (
&lt;a href="https://read.readwise.io/read/01gs90y21hye32n33nagqerbv2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Mongol Empire was remarkable for its religious freedoms, and most of all, for its love of ideas and convergence of cultures. (
&lt;a href="https://read.readwise.io/read/01gs90z0ve4630sbper1m3db0d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As we first succeed, we will find ourselves in new situations, facing new problems. The freshly promoted soldier must learn the art of politics. The salesman, how to manage. The founder, how to delegate. The writer, how to edit others. The comedian, how to act. (
&lt;a href="https://read.readwise.io/read/01gs9107q8rdpkejhhxgdjxz3k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>as our island of knowledge grows, so does the shore of our ignorance.” In other words, each victory and advancement that made Khan smarter also bumped him against new situations he’d never encountered before. (
&lt;a href="https://read.readwise.io/read/01gs911mc7tr8tgbw99w4wnre4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With accomplishment comes a growing pressure to pretend that we know more than we do. To pretend we already know everything. Scientia infla (knowledge puffs up). (
&lt;a href="https://read.readwise.io/read/01gs912d4mxm1v4jp6p2wx2sj2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step and every juncture in life, there is the opportunity to learn—and even if the lesson is purely remedial, we must not let ego block us from hearing it again. (
&lt;a href="https://read.readwise.io/read/01gs914m9adcbph0axfwwarkbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An amateur is defensive. The professional finds learning (and even, occasionally, being shown up) to be enjoyable; they like being challenged and humbled, and engage in education as an ongoing and endless process. (
&lt;a href="https://read.readwise.io/read/01gs91643cfm33t3nca98vkamy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the theory of disruption, which posits that at some point in time, every industry will be disrupted by some trend or innovation that, despite all the resources in the world, the incumbent interests will be incapable of responding to. (
&lt;a href="https://read.readwise.io/read/01gs916zxycx0anbg86dtftrfs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Peter Drucker says that it’s not enough simply to want to learn. As people progress, they must also understand how they learn and then set up processes to facilitate this continual education. (
&lt;a href="https://read.readwise.io/read/01gs9186fsfecz7yhyash36abj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Elbows of Data</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Elbows-of-Data/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Elbows-of-Data/</guid><description>&lt;h1 id="elbows-of-data">Elbows of Data&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F414bb562-bc65-4c80-9ff5-58640fb968ef_1500x1500.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Katie Bauer]]&lt;/li>
&lt;li>Full Title: Elbows of Data&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">https://wrongbutuseful.substack.com/p/elbows-of-data&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>For some time it was the consensus that new data tools and technologies were going to be the thing that finally helped data teams break through, get executive buy-in, and drive the successful outcomes that we all knew they could. (
&lt;a href="https://read.readwise.io/read/01gqb7escr3b29s7bxf0vs2s85" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when I hear those calls for focus on people and process, I can’t help but feel skeptical that either of those things will be the thing that changes the circumstances of data teams. (
&lt;a href="https://read.readwise.io/read/01gqb7ftt7rk2n3qeqd7b0ncc4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>many companies are not environments where data teams can be successful, no matter which people, processes or technologies they put into place. Simply said, &lt;strong>data teams being left on the sidelines is a problem of company culture&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqb7gv9r57x2dpwmkm9ng4ps" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It takes a lot of energy, persistence and positive belief, but it’s absolutely possible. Companies may not be sure how to best incorporate data teams into their processes of value creation, but that doesn’t mean we can’t
&lt;a href="https://idioms.thefreedictionary.com/elbow&amp;#43;your&amp;#43;way" rel="noopener">elbow our way in&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7q93khq81f0zqenqj1dzj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’ve been &lt;strong>elbows of data&lt;/strong>—folks who have insisted on being involved in driving the company forward, whether they were invited to or not. This way of working doesn’t come naturally to a lot of data people, who are often careful and non-confrontational by nature, and it can feel daunting to try to change your environment when there will always be
&lt;a href="https://lethain.com/hard-to-work-with/" rel="noopener">people who don’t want it to change&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7r035r8dnam026xgbyy7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elbows of data (
&lt;a href="https://read.readwise.io/read/01gqexbrrhwqkj79c5kg8xd2xb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data make a habit of fact finding.&lt;/strong> If teams at their companies send weekly updates or quarterly newsletters, they engage with them. (
&lt;a href="https://read.readwise.io/read/01gqb7sq4t3hvzjr7hef7evvwp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data also think about the second life of their work.&lt;/strong> They of course do their work with a specific customer or audience in mind, but they are also keenly aware that one of the most valuable things about data work is how cross-cutting it is. (
&lt;a href="https://read.readwise.io/read/01gqb7w6g3ydj6vdw01my1z5xm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. Elbows of data demonstrate the importance of data teams and data work by solving the company’s problems, even and especially if the company hasn’t recognized that a problem is a data problem yet (
&lt;a href="https://read.readwise.io/read/01gqb7y4wzex2pw9bhr8sg5ygn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data are proactive about explaining their constraints and asking for what they need.&lt;/strong> If an elbow of data is overwhelmed with stakeholder requests, they tell everyone who’s asking how much they’re being asked for so that those stakeholders understand why things are taking so long. (
&lt;a href="https://read.readwise.io/read/01gqb7yy5magtn2saram5w8s9t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They make it clear that data work isn’t free by helping their colleagues understand the reasons why something takes as much time as it does. (
&lt;a href="https://read.readwise.io/read/01gqb81fmr70w1jrmeqkfk720p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Katie Bauer]]
title: &amp;ldquo;Elbows of Data&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="elbows-of-data-1">Elbows of Data&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F414bb562-bc65-4c80-9ff5-58640fb968ef_1500x1500.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Katie Bauer]]&lt;/li>
&lt;li>Full Title: Elbows of Data&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">https://wrongbutuseful.substack.com/p/elbows-of-data&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>For some time it was the consensus that new data tools and technologies were going to be the thing that finally helped data teams break through, get executive buy-in, and drive the successful outcomes that we all knew they could. (
&lt;a href="https://read.readwise.io/read/01gqb7escr3b29s7bxf0vs2s85" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when I hear those calls for focus on people and process, I can’t help but feel skeptical that either of those things will be the thing that changes the circumstances of data teams. (
&lt;a href="https://read.readwise.io/read/01gqb7ftt7rk2n3qeqd7b0ncc4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>many companies are not environments where data teams can be successful, no matter which people, processes or technologies they put into place. Simply said, &lt;strong>data teams being left on the sidelines is a problem of company culture&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqb7gv9r57x2dpwmkm9ng4ps" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It takes a lot of energy, persistence and positive belief, but it’s absolutely possible. Companies may not be sure how to best incorporate data teams into their processes of value creation, but that doesn’t mean we can’t
&lt;a href="https://idioms.thefreedictionary.com/elbow&amp;#43;your&amp;#43;way" rel="noopener">elbow our way in&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7q93khq81f0zqenqj1dzj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’ve been &lt;strong>elbows of data&lt;/strong>—folks who have insisted on being involved in driving the company forward, whether they were invited to or not. This way of working doesn’t come naturally to a lot of data people, who are often careful and non-confrontational by nature, and it can feel daunting to try to change your environment when there will always be
&lt;a href="https://lethain.com/hard-to-work-with/" rel="noopener">people who don’t want it to change&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7r035r8dnam026xgbyy7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elbows of data (
&lt;a href="https://read.readwise.io/read/01gqexbrrhwqkj79c5kg8xd2xb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data make a habit of fact finding.&lt;/strong> If teams at their companies send weekly updates or quarterly newsletters, they engage with them. (
&lt;a href="https://read.readwise.io/read/01gqb7sq4t3hvzjr7hef7evvwp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data also think about the second life of their work.&lt;/strong> They of course do their work with a specific customer or audience in mind, but they are also keenly aware that one of the most valuable things about data work is how cross-cutting it is. (
&lt;a href="https://read.readwise.io/read/01gqb7w6g3ydj6vdw01my1z5xm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. Elbows of data demonstrate the importance of data teams and data work by solving the company’s problems, even and especially if the company hasn’t recognized that a problem is a data problem yet (
&lt;a href="https://read.readwise.io/read/01gqb7y4wzex2pw9bhr8sg5ygn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data are proactive about explaining their constraints and asking for what they need.&lt;/strong> If an elbow of data is overwhelmed with stakeholder requests, they tell everyone who’s asking how much they’re being asked for so that those stakeholders understand why things are taking so long. (
&lt;a href="https://read.readwise.io/read/01gqb7yy5magtn2saram5w8s9t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They make it clear that data work isn’t free by helping their colleagues understand the reasons why something takes as much time as it does. (
&lt;a href="https://read.readwise.io/read/01gqb81fmr70w1jrmeqkfk720p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Katie Bauer]]
title: &amp;ldquo;Elbows of Data&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="elbows-of-data-2">Elbows of Data&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F414bb562-bc65-4c80-9ff5-58640fb968ef_1500x1500.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Katie Bauer]]&lt;/li>
&lt;li>Full Title: Elbows of Data&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">https://wrongbutuseful.substack.com/p/elbows-of-data&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>For some time it was the consensus that new data tools and technologies were going to be the thing that finally helped data teams break through, get executive buy-in, and drive the successful outcomes that we all knew they could. (
&lt;a href="https://read.readwise.io/read/01gqb7escr3b29s7bxf0vs2s85" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when I hear those calls for focus on people and process, I can’t help but feel skeptical that either of those things will be the thing that changes the circumstances of data teams. (
&lt;a href="https://read.readwise.io/read/01gqb7ftt7rk2n3qeqd7b0ncc4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>many companies are not environments where data teams can be successful, no matter which people, processes or technologies they put into place. Simply said, &lt;strong>data teams being left on the sidelines is a problem of company culture&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqb7gv9r57x2dpwmkm9ng4ps" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It takes a lot of energy, persistence and positive belief, but it’s absolutely possible. Companies may not be sure how to best incorporate data teams into their processes of value creation, but that doesn’t mean we can’t
&lt;a href="https://idioms.thefreedictionary.com/elbow&amp;#43;your&amp;#43;way" rel="noopener">elbow our way in&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7q93khq81f0zqenqj1dzj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’ve been &lt;strong>elbows of data&lt;/strong>—folks who have insisted on being involved in driving the company forward, whether they were invited to or not. This way of working doesn’t come naturally to a lot of data people, who are often careful and non-confrontational by nature, and it can feel daunting to try to change your environment when there will always be
&lt;a href="https://lethain.com/hard-to-work-with/" rel="noopener">people who don’t want it to change&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7r035r8dnam026xgbyy7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elbows of data (
&lt;a href="https://read.readwise.io/read/01gqexbrrhwqkj79c5kg8xd2xb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data make a habit of fact finding.&lt;/strong> If teams at their companies send weekly updates or quarterly newsletters, they engage with them. (
&lt;a href="https://read.readwise.io/read/01gqb7sq4t3hvzjr7hef7evvwp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data also think about the second life of their work.&lt;/strong> They of course do their work with a specific customer or audience in mind, but they are also keenly aware that one of the most valuable things about data work is how cross-cutting it is. (
&lt;a href="https://read.readwise.io/read/01gqb7w6g3ydj6vdw01my1z5xm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. Elbows of data demonstrate the importance of data teams and data work by solving the company’s problems, even and especially if the company hasn’t recognized that a problem is a data problem yet (
&lt;a href="https://read.readwise.io/read/01gqb7y4wzex2pw9bhr8sg5ygn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data are proactive about explaining their constraints and asking for what they need.&lt;/strong> If an elbow of data is overwhelmed with stakeholder requests, they tell everyone who’s asking how much they’re being asked for so that those stakeholders understand why things are taking so long. (
&lt;a href="https://read.readwise.io/read/01gqb7yy5magtn2saram5w8s9t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They make it clear that data work isn’t free by helping their colleagues understand the reasons why something takes as much time as it does. (
&lt;a href="https://read.readwise.io/read/01gqb81fmr70w1jrmeqkfk720p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Katie Bauer]]
title: &amp;ldquo;Elbows of Data&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="elbows-of-data-3">Elbows of Data&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F414bb562-bc65-4c80-9ff5-58640fb968ef_1500x1500.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Katie Bauer]]&lt;/li>
&lt;li>Full Title: Elbows of Data&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">https://wrongbutuseful.substack.com/p/elbows-of-data&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>For some time it was the consensus that new data tools and technologies were going to be the thing that finally helped data teams break through, get executive buy-in, and drive the successful outcomes that we all knew they could. (
&lt;a href="https://read.readwise.io/read/01gqb7escr3b29s7bxf0vs2s85" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when I hear those calls for focus on people and process, I can’t help but feel skeptical that either of those things will be the thing that changes the circumstances of data teams. (
&lt;a href="https://read.readwise.io/read/01gqb7ftt7rk2n3qeqd7b0ncc4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>many companies are not environments where data teams can be successful, no matter which people, processes or technologies they put into place. Simply said, &lt;strong>data teams being left on the sidelines is a problem of company culture&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqb7gv9r57x2dpwmkm9ng4ps" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It takes a lot of energy, persistence and positive belief, but it’s absolutely possible. Companies may not be sure how to best incorporate data teams into their processes of value creation, but that doesn’t mean we can’t
&lt;a href="https://idioms.thefreedictionary.com/elbow&amp;#43;your&amp;#43;way" rel="noopener">elbow our way in&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7q93khq81f0zqenqj1dzj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’ve been &lt;strong>elbows of data&lt;/strong>—folks who have insisted on being involved in driving the company forward, whether they were invited to or not. This way of working doesn’t come naturally to a lot of data people, who are often careful and non-confrontational by nature, and it can feel daunting to try to change your environment when there will always be
&lt;a href="https://lethain.com/hard-to-work-with/" rel="noopener">people who don’t want it to change&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gqb7r035r8dnam026xgbyy7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elbows of data (
&lt;a href="https://read.readwise.io/read/01gqexbrrhwqkj79c5kg8xd2xb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data make a habit of fact finding.&lt;/strong> If teams at their companies send weekly updates or quarterly newsletters, they engage with them. (
&lt;a href="https://read.readwise.io/read/01gqb7sq4t3hvzjr7hef7evvwp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data also think about the second life of their work.&lt;/strong> They of course do their work with a specific customer or audience in mind, but they are also keenly aware that one of the most valuable things about data work is how cross-cutting it is. (
&lt;a href="https://read.readwise.io/read/01gqb7w6g3ydj6vdw01my1z5xm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. Elbows of data demonstrate the importance of data teams and data work by solving the company’s problems, even and especially if the company hasn’t recognized that a problem is a data problem yet (
&lt;a href="https://read.readwise.io/read/01gqb7y4wzex2pw9bhr8sg5ygn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Elbows of data are proactive about explaining their constraints and asking for what they need.&lt;/strong> If an elbow of data is overwhelmed with stakeholder requests, they tell everyone who’s asking how much they’re being asked for so that those stakeholders understand why things are taking so long. (
&lt;a href="https://read.readwise.io/read/01gqb7yy5magtn2saram5w8s9t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They make it clear that data work isn’t free by helping their colleagues understand the reasons why something takes as much time as it does. (
&lt;a href="https://read.readwise.io/read/01gqb81fmr70w1jrmeqkfk720p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Engineers-Shouldnt-Write-ETL-A-Guide-to-Building-a-High-Functioning-Data-Science-Department/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Engineers-Shouldnt-Write-ETL-A-Guide-to-Building-a-High-Functioning-Data-Science-Department/</guid><description>&lt;h1 id="engineers-shouldnt-write-etl-a-guide-to-building-a-high-functioning-data-science-department">Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/images/logomark-linkedin.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Frustration among groups.
&lt;ul>
&lt;li>DS: Misalignment of motivations and slow into production&lt;/li>
&lt;li>DE: Lack of debt tech vision and costs of productionizing&lt;/li>
&lt;li>Infrastructure: Lack of business context
What went wrong?&lt;/li>
&lt;li>In most ocasions you don&amp;rsquo;t need specialized DE to build solutions&lt;/li>
&lt;li>Everybody wants to be the thinker. In traditional departments there were only doers.
You need engineers to do engineer stuff, not to serve other roles.
Stitchfix proposal:
&lt;em>A way that allows for autonomy in roles, true ownership all the way into production, and accountability for output.&lt;/em>
The trick is to create an environment that allows for autonomy, ownership, and focus for everyone involved.
engineers and data scientists are impassioned by very different tasks
&lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>.
&lt;em>Engineers should not write ETL.&lt;/em> For the love of everything sacred and holy in the profession, this should not be a dedicated or specialized role. There is nothing more soul sucking than writing, maintaining, modifying, and supporting ETL to produce data that you yourself never get to use or consume.
Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. The best-case outcome of many efforts of data scientists is an artifact meant for a machine consumer, not a human one. Autonomy means the data scientists own that code as well. &lt;em>All the way into production.&lt;/em> 
What is the role of an engineer in this new, horizontal world? To sum it up, engineers must deploy platforms, services, abstractions, and frameworks that allow the data scientists to conceive of, develop, and deploy their ideas with autonomy
We are not optimizing the organization for efficiency, we are optimizing for autonomy.
&lt;em>It is absolutely essential for platform engineers to stay ahead of the data science teams.&lt;/em> You need very sharp platform engineers who can make intuitive decisions about what services, frameworks, and capabilities need to be in place before they are desperately needed.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/" rel="noopener">https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Here’s the thing. ETL engineers, Report Developers, and DBAs are all “Doers”. So, 10 years ago or so, when Big Data and data science started to become buzzwords, there were well-established BI departments who had plenty of Doers and not enough Thinkers. So, they made “Thinker” a role. (
&lt;a href="https://read.readwise.io/read/01gs3ny2cfcvgdwq93ggxxk39m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The fundamental flaw that prevents the Thinker and Doer model from living up to its recruiting hype is the assumption that there exists an army of soulless non-mediocre Doer engineers who eagerly implement the ideas and vision of data scientists. Does that sound like the profile of any talented engineers that you know? (
&lt;a href="https://read.readwise.io/read/01gs3nyqnvfkbgr88vt905cqsa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, you will hire mediocre engineers. They will create tremendously over complicated messes. This will exacerbate the contention. &lt;em>Welcome to the Vicious Cycle&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gs3nz29xsbdzyy71p1w28t3q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is important to recognize that engineers and data scientists are impassioned by very different tasks: (
&lt;a href="https://read.readwise.io/read/01gs3p0qmq6bxxm24db8w7nj4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data scientists love working on problems that are vertically aligned with the business and make a big impact on the success of projects/organization through their efforts. They set out to optimize a certain thing or process or create something from scratch. These are point-oriented problems and their solutions tend to be as well. They usually involve a heavy mix of business logic, reimagining of how things are done, and a healthy dose of creativity. Thus, they require a deep understanding of how specific portions of the business operate and a high degree of partnership with business verticals. (
&lt;a href="https://read.readwise.io/read/01gs3p11fgt00w778xr2qpkys8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Engineers excel in a world of abstraction, generalization, and finding efficient solutions in the places where they are needed. These problems are usually horizontally oriented in nature. They can be most impactful when applied broadly. They require a good overall understanding of how the business operates, but the abstracted nature of solutions mean they are light on business logic and do not require a heavy partnership with or deep understanding of verticals within the business. (
&lt;a href="https://read.readwise.io/read/01gs3p0ytm5c8mbgee088wdvw8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In case you did not realize it, &lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p1a0j9v3pfahj278qnrcp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. (
&lt;a href="https://read.readwise.io/read/01gs3p1m4aksq03kxph89ztn5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stitchfix.com]]
title: &amp;ldquo;Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="engineers-shouldnt-write-etl-a-guide-to-building-a-high-functioning-data-science-department-1">Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/images/logomark-linkedin.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Frustration among groups.
&lt;ul>
&lt;li>DS: Misalignment of motivations and slow into production&lt;/li>
&lt;li>DE: Lack of debt tech vision and costs of productionizing&lt;/li>
&lt;li>Infrastructure: Lack of business context
What went wrong?&lt;/li>
&lt;li>In most ocasions you don&amp;rsquo;t need specialized DE to build solutions&lt;/li>
&lt;li>Everybody wants to be the thinker. In traditional departments there were only doers.
You need engineers to do engineer stuff, not to serve other roles.
Stitchfix proposal:
&lt;em>A way that allows for autonomy in roles, true ownership all the way into production, and accountability for output.&lt;/em>
The trick is to create an environment that allows for autonomy, ownership, and focus for everyone involved.
engineers and data scientists are impassioned by very different tasks
&lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>.
&lt;em>Engineers should not write ETL.&lt;/em> For the love of everything sacred and holy in the profession, this should not be a dedicated or specialized role. There is nothing more soul sucking than writing, maintaining, modifying, and supporting ETL to produce data that you yourself never get to use or consume.
Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. The best-case outcome of many efforts of data scientists is an artifact meant for a machine consumer, not a human one. Autonomy means the data scientists own that code as well. &lt;em>All the way into production.&lt;/em> 
What is the role of an engineer in this new, horizontal world? To sum it up, engineers must deploy platforms, services, abstractions, and frameworks that allow the data scientists to conceive of, develop, and deploy their ideas with autonomy
We are not optimizing the organization for efficiency, we are optimizing for autonomy.
&lt;em>It is absolutely essential for platform engineers to stay ahead of the data science teams.&lt;/em> You need very sharp platform engineers who can make intuitive decisions about what services, frameworks, and capabilities need to be in place before they are desperately needed.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/" rel="noopener">https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Here’s the thing. ETL engineers, Report Developers, and DBAs are all “Doers”. So, 10 years ago or so, when Big Data and data science started to become buzzwords, there were well-established BI departments who had plenty of Doers and not enough Thinkers. So, they made “Thinker” a role. (
&lt;a href="https://read.readwise.io/read/01gs3ny2cfcvgdwq93ggxxk39m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The fundamental flaw that prevents the Thinker and Doer model from living up to its recruiting hype is the assumption that there exists an army of soulless non-mediocre Doer engineers who eagerly implement the ideas and vision of data scientists. Does that sound like the profile of any talented engineers that you know? (
&lt;a href="https://read.readwise.io/read/01gs3nyqnvfkbgr88vt905cqsa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, you will hire mediocre engineers. They will create tremendously over complicated messes. This will exacerbate the contention. &lt;em>Welcome to the Vicious Cycle&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gs3nz29xsbdzyy71p1w28t3q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is important to recognize that engineers and data scientists are impassioned by very different tasks: (
&lt;a href="https://read.readwise.io/read/01gs3p0qmq6bxxm24db8w7nj4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data scientists love working on problems that are vertically aligned with the business and make a big impact on the success of projects/organization through their efforts. They set out to optimize a certain thing or process or create something from scratch. These are point-oriented problems and their solutions tend to be as well. They usually involve a heavy mix of business logic, reimagining of how things are done, and a healthy dose of creativity. Thus, they require a deep understanding of how specific portions of the business operate and a high degree of partnership with business verticals. (
&lt;a href="https://read.readwise.io/read/01gs3p11fgt00w778xr2qpkys8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Engineers excel in a world of abstraction, generalization, and finding efficient solutions in the places where they are needed. These problems are usually horizontally oriented in nature. They can be most impactful when applied broadly. They require a good overall understanding of how the business operates, but the abstracted nature of solutions mean they are light on business logic and do not require a heavy partnership with or deep understanding of verticals within the business. (
&lt;a href="https://read.readwise.io/read/01gs3p0ytm5c8mbgee088wdvw8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In case you did not realize it, &lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p1a0j9v3pfahj278qnrcp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. (
&lt;a href="https://read.readwise.io/read/01gs3p1m4aksq03kxph89ztn5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stitchfix.com]]
title: &amp;ldquo;Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="engineers-shouldnt-write-etl-a-guide-to-building-a-high-functioning-data-science-department-2">Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/images/logomark-linkedin.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Frustration among groups.
&lt;ul>
&lt;li>DS: Misalignment of motivations and slow into production&lt;/li>
&lt;li>DE: Lack of debt tech vision and costs of productionizing&lt;/li>
&lt;li>Infrastructure: Lack of business context
What went wrong?&lt;/li>
&lt;li>In most ocasions you don&amp;rsquo;t need specialized DE to build solutions&lt;/li>
&lt;li>Everybody wants to be the thinker. In traditional departments there were only doers.
You need engineers to do engineer stuff, not to serve other roles.
Stitchfix proposal:
&lt;em>A way that allows for autonomy in roles, true ownership all the way into production, and accountability for output.&lt;/em>
The trick is to create an environment that allows for autonomy, ownership, and focus for everyone involved.
engineers and data scientists are impassioned by very different tasks
&lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>.
&lt;em>Engineers should not write ETL.&lt;/em> For the love of everything sacred and holy in the profession, this should not be a dedicated or specialized role. There is nothing more soul sucking than writing, maintaining, modifying, and supporting ETL to produce data that you yourself never get to use or consume.
Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. The best-case outcome of many efforts of data scientists is an artifact meant for a machine consumer, not a human one. Autonomy means the data scientists own that code as well. &lt;em>All the way into production.&lt;/em> 
What is the role of an engineer in this new, horizontal world? To sum it up, engineers must deploy platforms, services, abstractions, and frameworks that allow the data scientists to conceive of, develop, and deploy their ideas with autonomy
We are not optimizing the organization for efficiency, we are optimizing for autonomy.
&lt;em>It is absolutely essential for platform engineers to stay ahead of the data science teams.&lt;/em> You need very sharp platform engineers who can make intuitive decisions about what services, frameworks, and capabilities need to be in place before they are desperately needed.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/" rel="noopener">https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Here’s the thing. ETL engineers, Report Developers, and DBAs are all “Doers”. So, 10 years ago or so, when Big Data and data science started to become buzzwords, there were well-established BI departments who had plenty of Doers and not enough Thinkers. So, they made “Thinker” a role. (
&lt;a href="https://read.readwise.io/read/01gs3ny2cfcvgdwq93ggxxk39m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The fundamental flaw that prevents the Thinker and Doer model from living up to its recruiting hype is the assumption that there exists an army of soulless non-mediocre Doer engineers who eagerly implement the ideas and vision of data scientists. Does that sound like the profile of any talented engineers that you know? (
&lt;a href="https://read.readwise.io/read/01gs3nyqnvfkbgr88vt905cqsa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, you will hire mediocre engineers. They will create tremendously over complicated messes. This will exacerbate the contention. &lt;em>Welcome to the Vicious Cycle&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gs3nz29xsbdzyy71p1w28t3q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is important to recognize that engineers and data scientists are impassioned by very different tasks: (
&lt;a href="https://read.readwise.io/read/01gs3p0qmq6bxxm24db8w7nj4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data scientists love working on problems that are vertically aligned with the business and make a big impact on the success of projects/organization through their efforts. They set out to optimize a certain thing or process or create something from scratch. These are point-oriented problems and their solutions tend to be as well. They usually involve a heavy mix of business logic, reimagining of how things are done, and a healthy dose of creativity. Thus, they require a deep understanding of how specific portions of the business operate and a high degree of partnership with business verticals. (
&lt;a href="https://read.readwise.io/read/01gs3p11fgt00w778xr2qpkys8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Engineers excel in a world of abstraction, generalization, and finding efficient solutions in the places where they are needed. These problems are usually horizontally oriented in nature. They can be most impactful when applied broadly. They require a good overall understanding of how the business operates, but the abstracted nature of solutions mean they are light on business logic and do not require a heavy partnership with or deep understanding of verticals within the business. (
&lt;a href="https://read.readwise.io/read/01gs3p0ytm5c8mbgee088wdvw8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In case you did not realize it, &lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p1a0j9v3pfahj278qnrcp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. (
&lt;a href="https://read.readwise.io/read/01gs3p1m4aksq03kxph89ztn5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stitchfix.com]]
title: &amp;ldquo;Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="engineers-shouldnt-write-etl-a-guide-to-building-a-high-functioning-data-science-department-3">Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/h1>
&lt;p>
&lt;img src="https://multithreaded.stitchfix.com/assets/images/logomark-linkedin.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stitchfix.com]]&lt;/li>
&lt;li>Full Title: Engineers Shouldn’t Write ETL: A Guide to Building a High Functioning Data Science Department&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Frustration among groups.
&lt;ul>
&lt;li>DS: Misalignment of motivations and slow into production&lt;/li>
&lt;li>DE: Lack of debt tech vision and costs of productionizing&lt;/li>
&lt;li>Infrastructure: Lack of business context
What went wrong?&lt;/li>
&lt;li>In most ocasions you don&amp;rsquo;t need specialized DE to build solutions&lt;/li>
&lt;li>Everybody wants to be the thinker. In traditional departments there were only doers.
You need engineers to do engineer stuff, not to serve other roles.
Stitchfix proposal:
&lt;em>A way that allows for autonomy in roles, true ownership all the way into production, and accountability for output.&lt;/em>
The trick is to create an environment that allows for autonomy, ownership, and focus for everyone involved.
engineers and data scientists are impassioned by very different tasks
&lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>.
&lt;em>Engineers should not write ETL.&lt;/em> For the love of everything sacred and holy in the profession, this should not be a dedicated or specialized role. There is nothing more soul sucking than writing, maintaining, modifying, and supporting ETL to produce data that you yourself never get to use or consume.
Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. The best-case outcome of many efforts of data scientists is an artifact meant for a machine consumer, not a human one. Autonomy means the data scientists own that code as well. &lt;em>All the way into production.&lt;/em> 
What is the role of an engineer in this new, horizontal world? To sum it up, engineers must deploy platforms, services, abstractions, and frameworks that allow the data scientists to conceive of, develop, and deploy their ideas with autonomy
We are not optimizing the organization for efficiency, we are optimizing for autonomy.
&lt;em>It is absolutely essential for platform engineers to stay ahead of the data science teams.&lt;/em> You need very sharp platform engineers who can make intuitive decisions about what services, frameworks, and capabilities need to be in place before they are desperately needed.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/" rel="noopener">https://multithreaded.stitchfix.com/blog/2016/03/16/engineers-shouldnt-write-etl/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Here’s the thing. ETL engineers, Report Developers, and DBAs are all “Doers”. So, 10 years ago or so, when Big Data and data science started to become buzzwords, there were well-established BI departments who had plenty of Doers and not enough Thinkers. So, they made “Thinker” a role. (
&lt;a href="https://read.readwise.io/read/01gs3ny2cfcvgdwq93ggxxk39m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The fundamental flaw that prevents the Thinker and Doer model from living up to its recruiting hype is the assumption that there exists an army of soulless non-mediocre Doer engineers who eagerly implement the ideas and vision of data scientists. Does that sound like the profile of any talented engineers that you know? (
&lt;a href="https://read.readwise.io/read/01gs3nyqnvfkbgr88vt905cqsa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, you will hire mediocre engineers. They will create tremendously over complicated messes. This will exacerbate the contention. &lt;em>Welcome to the Vicious Cycle&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gs3nz29xsbdzyy71p1w28t3q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is important to recognize that engineers and data scientists are impassioned by very different tasks: (
&lt;a href="https://read.readwise.io/read/01gs3p0qmq6bxxm24db8w7nj4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data scientists love working on problems that are vertically aligned with the business and make a big impact on the success of projects/organization through their efforts. They set out to optimize a certain thing or process or create something from scratch. These are point-oriented problems and their solutions tend to be as well. They usually involve a heavy mix of business logic, reimagining of how things are done, and a healthy dose of creativity. Thus, they require a deep understanding of how specific portions of the business operate and a high degree of partnership with business verticals. (
&lt;a href="https://read.readwise.io/read/01gs3p11fgt00w778xr2qpkys8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Engineers excel in a world of abstraction, generalization, and finding efficient solutions in the places where they are needed. These problems are usually horizontally oriented in nature. They can be most impactful when applied broadly. They require a good overall understanding of how the business operates, but the abstracted nature of solutions mean they are light on business logic and do not require a heavy partnership with or deep understanding of verticals within the business. (
&lt;a href="https://read.readwise.io/read/01gs3p0ytm5c8mbgee088wdvw8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In case you did not realize it, &lt;strong>Nobody enjoys writing and maintaining data pipelines or ETL&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3p1a0j9v3pfahj278qnrcp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead, give people end-to-end ownership of the work they produce (autonomy). In the case of data scientists, that means ownership of the ETL. It also means ownership of the analysis of the data and the outcome of the data science. (
&lt;a href="https://read.readwise.io/read/01gs3p1m4aksq03kxph89ztn5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Feature Engineering for Personalized Search</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Feature-Engineering-for-Personalized-Search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Feature-Engineering-for-Personalized-Search/</guid><description>&lt;h1 id="feature-engineering-for-personalized-search">Feature Engineering for Personalized Search&lt;/h1>
&lt;p>
&lt;img src="https://fennel.ai/blog/favicon.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Nick Parsons]]&lt;/li>
&lt;li>Full Title: Feature Engineering for Personalized Search&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fennel.ai/blog/feature-engineering-for-personalized-search/" rel="noopener">https://fennel.ai/blog/feature-engineering-for-personalized-search/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>At the simplest level, search is the process of finding matches to a user-provided query string. While this base-level version of search is sometimes still utilized in simpler applications, for the most part, the results from queries that users perform are personalized to them, in order to surface documents that are more likely to be relevant to the user’s interests. (
&lt;a href="https://read.readwise.io/read/01gr7cmdy4k6dpj27gwt3e45kq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Search engines have typically relied on a reverse index-based information retrieval system, which maps individual words or terms in the documents or records, and helps drastically reduce the candidate sets by several orders of magnitude. (
&lt;a href="https://read.readwise.io/read/01gr7f85n2q72jjtpvkn0w62qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elasticsearch stores data in an index and searches the inverted indices for query terms when a query is submitted. When a match for the query term is found, the corresponding document is returned. Breaking down the documents and identifying them by their key terms allows for faster retrieval of results. (
&lt;a href="https://read.readwise.io/read/01gr7f8m2p7yytwzctc25xq2ax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Semantic Retrieval
While there are many ways to perform semantic retrieval, TTSN with BERT is frequently used in combination with KNN indices when working with personalized search. (
&lt;a href="https://read.readwise.io/read/01gr7ck3qah9qmzhb659nm4d0n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For personalized search, a KNN index is used to model the user&amp;rsquo;s interests and preferences, based on the user&amp;rsquo;s past search queries and the search results that the user has clicked on (which are modeled by the TTSN). (
&lt;a href="https://read.readwise.io/read/01gr7f9era9np34s44fsc2v85z" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>feature engineering for personalized search is more focused on designing features that can be used to rank and retrieve search results (documents) that are relevant to the user. (
&lt;a href="https://read.readwise.io/read/01gr7fbgezpqmdyfgddpdqef8b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>search has a much more severe long tail than recommendations. (
&lt;a href="https://read.readwise.io/read/01gr7fd1xppyj70x3jx7bxhga6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>NLP-Type Features&lt;/strong> – Features that understand the semantic content of the query. These might come from SOTA models (such as BERT), FastText (either directly fed or the dot product of the query), or document embeddings. (
&lt;a href="https://read.readwise.io/read/01gr7ffbr0dj2djt02txn4tnjb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Reputation Features&lt;/strong> – Features representing how reputable of a source the document comes from. These might include the author of the document, the number of inbound links, the page rank, etc. (
&lt;a href="https://read.readwise.io/read/01gr7fg9heahybz352cdqbmb84" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>latency is a big factor with search of any kind. (
&lt;a href="https://read.readwise.io/read/01gr7fh5cp49rsrx0kjkr2erg2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Nick Parsons]]
title: &amp;ldquo;Feature Engineering for Personalized Search&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="feature-engineering-for-personalized-search-1">Feature Engineering for Personalized Search&lt;/h1>
&lt;p>
&lt;img src="https://fennel.ai/blog/favicon.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Nick Parsons]]&lt;/li>
&lt;li>Full Title: Feature Engineering for Personalized Search&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fennel.ai/blog/feature-engineering-for-personalized-search/" rel="noopener">https://fennel.ai/blog/feature-engineering-for-personalized-search/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>At the simplest level, search is the process of finding matches to a user-provided query string. While this base-level version of search is sometimes still utilized in simpler applications, for the most part, the results from queries that users perform are personalized to them, in order to surface documents that are more likely to be relevant to the user’s interests. (
&lt;a href="https://read.readwise.io/read/01gr7cmdy4k6dpj27gwt3e45kq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Search engines have typically relied on a reverse index-based information retrieval system, which maps individual words or terms in the documents or records, and helps drastically reduce the candidate sets by several orders of magnitude. (
&lt;a href="https://read.readwise.io/read/01gr7f85n2q72jjtpvkn0w62qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elasticsearch stores data in an index and searches the inverted indices for query terms when a query is submitted. When a match for the query term is found, the corresponding document is returned. Breaking down the documents and identifying them by their key terms allows for faster retrieval of results. (
&lt;a href="https://read.readwise.io/read/01gr7f8m2p7yytwzctc25xq2ax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Semantic Retrieval
While there are many ways to perform semantic retrieval, TTSN with BERT is frequently used in combination with KNN indices when working with personalized search. (
&lt;a href="https://read.readwise.io/read/01gr7ck3qah9qmzhb659nm4d0n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For personalized search, a KNN index is used to model the user&amp;rsquo;s interests and preferences, based on the user&amp;rsquo;s past search queries and the search results that the user has clicked on (which are modeled by the TTSN). (
&lt;a href="https://read.readwise.io/read/01gr7f9era9np34s44fsc2v85z" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>feature engineering for personalized search is more focused on designing features that can be used to rank and retrieve search results (documents) that are relevant to the user. (
&lt;a href="https://read.readwise.io/read/01gr7fbgezpqmdyfgddpdqef8b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>search has a much more severe long tail than recommendations. (
&lt;a href="https://read.readwise.io/read/01gr7fd1xppyj70x3jx7bxhga6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>NLP-Type Features&lt;/strong> – Features that understand the semantic content of the query. These might come from SOTA models (such as BERT), FastText (either directly fed or the dot product of the query), or document embeddings. (
&lt;a href="https://read.readwise.io/read/01gr7ffbr0dj2djt02txn4tnjb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Reputation Features&lt;/strong> – Features representing how reputable of a source the document comes from. These might include the author of the document, the number of inbound links, the page rank, etc. (
&lt;a href="https://read.readwise.io/read/01gr7fg9heahybz352cdqbmb84" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>latency is a big factor with search of any kind. (
&lt;a href="https://read.readwise.io/read/01gr7fh5cp49rsrx0kjkr2erg2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Nick Parsons]]
title: &amp;ldquo;Feature Engineering for Personalized Search&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="feature-engineering-for-personalized-search-2">Feature Engineering for Personalized Search&lt;/h1>
&lt;p>
&lt;img src="https://fennel.ai/blog/favicon.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Nick Parsons]]&lt;/li>
&lt;li>Full Title: Feature Engineering for Personalized Search&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fennel.ai/blog/feature-engineering-for-personalized-search/" rel="noopener">https://fennel.ai/blog/feature-engineering-for-personalized-search/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>At the simplest level, search is the process of finding matches to a user-provided query string. While this base-level version of search is sometimes still utilized in simpler applications, for the most part, the results from queries that users perform are personalized to them, in order to surface documents that are more likely to be relevant to the user’s interests. (
&lt;a href="https://read.readwise.io/read/01gr7cmdy4k6dpj27gwt3e45kq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Search engines have typically relied on a reverse index-based information retrieval system, which maps individual words or terms in the documents or records, and helps drastically reduce the candidate sets by several orders of magnitude. (
&lt;a href="https://read.readwise.io/read/01gr7f85n2q72jjtpvkn0w62qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elasticsearch stores data in an index and searches the inverted indices for query terms when a query is submitted. When a match for the query term is found, the corresponding document is returned. Breaking down the documents and identifying them by their key terms allows for faster retrieval of results. (
&lt;a href="https://read.readwise.io/read/01gr7f8m2p7yytwzctc25xq2ax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Semantic Retrieval
While there are many ways to perform semantic retrieval, TTSN with BERT is frequently used in combination with KNN indices when working with personalized search. (
&lt;a href="https://read.readwise.io/read/01gr7ck3qah9qmzhb659nm4d0n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For personalized search, a KNN index is used to model the user&amp;rsquo;s interests and preferences, based on the user&amp;rsquo;s past search queries and the search results that the user has clicked on (which are modeled by the TTSN). (
&lt;a href="https://read.readwise.io/read/01gr7f9era9np34s44fsc2v85z" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>feature engineering for personalized search is more focused on designing features that can be used to rank and retrieve search results (documents) that are relevant to the user. (
&lt;a href="https://read.readwise.io/read/01gr7fbgezpqmdyfgddpdqef8b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>search has a much more severe long tail than recommendations. (
&lt;a href="https://read.readwise.io/read/01gr7fd1xppyj70x3jx7bxhga6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>NLP-Type Features&lt;/strong> – Features that understand the semantic content of the query. These might come from SOTA models (such as BERT), FastText (either directly fed or the dot product of the query), or document embeddings. (
&lt;a href="https://read.readwise.io/read/01gr7ffbr0dj2djt02txn4tnjb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Reputation Features&lt;/strong> – Features representing how reputable of a source the document comes from. These might include the author of the document, the number of inbound links, the page rank, etc. (
&lt;a href="https://read.readwise.io/read/01gr7fg9heahybz352cdqbmb84" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>latency is a big factor with search of any kind. (
&lt;a href="https://read.readwise.io/read/01gr7fh5cp49rsrx0kjkr2erg2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Nick Parsons]]
title: &amp;ldquo;Feature Engineering for Personalized Search&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="feature-engineering-for-personalized-search-3">Feature Engineering for Personalized Search&lt;/h1>
&lt;p>
&lt;img src="https://fennel.ai/blog/favicon.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Nick Parsons]]&lt;/li>
&lt;li>Full Title: Feature Engineering for Personalized Search&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://fennel.ai/blog/feature-engineering-for-personalized-search/" rel="noopener">https://fennel.ai/blog/feature-engineering-for-personalized-search/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>At the simplest level, search is the process of finding matches to a user-provided query string. While this base-level version of search is sometimes still utilized in simpler applications, for the most part, the results from queries that users perform are personalized to them, in order to surface documents that are more likely to be relevant to the user’s interests. (
&lt;a href="https://read.readwise.io/read/01gr7cmdy4k6dpj27gwt3e45kq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Search engines have typically relied on a reverse index-based information retrieval system, which maps individual words or terms in the documents or records, and helps drastically reduce the candidate sets by several orders of magnitude. (
&lt;a href="https://read.readwise.io/read/01gr7f85n2q72jjtpvkn0w62qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Elasticsearch stores data in an index and searches the inverted indices for query terms when a query is submitted. When a match for the query term is found, the corresponding document is returned. Breaking down the documents and identifying them by their key terms allows for faster retrieval of results. (
&lt;a href="https://read.readwise.io/read/01gr7f8m2p7yytwzctc25xq2ax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Semantic Retrieval
While there are many ways to perform semantic retrieval, TTSN with BERT is frequently used in combination with KNN indices when working with personalized search. (
&lt;a href="https://read.readwise.io/read/01gr7ck3qah9qmzhb659nm4d0n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For personalized search, a KNN index is used to model the user&amp;rsquo;s interests and preferences, based on the user&amp;rsquo;s past search queries and the search results that the user has clicked on (which are modeled by the TTSN). (
&lt;a href="https://read.readwise.io/read/01gr7f9era9np34s44fsc2v85z" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>feature engineering for personalized search is more focused on designing features that can be used to rank and retrieve search results (documents) that are relevant to the user. (
&lt;a href="https://read.readwise.io/read/01gr7fbgezpqmdyfgddpdqef8b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>search has a much more severe long tail than recommendations. (
&lt;a href="https://read.readwise.io/read/01gr7fd1xppyj70x3jx7bxhga6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>NLP-Type Features&lt;/strong> – Features that understand the semantic content of the query. These might come from SOTA models (such as BERT), FastText (either directly fed or the dot product of the query), or document embeddings. (
&lt;a href="https://read.readwise.io/read/01gr7ffbr0dj2djt02txn4tnjb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Reputation Features&lt;/strong> – Features representing how reputable of a source the document comes from. These might include the author of the document, the number of inbound links, the page rank, etc. (
&lt;a href="https://read.readwise.io/read/01gr7fg9heahybz352cdqbmb84" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>latency is a big factor with search of any kind. (
&lt;a href="https://read.readwise.io/read/01gr7fh5cp49rsrx0kjkr2erg2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Focus Time for Developers and Everybody Else</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Focus-Time-for-Developers-and-Everybody-Else/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Focus-Time-for-Developers-and-Everybody-Else/</guid><description>&lt;h1 id="focus-time-for-developers-and-everybody-else">Focus Time for Developers and Everybody Else&lt;/h1>
&lt;p>
&lt;img src="https://kore-nordmann.de/blog/card/focus_time_for_developers_and_everybody_else.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[kore-nordmann.de]]&lt;/li>
&lt;li>Full Title: Focus Time for Developers and Everybody Else&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14579/web" rel="noopener">https://techleaddigest.net/link/14579/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Everybody knows that focus time is important especially for individual contributor levels. But also in a management role I value focus time a lot for strategic work, research, analysis, and sometimes even just to be able to process all input and reflect on what the current state and bigger picture are. (
&lt;a href="https://read.readwise.io/read/01grw3vr9r093epqp0608g85e1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To ensure sufficient focus time for everyone we mainly used two strategies in the tech department:
&lt;ol>
&lt;li>Have dedicated meeting slots in everyone&amp;rsquo;s calendars and use them for all/most meetings&lt;/li>
&lt;li>Have senior/principal developers available to unblock people quickly (
&lt;a href="https://read.readwise.io/read/01grw3y4c405g3t5157qpcr5s4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>And by this there are usually only two hours of meeting time per day, and they are always at the same time, so you can plan your day accordingly and you&amp;rsquo;ll know when you have to leave your focus zone (
&lt;a href="https://read.readwise.io/read/01grw42xjgjffdjfj091svjdgk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Clearly define expected response times
• Mail: One working day
• Slack notification: 4 hours (during working hours) (
&lt;a href="https://read.readwise.io/read/01grw43k9v3jat5d8x2t0gqyrh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Offer a space to meet and host &amp;ldquo;open office hours&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01grw43ykavv6f1j6sad10xyf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is OK to close Slack (or not look at it) for 4 hours (
&lt;a href="https://read.readwise.io/read/01grw44ga6wkyrbxegfztxd230" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[kore-nordmann.de]]
title: &amp;ldquo;Focus Time for Developers and Everybody Else&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="focus-time-for-developers-and-everybody-else-1">Focus Time for Developers and Everybody Else&lt;/h1>
&lt;p>
&lt;img src="https://kore-nordmann.de/blog/card/focus_time_for_developers_and_everybody_else.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[kore-nordmann.de]]&lt;/li>
&lt;li>Full Title: Focus Time for Developers and Everybody Else&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14579/web" rel="noopener">https://techleaddigest.net/link/14579/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Everybody knows that focus time is important especially for individual contributor levels. But also in a management role I value focus time a lot for strategic work, research, analysis, and sometimes even just to be able to process all input and reflect on what the current state and bigger picture are. (
&lt;a href="https://read.readwise.io/read/01grw3vr9r093epqp0608g85e1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To ensure sufficient focus time for everyone we mainly used two strategies in the tech department:
&lt;ol>
&lt;li>Have dedicated meeting slots in everyone&amp;rsquo;s calendars and use them for all/most meetings&lt;/li>
&lt;li>Have senior/principal developers available to unblock people quickly (
&lt;a href="https://read.readwise.io/read/01grw3y4c405g3t5157qpcr5s4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>And by this there are usually only two hours of meeting time per day, and they are always at the same time, so you can plan your day accordingly and you&amp;rsquo;ll know when you have to leave your focus zone (
&lt;a href="https://read.readwise.io/read/01grw42xjgjffdjfj091svjdgk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Clearly define expected response times
• Mail: One working day
• Slack notification: 4 hours (during working hours) (
&lt;a href="https://read.readwise.io/read/01grw43k9v3jat5d8x2t0gqyrh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Offer a space to meet and host &amp;ldquo;open office hours&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01grw43ykavv6f1j6sad10xyf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is OK to close Slack (or not look at it) for 4 hours (
&lt;a href="https://read.readwise.io/read/01grw44ga6wkyrbxegfztxd230" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[kore-nordmann.de]]
title: &amp;ldquo;Focus Time for Developers and Everybody Else&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="focus-time-for-developers-and-everybody-else-2">Focus Time for Developers and Everybody Else&lt;/h1>
&lt;p>
&lt;img src="https://kore-nordmann.de/blog/card/focus_time_for_developers_and_everybody_else.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[kore-nordmann.de]]&lt;/li>
&lt;li>Full Title: Focus Time for Developers and Everybody Else&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14579/web" rel="noopener">https://techleaddigest.net/link/14579/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Everybody knows that focus time is important especially for individual contributor levels. But also in a management role I value focus time a lot for strategic work, research, analysis, and sometimes even just to be able to process all input and reflect on what the current state and bigger picture are. (
&lt;a href="https://read.readwise.io/read/01grw3vr9r093epqp0608g85e1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To ensure sufficient focus time for everyone we mainly used two strategies in the tech department:
&lt;ol>
&lt;li>Have dedicated meeting slots in everyone&amp;rsquo;s calendars and use them for all/most meetings&lt;/li>
&lt;li>Have senior/principal developers available to unblock people quickly (
&lt;a href="https://read.readwise.io/read/01grw3y4c405g3t5157qpcr5s4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>And by this there are usually only two hours of meeting time per day, and they are always at the same time, so you can plan your day accordingly and you&amp;rsquo;ll know when you have to leave your focus zone (
&lt;a href="https://read.readwise.io/read/01grw42xjgjffdjfj091svjdgk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Clearly define expected response times
• Mail: One working day
• Slack notification: 4 hours (during working hours) (
&lt;a href="https://read.readwise.io/read/01grw43k9v3jat5d8x2t0gqyrh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Offer a space to meet and host &amp;ldquo;open office hours&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01grw43ykavv6f1j6sad10xyf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is OK to close Slack (or not look at it) for 4 hours (
&lt;a href="https://read.readwise.io/read/01grw44ga6wkyrbxegfztxd230" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[kore-nordmann.de]]
title: &amp;ldquo;Focus Time for Developers and Everybody Else&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="focus-time-for-developers-and-everybody-else-3">Focus Time for Developers and Everybody Else&lt;/h1>
&lt;p>
&lt;img src="https://kore-nordmann.de/blog/card/focus_time_for_developers_and_everybody_else.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[kore-nordmann.de]]&lt;/li>
&lt;li>Full Title: Focus Time for Developers and Everybody Else&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14579/web" rel="noopener">https://techleaddigest.net/link/14579/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Everybody knows that focus time is important especially for individual contributor levels. But also in a management role I value focus time a lot for strategic work, research, analysis, and sometimes even just to be able to process all input and reflect on what the current state and bigger picture are. (
&lt;a href="https://read.readwise.io/read/01grw3vr9r093epqp0608g85e1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To ensure sufficient focus time for everyone we mainly used two strategies in the tech department:
&lt;ol>
&lt;li>Have dedicated meeting slots in everyone&amp;rsquo;s calendars and use them for all/most meetings&lt;/li>
&lt;li>Have senior/principal developers available to unblock people quickly (
&lt;a href="https://read.readwise.io/read/01grw3y4c405g3t5157qpcr5s4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>And by this there are usually only two hours of meeting time per day, and they are always at the same time, so you can plan your day accordingly and you&amp;rsquo;ll know when you have to leave your focus zone (
&lt;a href="https://read.readwise.io/read/01grw42xjgjffdjfj091svjdgk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Clearly define expected response times
• Mail: One working day
• Slack notification: 4 hours (during working hours) (
&lt;a href="https://read.readwise.io/read/01grw43k9v3jat5d8x2t0gqyrh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Offer a space to meet and host &amp;ldquo;open office hours&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01grw43ykavv6f1j6sad10xyf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it is OK to close Slack (or not look at it) for 4 hours (
&lt;a href="https://read.readwise.io/read/01grw44ga6wkyrbxegfztxd230" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>From Data to Product</title><link>https://pelayoarbues.github.io/literature-notes/Articles/From-Data-to-Product/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/From-Data-to-Product/</guid><description>&lt;h1 id="from-data-to-product">From Data to Product&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1008,h_528,c_fill,f_jpg,q_auto:best,fl_progressive:steep/https%3A%2F%2Fericdataproduct.substack.com%2Ftwitter%2Fsubscribe-card.svg%3Fv%3D1ae85614017f9ca385b888bb70c2878d%26version%3D7" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eric Weber]]&lt;/li>
&lt;li>Full Title: From Data to Product&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ericdataproduct.substack.com" rel="noopener">https://ericdataproduct.substack.com&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>I began to suspect I had fallen into the same “simplicity” trap that many do when they use the word platform. This platform product manager role was not in fact managing one product, but instead the 4-5 separate products that comprised the platform. It was only once I dug into that level of detail that I felt I could fully describe the role. (
&lt;a href="https://read.readwise.io/read/01gqd68y4kx0ewrxjgr3768dxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>My point in writing this is to elevate the importance of discussing &lt;em>if&lt;/em> something should become a data product. It is really tempting to automate everything, to democratize a capability, so to speak. It is much harder to say “I don’t think that’s the right investment for us, let’s keep doing it more manually.” But for many companies and organizations, that might be the right answer. (
&lt;a href="https://read.readwise.io/read/01gqdkjqbzgqystsdg1pfpvda1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Let’s put aside the idea of persona, user needs, understanding the business problem and getting stakeholder buy-in. While those are hugely important for creating a useful data product, I’ve previously written about the pitfalls of not accounting for these components in a careful, methodical way. Instead, here are a few situations where the design of the product itself (more backend than frontend for now) is the bottleneck for growth and adoption of the product. (
&lt;a href="https://read.readwise.io/read/01gqdkmdk03sy2xehh7qh39s75" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In these newsletters, I typically try to include 5 points or things to think about. But today, I’ve just got one: look at the product you are responsible for. Look at the list of things you wish could be better about it. Then cut that list down to 1 thing. Yes, just one. It might not have anything to do with improving the data and everything to do with the product experience itself. (
&lt;a href="https://read.readwise.io/read/01gqdkrj1qqvb7nazgsy5x45kp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Why am I taking the time to say all of this? Because the key to being a data product manager is knowing when it isn’t all about the data. At some point, you may get no improvement from technical enhancements. In the coming 12-24 months, we’ll only get to do fewer things, not more. It won’t be all about the data, even if your job is to own a data product. (
&lt;a href="https://read.readwise.io/read/01gqdkrvyhf5h8jt09kjs7715y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Personas&lt;/em> are general representations of a user or customer. We build personas to represent different user types and characteristics of those users that use the product we build in a consistent or similar way. People are &lt;em>not&lt;/em> personas. An individual person is full of nuances and unique background, intentions and training. We need to actively create personas, we do not just “find them”. (
&lt;a href="https://read.readwise.io/read/01gqdkt8bcdj79sfjbakw6mawx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This desire to help without thinking about personas is exactly where data products go off the rails. (
&lt;a href="https://read.readwise.io/read/01gqdktv31fy6vr2hcvch6j3d2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The builders of the data products are well intentioned. They are trying to do their best. They are listening to customers. It just happens to be the customers they are listening to are the loudest in the room and often those they are most familiar or comfortable with in the organization. We need to work actively against this tendency. (
&lt;a href="https://read.readwise.io/read/01gqdkv8s5j0rkpb812yda0mhe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Spend time defining the key personas in your organization that use or are impacted by data products. It is much easier to define these personas upfront that do it in an intense moment of planning or prioritization where time and patience are often much lower in availability. If you have these personas and socialize them in your company, you’ll be much better off when it comes to hard decisions. (
&lt;a href="https://read.readwise.io/read/01gqdkvdfm67ktvrn8hgvd27n2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Push actively against the “Person X wants us to build Product Y” mentality. Many organizations I have been a part of justify product decisions with a name of someone who wants it, rather than the personas that they product actually serves. Specific people and decision makers are temporary at companies, but personas are long lasting. Ask about the persona. This is where having the personas laid out already pays off. (
&lt;a href="https://read.readwise.io/read/01gqdkw6zsve17exmjywwf48er" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It sounds simple to say focus on the persona. But power structures in an organization are a very real thing. It is hard for a data scientist or product manager to tell a VP that the product doesn’t clearly address a persona. This is where leadership matters a great deal. If you want to see change in this space, it cannot just be put on individual contributors. Leadership needs to sponsor these ideas and these processes. (
&lt;a href="https://read.readwise.io/read/01gqdkwnmtrst7s3vzbx5x7zd4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company deprioritizes an area of investment, think about how your product investment should reflect that (or not). It is really common for a company to pivot investment in an “area” (which might be a key persona for your product) but the rest of the company does not quickly update to reflect that pivot. Specifically, you might have close relationships with key stakeholders who tell you “yeah, that isn’t important to the company, but I need it to do my job.” Be very wary of this type of situation. By focusing on people, it is easy to get confused about “what matters”. By focusing on where the company is headed and how different personas are part of that, it is easier to think less through the lens of working relationships and more through where the company needs to go. (
&lt;a href="https://read.readwise.io/read/01gqdkzczhxpzs69eazsg9jemy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eric Weber]]
title: &amp;ldquo;From Data to Product&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="from-data-to-product-1">From Data to Product&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1008,h_528,c_fill,f_jpg,q_auto:best,fl_progressive:steep/https%3A%2F%2Fericdataproduct.substack.com%2Ftwitter%2Fsubscribe-card.svg%3Fv%3D1ae85614017f9ca385b888bb70c2878d%26version%3D7" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eric Weber]]&lt;/li>
&lt;li>Full Title: From Data to Product&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ericdataproduct.substack.com" rel="noopener">https://ericdataproduct.substack.com&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>I began to suspect I had fallen into the same “simplicity” trap that many do when they use the word platform. This platform product manager role was not in fact managing one product, but instead the 4-5 separate products that comprised the platform. It was only once I dug into that level of detail that I felt I could fully describe the role. (
&lt;a href="https://read.readwise.io/read/01gqd68y4kx0ewrxjgr3768dxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>My point in writing this is to elevate the importance of discussing &lt;em>if&lt;/em> something should become a data product. It is really tempting to automate everything, to democratize a capability, so to speak. It is much harder to say “I don’t think that’s the right investment for us, let’s keep doing it more manually.” But for many companies and organizations, that might be the right answer. (
&lt;a href="https://read.readwise.io/read/01gqdkjqbzgqystsdg1pfpvda1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Let’s put aside the idea of persona, user needs, understanding the business problem and getting stakeholder buy-in. While those are hugely important for creating a useful data product, I’ve previously written about the pitfalls of not accounting for these components in a careful, methodical way. Instead, here are a few situations where the design of the product itself (more backend than frontend for now) is the bottleneck for growth and adoption of the product. (
&lt;a href="https://read.readwise.io/read/01gqdkmdk03sy2xehh7qh39s75" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In these newsletters, I typically try to include 5 points or things to think about. But today, I’ve just got one: look at the product you are responsible for. Look at the list of things you wish could be better about it. Then cut that list down to 1 thing. Yes, just one. It might not have anything to do with improving the data and everything to do with the product experience itself. (
&lt;a href="https://read.readwise.io/read/01gqdkrj1qqvb7nazgsy5x45kp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Why am I taking the time to say all of this? Because the key to being a data product manager is knowing when it isn’t all about the data. At some point, you may get no improvement from technical enhancements. In the coming 12-24 months, we’ll only get to do fewer things, not more. It won’t be all about the data, even if your job is to own a data product. (
&lt;a href="https://read.readwise.io/read/01gqdkrvyhf5h8jt09kjs7715y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Personas&lt;/em> are general representations of a user or customer. We build personas to represent different user types and characteristics of those users that use the product we build in a consistent or similar way. People are &lt;em>not&lt;/em> personas. An individual person is full of nuances and unique background, intentions and training. We need to actively create personas, we do not just “find them”. (
&lt;a href="https://read.readwise.io/read/01gqdkt8bcdj79sfjbakw6mawx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This desire to help without thinking about personas is exactly where data products go off the rails. (
&lt;a href="https://read.readwise.io/read/01gqdktv31fy6vr2hcvch6j3d2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The builders of the data products are well intentioned. They are trying to do their best. They are listening to customers. It just happens to be the customers they are listening to are the loudest in the room and often those they are most familiar or comfortable with in the organization. We need to work actively against this tendency. (
&lt;a href="https://read.readwise.io/read/01gqdkv8s5j0rkpb812yda0mhe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Spend time defining the key personas in your organization that use or are impacted by data products. It is much easier to define these personas upfront that do it in an intense moment of planning or prioritization where time and patience are often much lower in availability. If you have these personas and socialize them in your company, you’ll be much better off when it comes to hard decisions. (
&lt;a href="https://read.readwise.io/read/01gqdkvdfm67ktvrn8hgvd27n2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Push actively against the “Person X wants us to build Product Y” mentality. Many organizations I have been a part of justify product decisions with a name of someone who wants it, rather than the personas that they product actually serves. Specific people and decision makers are temporary at companies, but personas are long lasting. Ask about the persona. This is where having the personas laid out already pays off. (
&lt;a href="https://read.readwise.io/read/01gqdkw6zsve17exmjywwf48er" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It sounds simple to say focus on the persona. But power structures in an organization are a very real thing. It is hard for a data scientist or product manager to tell a VP that the product doesn’t clearly address a persona. This is where leadership matters a great deal. If you want to see change in this space, it cannot just be put on individual contributors. Leadership needs to sponsor these ideas and these processes. (
&lt;a href="https://read.readwise.io/read/01gqdkwnmtrst7s3vzbx5x7zd4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company deprioritizes an area of investment, think about how your product investment should reflect that (or not). It is really common for a company to pivot investment in an “area” (which might be a key persona for your product) but the rest of the company does not quickly update to reflect that pivot. Specifically, you might have close relationships with key stakeholders who tell you “yeah, that isn’t important to the company, but I need it to do my job.” Be very wary of this type of situation. By focusing on people, it is easy to get confused about “what matters”. By focusing on where the company is headed and how different personas are part of that, it is easier to think less through the lens of working relationships and more through where the company needs to go. (
&lt;a href="https://read.readwise.io/read/01gqdkzczhxpzs69eazsg9jemy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eric Weber]]
title: &amp;ldquo;From Data to Product&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="from-data-to-product-2">From Data to Product&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1008,h_528,c_fill,f_jpg,q_auto:best,fl_progressive:steep/https%3A%2F%2Fericdataproduct.substack.com%2Ftwitter%2Fsubscribe-card.svg%3Fv%3D1ae85614017f9ca385b888bb70c2878d%26version%3D7" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eric Weber]]&lt;/li>
&lt;li>Full Title: From Data to Product&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ericdataproduct.substack.com" rel="noopener">https://ericdataproduct.substack.com&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>I began to suspect I had fallen into the same “simplicity” trap that many do when they use the word platform. This platform product manager role was not in fact managing one product, but instead the 4-5 separate products that comprised the platform. It was only once I dug into that level of detail that I felt I could fully describe the role. (
&lt;a href="https://read.readwise.io/read/01gqd68y4kx0ewrxjgr3768dxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>My point in writing this is to elevate the importance of discussing &lt;em>if&lt;/em> something should become a data product. It is really tempting to automate everything, to democratize a capability, so to speak. It is much harder to say “I don’t think that’s the right investment for us, let’s keep doing it more manually.” But for many companies and organizations, that might be the right answer. (
&lt;a href="https://read.readwise.io/read/01gqdkjqbzgqystsdg1pfpvda1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Let’s put aside the idea of persona, user needs, understanding the business problem and getting stakeholder buy-in. While those are hugely important for creating a useful data product, I’ve previously written about the pitfalls of not accounting for these components in a careful, methodical way. Instead, here are a few situations where the design of the product itself (more backend than frontend for now) is the bottleneck for growth and adoption of the product. (
&lt;a href="https://read.readwise.io/read/01gqdkmdk03sy2xehh7qh39s75" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In these newsletters, I typically try to include 5 points or things to think about. But today, I’ve just got one: look at the product you are responsible for. Look at the list of things you wish could be better about it. Then cut that list down to 1 thing. Yes, just one. It might not have anything to do with improving the data and everything to do with the product experience itself. (
&lt;a href="https://read.readwise.io/read/01gqdkrj1qqvb7nazgsy5x45kp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Why am I taking the time to say all of this? Because the key to being a data product manager is knowing when it isn’t all about the data. At some point, you may get no improvement from technical enhancements. In the coming 12-24 months, we’ll only get to do fewer things, not more. It won’t be all about the data, even if your job is to own a data product. (
&lt;a href="https://read.readwise.io/read/01gqdkrvyhf5h8jt09kjs7715y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Personas&lt;/em> are general representations of a user or customer. We build personas to represent different user types and characteristics of those users that use the product we build in a consistent or similar way. People are &lt;em>not&lt;/em> personas. An individual person is full of nuances and unique background, intentions and training. We need to actively create personas, we do not just “find them”. (
&lt;a href="https://read.readwise.io/read/01gqdkt8bcdj79sfjbakw6mawx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This desire to help without thinking about personas is exactly where data products go off the rails. (
&lt;a href="https://read.readwise.io/read/01gqdktv31fy6vr2hcvch6j3d2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The builders of the data products are well intentioned. They are trying to do their best. They are listening to customers. It just happens to be the customers they are listening to are the loudest in the room and often those they are most familiar or comfortable with in the organization. We need to work actively against this tendency. (
&lt;a href="https://read.readwise.io/read/01gqdkv8s5j0rkpb812yda0mhe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Spend time defining the key personas in your organization that use or are impacted by data products. It is much easier to define these personas upfront that do it in an intense moment of planning or prioritization where time and patience are often much lower in availability. If you have these personas and socialize them in your company, you’ll be much better off when it comes to hard decisions. (
&lt;a href="https://read.readwise.io/read/01gqdkvdfm67ktvrn8hgvd27n2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Push actively against the “Person X wants us to build Product Y” mentality. Many organizations I have been a part of justify product decisions with a name of someone who wants it, rather than the personas that they product actually serves. Specific people and decision makers are temporary at companies, but personas are long lasting. Ask about the persona. This is where having the personas laid out already pays off. (
&lt;a href="https://read.readwise.io/read/01gqdkw6zsve17exmjywwf48er" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It sounds simple to say focus on the persona. But power structures in an organization are a very real thing. It is hard for a data scientist or product manager to tell a VP that the product doesn’t clearly address a persona. This is where leadership matters a great deal. If you want to see change in this space, it cannot just be put on individual contributors. Leadership needs to sponsor these ideas and these processes. (
&lt;a href="https://read.readwise.io/read/01gqdkwnmtrst7s3vzbx5x7zd4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company deprioritizes an area of investment, think about how your product investment should reflect that (or not). It is really common for a company to pivot investment in an “area” (which might be a key persona for your product) but the rest of the company does not quickly update to reflect that pivot. Specifically, you might have close relationships with key stakeholders who tell you “yeah, that isn’t important to the company, but I need it to do my job.” Be very wary of this type of situation. By focusing on people, it is easy to get confused about “what matters”. By focusing on where the company is headed and how different personas are part of that, it is easier to think less through the lens of working relationships and more through where the company needs to go. (
&lt;a href="https://read.readwise.io/read/01gqdkzczhxpzs69eazsg9jemy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eric Weber]]
title: &amp;ldquo;From Data to Product&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="from-data-to-product-3">From Data to Product&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1008,h_528,c_fill,f_jpg,q_auto:best,fl_progressive:steep/https%3A%2F%2Fericdataproduct.substack.com%2Ftwitter%2Fsubscribe-card.svg%3Fv%3D1ae85614017f9ca385b888bb70c2878d%26version%3D7" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eric Weber]]&lt;/li>
&lt;li>Full Title: From Data to Product&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ericdataproduct.substack.com" rel="noopener">https://ericdataproduct.substack.com&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>I began to suspect I had fallen into the same “simplicity” trap that many do when they use the word platform. This platform product manager role was not in fact managing one product, but instead the 4-5 separate products that comprised the platform. It was only once I dug into that level of detail that I felt I could fully describe the role. (
&lt;a href="https://read.readwise.io/read/01gqd68y4kx0ewrxjgr3768dxs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>My point in writing this is to elevate the importance of discussing &lt;em>if&lt;/em> something should become a data product. It is really tempting to automate everything, to democratize a capability, so to speak. It is much harder to say “I don’t think that’s the right investment for us, let’s keep doing it more manually.” But for many companies and organizations, that might be the right answer. (
&lt;a href="https://read.readwise.io/read/01gqdkjqbzgqystsdg1pfpvda1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Let’s put aside the idea of persona, user needs, understanding the business problem and getting stakeholder buy-in. While those are hugely important for creating a useful data product, I’ve previously written about the pitfalls of not accounting for these components in a careful, methodical way. Instead, here are a few situations where the design of the product itself (more backend than frontend for now) is the bottleneck for growth and adoption of the product. (
&lt;a href="https://read.readwise.io/read/01gqdkmdk03sy2xehh7qh39s75" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In these newsletters, I typically try to include 5 points or things to think about. But today, I’ve just got one: look at the product you are responsible for. Look at the list of things you wish could be better about it. Then cut that list down to 1 thing. Yes, just one. It might not have anything to do with improving the data and everything to do with the product experience itself. (
&lt;a href="https://read.readwise.io/read/01gqdkrj1qqvb7nazgsy5x45kp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Why am I taking the time to say all of this? Because the key to being a data product manager is knowing when it isn’t all about the data. At some point, you may get no improvement from technical enhancements. In the coming 12-24 months, we’ll only get to do fewer things, not more. It won’t be all about the data, even if your job is to own a data product. (
&lt;a href="https://read.readwise.io/read/01gqdkrvyhf5h8jt09kjs7715y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Personas&lt;/em> are general representations of a user or customer. We build personas to represent different user types and characteristics of those users that use the product we build in a consistent or similar way. People are &lt;em>not&lt;/em> personas. An individual person is full of nuances and unique background, intentions and training. We need to actively create personas, we do not just “find them”. (
&lt;a href="https://read.readwise.io/read/01gqdkt8bcdj79sfjbakw6mawx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This desire to help without thinking about personas is exactly where data products go off the rails. (
&lt;a href="https://read.readwise.io/read/01gqdktv31fy6vr2hcvch6j3d2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The builders of the data products are well intentioned. They are trying to do their best. They are listening to customers. It just happens to be the customers they are listening to are the loudest in the room and often those they are most familiar or comfortable with in the organization. We need to work actively against this tendency. (
&lt;a href="https://read.readwise.io/read/01gqdkv8s5j0rkpb812yda0mhe" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Spend time defining the key personas in your organization that use or are impacted by data products. It is much easier to define these personas upfront that do it in an intense moment of planning or prioritization where time and patience are often much lower in availability. If you have these personas and socialize them in your company, you’ll be much better off when it comes to hard decisions. (
&lt;a href="https://read.readwise.io/read/01gqdkvdfm67ktvrn8hgvd27n2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Push actively against the “Person X wants us to build Product Y” mentality. Many organizations I have been a part of justify product decisions with a name of someone who wants it, rather than the personas that they product actually serves. Specific people and decision makers are temporary at companies, but personas are long lasting. Ask about the persona. This is where having the personas laid out already pays off. (
&lt;a href="https://read.readwise.io/read/01gqdkw6zsve17exmjywwf48er" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It sounds simple to say focus on the persona. But power structures in an organization are a very real thing. It is hard for a data scientist or product manager to tell a VP that the product doesn’t clearly address a persona. This is where leadership matters a great deal. If you want to see change in this space, it cannot just be put on individual contributors. Leadership needs to sponsor these ideas and these processes. (
&lt;a href="https://read.readwise.io/read/01gqdkwnmtrst7s3vzbx5x7zd4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company deprioritizes an area of investment, think about how your product investment should reflect that (or not). It is really common for a company to pivot investment in an “area” (which might be a key persona for your product) but the rest of the company does not quickly update to reflect that pivot. Specifically, you might have close relationships with key stakeholders who tell you “yeah, that isn’t important to the company, but I need it to do my job.” Be very wary of this type of situation. By focusing on people, it is easy to get confused about “what matters”. By focusing on where the company is headed and how different personas are part of that, it is easier to think less through the lens of working relationships and more through where the company needs to go. (
&lt;a href="https://read.readwise.io/read/01gqdkzczhxpzs69eazsg9jemy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Growing With Your Company&amp;#39;s Complexity.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Growing-With-Your-Companys-Complexity./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Growing-With-Your-Companys-Complexity./</guid><description>&lt;h1 id="growing-with-your-companys-complexity">Growing With Your Company&amp;rsquo;s Complexity.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/dnm-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Growing With Your Company&amp;rsquo;s Complexity.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/growing-with-your-company/" rel="noopener">https://lethain.com/growing-with-your-company/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a business’ complexity rapidly grows, folks in important organizational roles often struggle to learn quickly enough to remain effective in their current roles. In such cases, opportunities moved on to someone else who was currently available, often someone newly hired into the company. (
&lt;a href="https://read.readwise.io/read/01gs6b98yg56kxceh4r9tdffhk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4m6mgeh3k93nz19j09n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4mrv32epq6by3yrtjvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everyone has some set of tasks that they’re already &lt;em>experienced&lt;/em> doing, and another set that they’re still &lt;em>learning&lt;/em>. In most jobs, you generate value when you’re performing tasks you’re experienced with, and you’re generating &lt;em>future&lt;/em> value when you’re performing tasks you’re learning. (
&lt;a href="https://read.readwise.io/read/01gs6ba1m83jtvaakaqw12syw9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf612c8y34j87yjf1wcb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf63dd512frtk2se17r3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an ideal career, you find yourself progressing up the difficultly curve, such that you are always doing some stuff you’re good at, and undertaking some new work (
&lt;a href="https://read.readwise.io/read/01gs6bb3qs5wa0r022y08tfrzm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>you often find yourself experienced at tasks that the broader organization is unfamiliar with. This is a tricky time, because the organization depends on you to deliver the work that only you’re experienced with, while simultaneously depending on you to rapidly learn new skills that no one in the organization can teach you. (
&lt;a href="https://read.readwise.io/read/01gs6bcb4acadtn9zzgsccka3v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The consequences here are significant. The person in that role will often become a bottleneck on the company’s execution, and their rate of learning will decrease even more as they refocus on work they’ve already mastered (
&lt;a href="https://read.readwise.io/read/01gs6bjneyn72ngndfhx9hw8bg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s often the case that any manager’s failure to scale with the company can unintentionally cram down an entire organization’s career growth. (
&lt;a href="https://read.readwise.io/read/01gs6bm0py2qdknv5fqqtsn0tq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>our goal as a leader is to offload work that you are experienced at to the wider organization as rapidly as possible, freeing up room for you to continue learning. (
&lt;a href="https://read.readwise.io/read/01gs6bmhdcvvv8qxfh725j24st" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>There is some nuance here. Often you’ll hear folks say that they want to be more strategic, and then they stop doing a bunch of critical work. That’s not the solution here. The goal is to solve for the work you’re experience with, not to abandon it. (
&lt;a href="https://read.readwise.io/read/01gs6c4ghvf1zch8vh3jcda8cn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the majority of my learning occurs while working through the challenges of my daily work, and I think that’s an important goal to optimize for when trying to learn quickly enough to remain in-role at a growing company. (
&lt;a href="https://read.readwise.io/read/01gs6c84dkcpwnahp1py0k93qp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Growing With Your Company's Complexity.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="growing-with-your-companys-complexity-1">Growing With Your Company&amp;rsquo;s Complexity.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/dnm-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Growing With Your Company&amp;rsquo;s Complexity.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/growing-with-your-company/" rel="noopener">https://lethain.com/growing-with-your-company/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a business’ complexity rapidly grows, folks in important organizational roles often struggle to learn quickly enough to remain effective in their current roles. In such cases, opportunities moved on to someone else who was currently available, often someone newly hired into the company. (
&lt;a href="https://read.readwise.io/read/01gs6b98yg56kxceh4r9tdffhk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4m6mgeh3k93nz19j09n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4mrv32epq6by3yrtjvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everyone has some set of tasks that they’re already &lt;em>experienced&lt;/em> doing, and another set that they’re still &lt;em>learning&lt;/em>. In most jobs, you generate value when you’re performing tasks you’re experienced with, and you’re generating &lt;em>future&lt;/em> value when you’re performing tasks you’re learning. (
&lt;a href="https://read.readwise.io/read/01gs6ba1m83jtvaakaqw12syw9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf612c8y34j87yjf1wcb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf63dd512frtk2se17r3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an ideal career, you find yourself progressing up the difficultly curve, such that you are always doing some stuff you’re good at, and undertaking some new work (
&lt;a href="https://read.readwise.io/read/01gs6bb3qs5wa0r022y08tfrzm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>you often find yourself experienced at tasks that the broader organization is unfamiliar with. This is a tricky time, because the organization depends on you to deliver the work that only you’re experienced with, while simultaneously depending on you to rapidly learn new skills that no one in the organization can teach you. (
&lt;a href="https://read.readwise.io/read/01gs6bcb4acadtn9zzgsccka3v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The consequences here are significant. The person in that role will often become a bottleneck on the company’s execution, and their rate of learning will decrease even more as they refocus on work they’ve already mastered (
&lt;a href="https://read.readwise.io/read/01gs6bjneyn72ngndfhx9hw8bg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s often the case that any manager’s failure to scale with the company can unintentionally cram down an entire organization’s career growth. (
&lt;a href="https://read.readwise.io/read/01gs6bm0py2qdknv5fqqtsn0tq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>our goal as a leader is to offload work that you are experienced at to the wider organization as rapidly as possible, freeing up room for you to continue learning. (
&lt;a href="https://read.readwise.io/read/01gs6bmhdcvvv8qxfh725j24st" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>There is some nuance here. Often you’ll hear folks say that they want to be more strategic, and then they stop doing a bunch of critical work. That’s not the solution here. The goal is to solve for the work you’re experience with, not to abandon it. (
&lt;a href="https://read.readwise.io/read/01gs6c4ghvf1zch8vh3jcda8cn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the majority of my learning occurs while working through the challenges of my daily work, and I think that’s an important goal to optimize for when trying to learn quickly enough to remain in-role at a growing company. (
&lt;a href="https://read.readwise.io/read/01gs6c84dkcpwnahp1py0k93qp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Growing With Your Company's Complexity.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="growing-with-your-companys-complexity-2">Growing With Your Company&amp;rsquo;s Complexity.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/dnm-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Growing With Your Company&amp;rsquo;s Complexity.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/growing-with-your-company/" rel="noopener">https://lethain.com/growing-with-your-company/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a business’ complexity rapidly grows, folks in important organizational roles often struggle to learn quickly enough to remain effective in their current roles. In such cases, opportunities moved on to someone else who was currently available, often someone newly hired into the company. (
&lt;a href="https://read.readwise.io/read/01gs6b98yg56kxceh4r9tdffhk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4m6mgeh3k93nz19j09n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4mrv32epq6by3yrtjvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everyone has some set of tasks that they’re already &lt;em>experienced&lt;/em> doing, and another set that they’re still &lt;em>learning&lt;/em>. In most jobs, you generate value when you’re performing tasks you’re experienced with, and you’re generating &lt;em>future&lt;/em> value when you’re performing tasks you’re learning. (
&lt;a href="https://read.readwise.io/read/01gs6ba1m83jtvaakaqw12syw9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf612c8y34j87yjf1wcb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf63dd512frtk2se17r3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an ideal career, you find yourself progressing up the difficultly curve, such that you are always doing some stuff you’re good at, and undertaking some new work (
&lt;a href="https://read.readwise.io/read/01gs6bb3qs5wa0r022y08tfrzm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>you often find yourself experienced at tasks that the broader organization is unfamiliar with. This is a tricky time, because the organization depends on you to deliver the work that only you’re experienced with, while simultaneously depending on you to rapidly learn new skills that no one in the organization can teach you. (
&lt;a href="https://read.readwise.io/read/01gs6bcb4acadtn9zzgsccka3v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The consequences here are significant. The person in that role will often become a bottleneck on the company’s execution, and their rate of learning will decrease even more as they refocus on work they’ve already mastered (
&lt;a href="https://read.readwise.io/read/01gs6bjneyn72ngndfhx9hw8bg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s often the case that any manager’s failure to scale with the company can unintentionally cram down an entire organization’s career growth. (
&lt;a href="https://read.readwise.io/read/01gs6bm0py2qdknv5fqqtsn0tq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>our goal as a leader is to offload work that you are experienced at to the wider organization as rapidly as possible, freeing up room for you to continue learning. (
&lt;a href="https://read.readwise.io/read/01gs6bmhdcvvv8qxfh725j24st" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>There is some nuance here. Often you’ll hear folks say that they want to be more strategic, and then they stop doing a bunch of critical work. That’s not the solution here. The goal is to solve for the work you’re experience with, not to abandon it. (
&lt;a href="https://read.readwise.io/read/01gs6c4ghvf1zch8vh3jcda8cn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the majority of my learning occurs while working through the challenges of my daily work, and I think that’s an important goal to optimize for when trying to learn quickly enough to remain in-role at a growing company. (
&lt;a href="https://read.readwise.io/read/01gs6c84dkcpwnahp1py0k93qp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Growing With Your Company's Complexity.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="growing-with-your-companys-complexity-3">Growing With Your Company&amp;rsquo;s Complexity.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/dnm-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Growing With Your Company&amp;rsquo;s Complexity.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/growing-with-your-company/" rel="noopener">https://lethain.com/growing-with-your-company/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a business’ complexity rapidly grows, folks in important organizational roles often struggle to learn quickly enough to remain effective in their current roles. In such cases, opportunities moved on to someone else who was currently available, often someone newly hired into the company. (
&lt;a href="https://read.readwise.io/read/01gs6b98yg56kxceh4r9tdffhk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4m6mgeh3k93nz19j09n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-simple.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6ba4mrv32epq6by3yrtjvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everyone has some set of tasks that they’re already &lt;em>experienced&lt;/em> doing, and another set that they’re still &lt;em>learning&lt;/em>. In most jobs, you generate value when you’re performing tasks you’re experienced with, and you’re generating &lt;em>future&lt;/em> value when you’re performing tasks you’re learning. (
&lt;a href="https://read.readwise.io/read/01gs6ba1m83jtvaakaqw12syw9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf612c8y34j87yjf1wcb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2019/dnm-over-time.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gs6baf63dd512frtk2se17r3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In an ideal career, you find yourself progressing up the difficultly curve, such that you are always doing some stuff you’re good at, and undertaking some new work (
&lt;a href="https://read.readwise.io/read/01gs6bb3qs5wa0r022y08tfrzm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>you often find yourself experienced at tasks that the broader organization is unfamiliar with. This is a tricky time, because the organization depends on you to deliver the work that only you’re experienced with, while simultaneously depending on you to rapidly learn new skills that no one in the organization can teach you. (
&lt;a href="https://read.readwise.io/read/01gs6bcb4acadtn9zzgsccka3v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The consequences here are significant. The person in that role will often become a bottleneck on the company’s execution, and their rate of learning will decrease even more as they refocus on work they’ve already mastered (
&lt;a href="https://read.readwise.io/read/01gs6bjneyn72ngndfhx9hw8bg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s often the case that any manager’s failure to scale with the company can unintentionally cram down an entire organization’s career growth. (
&lt;a href="https://read.readwise.io/read/01gs6bm0py2qdknv5fqqtsn0tq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>our goal as a leader is to offload work that you are experienced at to the wider organization as rapidly as possible, freeing up room for you to continue learning. (
&lt;a href="https://read.readwise.io/read/01gs6bmhdcvvv8qxfh725j24st" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>There is some nuance here. Often you’ll hear folks say that they want to be more strategic, and then they stop doing a bunch of critical work. That’s not the solution here. The goal is to solve for the work you’re experience with, not to abandon it. (
&lt;a href="https://read.readwise.io/read/01gs6c4ghvf1zch8vh3jcda8cn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the majority of my learning occurs while working through the challenges of my daily work, and I think that’s an important goal to optimize for when trying to learn quickly enough to remain in-role at a growing company. (
&lt;a href="https://read.readwise.io/read/01gs6c84dkcpwnahp1py0k93qp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Guides / Work on What Matters</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Guides-Work-on-What-Matters/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Guides-Work-on-What-Matters/</guid><description>&lt;h1 id="guides--work-on-what-matters">Guides / Work on What Matters&lt;/h1>
&lt;p>
&lt;img src="https://staffeng.com/StaffEngSocialShare.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[staffeng.com]]&lt;/li>
&lt;li>Full Title: Guides / Work on What Matters&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://staffeng.com/guides/work-on-what-matters" rel="noopener">https://staffeng.com/guides/work-on-what-matters&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>If you&amp;rsquo;re continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. (
&lt;a href="https://read.readwise.io/read/01grynq5kd14wkx58w0wx7kdgy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re in a well-run organization, at some point, you&amp;rsquo;re going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice&amp;ndash;easy and low-impact&amp;ndash;is what Walk refers to as &lt;em>snacking&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryntktdj6bnf6wzyhw42acv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you&amp;rsquo;re busy, these snacks give a sense of accomplishment that makes them psychologically rewarding. Still, you&amp;rsquo;re unlikely to learn much from doing them, others are likely equally capable of completing them (&lt;em>and&lt;/em> for some of them, it might be a good development opportunity), and there&amp;rsquo;s a tremendous opportunity cost versus doing something higher impact. (
&lt;a href="https://read.readwise.io/read/01grynvgdsndf2q85kc66qvf1q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you&amp;rsquo;re spending on high-impact work versus low-impact work. In senior roles, you&amp;rsquo;re more likely to self-determine your work, and if you&amp;rsquo;re not deliberately tracking your work, it&amp;rsquo;s easy to catch yourself doing little to no high-impact work. (
&lt;a href="https://read.readwise.io/read/01grynvy4gf9h0s485twwy3e76" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>is doing low-impact, high-visibility work. (
&lt;a href="https://read.readwise.io/read/01gryp1k5aen1e6ft1cyctnm6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s surprisingly common for a new senior leader to join a company and immediately drive
&lt;a href="https://lethain.com/grand-migration/" rel="noopener">a strategy shift that fundamentally misunderstands the challenges at hand&lt;/a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential. (
&lt;a href="https://read.readwise.io/read/01gryq4bkrdj7masjygqkx2w3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a senior leader, you have to maintain a hold on your ego to avoid investing in meaningless work on a grand scale. (
&lt;a href="https://read.readwise.io/read/01gryq4ydt42btkshg1qxyaedx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Taking the time to understand the status quo before shifting it will always repay diligence with results. (
&lt;a href="https://read.readwise.io/read/01gryq58fdv2t8xpx1dmem38v5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">iterative elimination tournament&lt;/a>, balancing future success against surviving until that future becomes the present. (
&lt;a href="https://read.readwise.io/read/01gryq71h8dtek8bq4kydjb048" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If something dire is happening at your company, then that&amp;rsquo;s the place to be engaged (
&lt;a href="https://read.readwise.io/read/01gryq7jk7apg4xn44zyh06exm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Existential issues are usually &lt;em>not&lt;/em> the most efficient place to add your efforts, but efficiency isn&amp;rsquo;t a priority when the walls are crashing down around you. You &lt;em>should&lt;/em> swarm to existential problems, but if a problem isn&amp;rsquo;t existential, then you should be skeptical of adding your efforts where everyone&amp;rsquo;s already focused. (
&lt;a href="https://read.readwise.io/read/01gryqcegj01cw4c7dtqjfrdte" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Sometimes an area that an organization doesn&amp;rsquo;t pay attention to is so important that you&amp;rsquo;re going to want to advocate for it to start paying attention. Teaching a company to value something it doesn&amp;rsquo;t care about is the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. (
&lt;a href="https://read.readwise.io/read/01gryqh6wnex9wxgcsdpmfa20a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One area that&amp;rsquo;s often underinvested in (i.e., lots of room to work in) while also being highly leveraged is growing the team around you (
&lt;a href="https://read.readwise.io/read/01gryqk33facz6jv4g1ckr5t43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A surprising number of projects are one small change away from succeeding, one quick modification away from unlocking a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications, and short conversations as &lt;em>editing&lt;/em> your team&amp;rsquo;s approach (
&lt;a href="https://read.readwise.io/read/01gryqwkqb0zsk580dmgrth54q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final category of work that matters is the sort that you&amp;rsquo;re uniquely capable of accomplishing. (
&lt;a href="https://read.readwise.io/read/01gryqyybdnhydzaqbsm6k7922" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Whatever it is, things that simply won&amp;rsquo;t happen if you don&amp;rsquo;t do them are your biggest opportunity to work on something that matters, and it&amp;rsquo;s a category that will get both narrower and deeper the further you get into your career. (
&lt;a href="https://read.readwise.io/read/01gryqzavd1t0m81p3gf4j2efx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can&amp;rsquo;t escape subjective interview practices, but you can deliberately accumulate expertise from doing valuable work. Indeed, that&amp;rsquo;s the only viable long-term bet on your career: focus on work that matters, do projects that develop you, and steer towards companies that value genuine experience. (
&lt;a href="https://read.readwise.io/read/01gryr082akktwz19em7cqktzq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[staffeng.com]]
title: &amp;ldquo;Guides / Work on What Matters&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="guides--work-on-what-matters-1">Guides / Work on What Matters&lt;/h1>
&lt;p>
&lt;img src="https://staffeng.com/StaffEngSocialShare.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[staffeng.com]]&lt;/li>
&lt;li>Full Title: Guides / Work on What Matters&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://staffeng.com/guides/work-on-what-matters" rel="noopener">https://staffeng.com/guides/work-on-what-matters&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>If you&amp;rsquo;re continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. (
&lt;a href="https://read.readwise.io/read/01grynq5kd14wkx58w0wx7kdgy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re in a well-run organization, at some point, you&amp;rsquo;re going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice&amp;ndash;easy and low-impact&amp;ndash;is what Walk refers to as &lt;em>snacking&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryntktdj6bnf6wzyhw42acv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you&amp;rsquo;re busy, these snacks give a sense of accomplishment that makes them psychologically rewarding. Still, you&amp;rsquo;re unlikely to learn much from doing them, others are likely equally capable of completing them (&lt;em>and&lt;/em> for some of them, it might be a good development opportunity), and there&amp;rsquo;s a tremendous opportunity cost versus doing something higher impact. (
&lt;a href="https://read.readwise.io/read/01grynvgdsndf2q85kc66qvf1q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you&amp;rsquo;re spending on high-impact work versus low-impact work. In senior roles, you&amp;rsquo;re more likely to self-determine your work, and if you&amp;rsquo;re not deliberately tracking your work, it&amp;rsquo;s easy to catch yourself doing little to no high-impact work. (
&lt;a href="https://read.readwise.io/read/01grynvy4gf9h0s485twwy3e76" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>is doing low-impact, high-visibility work. (
&lt;a href="https://read.readwise.io/read/01gryp1k5aen1e6ft1cyctnm6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s surprisingly common for a new senior leader to join a company and immediately drive
&lt;a href="https://lethain.com/grand-migration/" rel="noopener">a strategy shift that fundamentally misunderstands the challenges at hand&lt;/a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential. (
&lt;a href="https://read.readwise.io/read/01gryq4bkrdj7masjygqkx2w3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a senior leader, you have to maintain a hold on your ego to avoid investing in meaningless work on a grand scale. (
&lt;a href="https://read.readwise.io/read/01gryq4ydt42btkshg1qxyaedx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Taking the time to understand the status quo before shifting it will always repay diligence with results. (
&lt;a href="https://read.readwise.io/read/01gryq58fdv2t8xpx1dmem38v5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">iterative elimination tournament&lt;/a>, balancing future success against surviving until that future becomes the present. (
&lt;a href="https://read.readwise.io/read/01gryq71h8dtek8bq4kydjb048" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If something dire is happening at your company, then that&amp;rsquo;s the place to be engaged (
&lt;a href="https://read.readwise.io/read/01gryq7jk7apg4xn44zyh06exm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Existential issues are usually &lt;em>not&lt;/em> the most efficient place to add your efforts, but efficiency isn&amp;rsquo;t a priority when the walls are crashing down around you. You &lt;em>should&lt;/em> swarm to existential problems, but if a problem isn&amp;rsquo;t existential, then you should be skeptical of adding your efforts where everyone&amp;rsquo;s already focused. (
&lt;a href="https://read.readwise.io/read/01gryqcegj01cw4c7dtqjfrdte" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Sometimes an area that an organization doesn&amp;rsquo;t pay attention to is so important that you&amp;rsquo;re going to want to advocate for it to start paying attention. Teaching a company to value something it doesn&amp;rsquo;t care about is the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. (
&lt;a href="https://read.readwise.io/read/01gryqh6wnex9wxgcsdpmfa20a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One area that&amp;rsquo;s often underinvested in (i.e., lots of room to work in) while also being highly leveraged is growing the team around you (
&lt;a href="https://read.readwise.io/read/01gryqk33facz6jv4g1ckr5t43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A surprising number of projects are one small change away from succeeding, one quick modification away from unlocking a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications, and short conversations as &lt;em>editing&lt;/em> your team&amp;rsquo;s approach (
&lt;a href="https://read.readwise.io/read/01gryqwkqb0zsk580dmgrth54q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final category of work that matters is the sort that you&amp;rsquo;re uniquely capable of accomplishing. (
&lt;a href="https://read.readwise.io/read/01gryqyybdnhydzaqbsm6k7922" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Whatever it is, things that simply won&amp;rsquo;t happen if you don&amp;rsquo;t do them are your biggest opportunity to work on something that matters, and it&amp;rsquo;s a category that will get both narrower and deeper the further you get into your career. (
&lt;a href="https://read.readwise.io/read/01gryqzavd1t0m81p3gf4j2efx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can&amp;rsquo;t escape subjective interview practices, but you can deliberately accumulate expertise from doing valuable work. Indeed, that&amp;rsquo;s the only viable long-term bet on your career: focus on work that matters, do projects that develop you, and steer towards companies that value genuine experience. (
&lt;a href="https://read.readwise.io/read/01gryr082akktwz19em7cqktzq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[staffeng.com]]
title: &amp;ldquo;Guides / Work on What Matters&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="guides--work-on-what-matters-2">Guides / Work on What Matters&lt;/h1>
&lt;p>
&lt;img src="https://staffeng.com/StaffEngSocialShare.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[staffeng.com]]&lt;/li>
&lt;li>Full Title: Guides / Work on What Matters&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://staffeng.com/guides/work-on-what-matters" rel="noopener">https://staffeng.com/guides/work-on-what-matters&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>If you&amp;rsquo;re continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. (
&lt;a href="https://read.readwise.io/read/01grynq5kd14wkx58w0wx7kdgy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re in a well-run organization, at some point, you&amp;rsquo;re going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice&amp;ndash;easy and low-impact&amp;ndash;is what Walk refers to as &lt;em>snacking&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryntktdj6bnf6wzyhw42acv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you&amp;rsquo;re busy, these snacks give a sense of accomplishment that makes them psychologically rewarding. Still, you&amp;rsquo;re unlikely to learn much from doing them, others are likely equally capable of completing them (&lt;em>and&lt;/em> for some of them, it might be a good development opportunity), and there&amp;rsquo;s a tremendous opportunity cost versus doing something higher impact. (
&lt;a href="https://read.readwise.io/read/01grynvgdsndf2q85kc66qvf1q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you&amp;rsquo;re spending on high-impact work versus low-impact work. In senior roles, you&amp;rsquo;re more likely to self-determine your work, and if you&amp;rsquo;re not deliberately tracking your work, it&amp;rsquo;s easy to catch yourself doing little to no high-impact work. (
&lt;a href="https://read.readwise.io/read/01grynvy4gf9h0s485twwy3e76" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>is doing low-impact, high-visibility work. (
&lt;a href="https://read.readwise.io/read/01gryp1k5aen1e6ft1cyctnm6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s surprisingly common for a new senior leader to join a company and immediately drive
&lt;a href="https://lethain.com/grand-migration/" rel="noopener">a strategy shift that fundamentally misunderstands the challenges at hand&lt;/a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential. (
&lt;a href="https://read.readwise.io/read/01gryq4bkrdj7masjygqkx2w3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a senior leader, you have to maintain a hold on your ego to avoid investing in meaningless work on a grand scale. (
&lt;a href="https://read.readwise.io/read/01gryq4ydt42btkshg1qxyaedx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Taking the time to understand the status quo before shifting it will always repay diligence with results. (
&lt;a href="https://read.readwise.io/read/01gryq58fdv2t8xpx1dmem38v5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">iterative elimination tournament&lt;/a>, balancing future success against surviving until that future becomes the present. (
&lt;a href="https://read.readwise.io/read/01gryq71h8dtek8bq4kydjb048" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If something dire is happening at your company, then that&amp;rsquo;s the place to be engaged (
&lt;a href="https://read.readwise.io/read/01gryq7jk7apg4xn44zyh06exm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Existential issues are usually &lt;em>not&lt;/em> the most efficient place to add your efforts, but efficiency isn&amp;rsquo;t a priority when the walls are crashing down around you. You &lt;em>should&lt;/em> swarm to existential problems, but if a problem isn&amp;rsquo;t existential, then you should be skeptical of adding your efforts where everyone&amp;rsquo;s already focused. (
&lt;a href="https://read.readwise.io/read/01gryqcegj01cw4c7dtqjfrdte" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Sometimes an area that an organization doesn&amp;rsquo;t pay attention to is so important that you&amp;rsquo;re going to want to advocate for it to start paying attention. Teaching a company to value something it doesn&amp;rsquo;t care about is the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. (
&lt;a href="https://read.readwise.io/read/01gryqh6wnex9wxgcsdpmfa20a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One area that&amp;rsquo;s often underinvested in (i.e., lots of room to work in) while also being highly leveraged is growing the team around you (
&lt;a href="https://read.readwise.io/read/01gryqk33facz6jv4g1ckr5t43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A surprising number of projects are one small change away from succeeding, one quick modification away from unlocking a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications, and short conversations as &lt;em>editing&lt;/em> your team&amp;rsquo;s approach (
&lt;a href="https://read.readwise.io/read/01gryqwkqb0zsk580dmgrth54q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final category of work that matters is the sort that you&amp;rsquo;re uniquely capable of accomplishing. (
&lt;a href="https://read.readwise.io/read/01gryqyybdnhydzaqbsm6k7922" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Whatever it is, things that simply won&amp;rsquo;t happen if you don&amp;rsquo;t do them are your biggest opportunity to work on something that matters, and it&amp;rsquo;s a category that will get both narrower and deeper the further you get into your career. (
&lt;a href="https://read.readwise.io/read/01gryqzavd1t0m81p3gf4j2efx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can&amp;rsquo;t escape subjective interview practices, but you can deliberately accumulate expertise from doing valuable work. Indeed, that&amp;rsquo;s the only viable long-term bet on your career: focus on work that matters, do projects that develop you, and steer towards companies that value genuine experience. (
&lt;a href="https://read.readwise.io/read/01gryr082akktwz19em7cqktzq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[staffeng.com]]
title: &amp;ldquo;Guides / Work on What Matters&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="guides--work-on-what-matters-3">Guides / Work on What Matters&lt;/h1>
&lt;p>
&lt;img src="https://staffeng.com/StaffEngSocialShare.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[staffeng.com]]&lt;/li>
&lt;li>Full Title: Guides / Work on What Matters&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://staffeng.com/guides/work-on-what-matters" rel="noopener">https://staffeng.com/guides/work-on-what-matters&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>If you&amp;rsquo;re continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. (
&lt;a href="https://read.readwise.io/read/01grynq5kd14wkx58w0wx7kdgy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re in a well-run organization, at some point, you&amp;rsquo;re going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice&amp;ndash;easy and low-impact&amp;ndash;is what Walk refers to as &lt;em>snacking&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryntktdj6bnf6wzyhw42acv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you&amp;rsquo;re busy, these snacks give a sense of accomplishment that makes them psychologically rewarding. Still, you&amp;rsquo;re unlikely to learn much from doing them, others are likely equally capable of completing them (&lt;em>and&lt;/em> for some of them, it might be a good development opportunity), and there&amp;rsquo;s a tremendous opportunity cost versus doing something higher impact. (
&lt;a href="https://read.readwise.io/read/01grynvgdsndf2q85kc66qvf1q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you&amp;rsquo;re spending on high-impact work versus low-impact work. In senior roles, you&amp;rsquo;re more likely to self-determine your work, and if you&amp;rsquo;re not deliberately tracking your work, it&amp;rsquo;s easy to catch yourself doing little to no high-impact work. (
&lt;a href="https://read.readwise.io/read/01grynvy4gf9h0s485twwy3e76" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>is doing low-impact, high-visibility work. (
&lt;a href="https://read.readwise.io/read/01gryp1k5aen1e6ft1cyctnm6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s surprisingly common for a new senior leader to join a company and immediately drive
&lt;a href="https://lethain.com/grand-migration/" rel="noopener">a strategy shift that fundamentally misunderstands the challenges at hand&lt;/a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential. (
&lt;a href="https://read.readwise.io/read/01gryq4bkrdj7masjygqkx2w3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a senior leader, you have to maintain a hold on your ego to avoid investing in meaningless work on a grand scale. (
&lt;a href="https://read.readwise.io/read/01gryq4ydt42btkshg1qxyaedx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Taking the time to understand the status quo before shifting it will always repay diligence with results. (
&lt;a href="https://read.readwise.io/read/01gryq58fdv2t8xpx1dmem38v5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">iterative elimination tournament&lt;/a>, balancing future success against surviving until that future becomes the present. (
&lt;a href="https://read.readwise.io/read/01gryq71h8dtek8bq4kydjb048" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If something dire is happening at your company, then that&amp;rsquo;s the place to be engaged (
&lt;a href="https://read.readwise.io/read/01gryq7jk7apg4xn44zyh06exm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Existential issues are usually &lt;em>not&lt;/em> the most efficient place to add your efforts, but efficiency isn&amp;rsquo;t a priority when the walls are crashing down around you. You &lt;em>should&lt;/em> swarm to existential problems, but if a problem isn&amp;rsquo;t existential, then you should be skeptical of adding your efforts where everyone&amp;rsquo;s already focused. (
&lt;a href="https://read.readwise.io/read/01gryqcegj01cw4c7dtqjfrdte" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Sometimes an area that an organization doesn&amp;rsquo;t pay attention to is so important that you&amp;rsquo;re going to want to advocate for it to start paying attention. Teaching a company to value something it doesn&amp;rsquo;t care about is the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. (
&lt;a href="https://read.readwise.io/read/01gryqh6wnex9wxgcsdpmfa20a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One area that&amp;rsquo;s often underinvested in (i.e., lots of room to work in) while also being highly leveraged is growing the team around you (
&lt;a href="https://read.readwise.io/read/01gryqk33facz6jv4g1ckr5t43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A surprising number of projects are one small change away from succeeding, one quick modification away from unlocking a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications, and short conversations as &lt;em>editing&lt;/em> your team&amp;rsquo;s approach (
&lt;a href="https://read.readwise.io/read/01gryqwkqb0zsk580dmgrth54q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final category of work that matters is the sort that you&amp;rsquo;re uniquely capable of accomplishing. (
&lt;a href="https://read.readwise.io/read/01gryqyybdnhydzaqbsm6k7922" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Whatever it is, things that simply won&amp;rsquo;t happen if you don&amp;rsquo;t do them are your biggest opportunity to work on something that matters, and it&amp;rsquo;s a category that will get both narrower and deeper the further you get into your career. (
&lt;a href="https://read.readwise.io/read/01gryqzavd1t0m81p3gf4j2efx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can&amp;rsquo;t escape subjective interview practices, but you can deliberately accumulate expertise from doing valuable work. Indeed, that&amp;rsquo;s the only viable long-term bet on your career: focus on work that matters, do projects that develop you, and steer towards companies that value genuine experience. (
&lt;a href="https://read.readwise.io/read/01gryr082akktwz19em7cqktzq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Handling Mislabeled Tabular Data to Improve Your XGBoost Model</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Handling-Mislabeled-Tabular-Data-to-Improve-Your-XGBoost-Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Handling-Mislabeled-Tabular-Data-to-Improve-Your-XGBoost-Model/</guid><description>&lt;h1 id="handling-mislabeled-tabular-data-to-improve-your-xgboost-model">Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/958/1*Cn1SgK6hlvOu8E-SbHqqjg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Chris Mauck]]&lt;/li>
&lt;li>Full Title: Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6" rel="noopener">https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>This article highlights data-centric AI techniques (using
&lt;a href="https://github.com/cleanlab/cleanlab" rel="noopener">cleanlab&lt;/a>) to improve the accuracy of an XGBoost classifier (
&lt;a href="https://read.readwise.io/read/01gqnkec6jd6mrvxxwb44cgtd9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Chris Mauck]]
title: &amp;ldquo;Handling Mislabeled Tabular Data to Improve Your XGBoost Model&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="handling-mislabeled-tabular-data-to-improve-your-xgboost-model-1">Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/958/1*Cn1SgK6hlvOu8E-SbHqqjg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Chris Mauck]]&lt;/li>
&lt;li>Full Title: Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6" rel="noopener">https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>This article highlights data-centric AI techniques (using
&lt;a href="https://github.com/cleanlab/cleanlab" rel="noopener">cleanlab&lt;/a>) to improve the accuracy of an XGBoost classifier (
&lt;a href="https://read.readwise.io/read/01gqnkec6jd6mrvxxwb44cgtd9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Chris Mauck]]
title: &amp;ldquo;Handling Mislabeled Tabular Data to Improve Your XGBoost Model&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="handling-mislabeled-tabular-data-to-improve-your-xgboost-model-2">Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/958/1*Cn1SgK6hlvOu8E-SbHqqjg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Chris Mauck]]&lt;/li>
&lt;li>Full Title: Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6" rel="noopener">https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>This article highlights data-centric AI techniques (using
&lt;a href="https://github.com/cleanlab/cleanlab" rel="noopener">cleanlab&lt;/a>) to improve the accuracy of an XGBoost classifier (
&lt;a href="https://read.readwise.io/read/01gqnkec6jd6mrvxxwb44cgtd9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Chris Mauck]]
title: &amp;ldquo;Handling Mislabeled Tabular Data to Improve Your XGBoost Model&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="handling-mislabeled-tabular-data-to-improve-your-xgboost-model-3">Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/958/1*Cn1SgK6hlvOu8E-SbHqqjg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Chris Mauck]]&lt;/li>
&lt;li>Full Title: Handling Mislabeled Tabular Data to Improve Your XGBoost Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6" rel="noopener">https://pub.towardsai.net/handling-mislabeled-tabular-data-to-improve-your-xgboost-model-fbe051f4a6a6&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>This article highlights data-centric AI techniques (using
&lt;a href="https://github.com/cleanlab/cleanlab" rel="noopener">cleanlab&lt;/a>) to improve the accuracy of an XGBoost classifier (
&lt;a href="https://read.readwise.io/read/01gqnkec6jd6mrvxxwb44cgtd9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>How CEOs Can Lead a Data-Driven Culture</title><link>https://pelayoarbues.github.io/literature-notes/Articles/How-CEOs-Can-Lead-a-Data-Driven-Culture/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/How-CEOs-Can-Lead-a-Data-Driven-Culture/</guid><description>&lt;h1 id="how-ceos-can-lead-a-data-driven-culture">How CEOs Can Lead a Data-Driven Culture&lt;/h1>
&lt;p>
&lt;img src="https://hbr.org/resources/images/article_assets/2020/03/Mar20_23_1069992382.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Thomas H. Davenport
Nitin Mittal]]&lt;/li>
&lt;li>Full Title: How CEOs Can Lead a Data-Driven Culture&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Business adoption of data and AI initiatives usally face more cultural and organization barriers than technological ones.
The role of the CEO is to lead by example incorporating data in the decision making process.
Data literacy programs should include concepts and best practices in data analysis in communication but also skills on finding and manipulating data within company.
Forming cross-functional teams (data analytics, business, product, tech) brings diveristy to problem solving.
It is also important to assess and monitor the data/analytics savviness of the leadership team.&lt;/li>
&lt;li>URL:
&lt;a href="https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture" rel="noopener">https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Education should focus not only on attitudes and knowledge about data, analytics, and AI, but also on skills for finding and manipulating data at every level, including senior management levels. A
&lt;a href="https://www.splunk.com/en_us/form/the-state-of-dark-data.html" rel="noopener">survey&lt;/a> sponsored by the data analytics vendor Splunk of 1,300 senior executives found that while 81% of the executives agree that data skills are required to become a senior leader in their companies, 67% say they are not comfortable accessing or using data themselves. Seventy three percent felt that data skills are harder to learn than other business skills, and 53% believe they are too old to learn data skills. Effective education initiatives can prove them wrong. (
&lt;a href="https://read.readwise.io/read/01gs3p3t4ars83mfwe22y09v8r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Leading by example&lt;/strong>&lt;/em> is also important. This requires showcasing leaders who visibly use analytics and AI in internal marketing programs to spread the value of the approach across an organization. Leaders’ exemplary behavior can also include modeling the desired attitude about data and analytics in meetings; leaders should frequently ask, “Do you have data to support that point?” and encourage others to do likewise. (
&lt;a href="https://read.readwise.io/read/01gs3p3xm940ebqb29tdsaqjm4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Promotions and rewards&lt;/strong>&lt;/em> can also encourage change. If those who make effective use of data and analytics get faster promotions and salary increases, others will notice. Of course, this approach requires leadership endorsement and sign-off and execution by Human Resources. (
&lt;a href="https://read.readwise.io/read/01gs3p4235w1f001fmss20fc0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Highlighting successes by early adopters and enlisting them help get others engaged;
• Forming cross-functional teams that combine people with backgrounds in data analytics, business, and technology and combining computer science, applied math, engineering, and behavioral economics perspectives to bring diversity and innovate thinking to projects; and
• Launching programs across the organization, including open houses, forums, communities of practice, educational initiatives, and a leadership council – in effect, building marketing capability for analytics and AI within the company that helps create advocates and ambassadors. (
&lt;a href="https://read.readwise.io/read/01gs3p4cvf23eeyrjt730j03f7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Thomas H. Davenport
Nitin Mittal]]
title: &amp;ldquo;How CEOs Can Lead a Data-Driven Culture&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-ceos-can-lead-a-data-driven-culture-1">How CEOs Can Lead a Data-Driven Culture&lt;/h1>
&lt;p>
&lt;img src="https://hbr.org/resources/images/article_assets/2020/03/Mar20_23_1069992382.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Thomas H. Davenport
Nitin Mittal]]&lt;/li>
&lt;li>Full Title: How CEOs Can Lead a Data-Driven Culture&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Business adoption of data and AI initiatives usally face more cultural and organization barriers than technological ones.
The role of the CEO is to lead by example incorporating data in the decision making process.
Data literacy programs should include concepts and best practices in data analysis in communication but also skills on finding and manipulating data within company.
Forming cross-functional teams (data analytics, business, product, tech) brings diveristy to problem solving.
It is also important to assess and monitor the data/analytics savviness of the leadership team.&lt;/li>
&lt;li>URL:
&lt;a href="https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture" rel="noopener">https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Education should focus not only on attitudes and knowledge about data, analytics, and AI, but also on skills for finding and manipulating data at every level, including senior management levels. A
&lt;a href="https://www.splunk.com/en_us/form/the-state-of-dark-data.html" rel="noopener">survey&lt;/a> sponsored by the data analytics vendor Splunk of 1,300 senior executives found that while 81% of the executives agree that data skills are required to become a senior leader in their companies, 67% say they are not comfortable accessing or using data themselves. Seventy three percent felt that data skills are harder to learn than other business skills, and 53% believe they are too old to learn data skills. Effective education initiatives can prove them wrong. (
&lt;a href="https://read.readwise.io/read/01gs3p3t4ars83mfwe22y09v8r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Leading by example&lt;/strong>&lt;/em> is also important. This requires showcasing leaders who visibly use analytics and AI in internal marketing programs to spread the value of the approach across an organization. Leaders’ exemplary behavior can also include modeling the desired attitude about data and analytics in meetings; leaders should frequently ask, “Do you have data to support that point?” and encourage others to do likewise. (
&lt;a href="https://read.readwise.io/read/01gs3p3xm940ebqb29tdsaqjm4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Promotions and rewards&lt;/strong>&lt;/em> can also encourage change. If those who make effective use of data and analytics get faster promotions and salary increases, others will notice. Of course, this approach requires leadership endorsement and sign-off and execution by Human Resources. (
&lt;a href="https://read.readwise.io/read/01gs3p4235w1f001fmss20fc0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Highlighting successes by early adopters and enlisting them help get others engaged;
• Forming cross-functional teams that combine people with backgrounds in data analytics, business, and technology and combining computer science, applied math, engineering, and behavioral economics perspectives to bring diversity and innovate thinking to projects; and
• Launching programs across the organization, including open houses, forums, communities of practice, educational initiatives, and a leadership council – in effect, building marketing capability for analytics and AI within the company that helps create advocates and ambassadors. (
&lt;a href="https://read.readwise.io/read/01gs3p4cvf23eeyrjt730j03f7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Thomas H. Davenport
Nitin Mittal]]
title: &amp;ldquo;How CEOs Can Lead a Data-Driven Culture&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-ceos-can-lead-a-data-driven-culture-2">How CEOs Can Lead a Data-Driven Culture&lt;/h1>
&lt;p>
&lt;img src="https://hbr.org/resources/images/article_assets/2020/03/Mar20_23_1069992382.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Thomas H. Davenport
Nitin Mittal]]&lt;/li>
&lt;li>Full Title: How CEOs Can Lead a Data-Driven Culture&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Business adoption of data and AI initiatives usally face more cultural and organization barriers than technological ones.
The role of the CEO is to lead by example incorporating data in the decision making process.
Data literacy programs should include concepts and best practices in data analysis in communication but also skills on finding and manipulating data within company.
Forming cross-functional teams (data analytics, business, product, tech) brings diveristy to problem solving.
It is also important to assess and monitor the data/analytics savviness of the leadership team.&lt;/li>
&lt;li>URL:
&lt;a href="https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture" rel="noopener">https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Education should focus not only on attitudes and knowledge about data, analytics, and AI, but also on skills for finding and manipulating data at every level, including senior management levels. A
&lt;a href="https://www.splunk.com/en_us/form/the-state-of-dark-data.html" rel="noopener">survey&lt;/a> sponsored by the data analytics vendor Splunk of 1,300 senior executives found that while 81% of the executives agree that data skills are required to become a senior leader in their companies, 67% say they are not comfortable accessing or using data themselves. Seventy three percent felt that data skills are harder to learn than other business skills, and 53% believe they are too old to learn data skills. Effective education initiatives can prove them wrong. (
&lt;a href="https://read.readwise.io/read/01gs3p3t4ars83mfwe22y09v8r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Leading by example&lt;/strong>&lt;/em> is also important. This requires showcasing leaders who visibly use analytics and AI in internal marketing programs to spread the value of the approach across an organization. Leaders’ exemplary behavior can also include modeling the desired attitude about data and analytics in meetings; leaders should frequently ask, “Do you have data to support that point?” and encourage others to do likewise. (
&lt;a href="https://read.readwise.io/read/01gs3p3xm940ebqb29tdsaqjm4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Promotions and rewards&lt;/strong>&lt;/em> can also encourage change. If those who make effective use of data and analytics get faster promotions and salary increases, others will notice. Of course, this approach requires leadership endorsement and sign-off and execution by Human Resources. (
&lt;a href="https://read.readwise.io/read/01gs3p4235w1f001fmss20fc0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Highlighting successes by early adopters and enlisting them help get others engaged;
• Forming cross-functional teams that combine people with backgrounds in data analytics, business, and technology and combining computer science, applied math, engineering, and behavioral economics perspectives to bring diversity and innovate thinking to projects; and
• Launching programs across the organization, including open houses, forums, communities of practice, educational initiatives, and a leadership council – in effect, building marketing capability for analytics and AI within the company that helps create advocates and ambassadors. (
&lt;a href="https://read.readwise.io/read/01gs3p4cvf23eeyrjt730j03f7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Thomas H. Davenport
Nitin Mittal]]
title: &amp;ldquo;How CEOs Can Lead a Data-Driven Culture&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-ceos-can-lead-a-data-driven-culture-3">How CEOs Can Lead a Data-Driven Culture&lt;/h1>
&lt;p>
&lt;img src="https://hbr.org/resources/images/article_assets/2020/03/Mar20_23_1069992382.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Thomas H. Davenport
Nitin Mittal]]&lt;/li>
&lt;li>Full Title: How CEOs Can Lead a Data-Driven Culture&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Business adoption of data and AI initiatives usally face more cultural and organization barriers than technological ones.
The role of the CEO is to lead by example incorporating data in the decision making process.
Data literacy programs should include concepts and best practices in data analysis in communication but also skills on finding and manipulating data within company.
Forming cross-functional teams (data analytics, business, product, tech) brings diveristy to problem solving.
It is also important to assess and monitor the data/analytics savviness of the leadership team.&lt;/li>
&lt;li>URL:
&lt;a href="https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture" rel="noopener">https://hbr.org/2020/03/how-ceos-can-lead-a-data-driven-culture&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Education should focus not only on attitudes and knowledge about data, analytics, and AI, but also on skills for finding and manipulating data at every level, including senior management levels. A
&lt;a href="https://www.splunk.com/en_us/form/the-state-of-dark-data.html" rel="noopener">survey&lt;/a> sponsored by the data analytics vendor Splunk of 1,300 senior executives found that while 81% of the executives agree that data skills are required to become a senior leader in their companies, 67% say they are not comfortable accessing or using data themselves. Seventy three percent felt that data skills are harder to learn than other business skills, and 53% believe they are too old to learn data skills. Effective education initiatives can prove them wrong. (
&lt;a href="https://read.readwise.io/read/01gs3p3t4ars83mfwe22y09v8r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Leading by example&lt;/strong>&lt;/em> is also important. This requires showcasing leaders who visibly use analytics and AI in internal marketing programs to spread the value of the approach across an organization. Leaders’ exemplary behavior can also include modeling the desired attitude about data and analytics in meetings; leaders should frequently ask, “Do you have data to support that point?” and encourage others to do likewise. (
&lt;a href="https://read.readwise.io/read/01gs3p3xm940ebqb29tdsaqjm4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Promotions and rewards&lt;/strong>&lt;/em> can also encourage change. If those who make effective use of data and analytics get faster promotions and salary increases, others will notice. Of course, this approach requires leadership endorsement and sign-off and execution by Human Resources. (
&lt;a href="https://read.readwise.io/read/01gs3p4235w1f001fmss20fc0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Highlighting successes by early adopters and enlisting them help get others engaged;
• Forming cross-functional teams that combine people with backgrounds in data analytics, business, and technology and combining computer science, applied math, engineering, and behavioral economics perspectives to bring diversity and innovate thinking to projects; and
• Launching programs across the organization, including open houses, forums, communities of practice, educational initiatives, and a leadership council – in effect, building marketing capability for analytics and AI within the company that helps create advocates and ambassadors. (
&lt;a href="https://read.readwise.io/read/01gs3p4cvf23eeyrjt730j03f7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>How to Build Data Literacy in Your Company</title><link>https://pelayoarbues.github.io/literature-notes/Articles/How-to-Build-Data-Literacy-in-Your-Company/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/How-to-Build-Data-Literacy-in-Your-Company/</guid><description>&lt;h1 id="how-to-build-data-literacy-in-your-company">How to Build Data Literacy in Your Company&lt;/h1>
&lt;p>
&lt;img src="https://mitsloan.mit.edu/sites/default/files/styles/og_image/public/2021-02/data-literacy.jpg?h=7691f918&amp;amp;itok=nT7ZDRTr" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sara Brown]]&lt;/li>
&lt;li>Full Title: How to Build Data Literacy in Your Company&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Lack of data literacy skills among top 3 barriers in building strong data initiatives
Data literacy definition involves reading data, working with data, analyzing data and being able to argue with data.
&lt;a href="https://dam-prod.media.mit.edu/x/2016/10/20/Edu_D%27Ignazio_52.pdf" rel="noopener">Paper&lt;/a>
Challenging because requires high level in skills that haven&amp;rsquo;t usually been taught together: data analysis + effective data communication
Not everyone needs to become a data scientist, it is important to assess the level of skills needed by each role.
Why you need data literacy:
&lt;ul>
&lt;li>Data literates make better decisions&lt;/li>
&lt;li>Decisions have to be taken faster than ever
Data literacy roadmap:&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>Define data literacy goals&lt;/li>
&lt;li>Assess current skills levels&lt;/li>
&lt;li>Design learning paths
Principles:
Focus on data, not on technology
Agree on the level of proficiency fo different job types
Avoid jargon
Define success metrics
In order to become data driven: we also need data maturity, data-driven leadership and data-drive decision making&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company" rel="noopener">https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data literacy — the ability of a company’s employees to understand and work with data to the appropriate degree — can be a stepping stone or a stumbling block when it comes to building a data-driven company. (
&lt;a href="https://read.readwise.io/read/01gs3nvfjp089nms7qt647fw3s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Sara Brown]]
title: &amp;ldquo;How to Build Data Literacy in Your Company&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-build-data-literacy-in-your-company-1">How to Build Data Literacy in Your Company&lt;/h1>
&lt;p>
&lt;img src="https://mitsloan.mit.edu/sites/default/files/styles/og_image/public/2021-02/data-literacy.jpg?h=7691f918&amp;amp;itok=nT7ZDRTr" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sara Brown]]&lt;/li>
&lt;li>Full Title: How to Build Data Literacy in Your Company&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Lack of data literacy skills among top 3 barriers in building strong data initiatives
Data literacy definition involves reading data, working with data, analyzing data and being able to argue with data.
&lt;a href="https://dam-prod.media.mit.edu/x/2016/10/20/Edu_D%27Ignazio_52.pdf" rel="noopener">Paper&lt;/a>
Challenging because requires high level in skills that haven&amp;rsquo;t usually been taught together: data analysis + effective data communication
Not everyone needs to become a data scientist, it is important to assess the level of skills needed by each role.
Why you need data literacy:
&lt;ul>
&lt;li>Data literates make better decisions&lt;/li>
&lt;li>Decisions have to be taken faster than ever
Data literacy roadmap:&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>Define data literacy goals&lt;/li>
&lt;li>Assess current skills levels&lt;/li>
&lt;li>Design learning paths
Principles:
Focus on data, not on technology
Agree on the level of proficiency fo different job types
Avoid jargon
Define success metrics
In order to become data driven: we also need data maturity, data-driven leadership and data-drive decision making&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company" rel="noopener">https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data literacy — the ability of a company’s employees to understand and work with data to the appropriate degree — can be a stepping stone or a stumbling block when it comes to building a data-driven company. (
&lt;a href="https://read.readwise.io/read/01gs3nvfjp089nms7qt647fw3s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Sara Brown]]
title: &amp;ldquo;How to Build Data Literacy in Your Company&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-build-data-literacy-in-your-company-2">How to Build Data Literacy in Your Company&lt;/h1>
&lt;p>
&lt;img src="https://mitsloan.mit.edu/sites/default/files/styles/og_image/public/2021-02/data-literacy.jpg?h=7691f918&amp;amp;itok=nT7ZDRTr" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sara Brown]]&lt;/li>
&lt;li>Full Title: How to Build Data Literacy in Your Company&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Lack of data literacy skills among top 3 barriers in building strong data initiatives
Data literacy definition involves reading data, working with data, analyzing data and being able to argue with data.
&lt;a href="https://dam-prod.media.mit.edu/x/2016/10/20/Edu_D%27Ignazio_52.pdf" rel="noopener">Paper&lt;/a>
Challenging because requires high level in skills that haven&amp;rsquo;t usually been taught together: data analysis + effective data communication
Not everyone needs to become a data scientist, it is important to assess the level of skills needed by each role.
Why you need data literacy:
&lt;ul>
&lt;li>Data literates make better decisions&lt;/li>
&lt;li>Decisions have to be taken faster than ever
Data literacy roadmap:&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>Define data literacy goals&lt;/li>
&lt;li>Assess current skills levels&lt;/li>
&lt;li>Design learning paths
Principles:
Focus on data, not on technology
Agree on the level of proficiency fo different job types
Avoid jargon
Define success metrics
In order to become data driven: we also need data maturity, data-driven leadership and data-drive decision making&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company" rel="noopener">https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data literacy — the ability of a company’s employees to understand and work with data to the appropriate degree — can be a stepping stone or a stumbling block when it comes to building a data-driven company. (
&lt;a href="https://read.readwise.io/read/01gs3nvfjp089nms7qt647fw3s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Sara Brown]]
title: &amp;ldquo;How to Build Data Literacy in Your Company&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-build-data-literacy-in-your-company-3">How to Build Data Literacy in Your Company&lt;/h1>
&lt;p>
&lt;img src="https://mitsloan.mit.edu/sites/default/files/styles/og_image/public/2021-02/data-literacy.jpg?h=7691f918&amp;amp;itok=nT7ZDRTr" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sara Brown]]&lt;/li>
&lt;li>Full Title: How to Build Data Literacy in Your Company&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Lack of data literacy skills among top 3 barriers in building strong data initiatives
Data literacy definition involves reading data, working with data, analyzing data and being able to argue with data.
&lt;a href="https://dam-prod.media.mit.edu/x/2016/10/20/Edu_D%27Ignazio_52.pdf" rel="noopener">Paper&lt;/a>
Challenging because requires high level in skills that haven&amp;rsquo;t usually been taught together: data analysis + effective data communication
Not everyone needs to become a data scientist, it is important to assess the level of skills needed by each role.
Why you need data literacy:
&lt;ul>
&lt;li>Data literates make better decisions&lt;/li>
&lt;li>Decisions have to be taken faster than ever
Data literacy roadmap:&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>Define data literacy goals&lt;/li>
&lt;li>Assess current skills levels&lt;/li>
&lt;li>Design learning paths
Principles:
Focus on data, not on technology
Agree on the level of proficiency fo different job types
Avoid jargon
Define success metrics
In order to become data driven: we also need data maturity, data-driven leadership and data-drive decision making&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company" rel="noopener">https://mitsloan.mit.edu/ideas-made-to-matter/how-to-build-data-literacy-your-company&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data literacy — the ability of a company’s employees to understand and work with data to the appropriate degree — can be a stepping stone or a stumbling block when it comes to building a data-driven company. (
&lt;a href="https://read.readwise.io/read/01gs3nvfjp089nms7qt647fw3s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>How to Go Get Your Next Job in Tech</title><link>https://pelayoarbues.github.io/literature-notes/Articles/How-to-Go-Get-Your-Next-Job-in-Tech/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/How-to-Go-Get-Your-Next-Job-in-Tech/</guid><description>&lt;h1 id="how-to-go-get-your-next-job-in-tech">How to Go Get Your Next Job in Tech&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/1f5efef5-a6c1-4136-91f0-44248d6a12d0_301x224.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ian McAllister]]&lt;/li>
&lt;li>Full Title: How to Go Get Your Next Job in Tech&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech" rel="noopener">https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Elevator Pitch.&lt;/strong> Three (maximum) crisp sentences that describe your overall tech experience. The sentences quickly identify your job function and level, the industries you have experience in, and what separates you from others ( (
&lt;a href="https://read.readwise.io/read/01gr26dvh2d757sjyzwcbsr0yg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>About 6-8 bullet points listing your most impressive professional accomplishments. Brag (but don’t lie) about the work you’ve done that will be the most significant and relevant to hiring managers, and that you’re proudest of. (
&lt;a href="https://read.readwise.io/read/01gr26e83cgsn9kakgqkrp6kqs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you apply directly, you’ll be lumped in with all the other applications that will eventually get reviewed by a junior sourcer. You’re not using your network to your advantage. If an employee at the company finds out that you’ve already applied, then they will conclude you are already in the system and won’t likely take any other action to help you. (
&lt;a href="https://read.readwise.io/read/01gr26jg1rx7tyezhvcfhcy8ee" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This company-specific interview prep method includes first preparing to communicate how your past experience is relevant and valuable to the company by:
• Researching your target company’s core values or leadership principles.
• Identifying the best case studies from your past experience that best demonstrate each core value.
• Prepping talking points for each of your career case studies.
• Prepping for specific questions about each company core value, including the cast study and question-specific talking points you want to cover in your answer. (
&lt;a href="https://read.readwise.io/read/01gr26m4v0tcskr61wz82n2pce" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re reaching out to someone because you want a job at their company or want them to connect you with someone in their network, just say so. Don’t beat around the bush or try to get them to make the first move. Get to the point. (
&lt;a href="https://read.readwise.io/read/01gr26nyd7ay3zjzh8nqgzfda0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t apply directly via company’s job site without using your network first (
&lt;a href="https://read.readwise.io/read/01gr26q2h91pqw9040bt7v1v1y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Ian McAllister]]
title: &amp;ldquo;How to Go Get Your Next Job in Tech&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-go-get-your-next-job-in-tech-1">How to Go Get Your Next Job in Tech&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/1f5efef5-a6c1-4136-91f0-44248d6a12d0_301x224.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ian McAllister]]&lt;/li>
&lt;li>Full Title: How to Go Get Your Next Job in Tech&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech" rel="noopener">https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Elevator Pitch.&lt;/strong> Three (maximum) crisp sentences that describe your overall tech experience. The sentences quickly identify your job function and level, the industries you have experience in, and what separates you from others ( (
&lt;a href="https://read.readwise.io/read/01gr26dvh2d757sjyzwcbsr0yg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>About 6-8 bullet points listing your most impressive professional accomplishments. Brag (but don’t lie) about the work you’ve done that will be the most significant and relevant to hiring managers, and that you’re proudest of. (
&lt;a href="https://read.readwise.io/read/01gr26e83cgsn9kakgqkrp6kqs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you apply directly, you’ll be lumped in with all the other applications that will eventually get reviewed by a junior sourcer. You’re not using your network to your advantage. If an employee at the company finds out that you’ve already applied, then they will conclude you are already in the system and won’t likely take any other action to help you. (
&lt;a href="https://read.readwise.io/read/01gr26jg1rx7tyezhvcfhcy8ee" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This company-specific interview prep method includes first preparing to communicate how your past experience is relevant and valuable to the company by:
• Researching your target company’s core values or leadership principles.
• Identifying the best case studies from your past experience that best demonstrate each core value.
• Prepping talking points for each of your career case studies.
• Prepping for specific questions about each company core value, including the cast study and question-specific talking points you want to cover in your answer. (
&lt;a href="https://read.readwise.io/read/01gr26m4v0tcskr61wz82n2pce" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re reaching out to someone because you want a job at their company or want them to connect you with someone in their network, just say so. Don’t beat around the bush or try to get them to make the first move. Get to the point. (
&lt;a href="https://read.readwise.io/read/01gr26nyd7ay3zjzh8nqgzfda0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t apply directly via company’s job site without using your network first (
&lt;a href="https://read.readwise.io/read/01gr26q2h91pqw9040bt7v1v1y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Ian McAllister]]
title: &amp;ldquo;How to Go Get Your Next Job in Tech&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-go-get-your-next-job-in-tech-2">How to Go Get Your Next Job in Tech&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/1f5efef5-a6c1-4136-91f0-44248d6a12d0_301x224.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ian McAllister]]&lt;/li>
&lt;li>Full Title: How to Go Get Your Next Job in Tech&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech" rel="noopener">https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Elevator Pitch.&lt;/strong> Three (maximum) crisp sentences that describe your overall tech experience. The sentences quickly identify your job function and level, the industries you have experience in, and what separates you from others ( (
&lt;a href="https://read.readwise.io/read/01gr26dvh2d757sjyzwcbsr0yg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>About 6-8 bullet points listing your most impressive professional accomplishments. Brag (but don’t lie) about the work you’ve done that will be the most significant and relevant to hiring managers, and that you’re proudest of. (
&lt;a href="https://read.readwise.io/read/01gr26e83cgsn9kakgqkrp6kqs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you apply directly, you’ll be lumped in with all the other applications that will eventually get reviewed by a junior sourcer. You’re not using your network to your advantage. If an employee at the company finds out that you’ve already applied, then they will conclude you are already in the system and won’t likely take any other action to help you. (
&lt;a href="https://read.readwise.io/read/01gr26jg1rx7tyezhvcfhcy8ee" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This company-specific interview prep method includes first preparing to communicate how your past experience is relevant and valuable to the company by:
• Researching your target company’s core values or leadership principles.
• Identifying the best case studies from your past experience that best demonstrate each core value.
• Prepping talking points for each of your career case studies.
• Prepping for specific questions about each company core value, including the cast study and question-specific talking points you want to cover in your answer. (
&lt;a href="https://read.readwise.io/read/01gr26m4v0tcskr61wz82n2pce" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re reaching out to someone because you want a job at their company or want them to connect you with someone in their network, just say so. Don’t beat around the bush or try to get them to make the first move. Get to the point. (
&lt;a href="https://read.readwise.io/read/01gr26nyd7ay3zjzh8nqgzfda0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t apply directly via company’s job site without using your network first (
&lt;a href="https://read.readwise.io/read/01gr26q2h91pqw9040bt7v1v1y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Ian McAllister]]
title: &amp;ldquo;How to Go Get Your Next Job in Tech&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-go-get-your-next-job-in-tech-3">How to Go Get Your Next Job in Tech&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/1f5efef5-a6c1-4136-91f0-44248d6a12d0_301x224.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Ian McAllister]]&lt;/li>
&lt;li>Full Title: How to Go Get Your Next Job in Tech&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech" rel="noopener">https://ianmcallister.substack.com/p/how-to-go-get-your-next-job-in-tech&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>Elevator Pitch.&lt;/strong> Three (maximum) crisp sentences that describe your overall tech experience. The sentences quickly identify your job function and level, the industries you have experience in, and what separates you from others ( (
&lt;a href="https://read.readwise.io/read/01gr26dvh2d757sjyzwcbsr0yg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>About 6-8 bullet points listing your most impressive professional accomplishments. Brag (but don’t lie) about the work you’ve done that will be the most significant and relevant to hiring managers, and that you’re proudest of. (
&lt;a href="https://read.readwise.io/read/01gr26e83cgsn9kakgqkrp6kqs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you apply directly, you’ll be lumped in with all the other applications that will eventually get reviewed by a junior sourcer. You’re not using your network to your advantage. If an employee at the company finds out that you’ve already applied, then they will conclude you are already in the system and won’t likely take any other action to help you. (
&lt;a href="https://read.readwise.io/read/01gr26jg1rx7tyezhvcfhcy8ee" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This company-specific interview prep method includes first preparing to communicate how your past experience is relevant and valuable to the company by:
• Researching your target company’s core values or leadership principles.
• Identifying the best case studies from your past experience that best demonstrate each core value.
• Prepping talking points for each of your career case studies.
• Prepping for specific questions about each company core value, including the cast study and question-specific talking points you want to cover in your answer. (
&lt;a href="https://read.readwise.io/read/01gr26m4v0tcskr61wz82n2pce" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re reaching out to someone because you want a job at their company or want them to connect you with someone in their network, just say so. Don’t beat around the bush or try to get them to make the first move. Get to the point. (
&lt;a href="https://read.readwise.io/read/01gr26nyd7ay3zjzh8nqgzfda0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t apply directly via company’s job site without using your network first (
&lt;a href="https://read.readwise.io/read/01gr26q2h91pqw9040bt7v1v1y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>How to Write Better With the Why, What, How Framework</title><link>https://pelayoarbues.github.io/literature-notes/Articles/How-to-Write-Better-With-the-Why-What-How-Framework/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/How-to-Write-Better-With-the-Why-What-How-Framework/</guid><description>&lt;h1 id="how-to-write-better-with-the-why-what-how-framework">How to Write Better With the Why, What, How Framework&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/writing-docs.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: How to Write Better With the Why, What, How Framework&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/writing-docs-why-what-how/" rel="noopener">https://eugeneyan.com/writing/writing-docs-why-what-how/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Our data science team (in an e-commerce company) is challenged to help customers discover products easier. Senior leaders hypothesize that better product discovery will improve customer engagement and business outcomes. (
&lt;a href="https://read.readwise.io/read/01gr9wd4e4d6jb7k5791vz1mmj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eugene Yan]]
title: &amp;ldquo;How to Write Better With the Why, What, How Framework&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-write-better-with-the-why-what-how-framework-1">How to Write Better With the Why, What, How Framework&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/writing-docs.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: How to Write Better With the Why, What, How Framework&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/writing-docs-why-what-how/" rel="noopener">https://eugeneyan.com/writing/writing-docs-why-what-how/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Our data science team (in an e-commerce company) is challenged to help customers discover products easier. Senior leaders hypothesize that better product discovery will improve customer engagement and business outcomes. (
&lt;a href="https://read.readwise.io/read/01gr9wd4e4d6jb7k5791vz1mmj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eugene Yan]]
title: &amp;ldquo;How to Write Better With the Why, What, How Framework&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-write-better-with-the-why-what-how-framework-2">How to Write Better With the Why, What, How Framework&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/writing-docs.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: How to Write Better With the Why, What, How Framework&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/writing-docs-why-what-how/" rel="noopener">https://eugeneyan.com/writing/writing-docs-why-what-how/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Our data science team (in an e-commerce company) is challenged to help customers discover products easier. Senior leaders hypothesize that better product discovery will improve customer engagement and business outcomes. (
&lt;a href="https://read.readwise.io/read/01gr9wd4e4d6jb7k5791vz1mmj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eugene Yan]]
title: &amp;ldquo;How to Write Better With the Why, What, How Framework&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="how-to-write-better-with-the-why-what-how-framework-3">How to Write Better With the Why, What, How Framework&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/writing-docs.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: How to Write Better With the Why, What, How Framework&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/writing-docs-why-what-how/" rel="noopener">https://eugeneyan.com/writing/writing-docs-why-what-how/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Our data science team (in an e-commerce company) is challenged to help customers discover products easier. Senior leaders hypothesize that better product discovery will improve customer engagement and business outcomes. (
&lt;a href="https://read.readwise.io/read/01gr9wd4e4d6jb7k5791vz1mmj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>I Asked My Followers:</title><link>https://pelayoarbues.github.io/literature-notes/Articles/I-Asked-My-Followers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/I-Asked-My-Followers/</guid><description>&lt;h1 id="i-asked-my-followers">I Asked My Followers:&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1554845969828548610/MDTscd1U.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Codie Sanchez]]&lt;/li>
&lt;li>Full Title: I Asked My Followers:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Codie_Sanchez/status/1624416473480396802" rel="noopener">https://twitter.com/Codie_Sanchez/status/1624416473480396802&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>“What could you give a 5-minute presentation on with no prep?” (
&lt;a href="https://read.readwise.io/read/01gs58jy7hkq60d2dtc1bag550" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Walk me through your last project. What should have been different?” (
&lt;a href="https://read.readwise.io/read/01gs58k10eny4fg04maf1jev2r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Tell me about the last 5 books you&amp;rsquo;ve read.” (
&lt;a href="https://read.readwise.io/read/01gs58k2t603y8htqs8vnshphy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Who would follow you here?” (
&lt;a href="https://read.readwise.io/read/01gs58k4qf1bz6dfrs7pdjvnaq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What question am I not asking you that you want me to?” (
&lt;a href="https://read.readwise.io/read/01gs58k6mggygfhxc93zb1z6jd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&amp;ldquo;What does your calendar look like?&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gs58k8j52t4vrb5bckcap1hm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you prepare for this interview?” (
&lt;a href="https://read.readwise.io/read/01gs58kansm24j7hsw278bjm64" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What will past bosses say are your 3 biggest strengths and weaknesses?” (
&lt;a href="https://read.readwise.io/read/01gs58kdyam7qe9c0zqbk0zwb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you handle a coworker/boss you never got along with?” (
&lt;a href="https://read.readwise.io/read/01gs58knxyfmm4qrc91jbycvyr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What do you think we are doing wrong as a company right now?” (
&lt;a href="https://read.readwise.io/read/01gs58kqf539ft9hgcvytszp4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Codie Sanchez]]
title: &amp;ldquo;I Asked My Followers:&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="i-asked-my-followers-1">I Asked My Followers:&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1554845969828548610/MDTscd1U.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Codie Sanchez]]&lt;/li>
&lt;li>Full Title: I Asked My Followers:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Codie_Sanchez/status/1624416473480396802" rel="noopener">https://twitter.com/Codie_Sanchez/status/1624416473480396802&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>“What could you give a 5-minute presentation on with no prep?” (
&lt;a href="https://read.readwise.io/read/01gs58jy7hkq60d2dtc1bag550" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Walk me through your last project. What should have been different?” (
&lt;a href="https://read.readwise.io/read/01gs58k10eny4fg04maf1jev2r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Tell me about the last 5 books you&amp;rsquo;ve read.” (
&lt;a href="https://read.readwise.io/read/01gs58k2t603y8htqs8vnshphy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Who would follow you here?” (
&lt;a href="https://read.readwise.io/read/01gs58k4qf1bz6dfrs7pdjvnaq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What question am I not asking you that you want me to?” (
&lt;a href="https://read.readwise.io/read/01gs58k6mggygfhxc93zb1z6jd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&amp;ldquo;What does your calendar look like?&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gs58k8j52t4vrb5bckcap1hm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you prepare for this interview?” (
&lt;a href="https://read.readwise.io/read/01gs58kansm24j7hsw278bjm64" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What will past bosses say are your 3 biggest strengths and weaknesses?” (
&lt;a href="https://read.readwise.io/read/01gs58kdyam7qe9c0zqbk0zwb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you handle a coworker/boss you never got along with?” (
&lt;a href="https://read.readwise.io/read/01gs58knxyfmm4qrc91jbycvyr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What do you think we are doing wrong as a company right now?” (
&lt;a href="https://read.readwise.io/read/01gs58kqf539ft9hgcvytszp4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Codie Sanchez]]
title: &amp;ldquo;I Asked My Followers:&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="i-asked-my-followers-2">I Asked My Followers:&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1554845969828548610/MDTscd1U.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Codie Sanchez]]&lt;/li>
&lt;li>Full Title: I Asked My Followers:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Codie_Sanchez/status/1624416473480396802" rel="noopener">https://twitter.com/Codie_Sanchez/status/1624416473480396802&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>“What could you give a 5-minute presentation on with no prep?” (
&lt;a href="https://read.readwise.io/read/01gs58jy7hkq60d2dtc1bag550" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Walk me through your last project. What should have been different?” (
&lt;a href="https://read.readwise.io/read/01gs58k10eny4fg04maf1jev2r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Tell me about the last 5 books you&amp;rsquo;ve read.” (
&lt;a href="https://read.readwise.io/read/01gs58k2t603y8htqs8vnshphy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Who would follow you here?” (
&lt;a href="https://read.readwise.io/read/01gs58k4qf1bz6dfrs7pdjvnaq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What question am I not asking you that you want me to?” (
&lt;a href="https://read.readwise.io/read/01gs58k6mggygfhxc93zb1z6jd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&amp;ldquo;What does your calendar look like?&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gs58k8j52t4vrb5bckcap1hm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you prepare for this interview?” (
&lt;a href="https://read.readwise.io/read/01gs58kansm24j7hsw278bjm64" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What will past bosses say are your 3 biggest strengths and weaknesses?” (
&lt;a href="https://read.readwise.io/read/01gs58kdyam7qe9c0zqbk0zwb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you handle a coworker/boss you never got along with?” (
&lt;a href="https://read.readwise.io/read/01gs58knxyfmm4qrc91jbycvyr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What do you think we are doing wrong as a company right now?” (
&lt;a href="https://read.readwise.io/read/01gs58kqf539ft9hgcvytszp4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Codie Sanchez]]
title: &amp;ldquo;I Asked My Followers:&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="i-asked-my-followers-3">I Asked My Followers:&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1554845969828548610/MDTscd1U.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Codie Sanchez]]&lt;/li>
&lt;li>Full Title: I Asked My Followers:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Codie_Sanchez/status/1624416473480396802" rel="noopener">https://twitter.com/Codie_Sanchez/status/1624416473480396802&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>“What could you give a 5-minute presentation on with no prep?” (
&lt;a href="https://read.readwise.io/read/01gs58jy7hkq60d2dtc1bag550" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Walk me through your last project. What should have been different?” (
&lt;a href="https://read.readwise.io/read/01gs58k10eny4fg04maf1jev2r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Tell me about the last 5 books you&amp;rsquo;ve read.” (
&lt;a href="https://read.readwise.io/read/01gs58k2t603y8htqs8vnshphy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Who would follow you here?” (
&lt;a href="https://read.readwise.io/read/01gs58k4qf1bz6dfrs7pdjvnaq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What question am I not asking you that you want me to?” (
&lt;a href="https://read.readwise.io/read/01gs58k6mggygfhxc93zb1z6jd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&amp;ldquo;What does your calendar look like?&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gs58k8j52t4vrb5bckcap1hm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you prepare for this interview?” (
&lt;a href="https://read.readwise.io/read/01gs58kansm24j7hsw278bjm64" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What will past bosses say are your 3 biggest strengths and weaknesses?” (
&lt;a href="https://read.readwise.io/read/01gs58kdyam7qe9c0zqbk0zwb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“How did you handle a coworker/boss you never got along with?” (
&lt;a href="https://read.readwise.io/read/01gs58knxyfmm4qrc91jbycvyr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“What do you think we are doing wrong as a company right now?” (
&lt;a href="https://read.readwise.io/read/01gs58kqf539ft9hgcvytszp4b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons...</title><link>https://pelayoarbues.github.io/literature-notes/Articles/In-2009-a-Man-Asked-Ted-Kaczynski-if-Nuclear-Weapons.../</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/In-2009-a-Man-Asked-Ted-Kaczynski-if-Nuclear-Weapons.../</guid><description>&lt;h1 id="in-2009-a-man-asked-ted-kaczynski-if-nuclear-weapons">In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1540316982100238338/lPbR-eZi.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Forrest]]&lt;/li>
&lt;li>Full Title: In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Foz89107323/status/1619052988496023557" rel="noopener">https://twitter.com/Foz89107323/status/1619052988496023557&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>global remedies for climate change&amp;quot; pose the biggest threat to humanity (
&lt;a href="https://read.readwise.io/read/01gqzp10gg0604jzq8qbkan2pq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If humans meddled too much in the climate, to the point where further interventions were required, the survival of the planet would be entirely dependent on human management.
Our lives would be in the hands of those elites that run the technological system. (
&lt;a href="https://read.readwise.io/read/01gqzp3z6rjdqs0a28ff65j3ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The elites are afraid of nuclear war because it would lead to their own destruction. But they will be delighted to see the system that gives them their power and their status become indispensable and therefore immune to any serious challenge.&amp;quot; (
&lt;a href="https://read.readwise.io/read/01gqzp486f8c46ysm3v1yfmtje" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the global economy becomes more tightly coupled, the chances of one event having a catastrophic impact on the entire system increase. (
&lt;a href="https://read.readwise.io/read/01gqzp6yqwpxckyhwsmxvtyggn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Regardless of whether you think climate change is real or not, our global elite view it as an &amp;ldquo;existential threat&amp;rdquo; to the survival of humanity.
If they can meddle with the environment in order to acquire absolute power over the earth and humanity, they will do just that. (
&lt;a href="https://read.readwise.io/read/01gqzp86fb6mgsh811datctqa0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Forrest]]
title: &amp;ldquo;In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="in-2009-a-man-asked-ted-kaczynski-if-nuclear-weapons-1">In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1540316982100238338/lPbR-eZi.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Forrest]]&lt;/li>
&lt;li>Full Title: In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Foz89107323/status/1619052988496023557" rel="noopener">https://twitter.com/Foz89107323/status/1619052988496023557&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>global remedies for climate change&amp;quot; pose the biggest threat to humanity (
&lt;a href="https://read.readwise.io/read/01gqzp10gg0604jzq8qbkan2pq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If humans meddled too much in the climate, to the point where further interventions were required, the survival of the planet would be entirely dependent on human management.
Our lives would be in the hands of those elites that run the technological system. (
&lt;a href="https://read.readwise.io/read/01gqzp3z6rjdqs0a28ff65j3ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The elites are afraid of nuclear war because it would lead to their own destruction. But they will be delighted to see the system that gives them their power and their status become indispensable and therefore immune to any serious challenge.&amp;quot; (
&lt;a href="https://read.readwise.io/read/01gqzp486f8c46ysm3v1yfmtje" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the global economy becomes more tightly coupled, the chances of one event having a catastrophic impact on the entire system increase. (
&lt;a href="https://read.readwise.io/read/01gqzp6yqwpxckyhwsmxvtyggn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Regardless of whether you think climate change is real or not, our global elite view it as an &amp;ldquo;existential threat&amp;rdquo; to the survival of humanity.
If they can meddle with the environment in order to acquire absolute power over the earth and humanity, they will do just that. (
&lt;a href="https://read.readwise.io/read/01gqzp86fb6mgsh811datctqa0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Forrest]]
title: &amp;ldquo;In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="in-2009-a-man-asked-ted-kaczynski-if-nuclear-weapons-2">In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1540316982100238338/lPbR-eZi.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Forrest]]&lt;/li>
&lt;li>Full Title: In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Foz89107323/status/1619052988496023557" rel="noopener">https://twitter.com/Foz89107323/status/1619052988496023557&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>global remedies for climate change&amp;quot; pose the biggest threat to humanity (
&lt;a href="https://read.readwise.io/read/01gqzp10gg0604jzq8qbkan2pq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If humans meddled too much in the climate, to the point where further interventions were required, the survival of the planet would be entirely dependent on human management.
Our lives would be in the hands of those elites that run the technological system. (
&lt;a href="https://read.readwise.io/read/01gqzp3z6rjdqs0a28ff65j3ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The elites are afraid of nuclear war because it would lead to their own destruction. But they will be delighted to see the system that gives them their power and their status become indispensable and therefore immune to any serious challenge.&amp;quot; (
&lt;a href="https://read.readwise.io/read/01gqzp486f8c46ysm3v1yfmtje" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the global economy becomes more tightly coupled, the chances of one event having a catastrophic impact on the entire system increase. (
&lt;a href="https://read.readwise.io/read/01gqzp6yqwpxckyhwsmxvtyggn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Regardless of whether you think climate change is real or not, our global elite view it as an &amp;ldquo;existential threat&amp;rdquo; to the survival of humanity.
If they can meddle with the environment in order to acquire absolute power over the earth and humanity, they will do just that. (
&lt;a href="https://read.readwise.io/read/01gqzp86fb6mgsh811datctqa0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Forrest]]
title: &amp;ldquo;In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="in-2009-a-man-asked-ted-kaczynski-if-nuclear-weapons-3">In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1540316982100238338/lPbR-eZi.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Forrest]]&lt;/li>
&lt;li>Full Title: In 2009, a Man Asked Ted Kaczynski if Nuclear Weapons&amp;hellip;&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/Foz89107323/status/1619052988496023557" rel="noopener">https://twitter.com/Foz89107323/status/1619052988496023557&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>global remedies for climate change&amp;quot; pose the biggest threat to humanity (
&lt;a href="https://read.readwise.io/read/01gqzp10gg0604jzq8qbkan2pq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If humans meddled too much in the climate, to the point where further interventions were required, the survival of the planet would be entirely dependent on human management.
Our lives would be in the hands of those elites that run the technological system. (
&lt;a href="https://read.readwise.io/read/01gqzp3z6rjdqs0a28ff65j3ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The elites are afraid of nuclear war because it would lead to their own destruction. But they will be delighted to see the system that gives them their power and their status become indispensable and therefore immune to any serious challenge.&amp;quot; (
&lt;a href="https://read.readwise.io/read/01gqzp486f8c46ysm3v1yfmtje" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the global economy becomes more tightly coupled, the chances of one event having a catastrophic impact on the entire system increase. (
&lt;a href="https://read.readwise.io/read/01gqzp6yqwpxckyhwsmxvtyggn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Regardless of whether you think climate change is real or not, our global elite view it as an &amp;ldquo;existential threat&amp;rdquo; to the survival of humanity.
If they can meddle with the environment in order to acquire absolute power over the earth and humanity, they will do just that. (
&lt;a href="https://read.readwise.io/read/01gqzp86fb6mgsh811datctqa0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Joshua Angrist – Econometrics Is the Original Data Science</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Joshua-Angrist-Econometrics-Is-the-Original-Data-Science/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Joshua-Angrist-Econometrics-Is-the-Original-Data-Science/</guid><description>&lt;h1 id="joshua-angrist--econometrics-is-the-original-data-science">Joshua Angrist – Econometrics Is the Original Data Science&lt;/h1>
&lt;p>
&lt;img src="https://i.ytimg.com/vi/T24j8XTcpe0/maxresdefault.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Rajk College for Advanced Studies]]&lt;/li>
&lt;li>Full Title: Joshua Angrist – Econometrics Is the Original Data Science&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.youtube.com/watch?v=T24j8XTcpe0" rel="noopener">https://www.youtube.com/watch?v=T24j8XTcpe0&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>economics undergrads whohave good training and econometricscompanies like amazon and googleand facebook and tripadvisor theyare looking for people who can do somestatistics but a lot of the questionsthat theyare interested in are causal questionswhat will be the consequences ofchanging prices for exampleor changing marketing strategies andthese companies have discovered that the
best training for thatis undergraduate economics oreconometrics thatwe really specialize in causalityin a way that regular data science doesnoti think we have some unique skillssomebody whotrains in data science may learn a lotabout machine learning but won&amp;rsquo;tnecessarilylearn about for example instrumentalvariablesor regression discontinuity methods andthose turn out to be very useful (
&lt;a href="https://read.readwise.io/read/01gr4a8h9jzp32zwhd0089ctz3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Rajk College for Advanced Studies]]
title: &amp;ldquo;Joshua Angrist – Econometrics Is the Original Data Science&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="joshua-angrist--econometrics-is-the-original-data-science-1">Joshua Angrist – Econometrics Is the Original Data Science&lt;/h1>
&lt;p>
&lt;img src="https://i.ytimg.com/vi/T24j8XTcpe0/maxresdefault.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Rajk College for Advanced Studies]]&lt;/li>
&lt;li>Full Title: Joshua Angrist – Econometrics Is the Original Data Science&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.youtube.com/watch?v=T24j8XTcpe0" rel="noopener">https://www.youtube.com/watch?v=T24j8XTcpe0&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>economics undergrads whohave good training and econometricscompanies like amazon and googleand facebook and tripadvisor theyare looking for people who can do somestatistics but a lot of the questionsthat theyare interested in are causal questionswhat will be the consequences ofchanging prices for exampleor changing marketing strategies andthese companies have discovered that the
best training for thatis undergraduate economics oreconometrics thatwe really specialize in causalityin a way that regular data science doesnoti think we have some unique skillssomebody whotrains in data science may learn a lotabout machine learning but won&amp;rsquo;tnecessarilylearn about for example instrumentalvariablesor regression discontinuity methods andthose turn out to be very useful (
&lt;a href="https://read.readwise.io/read/01gr4a8h9jzp32zwhd0089ctz3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Rajk College for Advanced Studies]]
title: &amp;ldquo;Joshua Angrist – Econometrics Is the Original Data Science&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="joshua-angrist--econometrics-is-the-original-data-science-2">Joshua Angrist – Econometrics Is the Original Data Science&lt;/h1>
&lt;p>
&lt;img src="https://i.ytimg.com/vi/T24j8XTcpe0/maxresdefault.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Rajk College for Advanced Studies]]&lt;/li>
&lt;li>Full Title: Joshua Angrist – Econometrics Is the Original Data Science&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.youtube.com/watch?v=T24j8XTcpe0" rel="noopener">https://www.youtube.com/watch?v=T24j8XTcpe0&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>economics undergrads whohave good training and econometricscompanies like amazon and googleand facebook and tripadvisor theyare looking for people who can do somestatistics but a lot of the questionsthat theyare interested in are causal questionswhat will be the consequences ofchanging prices for exampleor changing marketing strategies andthese companies have discovered that the
best training for thatis undergraduate economics oreconometrics thatwe really specialize in causalityin a way that regular data science doesnoti think we have some unique skillssomebody whotrains in data science may learn a lotabout machine learning but won&amp;rsquo;tnecessarilylearn about for example instrumentalvariablesor regression discontinuity methods andthose turn out to be very useful (
&lt;a href="https://read.readwise.io/read/01gr4a8h9jzp32zwhd0089ctz3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Rajk College for Advanced Studies]]
title: &amp;ldquo;Joshua Angrist – Econometrics Is the Original Data Science&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="joshua-angrist--econometrics-is-the-original-data-science-3">Joshua Angrist – Econometrics Is the Original Data Science&lt;/h1>
&lt;p>
&lt;img src="https://i.ytimg.com/vi/T24j8XTcpe0/maxresdefault.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Rajk College for Advanced Studies]]&lt;/li>
&lt;li>Full Title: Joshua Angrist – Econometrics Is the Original Data Science&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.youtube.com/watch?v=T24j8XTcpe0" rel="noopener">https://www.youtube.com/watch?v=T24j8XTcpe0&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>economics undergrads whohave good training and econometricscompanies like amazon and googleand facebook and tripadvisor theyare looking for people who can do somestatistics but a lot of the questionsthat theyare interested in are causal questionswhat will be the consequences ofchanging prices for exampleor changing marketing strategies andthese companies have discovered that the
best training for thatis undergraduate economics oreconometrics thatwe really specialize in causalityin a way that regular data science doesnoti think we have some unique skillssomebody whotrains in data science may learn a lotabout machine learning but won&amp;rsquo;tnecessarilylearn about for example instrumentalvariablesor regression discontinuity methods andthose turn out to be very useful (
&lt;a href="https://read.readwise.io/read/01gr4a8h9jzp32zwhd0089ctz3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Large Models Are Expensive to Fine-Tune on Downstream Tasks</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Large-Models-Are-Expensive-to-Fine-Tune-on-Downstream-Tasks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Large-Models-Are-Expensive-to-Fine-Tune-on-Downstream-Tasks/</guid><description>&lt;h1 id="large-models-are-expensive-to-fine-tune-on-downstream-tasks">Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1616378799624687618/IrF7Ft2r.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sourab Mangrulkar]]&lt;/li>
&lt;li>Full Title: Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/sourab_m/status/1624090029198020612" rel="noopener">https://twitter.com/sourab_m/status/1624090029198020612&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>With PEFT, you can fit the fine-tuning of very large models within consumer GPUs with support from other techniques like CPU offloading! (
&lt;a href="https://read.readwise.io/read/01gs6aq5cf8c25hg0bkjser0mr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Sourab Mangrulkar]]
title: &amp;ldquo;Large Models Are Expensive to Fine-Tune on Downstream Tasks&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="large-models-are-expensive-to-fine-tune-on-downstream-tasks-1">Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1616378799624687618/IrF7Ft2r.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sourab Mangrulkar]]&lt;/li>
&lt;li>Full Title: Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/sourab_m/status/1624090029198020612" rel="noopener">https://twitter.com/sourab_m/status/1624090029198020612&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>With PEFT, you can fit the fine-tuning of very large models within consumer GPUs with support from other techniques like CPU offloading! (
&lt;a href="https://read.readwise.io/read/01gs6aq5cf8c25hg0bkjser0mr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Sourab Mangrulkar]]
title: &amp;ldquo;Large Models Are Expensive to Fine-Tune on Downstream Tasks&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="large-models-are-expensive-to-fine-tune-on-downstream-tasks-2">Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1616378799624687618/IrF7Ft2r.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sourab Mangrulkar]]&lt;/li>
&lt;li>Full Title: Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/sourab_m/status/1624090029198020612" rel="noopener">https://twitter.com/sourab_m/status/1624090029198020612&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>With PEFT, you can fit the fine-tuning of very large models within consumer GPUs with support from other techniques like CPU offloading! (
&lt;a href="https://read.readwise.io/read/01gs6aq5cf8c25hg0bkjser0mr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Sourab Mangrulkar]]
title: &amp;ldquo;Large Models Are Expensive to Fine-Tune on Downstream Tasks&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="large-models-are-expensive-to-fine-tune-on-downstream-tasks-3">Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/h1>
&lt;p>
&lt;img src="https://pbs.twimg.com/profile_images/1616378799624687618/IrF7Ft2r.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Sourab Mangrulkar]]&lt;/li>
&lt;li>Full Title: Large Models Are Expensive to Fine-Tune on Downstream Tasks&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://twitter.com/sourab_m/status/1624090029198020612" rel="noopener">https://twitter.com/sourab_m/status/1624090029198020612&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>With PEFT, you can fit the fine-tuning of very large models within consumer GPUs with support from other techniques like CPU offloading! (
&lt;a href="https://read.readwise.io/read/01gs6aq5cf8c25hg0bkjser0mr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Las-Ventajas-De-Que-Tus-Padres-Aparezcan-en-Azul-en-La-Wikipedia/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Las-Ventajas-De-Que-Tus-Padres-Aparezcan-en-Azul-en-La-Wikipedia/</guid><description>&lt;h1 id="las-ventajas-de-que-tus-padres-aparezcan-en-azul-en-la-wikipedia">Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3a85ef8-7b0c-492d-b611-e624e88a05f5_512x512.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Antonio Ortiz]]&lt;/li>
&lt;li>Full Title: Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan" rel="noopener">https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e53e9a0-ba0b-4ec4-9b2c-c732ae3889ce_1861x802.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqcg0837r24arz0vs48dp0mg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>lo que está sucediendo en EEUU. Allí &lt;strong>el 15% de los hombres declararon no tener amistades íntimas en 2021, frente al 3% en 1990. El 10% de las mujeres declaró no tener amistades íntimas en 2021, frente al 2% en 1990&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqcg5mzfwsgqfwjk5d34c5a1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>En 1990, casi la mitad (45%) de los jóvenes declararon que, cuando se enfrentaban a un problema personal, acudían en primer lugar a sus amigos. Hoy en día, sólo el 22% de los jóvenes se apoya en sus amigos en los momentos difíciles. El 36% dice que su primera llamada es a sus padres (
&lt;a href="https://read.readwise.io/read/01gqcg6d8rs6n1w0vdqwj77ee4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Antonio Ortiz]]
title: &amp;ldquo;Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="las-ventajas-de-que-tus-padres-aparezcan-en-azul-en-la-wikipedia-1">Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3a85ef8-7b0c-492d-b611-e624e88a05f5_512x512.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Antonio Ortiz]]&lt;/li>
&lt;li>Full Title: Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan" rel="noopener">https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e53e9a0-ba0b-4ec4-9b2c-c732ae3889ce_1861x802.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqcg0837r24arz0vs48dp0mg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>lo que está sucediendo en EEUU. Allí &lt;strong>el 15% de los hombres declararon no tener amistades íntimas en 2021, frente al 3% en 1990. El 10% de las mujeres declaró no tener amistades íntimas en 2021, frente al 2% en 1990&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqcg5mzfwsgqfwjk5d34c5a1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>En 1990, casi la mitad (45%) de los jóvenes declararon que, cuando se enfrentaban a un problema personal, acudían en primer lugar a sus amigos. Hoy en día, sólo el 22% de los jóvenes se apoya en sus amigos en los momentos difíciles. El 36% dice que su primera llamada es a sus padres (
&lt;a href="https://read.readwise.io/read/01gqcg6d8rs6n1w0vdqwj77ee4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Antonio Ortiz]]
title: &amp;ldquo;Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="las-ventajas-de-que-tus-padres-aparezcan-en-azul-en-la-wikipedia-2">Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3a85ef8-7b0c-492d-b611-e624e88a05f5_512x512.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Antonio Ortiz]]&lt;/li>
&lt;li>Full Title: Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan" rel="noopener">https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e53e9a0-ba0b-4ec4-9b2c-c732ae3889ce_1861x802.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqcg0837r24arz0vs48dp0mg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>lo que está sucediendo en EEUU. Allí &lt;strong>el 15% de los hombres declararon no tener amistades íntimas en 2021, frente al 3% en 1990. El 10% de las mujeres declaró no tener amistades íntimas en 2021, frente al 2% en 1990&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqcg5mzfwsgqfwjk5d34c5a1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>En 1990, casi la mitad (45%) de los jóvenes declararon que, cuando se enfrentaban a un problema personal, acudían en primer lugar a sus amigos. Hoy en día, sólo el 22% de los jóvenes se apoya en sus amigos en los momentos difíciles. El 36% dice que su primera llamada es a sus padres (
&lt;a href="https://read.readwise.io/read/01gqcg6d8rs6n1w0vdqwj77ee4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Antonio Ortiz]]
title: &amp;ldquo;Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="las-ventajas-de-que-tus-padres-aparezcan-en-azul-en-la-wikipedia-3">Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/h_600,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3a85ef8-7b0c-492d-b611-e624e88a05f5_512x512.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Antonio Ortiz]]&lt;/li>
&lt;li>Full Title: Las Ventajas De Que Tus Padres Aparezcan en Azul en La Wikipedia&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan" rel="noopener">https://causasyazares.substack.com/p/las-ventajas-de-que-tus-padres-aparezcan&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7e53e9a0-ba0b-4ec4-9b2c-c732ae3889ce_1861x802.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqcg0837r24arz0vs48dp0mg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>lo que está sucediendo en EEUU. Allí &lt;strong>el 15% de los hombres declararon no tener amistades íntimas en 2021, frente al 3% en 1990. El 10% de las mujeres declaró no tener amistades íntimas en 2021, frente al 2% en 1990&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gqcg5mzfwsgqfwjk5d34c5a1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>En 1990, casi la mitad (45%) de los jóvenes declararon que, cuando se enfrentaban a un problema personal, acudían en primer lugar a sus amigos. Hoy en día, sólo el 22% de los jóvenes se apoya en sus amigos en los momentos difíciles. El 36% dice que su primera llamada es a sus padres (
&lt;a href="https://read.readwise.io/read/01gqcg6d8rs6n1w0vdqwj77ee4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Make Timeline Tradeoffs Using Iterative Elimination Tournaments.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Make-Timeline-Tradeoffs-Using-Iterative-Elimination-Tournaments./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Make-Timeline-Tradeoffs-Using-Iterative-Elimination-Tournaments./</guid><description>&lt;h1 id="make-timeline-tradeoffs-using-iterative-elimination-tournaments">Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/iteration-tournament.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">https://lethain.com/iterative-elimination-tournaments/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>An iterative elimination tournament is a competition where you have to win your current round before advancing to play in the next round. If you don’t win, you don’t keep playing. If you have a great strategy for next round, but don’t do well in the current round, then you’ll never get a chance to take advantage of that strategy. If you have a great approach for today, but no plan for tomorrow, it’ll be a futre mired with regrets.
This model is so effective because it focuses you on (1) identifying what success looks like over various time frames, (2) selecting an evolution of approaches for your shifting needs. (
&lt;a href="https://read.readwise.io/read/01gs6b7b9r9k38tmj55ex8b62q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="make-timeline-tradeoffs-using-iterative-elimination-tournaments-1">Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/iteration-tournament.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">https://lethain.com/iterative-elimination-tournaments/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>An iterative elimination tournament is a competition where you have to win your current round before advancing to play in the next round. If you don’t win, you don’t keep playing. If you have a great strategy for next round, but don’t do well in the current round, then you’ll never get a chance to take advantage of that strategy. If you have a great approach for today, but no plan for tomorrow, it’ll be a futre mired with regrets.
This model is so effective because it focuses you on (1) identifying what success looks like over various time frames, (2) selecting an evolution of approaches for your shifting needs. (
&lt;a href="https://read.readwise.io/read/01gs6b7b9r9k38tmj55ex8b62q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="make-timeline-tradeoffs-using-iterative-elimination-tournaments-2">Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/iteration-tournament.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">https://lethain.com/iterative-elimination-tournaments/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>An iterative elimination tournament is a competition where you have to win your current round before advancing to play in the next round. If you don’t win, you don’t keep playing. If you have a great strategy for next round, but don’t do well in the current round, then you’ll never get a chance to take advantage of that strategy. If you have a great approach for today, but no plan for tomorrow, it’ll be a futre mired with regrets.
This model is so effective because it focuses you on (1) identifying what success looks like over various time frames, (2) selecting an evolution of approaches for your shifting needs. (
&lt;a href="https://read.readwise.io/read/01gs6b7b9r9k38tmj55ex8b62q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="make-timeline-tradeoffs-using-iterative-elimination-tournaments-3">Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2019/iteration-tournament.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Timeline Tradeoffs Using Iterative Elimination Tournaments.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/iterative-elimination-tournaments/" rel="noopener">https://lethain.com/iterative-elimination-tournaments/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>An iterative elimination tournament is a competition where you have to win your current round before advancing to play in the next round. If you don’t win, you don’t keep playing. If you have a great strategy for next round, but don’t do well in the current round, then you’ll never get a chance to take advantage of that strategy. If you have a great approach for today, but no plan for tomorrow, it’ll be a futre mired with regrets.
This model is so effective because it focuses you on (1) identifying what success looks like over various time frames, (2) selecting an evolution of approaches for your shifting needs. (
&lt;a href="https://read.readwise.io/read/01gs6b7b9r9k38tmj55ex8b62q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Make Your Peers Your First Team.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Make-Your-Peers-Your-First-Team./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Make-Your-Peers-Your-First-Team./</guid><description>&lt;h1 id="make-your-peers-your-first-team">Make Your Peers Your First Team.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/first-team-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Your Peers Your First Team.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/first-team/" rel="noopener">https://lethain.com/first-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>These dynamics can lead to teams whose camaraderie is at best a qualified non-aggression pact, and collaboration is infrequent. It’s a strange tragedy that we hold ourselves accountable for building healthy, functional teams, and are so rarely on them ourselves. (
&lt;a href="https://read.readwise.io/read/01grshx98mn7p7yyv8n28b86gv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Make Your Peers Your First Team.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="make-your-peers-your-first-team-1">Make Your Peers Your First Team.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/first-team-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Your Peers Your First Team.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/first-team/" rel="noopener">https://lethain.com/first-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>These dynamics can lead to teams whose camaraderie is at best a qualified non-aggression pact, and collaboration is infrequent. It’s a strange tragedy that we hold ourselves accountable for building healthy, functional teams, and are so rarely on them ourselves. (
&lt;a href="https://read.readwise.io/read/01grshx98mn7p7yyv8n28b86gv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Make Your Peers Your First Team.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="make-your-peers-your-first-team-2">Make Your Peers Your First Team.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/first-team-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Your Peers Your First Team.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/first-team/" rel="noopener">https://lethain.com/first-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>These dynamics can lead to teams whose camaraderie is at best a qualified non-aggression pact, and collaboration is infrequent. It’s a strange tragedy that we hold ourselves accountable for building healthy, functional teams, and are so rarely on them ourselves. (
&lt;a href="https://read.readwise.io/read/01grshx98mn7p7yyv8n28b86gv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Make Your Peers Your First Team.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="make-your-peers-your-first-team-3">Make Your Peers Your First Team.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/first-team-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Make Your Peers Your First Team.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/first-team/" rel="noopener">https://lethain.com/first-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>These dynamics can lead to teams whose camaraderie is at best a qualified non-aggression pact, and collaboration is infrequent. It’s a strange tragedy that we hold ourselves accountable for building healthy, functional teams, and are so rarely on them ourselves. (
&lt;a href="https://read.readwise.io/read/01grshx98mn7p7yyv8n28b86gv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Managing People 🤯</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Managing-People-/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Managing-People-/</guid><description>&lt;h1 id="managing-people-">Managing People 🤯&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Andreas Klinger]]&lt;/li>
&lt;li>Full Title: Managing People 🤯&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This article provides advice to managers of small teams and startups on how to effectively manage people. It covers topics such as taking ownership, decision making, fostering trust and transparency, providing feedback, and avoiding drive-by management. It also suggests to look for best practices that naturally emerge when hiring good people and to expect more from managers that report to you. It emphasizes that mistakes are not the team&amp;rsquo;s fault but the manager&amp;rsquo;s and encourages them to give their team members more authority and ways to shine.&lt;/li>
&lt;li>URL:
&lt;a href="https://klinger.io/posts/managing-people-%F0%9F%A4%AF" rel="noopener">https://klinger.io/posts/managing-people-%F0%9F%A4%AF&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a manager, everything is your fault (
&lt;a href="https://read.readwise.io/read/01gqtc51avge32p01ns9rpw28r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You either created the processes where this outcome happened
• or you hired (or did not fire) the wrong people (
&lt;a href="https://read.readwise.io/read/01gqtc5s2j5pw3wmdz05yc5ap7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes; you lead people (
&lt;a href="https://read.readwise.io/read/01gqtc5y8j3g07r129svsn0p5p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• your job is &lt;em>not to manage people&lt;/em>
• but to &lt;em>manage processes&lt;/em> and &lt;em>lead people&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqtc6b3crtsp6h7spzk82z0a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes on how you expect work to be done, where each person&amp;rsquo;s authority starts and ends, how their careers are made, and how all this can be discussed, and/or changed (
&lt;a href="https://read.readwise.io/read/01gqtc6qe5e5n3fvyd6ggvkxbf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Act how you would want them to act if the role would be reversed. (
&lt;a href="https://read.readwise.io/read/01gqtc80dqqyz81fbn5yjrdpzp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gqtcd5jbjearybcaxz1dc70n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5192mznjqntw38a76p9330" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5195sk5153na7a5f8zkmvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Have few but very explicit processes and expect them to be followed (
&lt;a href="https://read.readwise.io/read/01gqtccsyz7bf9xxvjcechz4kd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In every discussion/project/problem/situation, it needs to be clear who makes decisions
• …everyone else only adds opinions.
• Ideally, the person who will afterward do (or lead) the follow-up work makes the decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcdxm19dzcnzc4wwfakk0k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Their manager has a &lt;em>handbrake&lt;/em> they can use to hard-stop decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcewnp29atkf19vgacev4p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s hard to get people to own a problem space fully
• But this is the goal (
&lt;a href="https://read.readwise.io/read/01gqtcjncqmdq0wfv65fjbq65j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Feedback them, help them
• Trust them and let them make mistakes (within damage barriers)
• Consider mistakes &amp;ldquo;them leveling up&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqtch6r70893ccfw10d3x66n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The worst thing that can happen is that you frequently step in, and people disassociate from their work
• They become drones who do what&amp;rsquo;s told instead of taking ownership.
• If this is your goal, you can hire cheaper, less talented people. (
&lt;a href="https://read.readwise.io/read/01gqtchvhq117rb2fx7j4epy0w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stay in the loop, set expectations, voice opinions, but let them handle it. Use your handbrake if needed. (
&lt;a href="https://read.readwise.io/read/01gqtcn53ptx2p8ddnpxaqzvnt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The easiest way to have people trust your work is by transparently sharing it without request.
• Have everything accessible where people would look for it (
&lt;a href="https://read.readwise.io/read/01gqtcpr2mk4tska625vtr0n6g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Think of trust as something that you systemize
• Eg what kind of trust do you give a new team member?
• What are they expected to do in the first weeks? first month? (
&lt;a href="https://read.readwise.io/read/01gqtcqcnwe6spwmd6k0w9v30f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Don&amp;rsquo;t start throwing your opinion or ideas around in meetings
• You most likely lack context, and most likely, you won&amp;rsquo;t be the person needing to follow through.
• Make it clear that it&amp;rsquo;s just opinions and not decisions.
• But know the power that the &amp;ldquo;opinion of the founder (or manager)&amp;rdquo; has towards most employees (
&lt;a href="https://read.readwise.io/read/01gqtcrzv1ggktrm7qmnf7ep6f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I call it drive-by management because the manager comes by a group of people having a discussion. They throw requests, change mandates, and ideas around like bullets, create confusion, panic, chaos, and when they leave, they leave a bloody mess behind (
&lt;a href="https://read.readwise.io/read/01gqtcstw8xdghjhqky8typpr1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• people x context = output
• I had great people in bad setups that had lousy output
• I had very ordinary people in great setups that churned out more work than a whole team (
&lt;a href="https://read.readwise.io/read/01gqtctk7k9d9anqjc1qs3cs3e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A junior engineer not keeping up with the work?
• Is it their fault? Or is your team right now not able to support a junior learning the game?
• This is ok, but should be either fixed or acknowledged (by discontinuing (
&lt;a href="https://read.readwise.io/read/01gqte78j19smk0vcqekm5sdmw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People should never be surprised that they are fired
• Context changed; new requirements should have been communicated (
&lt;a href="https://read.readwise.io/read/01gqte7mf7qt2n1p8vqewq1hjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you discontinue someone, you do it usually because of context
• The company changed
• The expectations of the role changed
• You realized you looked for the wrong hiring criteria
• It&amp;rsquo;s most likely more your fault than theirs (
&lt;a href="https://read.readwise.io/read/01gqte82xp0dc6g4nf8krws0nt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Once you decide to fire someone, do it.
• Frequently people keep employees around in a zombie-like state (
&lt;a href="https://read.readwise.io/read/01gqte98beb6p6bc19s6qwp59s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Clear decisions after meetings
• No clear decision? Make that explicit too.
• Clear owners
• No clear owner? Make that explicit too.
• Hear everyone&amp;rsquo;s opinions
• Make explicit who makes the decision
• And what the decision is (
&lt;a href="https://read.readwise.io/read/01gqteb80n5n0vtc91shmp8a2k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When looking for best practices or changes in the team/processes, always look at first what already naturally emerged
• If you hire good people, they usually start looking for solutions naturally (
&lt;a href="https://read.readwise.io/read/01gqtebmdnd67bbq313pbawfb4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• You will always be unhappy with processes in your company
• You will have growing pains until you stagnate (
&lt;a href="https://read.readwise.io/read/01gqtec6fwa9bk5vhrv79rfbj3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Use the same principles you&amp;rsquo;d use in refactoring code
• Consider to
• Test in small isolation first
• Peer review
• Not to change everything at once
• Avoid over-engineering (
&lt;a href="https://read.readwise.io/read/01gqteck6tcww1783kx837yf2j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Burnout comes from a felt loss of control and/or impact. (
&lt;a href="https://read.readwise.io/read/01gqted9vdpbqefttkbxkgq8tb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How can you give people control over their impact?
• How can you define boundaries around chaos around them? (
&lt;a href="https://read.readwise.io/read/01gqtedfp4na0qjw1jar23bqwy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They are accountable for the outcomes
• Responsible for all failures
• But not responsible for the success
• Success is the team&amp;rsquo;s achievement (
&lt;a href="https://read.readwise.io/read/01gqteeckm1haa20sbhtzhm3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Andreas Klinger]]
title: &amp;ldquo;Managing People 🤯&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="managing-people--1">Managing People 🤯&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Andreas Klinger]]&lt;/li>
&lt;li>Full Title: Managing People 🤯&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This article provides advice to managers of small teams and startups on how to effectively manage people. It covers topics such as taking ownership, decision making, fostering trust and transparency, providing feedback, and avoiding drive-by management. It also suggests to look for best practices that naturally emerge when hiring good people and to expect more from managers that report to you. It emphasizes that mistakes are not the team&amp;rsquo;s fault but the manager&amp;rsquo;s and encourages them to give their team members more authority and ways to shine.&lt;/li>
&lt;li>URL:
&lt;a href="https://klinger.io/posts/managing-people-%F0%9F%A4%AF" rel="noopener">https://klinger.io/posts/managing-people-%F0%9F%A4%AF&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a manager, everything is your fault (
&lt;a href="https://read.readwise.io/read/01gqtc51avge32p01ns9rpw28r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You either created the processes where this outcome happened
• or you hired (or did not fire) the wrong people (
&lt;a href="https://read.readwise.io/read/01gqtc5s2j5pw3wmdz05yc5ap7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes; you lead people (
&lt;a href="https://read.readwise.io/read/01gqtc5y8j3g07r129svsn0p5p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• your job is &lt;em>not to manage people&lt;/em>
• but to &lt;em>manage processes&lt;/em> and &lt;em>lead people&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqtc6b3crtsp6h7spzk82z0a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes on how you expect work to be done, where each person&amp;rsquo;s authority starts and ends, how their careers are made, and how all this can be discussed, and/or changed (
&lt;a href="https://read.readwise.io/read/01gqtc6qe5e5n3fvyd6ggvkxbf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Act how you would want them to act if the role would be reversed. (
&lt;a href="https://read.readwise.io/read/01gqtc80dqqyz81fbn5yjrdpzp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gqtcd5jbjearybcaxz1dc70n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5192mznjqntw38a76p9330" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5195sk5153na7a5f8zkmvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Have few but very explicit processes and expect them to be followed (
&lt;a href="https://read.readwise.io/read/01gqtccsyz7bf9xxvjcechz4kd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In every discussion/project/problem/situation, it needs to be clear who makes decisions
• …everyone else only adds opinions.
• Ideally, the person who will afterward do (or lead) the follow-up work makes the decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcdxm19dzcnzc4wwfakk0k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Their manager has a &lt;em>handbrake&lt;/em> they can use to hard-stop decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcewnp29atkf19vgacev4p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s hard to get people to own a problem space fully
• But this is the goal (
&lt;a href="https://read.readwise.io/read/01gqtcjncqmdq0wfv65fjbq65j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Feedback them, help them
• Trust them and let them make mistakes (within damage barriers)
• Consider mistakes &amp;ldquo;them leveling up&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqtch6r70893ccfw10d3x66n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The worst thing that can happen is that you frequently step in, and people disassociate from their work
• They become drones who do what&amp;rsquo;s told instead of taking ownership.
• If this is your goal, you can hire cheaper, less talented people. (
&lt;a href="https://read.readwise.io/read/01gqtchvhq117rb2fx7j4epy0w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stay in the loop, set expectations, voice opinions, but let them handle it. Use your handbrake if needed. (
&lt;a href="https://read.readwise.io/read/01gqtcn53ptx2p8ddnpxaqzvnt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The easiest way to have people trust your work is by transparently sharing it without request.
• Have everything accessible where people would look for it (
&lt;a href="https://read.readwise.io/read/01gqtcpr2mk4tska625vtr0n6g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Think of trust as something that you systemize
• Eg what kind of trust do you give a new team member?
• What are they expected to do in the first weeks? first month? (
&lt;a href="https://read.readwise.io/read/01gqtcqcnwe6spwmd6k0w9v30f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Don&amp;rsquo;t start throwing your opinion or ideas around in meetings
• You most likely lack context, and most likely, you won&amp;rsquo;t be the person needing to follow through.
• Make it clear that it&amp;rsquo;s just opinions and not decisions.
• But know the power that the &amp;ldquo;opinion of the founder (or manager)&amp;rdquo; has towards most employees (
&lt;a href="https://read.readwise.io/read/01gqtcrzv1ggktrm7qmnf7ep6f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I call it drive-by management because the manager comes by a group of people having a discussion. They throw requests, change mandates, and ideas around like bullets, create confusion, panic, chaos, and when they leave, they leave a bloody mess behind (
&lt;a href="https://read.readwise.io/read/01gqtcstw8xdghjhqky8typpr1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• people x context = output
• I had great people in bad setups that had lousy output
• I had very ordinary people in great setups that churned out more work than a whole team (
&lt;a href="https://read.readwise.io/read/01gqtctk7k9d9anqjc1qs3cs3e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A junior engineer not keeping up with the work?
• Is it their fault? Or is your team right now not able to support a junior learning the game?
• This is ok, but should be either fixed or acknowledged (by discontinuing (
&lt;a href="https://read.readwise.io/read/01gqte78j19smk0vcqekm5sdmw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People should never be surprised that they are fired
• Context changed; new requirements should have been communicated (
&lt;a href="https://read.readwise.io/read/01gqte7mf7qt2n1p8vqewq1hjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you discontinue someone, you do it usually because of context
• The company changed
• The expectations of the role changed
• You realized you looked for the wrong hiring criteria
• It&amp;rsquo;s most likely more your fault than theirs (
&lt;a href="https://read.readwise.io/read/01gqte82xp0dc6g4nf8krws0nt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Once you decide to fire someone, do it.
• Frequently people keep employees around in a zombie-like state (
&lt;a href="https://read.readwise.io/read/01gqte98beb6p6bc19s6qwp59s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Clear decisions after meetings
• No clear decision? Make that explicit too.
• Clear owners
• No clear owner? Make that explicit too.
• Hear everyone&amp;rsquo;s opinions
• Make explicit who makes the decision
• And what the decision is (
&lt;a href="https://read.readwise.io/read/01gqteb80n5n0vtc91shmp8a2k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When looking for best practices or changes in the team/processes, always look at first what already naturally emerged
• If you hire good people, they usually start looking for solutions naturally (
&lt;a href="https://read.readwise.io/read/01gqtebmdnd67bbq313pbawfb4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• You will always be unhappy with processes in your company
• You will have growing pains until you stagnate (
&lt;a href="https://read.readwise.io/read/01gqtec6fwa9bk5vhrv79rfbj3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Use the same principles you&amp;rsquo;d use in refactoring code
• Consider to
• Test in small isolation first
• Peer review
• Not to change everything at once
• Avoid over-engineering (
&lt;a href="https://read.readwise.io/read/01gqteck6tcww1783kx837yf2j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Burnout comes from a felt loss of control and/or impact. (
&lt;a href="https://read.readwise.io/read/01gqted9vdpbqefttkbxkgq8tb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How can you give people control over their impact?
• How can you define boundaries around chaos around them? (
&lt;a href="https://read.readwise.io/read/01gqtedfp4na0qjw1jar23bqwy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They are accountable for the outcomes
• Responsible for all failures
• But not responsible for the success
• Success is the team&amp;rsquo;s achievement (
&lt;a href="https://read.readwise.io/read/01gqteeckm1haa20sbhtzhm3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Andreas Klinger]]
title: &amp;ldquo;Managing People 🤯&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="managing-people--2">Managing People 🤯&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Andreas Klinger]]&lt;/li>
&lt;li>Full Title: Managing People 🤯&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This article provides advice to managers of small teams and startups on how to effectively manage people. It covers topics such as taking ownership, decision making, fostering trust and transparency, providing feedback, and avoiding drive-by management. It also suggests to look for best practices that naturally emerge when hiring good people and to expect more from managers that report to you. It emphasizes that mistakes are not the team&amp;rsquo;s fault but the manager&amp;rsquo;s and encourages them to give their team members more authority and ways to shine.&lt;/li>
&lt;li>URL:
&lt;a href="https://klinger.io/posts/managing-people-%F0%9F%A4%AF" rel="noopener">https://klinger.io/posts/managing-people-%F0%9F%A4%AF&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a manager, everything is your fault (
&lt;a href="https://read.readwise.io/read/01gqtc51avge32p01ns9rpw28r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You either created the processes where this outcome happened
• or you hired (or did not fire) the wrong people (
&lt;a href="https://read.readwise.io/read/01gqtc5s2j5pw3wmdz05yc5ap7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes; you lead people (
&lt;a href="https://read.readwise.io/read/01gqtc5y8j3g07r129svsn0p5p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• your job is &lt;em>not to manage people&lt;/em>
• but to &lt;em>manage processes&lt;/em> and &lt;em>lead people&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqtc6b3crtsp6h7spzk82z0a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes on how you expect work to be done, where each person&amp;rsquo;s authority starts and ends, how their careers are made, and how all this can be discussed, and/or changed (
&lt;a href="https://read.readwise.io/read/01gqtc6qe5e5n3fvyd6ggvkxbf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Act how you would want them to act if the role would be reversed. (
&lt;a href="https://read.readwise.io/read/01gqtc80dqqyz81fbn5yjrdpzp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gqtcd5jbjearybcaxz1dc70n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5192mznjqntw38a76p9330" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5195sk5153na7a5f8zkmvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Have few but very explicit processes and expect them to be followed (
&lt;a href="https://read.readwise.io/read/01gqtccsyz7bf9xxvjcechz4kd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In every discussion/project/problem/situation, it needs to be clear who makes decisions
• …everyone else only adds opinions.
• Ideally, the person who will afterward do (or lead) the follow-up work makes the decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcdxm19dzcnzc4wwfakk0k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Their manager has a &lt;em>handbrake&lt;/em> they can use to hard-stop decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcewnp29atkf19vgacev4p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s hard to get people to own a problem space fully
• But this is the goal (
&lt;a href="https://read.readwise.io/read/01gqtcjncqmdq0wfv65fjbq65j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Feedback them, help them
• Trust them and let them make mistakes (within damage barriers)
• Consider mistakes &amp;ldquo;them leveling up&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqtch6r70893ccfw10d3x66n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The worst thing that can happen is that you frequently step in, and people disassociate from their work
• They become drones who do what&amp;rsquo;s told instead of taking ownership.
• If this is your goal, you can hire cheaper, less talented people. (
&lt;a href="https://read.readwise.io/read/01gqtchvhq117rb2fx7j4epy0w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stay in the loop, set expectations, voice opinions, but let them handle it. Use your handbrake if needed. (
&lt;a href="https://read.readwise.io/read/01gqtcn53ptx2p8ddnpxaqzvnt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The easiest way to have people trust your work is by transparently sharing it without request.
• Have everything accessible where people would look for it (
&lt;a href="https://read.readwise.io/read/01gqtcpr2mk4tska625vtr0n6g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Think of trust as something that you systemize
• Eg what kind of trust do you give a new team member?
• What are they expected to do in the first weeks? first month? (
&lt;a href="https://read.readwise.io/read/01gqtcqcnwe6spwmd6k0w9v30f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Don&amp;rsquo;t start throwing your opinion or ideas around in meetings
• You most likely lack context, and most likely, you won&amp;rsquo;t be the person needing to follow through.
• Make it clear that it&amp;rsquo;s just opinions and not decisions.
• But know the power that the &amp;ldquo;opinion of the founder (or manager)&amp;rdquo; has towards most employees (
&lt;a href="https://read.readwise.io/read/01gqtcrzv1ggktrm7qmnf7ep6f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I call it drive-by management because the manager comes by a group of people having a discussion. They throw requests, change mandates, and ideas around like bullets, create confusion, panic, chaos, and when they leave, they leave a bloody mess behind (
&lt;a href="https://read.readwise.io/read/01gqtcstw8xdghjhqky8typpr1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• people x context = output
• I had great people in bad setups that had lousy output
• I had very ordinary people in great setups that churned out more work than a whole team (
&lt;a href="https://read.readwise.io/read/01gqtctk7k9d9anqjc1qs3cs3e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A junior engineer not keeping up with the work?
• Is it their fault? Or is your team right now not able to support a junior learning the game?
• This is ok, but should be either fixed or acknowledged (by discontinuing (
&lt;a href="https://read.readwise.io/read/01gqte78j19smk0vcqekm5sdmw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People should never be surprised that they are fired
• Context changed; new requirements should have been communicated (
&lt;a href="https://read.readwise.io/read/01gqte7mf7qt2n1p8vqewq1hjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you discontinue someone, you do it usually because of context
• The company changed
• The expectations of the role changed
• You realized you looked for the wrong hiring criteria
• It&amp;rsquo;s most likely more your fault than theirs (
&lt;a href="https://read.readwise.io/read/01gqte82xp0dc6g4nf8krws0nt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Once you decide to fire someone, do it.
• Frequently people keep employees around in a zombie-like state (
&lt;a href="https://read.readwise.io/read/01gqte98beb6p6bc19s6qwp59s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Clear decisions after meetings
• No clear decision? Make that explicit too.
• Clear owners
• No clear owner? Make that explicit too.
• Hear everyone&amp;rsquo;s opinions
• Make explicit who makes the decision
• And what the decision is (
&lt;a href="https://read.readwise.io/read/01gqteb80n5n0vtc91shmp8a2k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When looking for best practices or changes in the team/processes, always look at first what already naturally emerged
• If you hire good people, they usually start looking for solutions naturally (
&lt;a href="https://read.readwise.io/read/01gqtebmdnd67bbq313pbawfb4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• You will always be unhappy with processes in your company
• You will have growing pains until you stagnate (
&lt;a href="https://read.readwise.io/read/01gqtec6fwa9bk5vhrv79rfbj3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Use the same principles you&amp;rsquo;d use in refactoring code
• Consider to
• Test in small isolation first
• Peer review
• Not to change everything at once
• Avoid over-engineering (
&lt;a href="https://read.readwise.io/read/01gqteck6tcww1783kx837yf2j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Burnout comes from a felt loss of control and/or impact. (
&lt;a href="https://read.readwise.io/read/01gqted9vdpbqefttkbxkgq8tb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How can you give people control over their impact?
• How can you define boundaries around chaos around them? (
&lt;a href="https://read.readwise.io/read/01gqtedfp4na0qjw1jar23bqwy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They are accountable for the outcomes
• Responsible for all failures
• But not responsible for the success
• Success is the team&amp;rsquo;s achievement (
&lt;a href="https://read.readwise.io/read/01gqteeckm1haa20sbhtzhm3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Andreas Klinger]]
title: &amp;ldquo;Managing People 🤯&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="managing-people--3">Managing People 🤯&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Andreas Klinger]]&lt;/li>
&lt;li>Full Title: Managing People 🤯&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This article provides advice to managers of small teams and startups on how to effectively manage people. It covers topics such as taking ownership, decision making, fostering trust and transparency, providing feedback, and avoiding drive-by management. It also suggests to look for best practices that naturally emerge when hiring good people and to expect more from managers that report to you. It emphasizes that mistakes are not the team&amp;rsquo;s fault but the manager&amp;rsquo;s and encourages them to give their team members more authority and ways to shine.&lt;/li>
&lt;li>URL:
&lt;a href="https://klinger.io/posts/managing-people-%F0%9F%A4%AF" rel="noopener">https://klinger.io/posts/managing-people-%F0%9F%A4%AF&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>As a manager, everything is your fault (
&lt;a href="https://read.readwise.io/read/01gqtc51avge32p01ns9rpw28r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You either created the processes where this outcome happened
• or you hired (or did not fire) the wrong people (
&lt;a href="https://read.readwise.io/read/01gqtc5s2j5pw3wmdz05yc5ap7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes; you lead people (
&lt;a href="https://read.readwise.io/read/01gqtc5y8j3g07r129svsn0p5p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• your job is &lt;em>not to manage people&lt;/em>
• but to &lt;em>manage processes&lt;/em> and &lt;em>lead people&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqtc6b3crtsp6h7spzk82z0a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You manage processes on how you expect work to be done, where each person&amp;rsquo;s authority starts and ends, how their careers are made, and how all this can be discussed, and/or changed (
&lt;a href="https://read.readwise.io/read/01gqtc6qe5e5n3fvyd6ggvkxbf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Act how you would want them to act if the role would be reversed. (
&lt;a href="https://read.readwise.io/read/01gqtc80dqqyz81fbn5yjrdpzp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gqtcd5jbjearybcaxz1dc70n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5192mznjqntw38a76p9330" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Processes are expectations made explicit (
&lt;a href="https://read.readwise.io/read/01gr5195sk5153na7a5f8zkmvt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Have few but very explicit processes and expect them to be followed (
&lt;a href="https://read.readwise.io/read/01gqtccsyz7bf9xxvjcechz4kd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In every discussion/project/problem/situation, it needs to be clear who makes decisions
• …everyone else only adds opinions.
• Ideally, the person who will afterward do (or lead) the follow-up work makes the decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcdxm19dzcnzc4wwfakk0k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Their manager has a &lt;em>handbrake&lt;/em> they can use to hard-stop decisions. (
&lt;a href="https://read.readwise.io/read/01gqtcewnp29atkf19vgacev4p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It&amp;rsquo;s hard to get people to own a problem space fully
• But this is the goal (
&lt;a href="https://read.readwise.io/read/01gqtcjncqmdq0wfv65fjbq65j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Feedback them, help them
• Trust them and let them make mistakes (within damage barriers)
• Consider mistakes &amp;ldquo;them leveling up&amp;rdquo; (
&lt;a href="https://read.readwise.io/read/01gqtch6r70893ccfw10d3x66n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The worst thing that can happen is that you frequently step in, and people disassociate from their work
• They become drones who do what&amp;rsquo;s told instead of taking ownership.
• If this is your goal, you can hire cheaper, less talented people. (
&lt;a href="https://read.readwise.io/read/01gqtchvhq117rb2fx7j4epy0w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stay in the loop, set expectations, voice opinions, but let them handle it. Use your handbrake if needed. (
&lt;a href="https://read.readwise.io/read/01gqtcn53ptx2p8ddnpxaqzvnt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The easiest way to have people trust your work is by transparently sharing it without request.
• Have everything accessible where people would look for it (
&lt;a href="https://read.readwise.io/read/01gqtcpr2mk4tska625vtr0n6g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Think of trust as something that you systemize
• Eg what kind of trust do you give a new team member?
• What are they expected to do in the first weeks? first month? (
&lt;a href="https://read.readwise.io/read/01gqtcqcnwe6spwmd6k0w9v30f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Don&amp;rsquo;t start throwing your opinion or ideas around in meetings
• You most likely lack context, and most likely, you won&amp;rsquo;t be the person needing to follow through.
• Make it clear that it&amp;rsquo;s just opinions and not decisions.
• But know the power that the &amp;ldquo;opinion of the founder (or manager)&amp;rdquo; has towards most employees (
&lt;a href="https://read.readwise.io/read/01gqtcrzv1ggktrm7qmnf7ep6f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I call it drive-by management because the manager comes by a group of people having a discussion. They throw requests, change mandates, and ideas around like bullets, create confusion, panic, chaos, and when they leave, they leave a bloody mess behind (
&lt;a href="https://read.readwise.io/read/01gqtcstw8xdghjhqky8typpr1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• people x context = output
• I had great people in bad setups that had lousy output
• I had very ordinary people in great setups that churned out more work than a whole team (
&lt;a href="https://read.readwise.io/read/01gqtctk7k9d9anqjc1qs3cs3e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A junior engineer not keeping up with the work?
• Is it their fault? Or is your team right now not able to support a junior learning the game?
• This is ok, but should be either fixed or acknowledged (by discontinuing (
&lt;a href="https://read.readwise.io/read/01gqte78j19smk0vcqekm5sdmw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People should never be surprised that they are fired
• Context changed; new requirements should have been communicated (
&lt;a href="https://read.readwise.io/read/01gqte7mf7qt2n1p8vqewq1hjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you discontinue someone, you do it usually because of context
• The company changed
• The expectations of the role changed
• You realized you looked for the wrong hiring criteria
• It&amp;rsquo;s most likely more your fault than theirs (
&lt;a href="https://read.readwise.io/read/01gqte82xp0dc6g4nf8krws0nt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Once you decide to fire someone, do it.
• Frequently people keep employees around in a zombie-like state (
&lt;a href="https://read.readwise.io/read/01gqte98beb6p6bc19s6qwp59s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Clear decisions after meetings
• No clear decision? Make that explicit too.
• Clear owners
• No clear owner? Make that explicit too.
• Hear everyone&amp;rsquo;s opinions
• Make explicit who makes the decision
• And what the decision is (
&lt;a href="https://read.readwise.io/read/01gqteb80n5n0vtc91shmp8a2k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When looking for best practices or changes in the team/processes, always look at first what already naturally emerged
• If you hire good people, they usually start looking for solutions naturally (
&lt;a href="https://read.readwise.io/read/01gqtebmdnd67bbq313pbawfb4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• You will always be unhappy with processes in your company
• You will have growing pains until you stagnate (
&lt;a href="https://read.readwise.io/read/01gqtec6fwa9bk5vhrv79rfbj3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Use the same principles you&amp;rsquo;d use in refactoring code
• Consider to
• Test in small isolation first
• Peer review
• Not to change everything at once
• Avoid over-engineering (
&lt;a href="https://read.readwise.io/read/01gqteck6tcww1783kx837yf2j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Burnout comes from a felt loss of control and/or impact. (
&lt;a href="https://read.readwise.io/read/01gqted9vdpbqefttkbxkgq8tb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How can you give people control over their impact?
• How can you define boundaries around chaos around them? (
&lt;a href="https://read.readwise.io/read/01gqtedfp4na0qjw1jar23bqwy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They are accountable for the outcomes
• Responsible for all failures
• But not responsible for the success
• Success is the team&amp;rsquo;s achievement (
&lt;a href="https://read.readwise.io/read/01gqteeckm1haa20sbhtzhm3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Managing the First Year</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Managing-the-First-Year/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Managing-the-First-Year/</guid><description>&lt;h1 id="managing-the-first-year">Managing the First Year&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[alexkgold.space]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Managing the First Year&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: When your team makes a mistake is often tempting to micromanage them and treat them as infants. The truth is that if you are surrounded by professionals is that they might need more context for doing a good job.
Management is more creative as it seems, how to structure your team, how to design effective processes, always having an eye on people development and delivery levels.
Management is a form of multiplying yourself and your very ultimate objective is to &lt;strong>make your team work well&lt;/strong>.
Management is hard and is more a craft than something you can learn.
Go to therapy to understand your inner tendencies and patterns. You have to deal with your fears and insecurities, you have the feeling of your technical skills degrade over time.&lt;/p>
&lt;h1 id="management-definition">Management definition&lt;/h1>
&lt;p>For the author management is not a role, is a constellation of roles. The main difficulty, besides a calendar packed of meetings with different people and projects is to change hats from minute to minute:&lt;/p>
&lt;ul>
&lt;li>People manager&lt;/li>
&lt;li>Resource manager&lt;/li>
&lt;li>Project manager&lt;/li>
&lt;li>Communications manager&lt;/li>
&lt;li>Process manager&lt;/li>
&lt;li>Technical mentor and coach&lt;/li>
&lt;/ul>
&lt;h1 id="meetings-are-the-main-tool-of-a-manager">Meetings are the main tool of a manager&lt;/h1>
&lt;p>From 1-1 meetings, team meetings and project specific ones.&lt;/p>
&lt;h1 id="managers-words-carry-a-lot-of-power">Managers words carry a lot of power&lt;/h1>
&lt;p>You are not a random member of your team anymore&lt;/p>
&lt;h1 id="resource-management-is-particularly-hard">Resource management is particularly hard&lt;/h1>
&lt;h1 id="mentoring-is-different-for-teaching">Mentoring is different for teaching&lt;/h1>
&lt;p>Mentoring as manager is more coaching than teaching. Difficult to let people find the time to study and develop while keeping a high speed delivery service&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_369" rel="noopener">https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_369&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>I’ve found management most exciting as a form of leverage. (
&lt;a href="https://read.readwise.io/read/01gs3nsg7xb650a49jjdk9mn0p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Good management is a flywheel generator — it gives the team clarity and helps them feel safe to experiment and grow, resulting in ever-higher levels of collective performance. (
&lt;a href="https://read.readwise.io/read/01gs3nskjpb0x8y1sghxskyqew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But it turned out management didn’t work like that. It turned out &lt;strong>management was a craft&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3nt5xnn50rh719e9ycm8b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Unlike data science, where learning more was the answer to a skills gap, my time spent in books didn’t seem to translate directly into being better at my job.
As a manager, I found that it wasn’t knowledge I needed, it was the daily practice of doing the work. And in that, I was constantly bumping up against the limits of my bravery and patience (
&lt;a href="https://read.readwise.io/read/01gs3ntpphzcx6wetgj6drmx9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[alexkgold.space]]
title: &amp;ldquo;Managing the First Year&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="managing-the-first-year-1">Managing the First Year&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[alexkgold.space]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Managing the First Year&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: When your team makes a mistake is often tempting to micromanage them and treat them as infants. The truth is that if you are surrounded by professionals is that they might need more context for doing a good job.
Management is more creative as it seems, how to structure your team, how to design effective processes, always having an eye on people development and delivery levels.
Management is a form of multiplying yourself and your very ultimate objective is to &lt;strong>make your team work well&lt;/strong>.
Management is hard and is more a craft than something you can learn.
Go to therapy to understand your inner tendencies and patterns. You have to deal with your fears and insecurities, you have the feeling of your technical skills degrade over time.&lt;/p>
&lt;h1 id="management-definition-1">Management definition&lt;/h1>
&lt;p>For the author management is not a role, is a constellation of roles. The main difficulty, besides a calendar packed of meetings with different people and projects is to change hats from minute to minute:&lt;/p>
&lt;ul>
&lt;li>People manager&lt;/li>
&lt;li>Resource manager&lt;/li>
&lt;li>Project manager&lt;/li>
&lt;li>Communications manager&lt;/li>
&lt;li>Process manager&lt;/li>
&lt;li>Technical mentor and coach&lt;/li>
&lt;/ul>
&lt;h1 id="meetings-are-the-main-tool-of-a-manager-1">Meetings are the main tool of a manager&lt;/h1>
&lt;p>From 1-1 meetings, team meetings and project specific ones.&lt;/p>
&lt;h1 id="managers-words-carry-a-lot-of-power-1">Managers words carry a lot of power&lt;/h1>
&lt;p>You are not a random member of your team anymore&lt;/p>
&lt;h1 id="resource-management-is-particularly-hard-1">Resource management is particularly hard&lt;/h1>
&lt;h1 id="mentoring-is-different-for-teaching-1">Mentoring is different for teaching&lt;/h1>
&lt;p>Mentoring as manager is more coaching than teaching. Difficult to let people find the time to study and develop while keeping a high speed delivery service&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_369" rel="noopener">https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_369&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>I’ve found management most exciting as a form of leverage. (
&lt;a href="https://read.readwise.io/read/01gs3nsg7xb650a49jjdk9mn0p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Good management is a flywheel generator — it gives the team clarity and helps them feel safe to experiment and grow, resulting in ever-higher levels of collective performance. (
&lt;a href="https://read.readwise.io/read/01gs3nskjpb0x8y1sghxskyqew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But it turned out management didn’t work like that. It turned out &lt;strong>management was a craft&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3nt5xnn50rh719e9ycm8b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Unlike data science, where learning more was the answer to a skills gap, my time spent in books didn’t seem to translate directly into being better at my job.
As a manager, I found that it wasn’t knowledge I needed, it was the daily practice of doing the work. And in that, I was constantly bumping up against the limits of my bravery and patience (
&lt;a href="https://read.readwise.io/read/01gs3ntpphzcx6wetgj6drmx9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[alexkgold.space]]
title: &amp;ldquo;Managing the First Year&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="managing-the-first-year-2">Managing the First Year&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[alexkgold.space]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Managing the First Year&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: When your team makes a mistake is often tempting to micromanage them and treat them as infants. The truth is that if you are surrounded by professionals is that they might need more context for doing a good job.
Management is more creative as it seems, how to structure your team, how to design effective processes, always having an eye on people development and delivery levels.
Management is a form of multiplying yourself and your very ultimate objective is to &lt;strong>make your team work well&lt;/strong>.
Management is hard and is more a craft than something you can learn.
Go to therapy to understand your inner tendencies and patterns. You have to deal with your fears and insecurities, you have the feeling of your technical skills degrade over time.&lt;/p>
&lt;h1 id="management-definition-2">Management definition&lt;/h1>
&lt;p>For the author management is not a role, is a constellation of roles. The main difficulty, besides a calendar packed of meetings with different people and projects is to change hats from minute to minute:&lt;/p>
&lt;ul>
&lt;li>People manager&lt;/li>
&lt;li>Resource manager&lt;/li>
&lt;li>Project manager&lt;/li>
&lt;li>Communications manager&lt;/li>
&lt;li>Process manager&lt;/li>
&lt;li>Technical mentor and coach&lt;/li>
&lt;/ul>
&lt;h1 id="meetings-are-the-main-tool-of-a-manager-2">Meetings are the main tool of a manager&lt;/h1>
&lt;p>From 1-1 meetings, team meetings and project specific ones.&lt;/p>
&lt;h1 id="managers-words-carry-a-lot-of-power-2">Managers words carry a lot of power&lt;/h1>
&lt;p>You are not a random member of your team anymore&lt;/p>
&lt;h1 id="resource-management-is-particularly-hard-2">Resource management is particularly hard&lt;/h1>
&lt;h1 id="mentoring-is-different-for-teaching-2">Mentoring is different for teaching&lt;/h1>
&lt;p>Mentoring as manager is more coaching than teaching. Difficult to let people find the time to study and develop while keeping a high speed delivery service&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_369" rel="noopener">https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_369&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>I’ve found management most exciting as a form of leverage. (
&lt;a href="https://read.readwise.io/read/01gs3nsg7xb650a49jjdk9mn0p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Good management is a flywheel generator — it gives the team clarity and helps them feel safe to experiment and grow, resulting in ever-higher levels of collective performance. (
&lt;a href="https://read.readwise.io/read/01gs3nskjpb0x8y1sghxskyqew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But it turned out management didn’t work like that. It turned out &lt;strong>management was a craft&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3nt5xnn50rh719e9ycm8b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Unlike data science, where learning more was the answer to a skills gap, my time spent in books didn’t seem to translate directly into being better at my job.
As a manager, I found that it wasn’t knowledge I needed, it was the daily practice of doing the work. And in that, I was constantly bumping up against the limits of my bravery and patience (
&lt;a href="https://read.readwise.io/read/01gs3ntpphzcx6wetgj6drmx9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[alexkgold.space]]
title: &amp;ldquo;Managing the First Year&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="managing-the-first-year-3">Managing the First Year&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[alexkgold.space]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: Managing the First Year&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: When your team makes a mistake is often tempting to micromanage them and treat them as infants. The truth is that if you are surrounded by professionals is that they might need more context for doing a good job.
Management is more creative as it seems, how to structure your team, how to design effective processes, always having an eye on people development and delivery levels.
Management is a form of multiplying yourself and your very ultimate objective is to &lt;strong>make your team work well&lt;/strong>.
Management is hard and is more a craft than something you can learn.
Go to therapy to understand your inner tendencies and patterns. You have to deal with your fears and insecurities, you have the feeling of your technical skills degrade over time.&lt;/p>
&lt;h1 id="management-definition-3">Management definition&lt;/h1>
&lt;p>For the author management is not a role, is a constellation of roles. The main difficulty, besides a calendar packed of meetings with different people and projects is to change hats from minute to minute:&lt;/p>
&lt;ul>
&lt;li>People manager&lt;/li>
&lt;li>Resource manager&lt;/li>
&lt;li>Project manager&lt;/li>
&lt;li>Communications manager&lt;/li>
&lt;li>Process manager&lt;/li>
&lt;li>Technical mentor and coach&lt;/li>
&lt;/ul>
&lt;h1 id="meetings-are-the-main-tool-of-a-manager-3">Meetings are the main tool of a manager&lt;/h1>
&lt;p>From 1-1 meetings, team meetings and project specific ones.&lt;/p>
&lt;h1 id="managers-words-carry-a-lot-of-power-3">Managers words carry a lot of power&lt;/h1>
&lt;p>You are not a random member of your team anymore&lt;/p>
&lt;h1 id="resource-management-is-particularly-hard-3">Resource management is particularly hard&lt;/h1>
&lt;h1 id="mentoring-is-different-for-teaching-3">Mentoring is different for teaching&lt;/h1>
&lt;p>Mentoring as manager is more coaching than teaching. Difficult to let people find the time to study and develop while keeping a high speed delivery service&lt;/p>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_369" rel="noopener">https://alexkgold.space/mfy.html?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_369&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>I’ve found management most exciting as a form of leverage. (
&lt;a href="https://read.readwise.io/read/01gs3nsg7xb650a49jjdk9mn0p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Good management is a flywheel generator — it gives the team clarity and helps them feel safe to experiment and grow, resulting in ever-higher levels of collective performance. (
&lt;a href="https://read.readwise.io/read/01gs3nskjpb0x8y1sghxskyqew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But it turned out management didn’t work like that. It turned out &lt;strong>management was a craft&lt;/strong>. (
&lt;a href="https://read.readwise.io/read/01gs3nt5xnn50rh719e9ycm8b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Unlike data science, where learning more was the answer to a skills gap, my time spent in books didn’t seem to translate directly into being better at my job.
As a manager, I found that it wasn’t knowledge I needed, it was the daily practice of doing the work. And in that, I was constantly bumping up against the limits of my bravery and patience (
&lt;a href="https://read.readwise.io/read/01gs3ntpphzcx6wetgj6drmx9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Mechanisms for Effective Machine Learning Projects</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Mechanisms-for-Effective-Machine-Learning-Projects/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Mechanisms-for-Effective-Machine-Learning-Projects/</guid><description>&lt;h1 id="mechanisms-for-effective-machine-learning-projects">Mechanisms for Effective Machine Learning Projects&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: Mechanisms for Effective Machine Learning Projects&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>If your team is like most teams I’ve been on, you have 2 - 3 problems for every available person. Thus, each member works on 1 or 2 problems simultaneously, with some folks taking 3 or more. And because everyone’s so busy, we barely have time to check in on each other’s projects outside of standup, planning, retrospective, etc. (
&lt;a href="https://read.readwise.io/read/01gqqszg0yetftsg6h4k19ev9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>have a pilot and copilot for each project. (
&lt;a href="https://read.readwise.io/read/01gqqszv6szhjqpw5cpc39e29y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The pilot is the main project owner and is in charge of its success (or failure). They own and delegate the work as required though they’re usually responsible for the bulk of design and critical code paths. (
&lt;a href="https://read.readwise.io/read/01gqqt0bsp8v2ka8bjgmrpa5me" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The copilot helps the pilot stay on track, identify critical flaws, and call out blindspots. (
&lt;a href="https://read.readwise.io/read/01gqqt18np1z9vbfh1k8qfc79j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For example, the copilot should challenge the pilot if the proposed design doesn’t solve the business problem, or if the train-validation split is invalid (
&lt;a href="https://read.readwise.io/read/01gqqt1njz8vqd8wtmvzamat7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For every 10 hours the pilot spends on the project, the copilot can expect to spend an hour on reviews (10% of the pilot’s effort). (
&lt;a href="https://read.readwise.io/read/01gqqt25xagwce0jgt22vshwnd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Pilots and copilots don’t have to be from the same job family. As an applied scientist, I often partner with an engineer who helps with infrastructure, observability, CI/CD, etc. If both scientist and engineer are sufficiently experienced, they can double up as each other’s copilot. As they review each other’s work, knowledge transfer occurs organically and they learn to be effective copilots for other engineers or scientists in future projects. (
&lt;a href="https://read.readwise.io/read/01gqqt3632cx4kdyf9fqm6sk6e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For a literature review, I &lt;strong>read papers relevant to the problem&lt;/strong> . I’m biased towards
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/vqh3hrhn6ledrnsw/aHR0cHM6Ly9naXRodWIuY29tL2V1Z2VuZXlhbi9hcHBsaWVkLW1s" rel="noopener">solutions that have been applied in industry&lt;/a> though more academic papers have also been helpful (
&lt;a href="https://read.readwise.io/read/01gqqtj8c1c6sy8j6hw5r43n8e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>similar to a code review but for machine learning prototypes and experiments&lt;/strong> . Once I have initial experiment results, I schedule a review with fellow scientists to ensure I haven’t overlooked any blindspots or committed critical errors. (
&lt;a href="https://read.readwise.io/read/01gqqtm48mzhan556ydsk66wcr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>During the review, I focus on understanding the methodology and the potential of the current approach. (
&lt;a href="https://read.readwise.io/read/01gqqtpgkx9r75fx7e82ge44je" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For (
&lt;a href="https://read.readwise.io/read/01gqqtn7v4day0gskxvk36bpax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>conduct methodology reviews asynchronously, like a code review, we could adopt a tool like DagsHub which supports
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/n2hohvhn4m6kp8s0/aHR0cHM6Ly9kYWdzaHViLmNvbS9PcGVyYXRpb25TYXZ0YS9TYXZ0YURlcHRoL3NyYy9tYWluL05vdGVib29rcy9TYXZ0YURlcHRoX0NvbGFiLmlweW5i" rel="noopener">comments on Jupyter notebooks&lt;/a> and
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/48hvheh03v6nepbq/aHR0cHM6Ly9kYWdzaHViLmNvbS9uaXJiYXJhemlkYS9DaGVYTmV0L3NyYy85NWM4NmMyOGZmZTE2ZWU2NDY2NTlhYjE4MGY2MWE0MGNmZDAxOTVkL2RhdGFfbGFiZWxpbmcvZGF0YS9pbWFnZXNfMDAxL2ltYWdlcy8wMDAwMDAwN18wMDAucG5n" rel="noopener">data&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqqtqrfv6khqn4rssew6egxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we &lt;strong>timebox each project phase and task&lt;/strong> . Time constraints help us focus on the most important tasks and not get bogged down in the details. Timeboxing for machine learning projects can be challenging, because compared to engineering projects, the work is relatively ill-defined. Furthermore, a large part of the work is research and experimentation which unfortunately leads to many a dead end. (
&lt;a href="https://read.readwise.io/read/01gqqtrfg1dx4anaqynhk27dya" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>less extreme approach is to set a timebox that is “comfortable yet challenging”. Thus, instead of halving the timebox, we reduce it by 10 - 20% (
&lt;a href="https://read.readwise.io/read/01gqqtsqtp19ca4gshzbwzj3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>for greenfield projects that may be hard to scope, we can adopt standard timeboxes. For example, we might allocate two weeks for a literature review, four to eight weeks to build a prototype, and three to six months to implement it in production. (
&lt;a href="https://read.readwise.io/read/01gr9w482wtatz1yv09yvztfmg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eugene Yan]]
title: &amp;ldquo;Mechanisms for Effective Machine Learning Projects&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="mechanisms-for-effective-machine-learning-projects-1">Mechanisms for Effective Machine Learning Projects&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: Mechanisms for Effective Machine Learning Projects&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>If your team is like most teams I’ve been on, you have 2 - 3 problems for every available person. Thus, each member works on 1 or 2 problems simultaneously, with some folks taking 3 or more. And because everyone’s so busy, we barely have time to check in on each other’s projects outside of standup, planning, retrospective, etc. (
&lt;a href="https://read.readwise.io/read/01gqqszg0yetftsg6h4k19ev9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>have a pilot and copilot for each project. (
&lt;a href="https://read.readwise.io/read/01gqqszv6szhjqpw5cpc39e29y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The pilot is the main project owner and is in charge of its success (or failure). They own and delegate the work as required though they’re usually responsible for the bulk of design and critical code paths. (
&lt;a href="https://read.readwise.io/read/01gqqt0bsp8v2ka8bjgmrpa5me" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The copilot helps the pilot stay on track, identify critical flaws, and call out blindspots. (
&lt;a href="https://read.readwise.io/read/01gqqt18np1z9vbfh1k8qfc79j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For example, the copilot should challenge the pilot if the proposed design doesn’t solve the business problem, or if the train-validation split is invalid (
&lt;a href="https://read.readwise.io/read/01gqqt1njz8vqd8wtmvzamat7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For every 10 hours the pilot spends on the project, the copilot can expect to spend an hour on reviews (10% of the pilot’s effort). (
&lt;a href="https://read.readwise.io/read/01gqqt25xagwce0jgt22vshwnd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Pilots and copilots don’t have to be from the same job family. As an applied scientist, I often partner with an engineer who helps with infrastructure, observability, CI/CD, etc. If both scientist and engineer are sufficiently experienced, they can double up as each other’s copilot. As they review each other’s work, knowledge transfer occurs organically and they learn to be effective copilots for other engineers or scientists in future projects. (
&lt;a href="https://read.readwise.io/read/01gqqt3632cx4kdyf9fqm6sk6e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For a literature review, I &lt;strong>read papers relevant to the problem&lt;/strong> . I’m biased towards
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/vqh3hrhn6ledrnsw/aHR0cHM6Ly9naXRodWIuY29tL2V1Z2VuZXlhbi9hcHBsaWVkLW1s" rel="noopener">solutions that have been applied in industry&lt;/a> though more academic papers have also been helpful (
&lt;a href="https://read.readwise.io/read/01gqqtj8c1c6sy8j6hw5r43n8e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>similar to a code review but for machine learning prototypes and experiments&lt;/strong> . Once I have initial experiment results, I schedule a review with fellow scientists to ensure I haven’t overlooked any blindspots or committed critical errors. (
&lt;a href="https://read.readwise.io/read/01gqqtm48mzhan556ydsk66wcr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>During the review, I focus on understanding the methodology and the potential of the current approach. (
&lt;a href="https://read.readwise.io/read/01gqqtpgkx9r75fx7e82ge44je" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For (
&lt;a href="https://read.readwise.io/read/01gqqtn7v4day0gskxvk36bpax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>conduct methodology reviews asynchronously, like a code review, we could adopt a tool like DagsHub which supports
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/n2hohvhn4m6kp8s0/aHR0cHM6Ly9kYWdzaHViLmNvbS9PcGVyYXRpb25TYXZ0YS9TYXZ0YURlcHRoL3NyYy9tYWluL05vdGVib29rcy9TYXZ0YURlcHRoX0NvbGFiLmlweW5i" rel="noopener">comments on Jupyter notebooks&lt;/a> and
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/48hvheh03v6nepbq/aHR0cHM6Ly9kYWdzaHViLmNvbS9uaXJiYXJhemlkYS9DaGVYTmV0L3NyYy85NWM4NmMyOGZmZTE2ZWU2NDY2NTlhYjE4MGY2MWE0MGNmZDAxOTVkL2RhdGFfbGFiZWxpbmcvZGF0YS9pbWFnZXNfMDAxL2ltYWdlcy8wMDAwMDAwN18wMDAucG5n" rel="noopener">data&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqqtqrfv6khqn4rssew6egxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we &lt;strong>timebox each project phase and task&lt;/strong> . Time constraints help us focus on the most important tasks and not get bogged down in the details. Timeboxing for machine learning projects can be challenging, because compared to engineering projects, the work is relatively ill-defined. Furthermore, a large part of the work is research and experimentation which unfortunately leads to many a dead end. (
&lt;a href="https://read.readwise.io/read/01gqqtrfg1dx4anaqynhk27dya" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>less extreme approach is to set a timebox that is “comfortable yet challenging”. Thus, instead of halving the timebox, we reduce it by 10 - 20% (
&lt;a href="https://read.readwise.io/read/01gqqtsqtp19ca4gshzbwzj3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>for greenfield projects that may be hard to scope, we can adopt standard timeboxes. For example, we might allocate two weeks for a literature review, four to eight weeks to build a prototype, and three to six months to implement it in production. (
&lt;a href="https://read.readwise.io/read/01gr9w482wtatz1yv09yvztfmg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eugene Yan]]
title: &amp;ldquo;Mechanisms for Effective Machine Learning Projects&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="mechanisms-for-effective-machine-learning-projects-2">Mechanisms for Effective Machine Learning Projects&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: Mechanisms for Effective Machine Learning Projects&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>If your team is like most teams I’ve been on, you have 2 - 3 problems for every available person. Thus, each member works on 1 or 2 problems simultaneously, with some folks taking 3 or more. And because everyone’s so busy, we barely have time to check in on each other’s projects outside of standup, planning, retrospective, etc. (
&lt;a href="https://read.readwise.io/read/01gqqszg0yetftsg6h4k19ev9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>have a pilot and copilot for each project. (
&lt;a href="https://read.readwise.io/read/01gqqszv6szhjqpw5cpc39e29y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The pilot is the main project owner and is in charge of its success (or failure). They own and delegate the work as required though they’re usually responsible for the bulk of design and critical code paths. (
&lt;a href="https://read.readwise.io/read/01gqqt0bsp8v2ka8bjgmrpa5me" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The copilot helps the pilot stay on track, identify critical flaws, and call out blindspots. (
&lt;a href="https://read.readwise.io/read/01gqqt18np1z9vbfh1k8qfc79j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For example, the copilot should challenge the pilot if the proposed design doesn’t solve the business problem, or if the train-validation split is invalid (
&lt;a href="https://read.readwise.io/read/01gqqt1njz8vqd8wtmvzamat7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For every 10 hours the pilot spends on the project, the copilot can expect to spend an hour on reviews (10% of the pilot’s effort). (
&lt;a href="https://read.readwise.io/read/01gqqt25xagwce0jgt22vshwnd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Pilots and copilots don’t have to be from the same job family. As an applied scientist, I often partner with an engineer who helps with infrastructure, observability, CI/CD, etc. If both scientist and engineer are sufficiently experienced, they can double up as each other’s copilot. As they review each other’s work, knowledge transfer occurs organically and they learn to be effective copilots for other engineers or scientists in future projects. (
&lt;a href="https://read.readwise.io/read/01gqqt3632cx4kdyf9fqm6sk6e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For a literature review, I &lt;strong>read papers relevant to the problem&lt;/strong> . I’m biased towards
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/vqh3hrhn6ledrnsw/aHR0cHM6Ly9naXRodWIuY29tL2V1Z2VuZXlhbi9hcHBsaWVkLW1s" rel="noopener">solutions that have been applied in industry&lt;/a> though more academic papers have also been helpful (
&lt;a href="https://read.readwise.io/read/01gqqtj8c1c6sy8j6hw5r43n8e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>similar to a code review but for machine learning prototypes and experiments&lt;/strong> . Once I have initial experiment results, I schedule a review with fellow scientists to ensure I haven’t overlooked any blindspots or committed critical errors. (
&lt;a href="https://read.readwise.io/read/01gqqtm48mzhan556ydsk66wcr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>During the review, I focus on understanding the methodology and the potential of the current approach. (
&lt;a href="https://read.readwise.io/read/01gqqtpgkx9r75fx7e82ge44je" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For (
&lt;a href="https://read.readwise.io/read/01gqqtn7v4day0gskxvk36bpax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>conduct methodology reviews asynchronously, like a code review, we could adopt a tool like DagsHub which supports
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/n2hohvhn4m6kp8s0/aHR0cHM6Ly9kYWdzaHViLmNvbS9PcGVyYXRpb25TYXZ0YS9TYXZ0YURlcHRoL3NyYy9tYWluL05vdGVib29rcy9TYXZ0YURlcHRoX0NvbGFiLmlweW5i" rel="noopener">comments on Jupyter notebooks&lt;/a> and
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/48hvheh03v6nepbq/aHR0cHM6Ly9kYWdzaHViLmNvbS9uaXJiYXJhemlkYS9DaGVYTmV0L3NyYy85NWM4NmMyOGZmZTE2ZWU2NDY2NTlhYjE4MGY2MWE0MGNmZDAxOTVkL2RhdGFfbGFiZWxpbmcvZGF0YS9pbWFnZXNfMDAxL2ltYWdlcy8wMDAwMDAwN18wMDAucG5n" rel="noopener">data&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqqtqrfv6khqn4rssew6egxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we &lt;strong>timebox each project phase and task&lt;/strong> . Time constraints help us focus on the most important tasks and not get bogged down in the details. Timeboxing for machine learning projects can be challenging, because compared to engineering projects, the work is relatively ill-defined. Furthermore, a large part of the work is research and experimentation which unfortunately leads to many a dead end. (
&lt;a href="https://read.readwise.io/read/01gqqtrfg1dx4anaqynhk27dya" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>less extreme approach is to set a timebox that is “comfortable yet challenging”. Thus, instead of halving the timebox, we reduce it by 10 - 20% (
&lt;a href="https://read.readwise.io/read/01gqqtsqtp19ca4gshzbwzj3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>for greenfield projects that may be hard to scope, we can adopt standard timeboxes. For example, we might allocate two weeks for a literature review, four to eight weeks to build a prototype, and three to six months to implement it in production. (
&lt;a href="https://read.readwise.io/read/01gr9w482wtatz1yv09yvztfmg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Eugene Yan]]
title: &amp;ldquo;Mechanisms for Effective Machine Learning Projects&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="mechanisms-for-effective-machine-learning-projects-3">Mechanisms for Effective Machine Learning Projects&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Eugene Yan]]&lt;/li>
&lt;li>Full Title: Mechanisms for Effective Machine Learning Projects&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>If your team is like most teams I’ve been on, you have 2 - 3 problems for every available person. Thus, each member works on 1 or 2 problems simultaneously, with some folks taking 3 or more. And because everyone’s so busy, we barely have time to check in on each other’s projects outside of standup, planning, retrospective, etc. (
&lt;a href="https://read.readwise.io/read/01gqqszg0yetftsg6h4k19ev9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>have a pilot and copilot for each project. (
&lt;a href="https://read.readwise.io/read/01gqqszv6szhjqpw5cpc39e29y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The pilot is the main project owner and is in charge of its success (or failure). They own and delegate the work as required though they’re usually responsible for the bulk of design and critical code paths. (
&lt;a href="https://read.readwise.io/read/01gqqt0bsp8v2ka8bjgmrpa5me" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The copilot helps the pilot stay on track, identify critical flaws, and call out blindspots. (
&lt;a href="https://read.readwise.io/read/01gqqt18np1z9vbfh1k8qfc79j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For example, the copilot should challenge the pilot if the proposed design doesn’t solve the business problem, or if the train-validation split is invalid (
&lt;a href="https://read.readwise.io/read/01gqqt1njz8vqd8wtmvzamat7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For every 10 hours the pilot spends on the project, the copilot can expect to spend an hour on reviews (10% of the pilot’s effort). (
&lt;a href="https://read.readwise.io/read/01gqqt25xagwce0jgt22vshwnd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Pilots and copilots don’t have to be from the same job family. As an applied scientist, I often partner with an engineer who helps with infrastructure, observability, CI/CD, etc. If both scientist and engineer are sufficiently experienced, they can double up as each other’s copilot. As they review each other’s work, knowledge transfer occurs organically and they learn to be effective copilots for other engineers or scientists in future projects. (
&lt;a href="https://read.readwise.io/read/01gqqt3632cx4kdyf9fqm6sk6e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For a literature review, I &lt;strong>read papers relevant to the problem&lt;/strong> . I’m biased towards
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/vqh3hrhn6ledrnsw/aHR0cHM6Ly9naXRodWIuY29tL2V1Z2VuZXlhbi9hcHBsaWVkLW1s" rel="noopener">solutions that have been applied in industry&lt;/a> though more academic papers have also been helpful (
&lt;a href="https://read.readwise.io/read/01gqqtj8c1c6sy8j6hw5r43n8e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>similar to a code review but for machine learning prototypes and experiments&lt;/strong> . Once I have initial experiment results, I schedule a review with fellow scientists to ensure I haven’t overlooked any blindspots or committed critical errors. (
&lt;a href="https://read.readwise.io/read/01gqqtm48mzhan556ydsk66wcr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>During the review, I focus on understanding the methodology and the potential of the current approach. (
&lt;a href="https://read.readwise.io/read/01gqqtpgkx9r75fx7e82ge44je" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For (
&lt;a href="https://read.readwise.io/read/01gqqtn7v4day0gskxvk36bpax" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>conduct methodology reviews asynchronously, like a code review, we could adopt a tool like DagsHub which supports
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/n2hohvhn4m6kp8s0/aHR0cHM6Ly9kYWdzaHViLmNvbS9PcGVyYXRpb25TYXZ0YS9TYXZ0YURlcHRoL3NyYy9tYWluL05vdGVib29rcy9TYXZ0YURlcHRoX0NvbGFiLmlweW5i" rel="noopener">comments on Jupyter notebooks&lt;/a> and
&lt;a href="https://click.convertkit-mail2.com/p9unze2olzb9h3lpn93aq/48hvheh03v6nepbq/aHR0cHM6Ly9kYWdzaHViLmNvbS9uaXJiYXJhemlkYS9DaGVYTmV0L3NyYy85NWM4NmMyOGZmZTE2ZWU2NDY2NTlhYjE4MGY2MWE0MGNmZDAxOTVkL2RhdGFfbGFiZWxpbmcvZGF0YS9pbWFnZXNfMDAxL2ltYWdlcy8wMDAwMDAwN18wMDAucG5n" rel="noopener">data&lt;/a> (
&lt;a href="https://read.readwise.io/read/01gqqtqrfv6khqn4rssew6egxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we &lt;strong>timebox each project phase and task&lt;/strong> . Time constraints help us focus on the most important tasks and not get bogged down in the details. Timeboxing for machine learning projects can be challenging, because compared to engineering projects, the work is relatively ill-defined. Furthermore, a large part of the work is research and experimentation which unfortunately leads to many a dead end. (
&lt;a href="https://read.readwise.io/read/01gqqtrfg1dx4anaqynhk27dya" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>less extreme approach is to set a timebox that is “comfortable yet challenging”. Thus, instead of halving the timebox, we reduce it by 10 - 20% (
&lt;a href="https://read.readwise.io/read/01gqqtsqtp19ca4gshzbwzj3p1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>for greenfield projects that may be hard to scope, we can adopt standard timeboxes. For example, we might allocate two weeks for a literature review, four to eight weeks to build a prototype, and three to six months to implement it in production. (
&lt;a href="https://read.readwise.io/read/01gr9w482wtatz1yv09yvztfmg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>New Week #109</title><link>https://pelayoarbues.github.io/literature-notes/Articles/New-Week-#109/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/New-Week-#109/</guid><description>&lt;h1 id="new-week-109">New Week #109&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c1148ff-5ac3-4234-b00a-288ed5839c51_1600x800.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Mattin]]&lt;/li>
&lt;li>Full Title: New Week #109&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://newworldsamehumans.substack.com/p/new-week-109" rel="noopener">https://newworldsamehumans.substack.com/p/new-week-109&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>mainstream scientific opinion is that the accumulation of mutations in DNA is the primary driver of ageing. Sinclair, though, has long believed that the real culprits are errors that appear over time in the information carried in the epigenome. (
&lt;a href="https://read.readwise.io/read/01gqzr6e2na817zfatr572tnvd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can repair the epigenetic instructions — Sinclair likens this to ‘rebooting the epigenome’ — and so literally unspool the ageing process. (
&lt;a href="https://read.readwise.io/read/01gqzr86hnkgmz29e9p5g6tnsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[David Mattin]]
title: &amp;ldquo;New Week #109&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="new-week-109-1">New Week #109&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c1148ff-5ac3-4234-b00a-288ed5839c51_1600x800.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Mattin]]&lt;/li>
&lt;li>Full Title: New Week #109&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://newworldsamehumans.substack.com/p/new-week-109" rel="noopener">https://newworldsamehumans.substack.com/p/new-week-109&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>mainstream scientific opinion is that the accumulation of mutations in DNA is the primary driver of ageing. Sinclair, though, has long believed that the real culprits are errors that appear over time in the information carried in the epigenome. (
&lt;a href="https://read.readwise.io/read/01gqzr6e2na817zfatr572tnvd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can repair the epigenetic instructions — Sinclair likens this to ‘rebooting the epigenome’ — and so literally unspool the ageing process. (
&lt;a href="https://read.readwise.io/read/01gqzr86hnkgmz29e9p5g6tnsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[David Mattin]]
title: &amp;ldquo;New Week #109&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="new-week-109-2">New Week #109&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c1148ff-5ac3-4234-b00a-288ed5839c51_1600x800.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Mattin]]&lt;/li>
&lt;li>Full Title: New Week #109&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://newworldsamehumans.substack.com/p/new-week-109" rel="noopener">https://newworldsamehumans.substack.com/p/new-week-109&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>mainstream scientific opinion is that the accumulation of mutations in DNA is the primary driver of ageing. Sinclair, though, has long believed that the real culprits are errors that appear over time in the information carried in the epigenome. (
&lt;a href="https://read.readwise.io/read/01gqzr6e2na817zfatr572tnvd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can repair the epigenetic instructions — Sinclair likens this to ‘rebooting the epigenome’ — and so literally unspool the ageing process. (
&lt;a href="https://read.readwise.io/read/01gqzr86hnkgmz29e9p5g6tnsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[David Mattin]]
title: &amp;ldquo;New Week #109&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="new-week-109-3">New Week #109&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5c1148ff-5ac3-4234-b00a-288ed5839c51_1600x800.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[David Mattin]]&lt;/li>
&lt;li>Full Title: New Week #109&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://newworldsamehumans.substack.com/p/new-week-109" rel="noopener">https://newworldsamehumans.substack.com/p/new-week-109&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>mainstream scientific opinion is that the accumulation of mutations in DNA is the primary driver of ageing. Sinclair, though, has long believed that the real culprits are errors that appear over time in the information carried in the epigenome. (
&lt;a href="https://read.readwise.io/read/01gqzr6e2na817zfatr572tnvd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can repair the epigenetic instructions — Sinclair likens this to ‘rebooting the epigenome’ — and so literally unspool the ageing process. (
&lt;a href="https://read.readwise.io/read/01gqzr86hnkgmz29e9p5g6tnsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Platform Products for Machine Learning</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Platform-Products-for-Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Platform-Products-for-Machine-Learning/</guid><description>&lt;h1 id="platform-products-for-machine-learning">Platform Products for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*1xkIr2hO0p-ogdDEfpIsrg.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Platform Products for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: # Why ML Platform teams
ML stream aligned teams (those facing ML projects for end users) cognitive load might be reduced if superflous MLOps tasks are managed by the ML platform. The lesser the team needs to think about Ops the more the team can take on solving high value-added questions.
&lt;h1 id="what-ml-platform-products">What ML Platform products&lt;/h1>
&lt;ol>
&lt;li>Data/ML exploration:&lt;/li>
&lt;li>Code management&lt;/li>
&lt;li>Data/feature management&lt;/li>
&lt;li>Model management&lt;/li>
&lt;li>Reporting:&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2" rel="noopener">https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>or an ML team, there can be three types of cognitive load, as adapted from
&lt;a href="https://12devsofxmas.co.uk/2015/12/day-3-managing-cognitive-load-for-team-learning/" rel="noopener">Managing cognitive load for team learning&lt;/a>.
&lt;ol>
&lt;li>&lt;em>Intrinsic:&lt;/em> relates to fundamental Data/ML tasks, such as, how to write Spark transformations, formulate ML pipeline, etc.&lt;/li>
&lt;li>&lt;em>Germane:&lt;/em> relates to complex Data/ML tasks that require special attention, such as, how to prepare features for a specific operational use, how to interpret a model performance before/during/after its usage?&lt;/li>
&lt;li>&lt;em>Extraneous&lt;/em>: relates to the environment in which the Data/ML task is carried out. For example, where perform code quality analysis and how to carry out rudimentary code quality analysis in that environment, where to manage modeling activities, and how to carry out common model management tasks in that environment? (
&lt;a href="https://read.readwise.io/read/01gs3nphjm8n4b8yanscgr3tvk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>The intrinsic cognitive relates to fundamental skills in a stream-aligned ML team and should be handled through hiring, training, pair/mob programming, hackathon, etc. The reduction efforts of such loads should be driven by engineering/data science/analyst managers. The germane cognitive load relates to advanced tasks in a stream-aligned team and can be reduced through sufficient opportunity to work on such problems and review support by experts. However, extraneous cognitive load relates to routine superfluous MLOps tasks that add little value in retaining working memory. Most of these relate to platform management. (
&lt;a href="https://read.readwise.io/read/01gs3nq4qjanzd83fq24vm6s6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Common ML platform activities are as follows:
&lt;ol>
&lt;li>Data/ML Exploration: Explore data access/wrangling, ML methods, visualization, …&lt;/li>
&lt;li>Code Management: source code editing, version control, continuous code quality evaluation, continuous code release, …&lt;/li>
&lt;li>Data/Feature Management: data pipeline orchestration, data snapshotting, feature, …&lt;/li>
&lt;li>Model Management: ML pipeline orchestration, track experiments, handle model lifecycle, model serving, …&lt;/li>
&lt;li>Reporting: dashboards, error logging, monitoring, … (
&lt;a href="https://read.readwise.io/read/01gs3nqeaksg7z2kz37zsv9zy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Misbah Uddin]]
title: &amp;ldquo;Platform Products for Machine Learning&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="platform-products-for-machine-learning-1">Platform Products for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*1xkIr2hO0p-ogdDEfpIsrg.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Platform Products for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: # Why ML Platform teams
ML stream aligned teams (those facing ML projects for end users) cognitive load might be reduced if superflous MLOps tasks are managed by the ML platform. The lesser the team needs to think about Ops the more the team can take on solving high value-added questions.
&lt;h1 id="what-ml-platform-products-1">What ML Platform products&lt;/h1>
&lt;ol>
&lt;li>Data/ML exploration:&lt;/li>
&lt;li>Code management&lt;/li>
&lt;li>Data/feature management&lt;/li>
&lt;li>Model management&lt;/li>
&lt;li>Reporting:&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2" rel="noopener">https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>or an ML team, there can be three types of cognitive load, as adapted from
&lt;a href="https://12devsofxmas.co.uk/2015/12/day-3-managing-cognitive-load-for-team-learning/" rel="noopener">Managing cognitive load for team learning&lt;/a>.
&lt;ol>
&lt;li>&lt;em>Intrinsic:&lt;/em> relates to fundamental Data/ML tasks, such as, how to write Spark transformations, formulate ML pipeline, etc.&lt;/li>
&lt;li>&lt;em>Germane:&lt;/em> relates to complex Data/ML tasks that require special attention, such as, how to prepare features for a specific operational use, how to interpret a model performance before/during/after its usage?&lt;/li>
&lt;li>&lt;em>Extraneous&lt;/em>: relates to the environment in which the Data/ML task is carried out. For example, where perform code quality analysis and how to carry out rudimentary code quality analysis in that environment, where to manage modeling activities, and how to carry out common model management tasks in that environment? (
&lt;a href="https://read.readwise.io/read/01gs3nphjm8n4b8yanscgr3tvk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>The intrinsic cognitive relates to fundamental skills in a stream-aligned ML team and should be handled through hiring, training, pair/mob programming, hackathon, etc. The reduction efforts of such loads should be driven by engineering/data science/analyst managers. The germane cognitive load relates to advanced tasks in a stream-aligned team and can be reduced through sufficient opportunity to work on such problems and review support by experts. However, extraneous cognitive load relates to routine superfluous MLOps tasks that add little value in retaining working memory. Most of these relate to platform management. (
&lt;a href="https://read.readwise.io/read/01gs3nq4qjanzd83fq24vm6s6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Common ML platform activities are as follows:
&lt;ol>
&lt;li>Data/ML Exploration: Explore data access/wrangling, ML methods, visualization, …&lt;/li>
&lt;li>Code Management: source code editing, version control, continuous code quality evaluation, continuous code release, …&lt;/li>
&lt;li>Data/Feature Management: data pipeline orchestration, data snapshotting, feature, …&lt;/li>
&lt;li>Model Management: ML pipeline orchestration, track experiments, handle model lifecycle, model serving, …&lt;/li>
&lt;li>Reporting: dashboards, error logging, monitoring, … (
&lt;a href="https://read.readwise.io/read/01gs3nqeaksg7z2kz37zsv9zy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Misbah Uddin]]
title: &amp;ldquo;Platform Products for Machine Learning&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="platform-products-for-machine-learning-2">Platform Products for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*1xkIr2hO0p-ogdDEfpIsrg.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Platform Products for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: # Why ML Platform teams
ML stream aligned teams (those facing ML projects for end users) cognitive load might be reduced if superflous MLOps tasks are managed by the ML platform. The lesser the team needs to think about Ops the more the team can take on solving high value-added questions.
&lt;h1 id="what-ml-platform-products-2">What ML Platform products&lt;/h1>
&lt;ol>
&lt;li>Data/ML exploration:&lt;/li>
&lt;li>Code management&lt;/li>
&lt;li>Data/feature management&lt;/li>
&lt;li>Model management&lt;/li>
&lt;li>Reporting:&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2" rel="noopener">https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>or an ML team, there can be three types of cognitive load, as adapted from
&lt;a href="https://12devsofxmas.co.uk/2015/12/day-3-managing-cognitive-load-for-team-learning/" rel="noopener">Managing cognitive load for team learning&lt;/a>.
&lt;ol>
&lt;li>&lt;em>Intrinsic:&lt;/em> relates to fundamental Data/ML tasks, such as, how to write Spark transformations, formulate ML pipeline, etc.&lt;/li>
&lt;li>&lt;em>Germane:&lt;/em> relates to complex Data/ML tasks that require special attention, such as, how to prepare features for a specific operational use, how to interpret a model performance before/during/after its usage?&lt;/li>
&lt;li>&lt;em>Extraneous&lt;/em>: relates to the environment in which the Data/ML task is carried out. For example, where perform code quality analysis and how to carry out rudimentary code quality analysis in that environment, where to manage modeling activities, and how to carry out common model management tasks in that environment? (
&lt;a href="https://read.readwise.io/read/01gs3nphjm8n4b8yanscgr3tvk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>The intrinsic cognitive relates to fundamental skills in a stream-aligned ML team and should be handled through hiring, training, pair/mob programming, hackathon, etc. The reduction efforts of such loads should be driven by engineering/data science/analyst managers. The germane cognitive load relates to advanced tasks in a stream-aligned team and can be reduced through sufficient opportunity to work on such problems and review support by experts. However, extraneous cognitive load relates to routine superfluous MLOps tasks that add little value in retaining working memory. Most of these relate to platform management. (
&lt;a href="https://read.readwise.io/read/01gs3nq4qjanzd83fq24vm6s6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Common ML platform activities are as follows:
&lt;ol>
&lt;li>Data/ML Exploration: Explore data access/wrangling, ML methods, visualization, …&lt;/li>
&lt;li>Code Management: source code editing, version control, continuous code quality evaluation, continuous code release, …&lt;/li>
&lt;li>Data/Feature Management: data pipeline orchestration, data snapshotting, feature, …&lt;/li>
&lt;li>Model Management: ML pipeline orchestration, track experiments, handle model lifecycle, model serving, …&lt;/li>
&lt;li>Reporting: dashboards, error logging, monitoring, … (
&lt;a href="https://read.readwise.io/read/01gs3nqeaksg7z2kz37zsv9zy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Misbah Uddin]]
title: &amp;ldquo;Platform Products for Machine Learning&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="platform-products-for-machine-learning-3">Platform Products for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*1xkIr2hO0p-ogdDEfpIsrg.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Platform Products for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: # Why ML Platform teams
ML stream aligned teams (those facing ML projects for end users) cognitive load might be reduced if superflous MLOps tasks are managed by the ML platform. The lesser the team needs to think about Ops the more the team can take on solving high value-added questions.
&lt;h1 id="what-ml-platform-products-3">What ML Platform products&lt;/h1>
&lt;ol>
&lt;li>Data/ML exploration:&lt;/li>
&lt;li>Code management&lt;/li>
&lt;li>Data/feature management&lt;/li>
&lt;li>Model management&lt;/li>
&lt;li>Reporting:&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2" rel="noopener">https://towardsdatascience.com/platform-products-for-machine-learning-3d3749443d2&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>or an ML team, there can be three types of cognitive load, as adapted from
&lt;a href="https://12devsofxmas.co.uk/2015/12/day-3-managing-cognitive-load-for-team-learning/" rel="noopener">Managing cognitive load for team learning&lt;/a>.
&lt;ol>
&lt;li>&lt;em>Intrinsic:&lt;/em> relates to fundamental Data/ML tasks, such as, how to write Spark transformations, formulate ML pipeline, etc.&lt;/li>
&lt;li>&lt;em>Germane:&lt;/em> relates to complex Data/ML tasks that require special attention, such as, how to prepare features for a specific operational use, how to interpret a model performance before/during/after its usage?&lt;/li>
&lt;li>&lt;em>Extraneous&lt;/em>: relates to the environment in which the Data/ML task is carried out. For example, where perform code quality analysis and how to carry out rudimentary code quality analysis in that environment, where to manage modeling activities, and how to carry out common model management tasks in that environment? (
&lt;a href="https://read.readwise.io/read/01gs3nphjm8n4b8yanscgr3tvk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>The intrinsic cognitive relates to fundamental skills in a stream-aligned ML team and should be handled through hiring, training, pair/mob programming, hackathon, etc. The reduction efforts of such loads should be driven by engineering/data science/analyst managers. The germane cognitive load relates to advanced tasks in a stream-aligned team and can be reduced through sufficient opportunity to work on such problems and review support by experts. However, extraneous cognitive load relates to routine superfluous MLOps tasks that add little value in retaining working memory. Most of these relate to platform management. (
&lt;a href="https://read.readwise.io/read/01gs3nq4qjanzd83fq24vm6s6h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Common ML platform activities are as follows:
&lt;ol>
&lt;li>Data/ML Exploration: Explore data access/wrangling, ML methods, visualization, …&lt;/li>
&lt;li>Code Management: source code editing, version control, continuous code quality evaluation, continuous code release, …&lt;/li>
&lt;li>Data/Feature Management: data pipeline orchestration, data snapshotting, feature, …&lt;/li>
&lt;li>Model Management: ML pipeline orchestration, track experiments, handle model lifecycle, model serving, …&lt;/li>
&lt;li>Reporting: dashboards, error logging, monitoring, … (
&lt;a href="https://read.readwise.io/read/01gs3nqeaksg7z2kz37zsv9zy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul></description></item><item><title>Reminiscing: The Retreat to Comforting Work.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Reminiscing-The-Retreat-to-Comforting-Work./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Reminiscing-The-Retreat-to-Comforting-Work./</guid><description>&lt;h1 id="reminiscing-the-retreat-to-comforting-work">Reminiscing: The Retreat to Comforting Work.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Reminiscing: The Retreat to Comforting Work.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/reminiscing/" rel="noopener">https://lethain.com/reminiscing/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Once you start looking for this behavior, it is everywhere, including on your weekly calendar. Snacking isn’t necessarily bad, a certain amount gives you energy to redeploy against more impactful tasks, but you do have to be careful to avoid overindulging. (
&lt;a href="https://read.readwise.io/read/01gryhbe7wfgx4chah06d7vk7y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under pressure, most people retreat to their area of highest perceived historical impact, even if it isn’t very relevant to today’s problems. Let’s call this &lt;em>reminiscing&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryhc956jsnx2t1svzahq233" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’d be better served by addressing the cultural or skill-gaps culminating in the reliability problems instead of trying to solve it themselves (
&lt;a href="https://read.readwise.io/read/01gryhdv7zntf77mmt838ppb61" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of these examples is tightly ingrained into the person’s identity about why they’re someone successful. You can help them recognize the misalignment with today’s needs, but real progress on this issue depends on their own self-awareness. (
&lt;a href="https://read.readwise.io/read/01gryhh6xmjfgwr1qegcyhmaqf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To catch my own reminiscing, I find I really need to write out my weekly priorities, and look at the ones that keep slipping. Why am I avoiding that work, and is it more important than what I’m doing instead? If a given task slips more than two weeks, then usually I’m avoiding it, and it’s time to figure out where I’m spending time reminiscing. (
&lt;a href="https://read.readwise.io/read/01gryhjmkxwf9q1sa26m82bd50" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Reminiscing: The Retreat to Comforting Work.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="reminiscing-the-retreat-to-comforting-work-1">Reminiscing: The Retreat to Comforting Work.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Reminiscing: The Retreat to Comforting Work.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/reminiscing/" rel="noopener">https://lethain.com/reminiscing/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Once you start looking for this behavior, it is everywhere, including on your weekly calendar. Snacking isn’t necessarily bad, a certain amount gives you energy to redeploy against more impactful tasks, but you do have to be careful to avoid overindulging. (
&lt;a href="https://read.readwise.io/read/01gryhbe7wfgx4chah06d7vk7y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under pressure, most people retreat to their area of highest perceived historical impact, even if it isn’t very relevant to today’s problems. Let’s call this &lt;em>reminiscing&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryhc956jsnx2t1svzahq233" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’d be better served by addressing the cultural or skill-gaps culminating in the reliability problems instead of trying to solve it themselves (
&lt;a href="https://read.readwise.io/read/01gryhdv7zntf77mmt838ppb61" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of these examples is tightly ingrained into the person’s identity about why they’re someone successful. You can help them recognize the misalignment with today’s needs, but real progress on this issue depends on their own self-awareness. (
&lt;a href="https://read.readwise.io/read/01gryhh6xmjfgwr1qegcyhmaqf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To catch my own reminiscing, I find I really need to write out my weekly priorities, and look at the ones that keep slipping. Why am I avoiding that work, and is it more important than what I’m doing instead? If a given task slips more than two weeks, then usually I’m avoiding it, and it’s time to figure out where I’m spending time reminiscing. (
&lt;a href="https://read.readwise.io/read/01gryhjmkxwf9q1sa26m82bd50" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Reminiscing: The Retreat to Comforting Work.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="reminiscing-the-retreat-to-comforting-work-2">Reminiscing: The Retreat to Comforting Work.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Reminiscing: The Retreat to Comforting Work.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/reminiscing/" rel="noopener">https://lethain.com/reminiscing/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Once you start looking for this behavior, it is everywhere, including on your weekly calendar. Snacking isn’t necessarily bad, a certain amount gives you energy to redeploy against more impactful tasks, but you do have to be careful to avoid overindulging. (
&lt;a href="https://read.readwise.io/read/01gryhbe7wfgx4chah06d7vk7y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under pressure, most people retreat to their area of highest perceived historical impact, even if it isn’t very relevant to today’s problems. Let’s call this &lt;em>reminiscing&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryhc956jsnx2t1svzahq233" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’d be better served by addressing the cultural or skill-gaps culminating in the reliability problems instead of trying to solve it themselves (
&lt;a href="https://read.readwise.io/read/01gryhdv7zntf77mmt838ppb61" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of these examples is tightly ingrained into the person’s identity about why they’re someone successful. You can help them recognize the misalignment with today’s needs, but real progress on this issue depends on their own self-awareness. (
&lt;a href="https://read.readwise.io/read/01gryhh6xmjfgwr1qegcyhmaqf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To catch my own reminiscing, I find I really need to write out my weekly priorities, and look at the ones that keep slipping. Why am I avoiding that work, and is it more important than what I’m doing instead? If a given task slips more than two weeks, then usually I’m avoiding it, and it’s time to figure out where I’m spending time reminiscing. (
&lt;a href="https://read.readwise.io/read/01gryhjmkxwf9q1sa26m82bd50" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Reminiscing: The Retreat to Comforting Work.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="reminiscing-the-retreat-to-comforting-work-3">Reminiscing: The Retreat to Comforting Work.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Reminiscing: The Retreat to Comforting Work.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/reminiscing/" rel="noopener">https://lethain.com/reminiscing/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Once you start looking for this behavior, it is everywhere, including on your weekly calendar. Snacking isn’t necessarily bad, a certain amount gives you energy to redeploy against more impactful tasks, but you do have to be careful to avoid overindulging. (
&lt;a href="https://read.readwise.io/read/01gryhbe7wfgx4chah06d7vk7y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under pressure, most people retreat to their area of highest perceived historical impact, even if it isn’t very relevant to today’s problems. Let’s call this &lt;em>reminiscing&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gryhc956jsnx2t1svzahq233" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>They’d be better served by addressing the cultural or skill-gaps culminating in the reliability problems instead of trying to solve it themselves (
&lt;a href="https://read.readwise.io/read/01gryhdv7zntf77mmt838ppb61" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of these examples is tightly ingrained into the person’s identity about why they’re someone successful. You can help them recognize the misalignment with today’s needs, but real progress on this issue depends on their own self-awareness. (
&lt;a href="https://read.readwise.io/read/01gryhh6xmjfgwr1qegcyhmaqf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>To catch my own reminiscing, I find I really need to write out my weekly priorities, and look at the ones that keep slipping. Why am I avoiding that work, and is it more important than what I’m doing instead? If a given task slips more than two weeks, then usually I’m avoiding it, and it’s time to figure out where I’m spending time reminiscing. (
&lt;a href="https://read.readwise.io/read/01gryhjmkxwf9q1sa26m82bd50" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Run Your Data Team Like a Product Team</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Run-Your-Data-Team-Like-a-Product-Team/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Run-Your-Data-Team-Like-a-Product-Team/</guid><description>&lt;h1 id="run-your-data-team-like-a-product-team">Run Your Data Team Like a Product Team&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/04/Image-from-iOS-1024x791.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emilie Schario and Taylor A. Murphy, PhD]]&lt;/li>
&lt;li>Full Title: Run Your Data Team Like a Product Team&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note:
Q: What is the Data Product?
A: The Data Product is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization.
Q: How should a Data Team be funded?
A: A Data Team can be funded directly by the company or by the departments who are supported by the Data Team. Explaining the ROI to business partners can be a useful tool in securing funding.&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/" rel="noopener">https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data teams aim to help the people in their organization make better decisions. Many data teams aren’t doing this as well as they could and are missing out on a huge opportunity, both for the organization and the team. This gap is due to teams not being set up for success, which undermines trust in the data and the insights the team generates (
&lt;a href="https://read.readwise.io/read/01gqcqp282z1gj2jb4nbn69vxd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Service-oriented data teams aren’t effective
Most data teams aren’t set up for success. For many years, data teams have been buried in the IT function. Like IT functions, those data teams handled getting data out of their systems and presenting them to the stakeholder as CSVs from which the stakeholders could work their magic and come up with conclusions (
&lt;a href="https://read.readwise.io/read/01gqcqps1727gmvdb2ma0d0czt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>submit a ticket with a question, get a very specific answer” mindset. Data folks who are bound to this model rarely spend time being proactive. (
&lt;a href="https://read.readwise.io/read/01gqcqqkr1c7enbtf41w36wppt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you view your colleagues as your customer and the Data Team as building and supporting a Data Product, then you’re able to unlock the opportunity of your data and data team (
&lt;a href="https://read.readwise.io/read/01gqcqvf58bfsfsf36wn21a44m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So what is the Data Product? It is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization. (
&lt;a href="https://read.readwise.io/read/01gqcqvtp6neas9fmjns3r14wp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Every internal tool or app that gives people the ability to generate, access, and analyze data is also a part of the Data Product. These can be thought of as “features” of the Data Product. A simple heuristic is this: if people are using it to make decisions, then it’s a feature of the Data Product (
&lt;a href="https://read.readwise.io/read/01gqcqwgyj0m82an06bbxf0sd0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The data and associated features have limited meaning and value within their own silo, but
&lt;a href="https://about.gitlab.com/blog/2019/11/04/three-levels-data-analysis/" rel="noopener">when integrated together within the Data Product&lt;/a>, then superlinear value can be revealed. With this mindset, the data team’s role grows to include building and guiding the strategy and features of the Data Product. And because you’re building a product, you can take all of the best practices of product-led organizations to dramatically increase the value of the Data Team to the organization (
&lt;a href="https://read.readwise.io/read/01gqcsh46ajze5btzeq2w5js1n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When moving your Data Team to the product model, you should expect some pushback from other people in the organization. As a leader you must have strong 2-way communication. This will require a great deal of empathy as you’ll have to constantly balance the need to share your vision and goals with the need to integrate the feedback from your users (colleagues). (
&lt;a href="https://read.readwise.io/read/01gqcsq5yzjg6zd5jtp6q4df3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>continually communicate what you’re working on, what you’re &lt;em>not&lt;/em> working on, and why you’ve made these decisions in order to bring your stakeholders along on the journey. (
&lt;a href="https://read.readwise.io/read/01gqcsqjjf4ha314km286726sf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Tip:&lt;/strong> Communicate with your colleagues (users) proactively and hear their feedback (
&lt;a href="https://read.readwise.io/read/01gqcsqv3dpt61f7vt8h3ch12m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s the business impact of the work that the Data Team produces that matters, which can be difficult to measure. If you have a strong foundation of 2-way communication, it is worthwhile to align with your stakeholders on what that measurement looks like to them; for example, what KPIs is your team supporting and how are your initiatives supporting them. (
&lt;a href="https://read.readwise.io/read/01gqctsvj8mmb0x8549bxnxymz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Write this definition in a team handbook and visit it frequently. Build a culture of continuous documentation so you’re regularly aligning with your business stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqctt4nwk88f3763vb8y9xr2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With a strong user focus, 2-way communication, and a solid definition of success, you can start to drive business impact through better decisions by using many of the tactics of product management. (
&lt;a href="https://read.readwise.io/read/01gqcttmg25rzysns1gsh7txq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>user stories and other tactics should be deployed in such a way that you and your Data Team are focused on deeply understanding what your colleagues are trying to do. When you understand their needs and what solutions are possible, then you’ll be able to match the problem with the right solution more effectively than the requester imagined, thereby building something that will scale and have long term value. (
&lt;a href="https://read.readwise.io/read/01gqctw59qjck40vxaz0f13sgc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company is forward thinking, they’ll pay for the Data team directly. You can also experiment with data funding coming from the departments who are supported by the Data team. Explain to your business partners what folks on your team do to support them and what it would take for them to get (
&lt;a href="https://read.readwise.io/read/01gqcvp32yp3yc3kybjefz3s4r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Start identifying and documenting the different parts of your Data Product. This can be an excellent opportunity to talk to many different stakeholders across the company. (
&lt;a href="https://read.readwise.io/read/01gqcvq9barwfbys41cbyywk23" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Emilie Schario and Taylor A. Murphy, PhD]]
title: &amp;ldquo;Run Your Data Team Like a Product Team&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="run-your-data-team-like-a-product-team-1">Run Your Data Team Like a Product Team&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/04/Image-from-iOS-1024x791.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emilie Schario and Taylor A. Murphy, PhD]]&lt;/li>
&lt;li>Full Title: Run Your Data Team Like a Product Team&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note:
Q: What is the Data Product?
A: The Data Product is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization.
Q: How should a Data Team be funded?
A: A Data Team can be funded directly by the company or by the departments who are supported by the Data Team. Explaining the ROI to business partners can be a useful tool in securing funding.&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/" rel="noopener">https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data teams aim to help the people in their organization make better decisions. Many data teams aren’t doing this as well as they could and are missing out on a huge opportunity, both for the organization and the team. This gap is due to teams not being set up for success, which undermines trust in the data and the insights the team generates (
&lt;a href="https://read.readwise.io/read/01gqcqp282z1gj2jb4nbn69vxd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Service-oriented data teams aren’t effective
Most data teams aren’t set up for success. For many years, data teams have been buried in the IT function. Like IT functions, those data teams handled getting data out of their systems and presenting them to the stakeholder as CSVs from which the stakeholders could work their magic and come up with conclusions (
&lt;a href="https://read.readwise.io/read/01gqcqps1727gmvdb2ma0d0czt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>submit a ticket with a question, get a very specific answer” mindset. Data folks who are bound to this model rarely spend time being proactive. (
&lt;a href="https://read.readwise.io/read/01gqcqqkr1c7enbtf41w36wppt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you view your colleagues as your customer and the Data Team as building and supporting a Data Product, then you’re able to unlock the opportunity of your data and data team (
&lt;a href="https://read.readwise.io/read/01gqcqvf58bfsfsf36wn21a44m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So what is the Data Product? It is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization. (
&lt;a href="https://read.readwise.io/read/01gqcqvtp6neas9fmjns3r14wp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Every internal tool or app that gives people the ability to generate, access, and analyze data is also a part of the Data Product. These can be thought of as “features” of the Data Product. A simple heuristic is this: if people are using it to make decisions, then it’s a feature of the Data Product (
&lt;a href="https://read.readwise.io/read/01gqcqwgyj0m82an06bbxf0sd0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The data and associated features have limited meaning and value within their own silo, but
&lt;a href="https://about.gitlab.com/blog/2019/11/04/three-levels-data-analysis/" rel="noopener">when integrated together within the Data Product&lt;/a>, then superlinear value can be revealed. With this mindset, the data team’s role grows to include building and guiding the strategy and features of the Data Product. And because you’re building a product, you can take all of the best practices of product-led organizations to dramatically increase the value of the Data Team to the organization (
&lt;a href="https://read.readwise.io/read/01gqcsh46ajze5btzeq2w5js1n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When moving your Data Team to the product model, you should expect some pushback from other people in the organization. As a leader you must have strong 2-way communication. This will require a great deal of empathy as you’ll have to constantly balance the need to share your vision and goals with the need to integrate the feedback from your users (colleagues). (
&lt;a href="https://read.readwise.io/read/01gqcsq5yzjg6zd5jtp6q4df3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>continually communicate what you’re working on, what you’re &lt;em>not&lt;/em> working on, and why you’ve made these decisions in order to bring your stakeholders along on the journey. (
&lt;a href="https://read.readwise.io/read/01gqcsqjjf4ha314km286726sf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Tip:&lt;/strong> Communicate with your colleagues (users) proactively and hear their feedback (
&lt;a href="https://read.readwise.io/read/01gqcsqv3dpt61f7vt8h3ch12m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s the business impact of the work that the Data Team produces that matters, which can be difficult to measure. If you have a strong foundation of 2-way communication, it is worthwhile to align with your stakeholders on what that measurement looks like to them; for example, what KPIs is your team supporting and how are your initiatives supporting them. (
&lt;a href="https://read.readwise.io/read/01gqctsvj8mmb0x8549bxnxymz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Write this definition in a team handbook and visit it frequently. Build a culture of continuous documentation so you’re regularly aligning with your business stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqctt4nwk88f3763vb8y9xr2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With a strong user focus, 2-way communication, and a solid definition of success, you can start to drive business impact through better decisions by using many of the tactics of product management. (
&lt;a href="https://read.readwise.io/read/01gqcttmg25rzysns1gsh7txq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>user stories and other tactics should be deployed in such a way that you and your Data Team are focused on deeply understanding what your colleagues are trying to do. When you understand their needs and what solutions are possible, then you’ll be able to match the problem with the right solution more effectively than the requester imagined, thereby building something that will scale and have long term value. (
&lt;a href="https://read.readwise.io/read/01gqctw59qjck40vxaz0f13sgc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company is forward thinking, they’ll pay for the Data team directly. You can also experiment with data funding coming from the departments who are supported by the Data team. Explain to your business partners what folks on your team do to support them and what it would take for them to get (
&lt;a href="https://read.readwise.io/read/01gqcvp32yp3yc3kybjefz3s4r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Start identifying and documenting the different parts of your Data Product. This can be an excellent opportunity to talk to many different stakeholders across the company. (
&lt;a href="https://read.readwise.io/read/01gqcvq9barwfbys41cbyywk23" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Emilie Schario and Taylor A. Murphy, PhD]]
title: &amp;ldquo;Run Your Data Team Like a Product Team&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="run-your-data-team-like-a-product-team-2">Run Your Data Team Like a Product Team&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/04/Image-from-iOS-1024x791.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emilie Schario and Taylor A. Murphy, PhD]]&lt;/li>
&lt;li>Full Title: Run Your Data Team Like a Product Team&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note:
Q: What is the Data Product?
A: The Data Product is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization.
Q: How should a Data Team be funded?
A: A Data Team can be funded directly by the company or by the departments who are supported by the Data Team. Explaining the ROI to business partners can be a useful tool in securing funding.&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/" rel="noopener">https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data teams aim to help the people in their organization make better decisions. Many data teams aren’t doing this as well as they could and are missing out on a huge opportunity, both for the organization and the team. This gap is due to teams not being set up for success, which undermines trust in the data and the insights the team generates (
&lt;a href="https://read.readwise.io/read/01gqcqp282z1gj2jb4nbn69vxd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Service-oriented data teams aren’t effective
Most data teams aren’t set up for success. For many years, data teams have been buried in the IT function. Like IT functions, those data teams handled getting data out of their systems and presenting them to the stakeholder as CSVs from which the stakeholders could work their magic and come up with conclusions (
&lt;a href="https://read.readwise.io/read/01gqcqps1727gmvdb2ma0d0czt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>submit a ticket with a question, get a very specific answer” mindset. Data folks who are bound to this model rarely spend time being proactive. (
&lt;a href="https://read.readwise.io/read/01gqcqqkr1c7enbtf41w36wppt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you view your colleagues as your customer and the Data Team as building and supporting a Data Product, then you’re able to unlock the opportunity of your data and data team (
&lt;a href="https://read.readwise.io/read/01gqcqvf58bfsfsf36wn21a44m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So what is the Data Product? It is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization. (
&lt;a href="https://read.readwise.io/read/01gqcqvtp6neas9fmjns3r14wp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Every internal tool or app that gives people the ability to generate, access, and analyze data is also a part of the Data Product. These can be thought of as “features” of the Data Product. A simple heuristic is this: if people are using it to make decisions, then it’s a feature of the Data Product (
&lt;a href="https://read.readwise.io/read/01gqcqwgyj0m82an06bbxf0sd0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The data and associated features have limited meaning and value within their own silo, but
&lt;a href="https://about.gitlab.com/blog/2019/11/04/three-levels-data-analysis/" rel="noopener">when integrated together within the Data Product&lt;/a>, then superlinear value can be revealed. With this mindset, the data team’s role grows to include building and guiding the strategy and features of the Data Product. And because you’re building a product, you can take all of the best practices of product-led organizations to dramatically increase the value of the Data Team to the organization (
&lt;a href="https://read.readwise.io/read/01gqcsh46ajze5btzeq2w5js1n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When moving your Data Team to the product model, you should expect some pushback from other people in the organization. As a leader you must have strong 2-way communication. This will require a great deal of empathy as you’ll have to constantly balance the need to share your vision and goals with the need to integrate the feedback from your users (colleagues). (
&lt;a href="https://read.readwise.io/read/01gqcsq5yzjg6zd5jtp6q4df3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>continually communicate what you’re working on, what you’re &lt;em>not&lt;/em> working on, and why you’ve made these decisions in order to bring your stakeholders along on the journey. (
&lt;a href="https://read.readwise.io/read/01gqcsqjjf4ha314km286726sf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Tip:&lt;/strong> Communicate with your colleagues (users) proactively and hear their feedback (
&lt;a href="https://read.readwise.io/read/01gqcsqv3dpt61f7vt8h3ch12m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s the business impact of the work that the Data Team produces that matters, which can be difficult to measure. If you have a strong foundation of 2-way communication, it is worthwhile to align with your stakeholders on what that measurement looks like to them; for example, what KPIs is your team supporting and how are your initiatives supporting them. (
&lt;a href="https://read.readwise.io/read/01gqctsvj8mmb0x8549bxnxymz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Write this definition in a team handbook and visit it frequently. Build a culture of continuous documentation so you’re regularly aligning with your business stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqctt4nwk88f3763vb8y9xr2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With a strong user focus, 2-way communication, and a solid definition of success, you can start to drive business impact through better decisions by using many of the tactics of product management. (
&lt;a href="https://read.readwise.io/read/01gqcttmg25rzysns1gsh7txq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>user stories and other tactics should be deployed in such a way that you and your Data Team are focused on deeply understanding what your colleagues are trying to do. When you understand their needs and what solutions are possible, then you’ll be able to match the problem with the right solution more effectively than the requester imagined, thereby building something that will scale and have long term value. (
&lt;a href="https://read.readwise.io/read/01gqctw59qjck40vxaz0f13sgc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company is forward thinking, they’ll pay for the Data team directly. You can also experiment with data funding coming from the departments who are supported by the Data team. Explain to your business partners what folks on your team do to support them and what it would take for them to get (
&lt;a href="https://read.readwise.io/read/01gqcvp32yp3yc3kybjefz3s4r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Start identifying and documenting the different parts of your Data Product. This can be an excellent opportunity to talk to many different stakeholders across the company. (
&lt;a href="https://read.readwise.io/read/01gqcvq9barwfbys41cbyywk23" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Emilie Schario and Taylor A. Murphy, PhD]]
title: &amp;ldquo;Run Your Data Team Like a Product Team&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="run-your-data-team-like-a-product-team-3">Run Your Data Team Like a Product Team&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/04/Image-from-iOS-1024x791.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emilie Schario and Taylor A. Murphy, PhD]]&lt;/li>
&lt;li>Full Title: Run Your Data Team Like a Product Team&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note:
Q: What is the Data Product?
A: The Data Product is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization.
Q: How should a Data Team be funded?
A: A Data Team can be funded directly by the company or by the departments who are supported by the Data Team. Explaining the ROI to business partners can be a useful tool in securing funding.&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/" rel="noopener">https://locallyoptimistic.com/post/run-your-data-team-like-a-product-team/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Data teams aim to help the people in their organization make better decisions. Many data teams aren’t doing this as well as they could and are missing out on a huge opportunity, both for the organization and the team. This gap is due to teams not being set up for success, which undermines trust in the data and the insights the team generates (
&lt;a href="https://read.readwise.io/read/01gqcqp282z1gj2jb4nbn69vxd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Service-oriented data teams aren’t effective
Most data teams aren’t set up for success. For many years, data teams have been buried in the IT function. Like IT functions, those data teams handled getting data out of their systems and presenting them to the stakeholder as CSVs from which the stakeholders could work their magic and come up with conclusions (
&lt;a href="https://read.readwise.io/read/01gqcqps1727gmvdb2ma0d0czt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>submit a ticket with a question, get a very specific answer” mindset. Data folks who are bound to this model rarely spend time being proactive. (
&lt;a href="https://read.readwise.io/read/01gqcqqkr1c7enbtf41w36wppt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When you view your colleagues as your customer and the Data Team as building and supporting a Data Product, then you’re able to unlock the opportunity of your data and data team (
&lt;a href="https://read.readwise.io/read/01gqcqvf58bfsfsf36wn21a44m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So what is the Data Product? It is the collection of every piece of data, and the tools used to generate, access, and analyze that data, within an organization. (
&lt;a href="https://read.readwise.io/read/01gqcqvtp6neas9fmjns3r14wp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Every internal tool or app that gives people the ability to generate, access, and analyze data is also a part of the Data Product. These can be thought of as “features” of the Data Product. A simple heuristic is this: if people are using it to make decisions, then it’s a feature of the Data Product (
&lt;a href="https://read.readwise.io/read/01gqcqwgyj0m82an06bbxf0sd0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The data and associated features have limited meaning and value within their own silo, but
&lt;a href="https://about.gitlab.com/blog/2019/11/04/three-levels-data-analysis/" rel="noopener">when integrated together within the Data Product&lt;/a>, then superlinear value can be revealed. With this mindset, the data team’s role grows to include building and guiding the strategy and features of the Data Product. And because you’re building a product, you can take all of the best practices of product-led organizations to dramatically increase the value of the Data Team to the organization (
&lt;a href="https://read.readwise.io/read/01gqcsh46ajze5btzeq2w5js1n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When moving your Data Team to the product model, you should expect some pushback from other people in the organization. As a leader you must have strong 2-way communication. This will require a great deal of empathy as you’ll have to constantly balance the need to share your vision and goals with the need to integrate the feedback from your users (colleagues). (
&lt;a href="https://read.readwise.io/read/01gqcsq5yzjg6zd5jtp6q4df3w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>continually communicate what you’re working on, what you’re &lt;em>not&lt;/em> working on, and why you’ve made these decisions in order to bring your stakeholders along on the journey. (
&lt;a href="https://read.readwise.io/read/01gqcsqjjf4ha314km286726sf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Tip:&lt;/strong> Communicate with your colleagues (users) proactively and hear their feedback (
&lt;a href="https://read.readwise.io/read/01gqcsqv3dpt61f7vt8h3ch12m" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s the business impact of the work that the Data Team produces that matters, which can be difficult to measure. If you have a strong foundation of 2-way communication, it is worthwhile to align with your stakeholders on what that measurement looks like to them; for example, what KPIs is your team supporting and how are your initiatives supporting them. (
&lt;a href="https://read.readwise.io/read/01gqctsvj8mmb0x8549bxnxymz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Write this definition in a team handbook and visit it frequently. Build a culture of continuous documentation so you’re regularly aligning with your business stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqctt4nwk88f3763vb8y9xr2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>With a strong user focus, 2-way communication, and a solid definition of success, you can start to drive business impact through better decisions by using many of the tactics of product management. (
&lt;a href="https://read.readwise.io/read/01gqcttmg25rzysns1gsh7txq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>user stories and other tactics should be deployed in such a way that you and your Data Team are focused on deeply understanding what your colleagues are trying to do. When you understand their needs and what solutions are possible, then you’ll be able to match the problem with the right solution more effectively than the requester imagined, thereby building something that will scale and have long term value. (
&lt;a href="https://read.readwise.io/read/01gqctw59qjck40vxaz0f13sgc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If your company is forward thinking, they’ll pay for the Data team directly. You can also experiment with data funding coming from the departments who are supported by the Data team. Explain to your business partners what folks on your team do to support them and what it would take for them to get (
&lt;a href="https://read.readwise.io/read/01gqcvp32yp3yc3kybjefz3s4r" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Start identifying and documenting the different parts of your Data Product. This can be an excellent opportunity to talk to many different stakeholders across the company. (
&lt;a href="https://read.readwise.io/read/01gqcvq9barwfbys41cbyywk23" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Running an Engineering Reorg</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Running-an-Engineering-Reorg/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Running-an-Engineering-Reorg/</guid><description>&lt;h1 id="running-an-engineering-reorg">Running an Engineering Reorg&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/heroes/reorg-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Running an Engineering Reorg&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">https://lethain.com/running-an-engineering-reorg/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>At
&lt;a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/" rel="noopener">quickly growing companies&lt;/a>, I believe there are two managerial skills that have a disproportionate impact on your organization’s success: making technical migrations cheap, and running clean reorganizations (
&lt;a href="https://read.readwise.io/read/01grvxs79ppwv9mscqjdfg5tnp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>managing organizational change is more general so let’s work through a lightly structured framework for (re)designing an engineering organization. (
&lt;a href="https://read.readwise.io/read/01grvxsqgttgckjkssg4f7rz69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Is the problem structural? The opportunities of organization change are to increase communication, reduce decision friction, and focus attention; if you’re looking for a different change, consider a bit if there’s a more direct approach. (
&lt;a href="https://read.readwise.io/read/01grw1r3xp3thjdaj9qxerygp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put teams which work together (especially poorly) as close together as possible. This minimizes the distance for escalations during disagreements, allowing arbiters to have sufficient context, but also most poor working relationships are the byproduct of information gaps, and nothing fills them faster than proximity. (
&lt;a href="https://read.readwise.io/read/01grw1ymmnpxbam0ek45mdx6wz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you define clear interfaces for each teams? (
&lt;a href="https://read.readwise.io/read/01grw1yswbapye6kgda0ft8t8g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you list the areas of ownership for each team? (
&lt;a href="https://read.readwise.io/read/01grw1z2c93kd6erzjyxnz6jxm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final and often times most awkward phase of a reorganization is its rollout. There are three key elements to a good rollout:
&lt;ol>
&lt;li>Explanation of reasoning driving the reorganization.&lt;/li>
&lt;li>Documentation of how each person and team will be impacted.&lt;/li>
&lt;li>Availability and empathy to help bleed off frustration from impacted individuals. (
&lt;a href="https://read.readwise.io/read/01grw22658z1rkangsvemq2d77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Running an Engineering Reorg&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="running-an-engineering-reorg-1">Running an Engineering Reorg&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/heroes/reorg-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Running an Engineering Reorg&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">https://lethain.com/running-an-engineering-reorg/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>At
&lt;a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/" rel="noopener">quickly growing companies&lt;/a>, I believe there are two managerial skills that have a disproportionate impact on your organization’s success: making technical migrations cheap, and running clean reorganizations (
&lt;a href="https://read.readwise.io/read/01grvxs79ppwv9mscqjdfg5tnp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>managing organizational change is more general so let’s work through a lightly structured framework for (re)designing an engineering organization. (
&lt;a href="https://read.readwise.io/read/01grvxsqgttgckjkssg4f7rz69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Is the problem structural? The opportunities of organization change are to increase communication, reduce decision friction, and focus attention; if you’re looking for a different change, consider a bit if there’s a more direct approach. (
&lt;a href="https://read.readwise.io/read/01grw1r3xp3thjdaj9qxerygp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put teams which work together (especially poorly) as close together as possible. This minimizes the distance for escalations during disagreements, allowing arbiters to have sufficient context, but also most poor working relationships are the byproduct of information gaps, and nothing fills them faster than proximity. (
&lt;a href="https://read.readwise.io/read/01grw1ymmnpxbam0ek45mdx6wz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you define clear interfaces for each teams? (
&lt;a href="https://read.readwise.io/read/01grw1yswbapye6kgda0ft8t8g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you list the areas of ownership for each team? (
&lt;a href="https://read.readwise.io/read/01grw1z2c93kd6erzjyxnz6jxm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final and often times most awkward phase of a reorganization is its rollout. There are three key elements to a good rollout:
&lt;ol>
&lt;li>Explanation of reasoning driving the reorganization.&lt;/li>
&lt;li>Documentation of how each person and team will be impacted.&lt;/li>
&lt;li>Availability and empathy to help bleed off frustration from impacted individuals. (
&lt;a href="https://read.readwise.io/read/01grw22658z1rkangsvemq2d77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Running an Engineering Reorg&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="running-an-engineering-reorg-2">Running an Engineering Reorg&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/heroes/reorg-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Running an Engineering Reorg&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">https://lethain.com/running-an-engineering-reorg/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>At
&lt;a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/" rel="noopener">quickly growing companies&lt;/a>, I believe there are two managerial skills that have a disproportionate impact on your organization’s success: making technical migrations cheap, and running clean reorganizations (
&lt;a href="https://read.readwise.io/read/01grvxs79ppwv9mscqjdfg5tnp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>managing organizational change is more general so let’s work through a lightly structured framework for (re)designing an engineering organization. (
&lt;a href="https://read.readwise.io/read/01grvxsqgttgckjkssg4f7rz69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Is the problem structural? The opportunities of organization change are to increase communication, reduce decision friction, and focus attention; if you’re looking for a different change, consider a bit if there’s a more direct approach. (
&lt;a href="https://read.readwise.io/read/01grw1r3xp3thjdaj9qxerygp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put teams which work together (especially poorly) as close together as possible. This minimizes the distance for escalations during disagreements, allowing arbiters to have sufficient context, but also most poor working relationships are the byproduct of information gaps, and nothing fills them faster than proximity. (
&lt;a href="https://read.readwise.io/read/01grw1ymmnpxbam0ek45mdx6wz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you define clear interfaces for each teams? (
&lt;a href="https://read.readwise.io/read/01grw1yswbapye6kgda0ft8t8g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you list the areas of ownership for each team? (
&lt;a href="https://read.readwise.io/read/01grw1z2c93kd6erzjyxnz6jxm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final and often times most awkward phase of a reorganization is its rollout. There are three key elements to a good rollout:
&lt;ol>
&lt;li>Explanation of reasoning driving the reorganization.&lt;/li>
&lt;li>Documentation of how each person and team will be impacted.&lt;/li>
&lt;li>Availability and empathy to help bleed off frustration from impacted individuals. (
&lt;a href="https://read.readwise.io/read/01grw22658z1rkangsvemq2d77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Running an Engineering Reorg&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="running-an-engineering-reorg-3">Running an Engineering Reorg&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/heroes/reorg-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Running an Engineering Reorg&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">https://lethain.com/running-an-engineering-reorg/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>At
&lt;a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/" rel="noopener">quickly growing companies&lt;/a>, I believe there are two managerial skills that have a disproportionate impact on your organization’s success: making technical migrations cheap, and running clean reorganizations (
&lt;a href="https://read.readwise.io/read/01grvxs79ppwv9mscqjdfg5tnp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>managing organizational change is more general so let’s work through a lightly structured framework for (re)designing an engineering organization. (
&lt;a href="https://read.readwise.io/read/01grvxsqgttgckjkssg4f7rz69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Is the problem structural? The opportunities of organization change are to increase communication, reduce decision friction, and focus attention; if you’re looking for a different change, consider a bit if there’s a more direct approach. (
&lt;a href="https://read.readwise.io/read/01grw1r3xp3thjdaj9qxerygp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put teams which work together (especially poorly) as close together as possible. This minimizes the distance for escalations during disagreements, allowing arbiters to have sufficient context, but also most poor working relationships are the byproduct of information gaps, and nothing fills them faster than proximity. (
&lt;a href="https://read.readwise.io/read/01grw1ymmnpxbam0ek45mdx6wz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you define clear interfaces for each teams? (
&lt;a href="https://read.readwise.io/read/01grw1yswbapye6kgda0ft8t8g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Can you list the areas of ownership for each team? (
&lt;a href="https://read.readwise.io/read/01grw1z2c93kd6erzjyxnz6jxm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The final and often times most awkward phase of a reorganization is its rollout. There are three key elements to a good rollout:
&lt;ol>
&lt;li>Explanation of reasoning driving the reorganization.&lt;/li>
&lt;li>Documentation of how each person and team will be impacted.&lt;/li>
&lt;li>Availability and empathy to help bleed off frustration from impacted individuals. (
&lt;a href="https://read.readwise.io/read/01grw22658z1rkangsvemq2d77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul></description></item><item><title>Setting Engineering Org Values.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Setting-Engineering-Org-Values./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Setting-Engineering-Org-Values./</guid><description>&lt;h1 id="setting-engineering-org-values">Setting Engineering Org Values.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Setting Engineering Org Values.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14576/web" rel="noopener">https://techleaddigest.net/link/14576/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Stated values possess no magic for cultural transformation, but with a bit of care they can be useful for consolidating cultural change that you’ve already made. (
&lt;a href="https://read.readwise.io/read/01grpz02g2zs3cv0wfv87x0ch5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stated values make it clear how you want people to make decisions. If senior team members live and role model the values, then those values will become an active, living artifact. If stated values don’t align, then they’ll become a frequently forgotten, running joke. (
&lt;a href="https://read.readwise.io/read/01grpz11mc14c3yca3c7njcyp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Documented values increase cohesion across the new and existing team. They also avoid the scenario where new hires unknowingly practice their previous companies’ values, causing a cultural rift between new and existing teams (
&lt;a href="https://read.readwise.io/read/01grpz1qkmtyj8x3a17qz6a5s1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>welcome ideas from across the team rather than only accepting top-down ideas, and you want to formalize that change so it persists over time (
&lt;a href="https://read.readwise.io/read/01grpz27qnfgg3aypnnjmtn5es" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a few vocal engineers are advocating for teams setting their own patterns independently of the organization’s existing ones. Formalizing the reuse of existing approaches when possible will prevent a prolonged conflict (
&lt;a href="https://read.readwise.io/read/01grpz305k0nm3391chyqkqmy7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You’ve acquired a very small company of five engineers to join your existing organization of five hundred engineers. You’ve been clear in the acquisition process that you’re looking for the new team to merge into the existing organization, and your documented values help them navigate that change successfully (
&lt;a href="https://read.readwise.io/read/01grpz3dz32eeazw3xdwhz9pp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding an organization-appropriate interpretation to an existing value reinforces that company value, rather than detracting from it, and is an easy sell to the wider executive team. (
&lt;a href="https://read.readwise.io/read/01grpz5q4m5c15tbwd0pqzt55w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s much more work to maintain values than to create them, and adding to the company values will allow you to share the maintenance across the executive team. If it’s not widely applicable, then you have the choice between adding either engineering organizational values or engineering leadership values. (
&lt;a href="https://read.readwise.io/read/01grpz7vd3cewc5w2cdpvv1238" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>people often have a strong internalized belief that a company should have one shared culture, you may find that introducing organization-specific values often run into a surprising amount of friction. (
&lt;a href="https://read.readwise.io/read/01grpz8qamhrf04ypf7548vw1h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In practice, almost everyone aspires to be a leader, and will model their behavior on leaders within the team, so leadership values tend to establish themselves as organizational values while side-stepping some of the tripwires that come being explicit. (
&lt;a href="https://read.readwise.io/read/01grpzb69nxke79rgh8wxmp7cx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A useful value is reversible, applicable, and honest (
&lt;a href="https://read.readwise.io/read/01grpzenpc1687ne4a7s9ynrrm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Effective values guide behavior, and it’s only practical to guide behavior when there are multiple, viable approaches. (
&lt;a href="https://read.readwise.io/read/01grpzfp56rvjz3excwn2p09kr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Many values are written down and forgotten. To keep a value alive and useful, it needs to be used frequently and visibly by the team. Applicability means a value that contributes to planning sessions, performance reviews, and hiring decisions. (
&lt;a href="https://read.readwise.io/read/01grpzhv1egnrs5v83k29ycapg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Seek feedback&lt;/em> clarifies the expectation that you should be actively seeking feedback on your work rather than working in isolation. (
&lt;a href="https://read.readwise.io/read/01grq0a4wahznr8pw2m1nd1dqm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A touch of aspiration is OK, but useful values should explain how effective employees navigate the organization as it exists today (
&lt;a href="https://read.readwise.io/read/01grq0cnrdmezt1t6jmzh92tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way for your entire team to operate on the same values is to describe behavior honestly. (If you want to change company behavior, change the behavior first, and document it second.) (
&lt;a href="https://read.readwise.io/read/01grq0da0fwjwcpwd7t32ft3x7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>While you should try to avoid useless values, as long as they’re honest, they tend to be inert rather than harmful, so I wouldn’t spend too much time fighting against, particularly them if you’re working on values as a participant (e.g. for the company) rather than as the final decider (e.g. for engineering). (
&lt;a href="https://read.readwise.io/read/01grq0nqajnkwxx6hd92g55hqb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The best way to think of the relationship between values and a strategy (business, technology, or otherwise) is that useful values generally can serve as a strategy’s guiding principle. Not all guiding principles are values (e.g. how you respond to a current market opportunity is unlikely to be a value), but most values are viable guiding principles. (
&lt;a href="https://read.readwise.io/read/01grq0pev7118dw6a0k183bhme" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Establishing values should follow
&lt;a href="https://lethain.com/good-process-is-evolved/" rel="noopener">the general patterns of good process rollout&lt;/a>: identify the opportunity, document potential options, involve stakeholders early to build buy-in, test before finalizing to avoid folks feeling trapped, and iterate until it’s useful. It’s easy to announce values, but much harder to introduce values that get used. Reduce that risk by including the wider team, listening, and iterating a few times to make them feel like a shared creation rather than a top-down one. (
&lt;a href="https://read.readwise.io/read/01grq0t978jj1tpaeqfsy3h1wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Approach conflict with curiosity.&lt;/strong> One of my foundational beliefs is that most professional conflict between reasonable people is driven by asymmetric information. If you approach conflict with curiosity, you can quickly learn the missing information and generally make the right decision without conflict. (
&lt;a href="https://read.readwise.io/read/01grq0z12s4a8fgbxyjv2f9e1f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Setting Engineering Org Values.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="setting-engineering-org-values-1">Setting Engineering Org Values.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Setting Engineering Org Values.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14576/web" rel="noopener">https://techleaddigest.net/link/14576/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Stated values possess no magic for cultural transformation, but with a bit of care they can be useful for consolidating cultural change that you’ve already made. (
&lt;a href="https://read.readwise.io/read/01grpz02g2zs3cv0wfv87x0ch5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stated values make it clear how you want people to make decisions. If senior team members live and role model the values, then those values will become an active, living artifact. If stated values don’t align, then they’ll become a frequently forgotten, running joke. (
&lt;a href="https://read.readwise.io/read/01grpz11mc14c3yca3c7njcyp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Documented values increase cohesion across the new and existing team. They also avoid the scenario where new hires unknowingly practice their previous companies’ values, causing a cultural rift between new and existing teams (
&lt;a href="https://read.readwise.io/read/01grpz1qkmtyj8x3a17qz6a5s1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>welcome ideas from across the team rather than only accepting top-down ideas, and you want to formalize that change so it persists over time (
&lt;a href="https://read.readwise.io/read/01grpz27qnfgg3aypnnjmtn5es" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a few vocal engineers are advocating for teams setting their own patterns independently of the organization’s existing ones. Formalizing the reuse of existing approaches when possible will prevent a prolonged conflict (
&lt;a href="https://read.readwise.io/read/01grpz305k0nm3391chyqkqmy7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You’ve acquired a very small company of five engineers to join your existing organization of five hundred engineers. You’ve been clear in the acquisition process that you’re looking for the new team to merge into the existing organization, and your documented values help them navigate that change successfully (
&lt;a href="https://read.readwise.io/read/01grpz3dz32eeazw3xdwhz9pp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding an organization-appropriate interpretation to an existing value reinforces that company value, rather than detracting from it, and is an easy sell to the wider executive team. (
&lt;a href="https://read.readwise.io/read/01grpz5q4m5c15tbwd0pqzt55w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s much more work to maintain values than to create them, and adding to the company values will allow you to share the maintenance across the executive team. If it’s not widely applicable, then you have the choice between adding either engineering organizational values or engineering leadership values. (
&lt;a href="https://read.readwise.io/read/01grpz7vd3cewc5w2cdpvv1238" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>people often have a strong internalized belief that a company should have one shared culture, you may find that introducing organization-specific values often run into a surprising amount of friction. (
&lt;a href="https://read.readwise.io/read/01grpz8qamhrf04ypf7548vw1h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In practice, almost everyone aspires to be a leader, and will model their behavior on leaders within the team, so leadership values tend to establish themselves as organizational values while side-stepping some of the tripwires that come being explicit. (
&lt;a href="https://read.readwise.io/read/01grpzb69nxke79rgh8wxmp7cx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A useful value is reversible, applicable, and honest (
&lt;a href="https://read.readwise.io/read/01grpzenpc1687ne4a7s9ynrrm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Effective values guide behavior, and it’s only practical to guide behavior when there are multiple, viable approaches. (
&lt;a href="https://read.readwise.io/read/01grpzfp56rvjz3excwn2p09kr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Many values are written down and forgotten. To keep a value alive and useful, it needs to be used frequently and visibly by the team. Applicability means a value that contributes to planning sessions, performance reviews, and hiring decisions. (
&lt;a href="https://read.readwise.io/read/01grpzhv1egnrs5v83k29ycapg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Seek feedback&lt;/em> clarifies the expectation that you should be actively seeking feedback on your work rather than working in isolation. (
&lt;a href="https://read.readwise.io/read/01grq0a4wahznr8pw2m1nd1dqm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A touch of aspiration is OK, but useful values should explain how effective employees navigate the organization as it exists today (
&lt;a href="https://read.readwise.io/read/01grq0cnrdmezt1t6jmzh92tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way for your entire team to operate on the same values is to describe behavior honestly. (If you want to change company behavior, change the behavior first, and document it second.) (
&lt;a href="https://read.readwise.io/read/01grq0da0fwjwcpwd7t32ft3x7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>While you should try to avoid useless values, as long as they’re honest, they tend to be inert rather than harmful, so I wouldn’t spend too much time fighting against, particularly them if you’re working on values as a participant (e.g. for the company) rather than as the final decider (e.g. for engineering). (
&lt;a href="https://read.readwise.io/read/01grq0nqajnkwxx6hd92g55hqb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The best way to think of the relationship between values and a strategy (business, technology, or otherwise) is that useful values generally can serve as a strategy’s guiding principle. Not all guiding principles are values (e.g. how you respond to a current market opportunity is unlikely to be a value), but most values are viable guiding principles. (
&lt;a href="https://read.readwise.io/read/01grq0pev7118dw6a0k183bhme" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Establishing values should follow
&lt;a href="https://lethain.com/good-process-is-evolved/" rel="noopener">the general patterns of good process rollout&lt;/a>: identify the opportunity, document potential options, involve stakeholders early to build buy-in, test before finalizing to avoid folks feeling trapped, and iterate until it’s useful. It’s easy to announce values, but much harder to introduce values that get used. Reduce that risk by including the wider team, listening, and iterating a few times to make them feel like a shared creation rather than a top-down one. (
&lt;a href="https://read.readwise.io/read/01grq0t978jj1tpaeqfsy3h1wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Approach conflict with curiosity.&lt;/strong> One of my foundational beliefs is that most professional conflict between reasonable people is driven by asymmetric information. If you approach conflict with curiosity, you can quickly learn the missing information and generally make the right decision without conflict. (
&lt;a href="https://read.readwise.io/read/01grq0z12s4a8fgbxyjv2f9e1f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Setting Engineering Org Values.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="setting-engineering-org-values-2">Setting Engineering Org Values.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Setting Engineering Org Values.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14576/web" rel="noopener">https://techleaddigest.net/link/14576/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Stated values possess no magic for cultural transformation, but with a bit of care they can be useful for consolidating cultural change that you’ve already made. (
&lt;a href="https://read.readwise.io/read/01grpz02g2zs3cv0wfv87x0ch5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stated values make it clear how you want people to make decisions. If senior team members live and role model the values, then those values will become an active, living artifact. If stated values don’t align, then they’ll become a frequently forgotten, running joke. (
&lt;a href="https://read.readwise.io/read/01grpz11mc14c3yca3c7njcyp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Documented values increase cohesion across the new and existing team. They also avoid the scenario where new hires unknowingly practice their previous companies’ values, causing a cultural rift between new and existing teams (
&lt;a href="https://read.readwise.io/read/01grpz1qkmtyj8x3a17qz6a5s1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>welcome ideas from across the team rather than only accepting top-down ideas, and you want to formalize that change so it persists over time (
&lt;a href="https://read.readwise.io/read/01grpz27qnfgg3aypnnjmtn5es" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a few vocal engineers are advocating for teams setting their own patterns independently of the organization’s existing ones. Formalizing the reuse of existing approaches when possible will prevent a prolonged conflict (
&lt;a href="https://read.readwise.io/read/01grpz305k0nm3391chyqkqmy7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You’ve acquired a very small company of five engineers to join your existing organization of five hundred engineers. You’ve been clear in the acquisition process that you’re looking for the new team to merge into the existing organization, and your documented values help them navigate that change successfully (
&lt;a href="https://read.readwise.io/read/01grpz3dz32eeazw3xdwhz9pp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding an organization-appropriate interpretation to an existing value reinforces that company value, rather than detracting from it, and is an easy sell to the wider executive team. (
&lt;a href="https://read.readwise.io/read/01grpz5q4m5c15tbwd0pqzt55w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s much more work to maintain values than to create them, and adding to the company values will allow you to share the maintenance across the executive team. If it’s not widely applicable, then you have the choice between adding either engineering organizational values or engineering leadership values. (
&lt;a href="https://read.readwise.io/read/01grpz7vd3cewc5w2cdpvv1238" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>people often have a strong internalized belief that a company should have one shared culture, you may find that introducing organization-specific values often run into a surprising amount of friction. (
&lt;a href="https://read.readwise.io/read/01grpz8qamhrf04ypf7548vw1h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In practice, almost everyone aspires to be a leader, and will model their behavior on leaders within the team, so leadership values tend to establish themselves as organizational values while side-stepping some of the tripwires that come being explicit. (
&lt;a href="https://read.readwise.io/read/01grpzb69nxke79rgh8wxmp7cx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A useful value is reversible, applicable, and honest (
&lt;a href="https://read.readwise.io/read/01grpzenpc1687ne4a7s9ynrrm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Effective values guide behavior, and it’s only practical to guide behavior when there are multiple, viable approaches. (
&lt;a href="https://read.readwise.io/read/01grpzfp56rvjz3excwn2p09kr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Many values are written down and forgotten. To keep a value alive and useful, it needs to be used frequently and visibly by the team. Applicability means a value that contributes to planning sessions, performance reviews, and hiring decisions. (
&lt;a href="https://read.readwise.io/read/01grpzhv1egnrs5v83k29ycapg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Seek feedback&lt;/em> clarifies the expectation that you should be actively seeking feedback on your work rather than working in isolation. (
&lt;a href="https://read.readwise.io/read/01grq0a4wahznr8pw2m1nd1dqm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A touch of aspiration is OK, but useful values should explain how effective employees navigate the organization as it exists today (
&lt;a href="https://read.readwise.io/read/01grq0cnrdmezt1t6jmzh92tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way for your entire team to operate on the same values is to describe behavior honestly. (If you want to change company behavior, change the behavior first, and document it second.) (
&lt;a href="https://read.readwise.io/read/01grq0da0fwjwcpwd7t32ft3x7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>While you should try to avoid useless values, as long as they’re honest, they tend to be inert rather than harmful, so I wouldn’t spend too much time fighting against, particularly them if you’re working on values as a participant (e.g. for the company) rather than as the final decider (e.g. for engineering). (
&lt;a href="https://read.readwise.io/read/01grq0nqajnkwxx6hd92g55hqb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The best way to think of the relationship between values and a strategy (business, technology, or otherwise) is that useful values generally can serve as a strategy’s guiding principle. Not all guiding principles are values (e.g. how you respond to a current market opportunity is unlikely to be a value), but most values are viable guiding principles. (
&lt;a href="https://read.readwise.io/read/01grq0pev7118dw6a0k183bhme" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Establishing values should follow
&lt;a href="https://lethain.com/good-process-is-evolved/" rel="noopener">the general patterns of good process rollout&lt;/a>: identify the opportunity, document potential options, involve stakeholders early to build buy-in, test before finalizing to avoid folks feeling trapped, and iterate until it’s useful. It’s easy to announce values, but much harder to introduce values that get used. Reduce that risk by including the wider team, listening, and iterating a few times to make them feel like a shared creation rather than a top-down one. (
&lt;a href="https://read.readwise.io/read/01grq0t978jj1tpaeqfsy3h1wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Approach conflict with curiosity.&lt;/strong> One of my foundational beliefs is that most professional conflict between reasonable people is driven by asymmetric information. If you approach conflict with curiosity, you can quickly learn the missing information and generally make the right decision without conflict. (
&lt;a href="https://read.readwise.io/read/01grq0z12s4a8fgbxyjv2f9e1f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Setting Engineering Org Values.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="setting-engineering-org-values-3">Setting Engineering Org Values.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Setting Engineering Org Values.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://techleaddigest.net/link/14576/web" rel="noopener">https://techleaddigest.net/link/14576/web&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Stated values possess no magic for cultural transformation, but with a bit of care they can be useful for consolidating cultural change that you’ve already made. (
&lt;a href="https://read.readwise.io/read/01grpz02g2zs3cv0wfv87x0ch5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Stated values make it clear how you want people to make decisions. If senior team members live and role model the values, then those values will become an active, living artifact. If stated values don’t align, then they’ll become a frequently forgotten, running joke. (
&lt;a href="https://read.readwise.io/read/01grpz11mc14c3yca3c7njcyp8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Documented values increase cohesion across the new and existing team. They also avoid the scenario where new hires unknowingly practice their previous companies’ values, causing a cultural rift between new and existing teams (
&lt;a href="https://read.readwise.io/read/01grpz1qkmtyj8x3a17qz6a5s1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>welcome ideas from across the team rather than only accepting top-down ideas, and you want to formalize that change so it persists over time (
&lt;a href="https://read.readwise.io/read/01grpz27qnfgg3aypnnjmtn5es" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a few vocal engineers are advocating for teams setting their own patterns independently of the organization’s existing ones. Formalizing the reuse of existing approaches when possible will prevent a prolonged conflict (
&lt;a href="https://read.readwise.io/read/01grpz305k0nm3391chyqkqmy7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You’ve acquired a very small company of five engineers to join your existing organization of five hundred engineers. You’ve been clear in the acquisition process that you’re looking for the new team to merge into the existing organization, and your documented values help them navigate that change successfully (
&lt;a href="https://read.readwise.io/read/01grpz3dz32eeazw3xdwhz9pp5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding an organization-appropriate interpretation to an existing value reinforces that company value, rather than detracting from it, and is an easy sell to the wider executive team. (
&lt;a href="https://read.readwise.io/read/01grpz5q4m5c15tbwd0pqzt55w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>It’s much more work to maintain values than to create them, and adding to the company values will allow you to share the maintenance across the executive team. If it’s not widely applicable, then you have the choice between adding either engineering organizational values or engineering leadership values. (
&lt;a href="https://read.readwise.io/read/01grpz7vd3cewc5w2cdpvv1238" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>people often have a strong internalized belief that a company should have one shared culture, you may find that introducing organization-specific values often run into a surprising amount of friction. (
&lt;a href="https://read.readwise.io/read/01grpz8qamhrf04ypf7548vw1h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In practice, almost everyone aspires to be a leader, and will model their behavior on leaders within the team, so leadership values tend to establish themselves as organizational values while side-stepping some of the tripwires that come being explicit. (
&lt;a href="https://read.readwise.io/read/01grpzb69nxke79rgh8wxmp7cx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A useful value is reversible, applicable, and honest (
&lt;a href="https://read.readwise.io/read/01grpzenpc1687ne4a7s9ynrrm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Effective values guide behavior, and it’s only practical to guide behavior when there are multiple, viable approaches. (
&lt;a href="https://read.readwise.io/read/01grpzfp56rvjz3excwn2p09kr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Many values are written down and forgotten. To keep a value alive and useful, it needs to be used frequently and visibly by the team. Applicability means a value that contributes to planning sessions, performance reviews, and hiring decisions. (
&lt;a href="https://read.readwise.io/read/01grpzhv1egnrs5v83k29ycapg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Seek feedback&lt;/em> clarifies the expectation that you should be actively seeking feedback on your work rather than working in isolation. (
&lt;a href="https://read.readwise.io/read/01grq0a4wahznr8pw2m1nd1dqm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A touch of aspiration is OK, but useful values should explain how effective employees navigate the organization as it exists today (
&lt;a href="https://read.readwise.io/read/01grq0cnrdmezt1t6jmzh92tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way for your entire team to operate on the same values is to describe behavior honestly. (If you want to change company behavior, change the behavior first, and document it second.) (
&lt;a href="https://read.readwise.io/read/01grq0da0fwjwcpwd7t32ft3x7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>While you should try to avoid useless values, as long as they’re honest, they tend to be inert rather than harmful, so I wouldn’t spend too much time fighting against, particularly them if you’re working on values as a participant (e.g. for the company) rather than as the final decider (e.g. for engineering). (
&lt;a href="https://read.readwise.io/read/01grq0nqajnkwxx6hd92g55hqb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The best way to think of the relationship between values and a strategy (business, technology, or otherwise) is that useful values generally can serve as a strategy’s guiding principle. Not all guiding principles are values (e.g. how you respond to a current market opportunity is unlikely to be a value), but most values are viable guiding principles. (
&lt;a href="https://read.readwise.io/read/01grq0pev7118dw6a0k183bhme" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Establishing values should follow
&lt;a href="https://lethain.com/good-process-is-evolved/" rel="noopener">the general patterns of good process rollout&lt;/a>: identify the opportunity, document potential options, involve stakeholders early to build buy-in, test before finalizing to avoid folks feeling trapped, and iterate until it’s useful. It’s easy to announce values, but much harder to introduce values that get used. Reduce that risk by including the wider team, listening, and iterating a few times to make them feel like a shared creation rather than a top-down one. (
&lt;a href="https://read.readwise.io/read/01grq0t978jj1tpaeqfsy3h1wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Approach conflict with curiosity.&lt;/strong> One of my foundational beliefs is that most professional conflict between reasonable people is driven by asymmetric information. If you approach conflict with curiosity, you can quickly learn the missing information and generally make the right decision without conflict. (
&lt;a href="https://read.readwise.io/read/01grq0z12s4a8fgbxyjv2f9e1f" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Shape-Up</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Shape-Up/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Shape-Up/</guid><description>&lt;h1 id="shape-up">Shape-Up&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[basecamp.com]]&lt;/li>
&lt;li>Full Title: Shape-Up&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://basecamp.com/shapeup/shape-up.pdf" rel="noopener">https://basecamp.com/shapeup/shape-up.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>The way a team works has an enormous influence on what it can do. The process, the methods, the practices, the approach, the discipline, the trust, the communication style, the pace. The way—the how—is foundational and fundamental. (
&lt;a href="https://read.readwise.io/read/01gre7kv9bzj0q5hqxvv3931vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>focus on “hammering” the scope to fit within a given time budget was born under these constraints. (
&lt;a href="https://read.readwise.io/read/01gre7qxyqbhgenxe8ks3kfmwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>in six-week cycles. Six weeks is long enough to build something meaningful start-to-finish and short enough that everyone can feel the deadline looming from the start, so they use the time wisely. The (
&lt;a href="https://read.readwise.io/read/01gre7vtjxpcj5agbm71xsz5wv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we shape the work before giving it to a team. A small senior group works in parallel to the cycle teams. They define the key elements of a solution before we consider a project ready to bet on. Projects are defined at the right level of abstraction: concrete enough that the teams know what to do, yet abstract enough that they have room to work out the interesting details themselves. (
&lt;a href="https://read.readwise.io/read/01gre7x4nwmdegdr9yzf7960b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>14 (
&lt;a href="https://read.readwise.io/read/01gre7xpypxzyqmwmhxznx85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>appetite. Instead of asking how much time it will take to do some work, we ask: How much time do we want to spend? How much is this idea worth? This is the task of shaping: narrowing down the problem and designing the outline of a solution that fits within the constraints of our appetite. (
&lt;a href="https://read.readwise.io/read/01gre7xrpjam85z5by8p85rvqk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we give full responsibility to a small integrated team of designers and programmers. They define their own tasks, make adjustments to the scope, and work together to build vertical slices of the product one at a time. (
&lt;a href="https://read.readwise.io/read/01gre7yr6wz7hrph5q431cx0gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When teams are more autonomous, senior people can spend less time managing them. With less time spent on management, senior people can shape up better projects. When projects are better shaped, teams have clearer boundaries and so can work more autonomously. (
&lt;a href="https://read.readwise.io/read/01gre82mjb23vtt4n78z5tqn43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step of the process we target a specific risk: the risk of not shipping on time. (
&lt;a href="https://read.readwise.io/read/01gre867pa57xb4bfg6k6wzk77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Improving your discovery process should come after regaining your ability to ship. You can have the best strategy in the world, but if you can’t act on it, what good does it do? (
&lt;a href="https://read.readwise.io/read/01gre84dt3aqyw36ghr8skxxq5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We reduce risk in the planning process by capping our bets to six weeks. If a project runs over, by default it doesn’t get an extension. This “circuit breaker” ensures that we don’t invest multiples of the original appetite on a concept that needs rethinking first. (
&lt;a href="https://read.readwise.io/read/01gre85xex8h27bxef9vdkqbm1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we reduce risk in the building process by integrating design and programming early. Instead of building lots of disconnected parts and hoping they’ll fit together in the 11th hour, we build one meaningful piece of the work end-to-end early on and then repeat. The team sequences the work from the most unknown to the least worrisome pieces and learns what works and what doesn’t by integrating as soon as possible. (
&lt;a href="https://read.readwise.io/read/01gre87cdpvsvf66xhbexzscwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we shape the work, we need to do it at the right level of abstraction: not too vague and not too concrete. Product managers often err on one of these two extremes. (
&lt;a href="https://read.readwise.io/read/01gre8fmgc1pmfgnckqvnnbkyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Over-specifying the design also leads to estimation errors. Counterintuitive as it may seem, the more specific the work is, the harder it can be to estimate. (
&lt;a href="https://read.readwise.io/read/01gre8gabx7bwh55q3cqm3dsym" rel="noopener">View Highlight&lt;/a>)
&lt;ul>
&lt;li>Note: This might be one of the major flaws of waterfall&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>When the scope isn’t variable, the team can’t reconsider a design decision that is turning out to cost more than it’s worth. (
&lt;a href="https://read.readwise.io/read/01gre8hxpzf8xrzzk6b8g5vbvw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>projects that are too vague don’t work either. When a project is defined in a few words, nobody knows what it means. (
&lt;a href="https://read.readwise.io/read/01gre8p97p4jbpkjkjcan2vjb1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Team members don’t have enough information to make trade-offs. They don’t know what to include or leave out (
&lt;a href="https://read.readwise.io/read/01gre8pqy5menm7ewnf8rc3cy8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under-specified projects naturally grow out of control because there’s no boundary to define what’s out of scope. (
&lt;a href="https://read.readwise.io/read/01gre8q1dxck6g3mf5xbd96bba" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Work in the shaping stage is rough. Everyone can tell by looking at it that it’s unfinished. They can see the open spaces where their contributions will go. Work that’s too fine, too early commits
24 (
&lt;a href="https://read.readwise.io/read/01gs082s5vnn56g601jmt1de9v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>everyone to the wrong details. Designers and programmers need room to apply their own judgement and expertise when they roll up their sleeves and discover all the real trade-offs that emerge. (
&lt;a href="https://read.readwise.io/read/01gs082vgw6h7gb6vmq3fttex1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Despite being rough and unfinished, shaped work has been thought through. All the main elements of the solution are there at the macro level and they connect together. (
&lt;a href="https://read.readwise.io/read/01gs083af3z422a77hfmcp1fcw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>shaped work indicates what not to do. It tells the team where to stop. There’s a specific appetite—the amount of time the team is allowed to spend on the project. Completing the project within that fixed amount of time requires limiting the scope and leaving specific things out (
&lt;a href="https://read.readwise.io/read/01gs0844yyh61ycz9dzcy3f2xs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Shaping is a closed-door, creative process. You might be alone sketching on paper or in front of a whiteboard with a close collaborator. There’ll be rough diagrams in front of you that nobody outside the room would be able to interpret. When working with a collaborator, you move fast, speak frankly and jump from one promising position to another. It’s that kind of private, rough, early work. (
&lt;a href="https://read.readwise.io/read/01gs08pwhjh29qd5h6exedm90n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can’t really schedule shaping work because, by its very nature, unshaped work is risky and unknown. For that reason we have two separate tracks: one for shaping, one for building. During any six week cycle, the teams are building work that’s been previously shaped and the shapers are working on what the teams might potentially build in a future cycle. Work on the shaping track is kept private and not shared with the wider team until the commitment
26 (
&lt;a href="https://read.readwise.io/read/01gs08r64pxb8bwzaq4t6b1vrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>has been made to bet on it. That gives the shapers the option to put work-in-progress on the shelf or drop it when it’s not working out. (
&lt;a href="https://read.readwise.io/read/01gs08r5qd4hsgmgyyqz261ska" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[basecamp.com]]
title: &amp;ldquo;Shape-Up&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="shape-up-1">Shape-Up&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[basecamp.com]]&lt;/li>
&lt;li>Full Title: Shape-Up&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://basecamp.com/shapeup/shape-up.pdf" rel="noopener">https://basecamp.com/shapeup/shape-up.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>The way a team works has an enormous influence on what it can do. The process, the methods, the practices, the approach, the discipline, the trust, the communication style, the pace. The way—the how—is foundational and fundamental. (
&lt;a href="https://read.readwise.io/read/01gre7kv9bzj0q5hqxvv3931vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>focus on “hammering” the scope to fit within a given time budget was born under these constraints. (
&lt;a href="https://read.readwise.io/read/01gre7qxyqbhgenxe8ks3kfmwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>in six-week cycles. Six weeks is long enough to build something meaningful start-to-finish and short enough that everyone can feel the deadline looming from the start, so they use the time wisely. The (
&lt;a href="https://read.readwise.io/read/01gre7vtjxpcj5agbm71xsz5wv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we shape the work before giving it to a team. A small senior group works in parallel to the cycle teams. They define the key elements of a solution before we consider a project ready to bet on. Projects are defined at the right level of abstraction: concrete enough that the teams know what to do, yet abstract enough that they have room to work out the interesting details themselves. (
&lt;a href="https://read.readwise.io/read/01gre7x4nwmdegdr9yzf7960b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>14 (
&lt;a href="https://read.readwise.io/read/01gre7xpypxzyqmwmhxznx85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>appetite. Instead of asking how much time it will take to do some work, we ask: How much time do we want to spend? How much is this idea worth? This is the task of shaping: narrowing down the problem and designing the outline of a solution that fits within the constraints of our appetite. (
&lt;a href="https://read.readwise.io/read/01gre7xrpjam85z5by8p85rvqk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we give full responsibility to a small integrated team of designers and programmers. They define their own tasks, make adjustments to the scope, and work together to build vertical slices of the product one at a time. (
&lt;a href="https://read.readwise.io/read/01gre7yr6wz7hrph5q431cx0gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When teams are more autonomous, senior people can spend less time managing them. With less time spent on management, senior people can shape up better projects. When projects are better shaped, teams have clearer boundaries and so can work more autonomously. (
&lt;a href="https://read.readwise.io/read/01gre82mjb23vtt4n78z5tqn43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step of the process we target a specific risk: the risk of not shipping on time. (
&lt;a href="https://read.readwise.io/read/01gre867pa57xb4bfg6k6wzk77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Improving your discovery process should come after regaining your ability to ship. You can have the best strategy in the world, but if you can’t act on it, what good does it do? (
&lt;a href="https://read.readwise.io/read/01gre84dt3aqyw36ghr8skxxq5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We reduce risk in the planning process by capping our bets to six weeks. If a project runs over, by default it doesn’t get an extension. This “circuit breaker” ensures that we don’t invest multiples of the original appetite on a concept that needs rethinking first. (
&lt;a href="https://read.readwise.io/read/01gre85xex8h27bxef9vdkqbm1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we reduce risk in the building process by integrating design and programming early. Instead of building lots of disconnected parts and hoping they’ll fit together in the 11th hour, we build one meaningful piece of the work end-to-end early on and then repeat. The team sequences the work from the most unknown to the least worrisome pieces and learns what works and what doesn’t by integrating as soon as possible. (
&lt;a href="https://read.readwise.io/read/01gre87cdpvsvf66xhbexzscwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we shape the work, we need to do it at the right level of abstraction: not too vague and not too concrete. Product managers often err on one of these two extremes. (
&lt;a href="https://read.readwise.io/read/01gre8fmgc1pmfgnckqvnnbkyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Over-specifying the design also leads to estimation errors. Counterintuitive as it may seem, the more specific the work is, the harder it can be to estimate. (
&lt;a href="https://read.readwise.io/read/01gre8gabx7bwh55q3cqm3dsym" rel="noopener">View Highlight&lt;/a>)
&lt;ul>
&lt;li>Note: This might be one of the major flaws of waterfall&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>When the scope isn’t variable, the team can’t reconsider a design decision that is turning out to cost more than it’s worth. (
&lt;a href="https://read.readwise.io/read/01gre8hxpzf8xrzzk6b8g5vbvw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>projects that are too vague don’t work either. When a project is defined in a few words, nobody knows what it means. (
&lt;a href="https://read.readwise.io/read/01gre8p97p4jbpkjkjcan2vjb1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Team members don’t have enough information to make trade-offs. They don’t know what to include or leave out (
&lt;a href="https://read.readwise.io/read/01gre8pqy5menm7ewnf8rc3cy8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under-specified projects naturally grow out of control because there’s no boundary to define what’s out of scope. (
&lt;a href="https://read.readwise.io/read/01gre8q1dxck6g3mf5xbd96bba" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Work in the shaping stage is rough. Everyone can tell by looking at it that it’s unfinished. They can see the open spaces where their contributions will go. Work that’s too fine, too early commits
24 (
&lt;a href="https://read.readwise.io/read/01gs082s5vnn56g601jmt1de9v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>everyone to the wrong details. Designers and programmers need room to apply their own judgement and expertise when they roll up their sleeves and discover all the real trade-offs that emerge. (
&lt;a href="https://read.readwise.io/read/01gs082vgw6h7gb6vmq3fttex1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Despite being rough and unfinished, shaped work has been thought through. All the main elements of the solution are there at the macro level and they connect together. (
&lt;a href="https://read.readwise.io/read/01gs083af3z422a77hfmcp1fcw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>shaped work indicates what not to do. It tells the team where to stop. There’s a specific appetite—the amount of time the team is allowed to spend on the project. Completing the project within that fixed amount of time requires limiting the scope and leaving specific things out (
&lt;a href="https://read.readwise.io/read/01gs0844yyh61ycz9dzcy3f2xs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Shaping is a closed-door, creative process. You might be alone sketching on paper or in front of a whiteboard with a close collaborator. There’ll be rough diagrams in front of you that nobody outside the room would be able to interpret. When working with a collaborator, you move fast, speak frankly and jump from one promising position to another. It’s that kind of private, rough, early work. (
&lt;a href="https://read.readwise.io/read/01gs08pwhjh29qd5h6exedm90n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can’t really schedule shaping work because, by its very nature, unshaped work is risky and unknown. For that reason we have two separate tracks: one for shaping, one for building. During any six week cycle, the teams are building work that’s been previously shaped and the shapers are working on what the teams might potentially build in a future cycle. Work on the shaping track is kept private and not shared with the wider team until the commitment
26 (
&lt;a href="https://read.readwise.io/read/01gs08r64pxb8bwzaq4t6b1vrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>has been made to bet on it. That gives the shapers the option to put work-in-progress on the shelf or drop it when it’s not working out. (
&lt;a href="https://read.readwise.io/read/01gs08r5qd4hsgmgyyqz261ska" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[basecamp.com]]
title: &amp;ldquo;Shape-Up&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="shape-up-2">Shape-Up&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[basecamp.com]]&lt;/li>
&lt;li>Full Title: Shape-Up&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://basecamp.com/shapeup/shape-up.pdf" rel="noopener">https://basecamp.com/shapeup/shape-up.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>The way a team works has an enormous influence on what it can do. The process, the methods, the practices, the approach, the discipline, the trust, the communication style, the pace. The way—the how—is foundational and fundamental. (
&lt;a href="https://read.readwise.io/read/01gre7kv9bzj0q5hqxvv3931vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>focus on “hammering” the scope to fit within a given time budget was born under these constraints. (
&lt;a href="https://read.readwise.io/read/01gre7qxyqbhgenxe8ks3kfmwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>in six-week cycles. Six weeks is long enough to build something meaningful start-to-finish and short enough that everyone can feel the deadline looming from the start, so they use the time wisely. The (
&lt;a href="https://read.readwise.io/read/01gre7vtjxpcj5agbm71xsz5wv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we shape the work before giving it to a team. A small senior group works in parallel to the cycle teams. They define the key elements of a solution before we consider a project ready to bet on. Projects are defined at the right level of abstraction: concrete enough that the teams know what to do, yet abstract enough that they have room to work out the interesting details themselves. (
&lt;a href="https://read.readwise.io/read/01gre7x4nwmdegdr9yzf7960b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>14 (
&lt;a href="https://read.readwise.io/read/01gre7xpypxzyqmwmhxznx85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>appetite. Instead of asking how much time it will take to do some work, we ask: How much time do we want to spend? How much is this idea worth? This is the task of shaping: narrowing down the problem and designing the outline of a solution that fits within the constraints of our appetite. (
&lt;a href="https://read.readwise.io/read/01gre7xrpjam85z5by8p85rvqk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we give full responsibility to a small integrated team of designers and programmers. They define their own tasks, make adjustments to the scope, and work together to build vertical slices of the product one at a time. (
&lt;a href="https://read.readwise.io/read/01gre7yr6wz7hrph5q431cx0gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When teams are more autonomous, senior people can spend less time managing them. With less time spent on management, senior people can shape up better projects. When projects are better shaped, teams have clearer boundaries and so can work more autonomously. (
&lt;a href="https://read.readwise.io/read/01gre82mjb23vtt4n78z5tqn43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step of the process we target a specific risk: the risk of not shipping on time. (
&lt;a href="https://read.readwise.io/read/01gre867pa57xb4bfg6k6wzk77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Improving your discovery process should come after regaining your ability to ship. You can have the best strategy in the world, but if you can’t act on it, what good does it do? (
&lt;a href="https://read.readwise.io/read/01gre84dt3aqyw36ghr8skxxq5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We reduce risk in the planning process by capping our bets to six weeks. If a project runs over, by default it doesn’t get an extension. This “circuit breaker” ensures that we don’t invest multiples of the original appetite on a concept that needs rethinking first. (
&lt;a href="https://read.readwise.io/read/01gre85xex8h27bxef9vdkqbm1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we reduce risk in the building process by integrating design and programming early. Instead of building lots of disconnected parts and hoping they’ll fit together in the 11th hour, we build one meaningful piece of the work end-to-end early on and then repeat. The team sequences the work from the most unknown to the least worrisome pieces and learns what works and what doesn’t by integrating as soon as possible. (
&lt;a href="https://read.readwise.io/read/01gre87cdpvsvf66xhbexzscwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we shape the work, we need to do it at the right level of abstraction: not too vague and not too concrete. Product managers often err on one of these two extremes. (
&lt;a href="https://read.readwise.io/read/01gre8fmgc1pmfgnckqvnnbkyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Over-specifying the design also leads to estimation errors. Counterintuitive as it may seem, the more specific the work is, the harder it can be to estimate. (
&lt;a href="https://read.readwise.io/read/01gre8gabx7bwh55q3cqm3dsym" rel="noopener">View Highlight&lt;/a>)
&lt;ul>
&lt;li>Note: This might be one of the major flaws of waterfall&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>When the scope isn’t variable, the team can’t reconsider a design decision that is turning out to cost more than it’s worth. (
&lt;a href="https://read.readwise.io/read/01gre8hxpzf8xrzzk6b8g5vbvw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>projects that are too vague don’t work either. When a project is defined in a few words, nobody knows what it means. (
&lt;a href="https://read.readwise.io/read/01gre8p97p4jbpkjkjcan2vjb1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Team members don’t have enough information to make trade-offs. They don’t know what to include or leave out (
&lt;a href="https://read.readwise.io/read/01gre8pqy5menm7ewnf8rc3cy8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under-specified projects naturally grow out of control because there’s no boundary to define what’s out of scope. (
&lt;a href="https://read.readwise.io/read/01gre8q1dxck6g3mf5xbd96bba" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Work in the shaping stage is rough. Everyone can tell by looking at it that it’s unfinished. They can see the open spaces where their contributions will go. Work that’s too fine, too early commits
24 (
&lt;a href="https://read.readwise.io/read/01gs082s5vnn56g601jmt1de9v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>everyone to the wrong details. Designers and programmers need room to apply their own judgement and expertise when they roll up their sleeves and discover all the real trade-offs that emerge. (
&lt;a href="https://read.readwise.io/read/01gs082vgw6h7gb6vmq3fttex1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Despite being rough and unfinished, shaped work has been thought through. All the main elements of the solution are there at the macro level and they connect together. (
&lt;a href="https://read.readwise.io/read/01gs083af3z422a77hfmcp1fcw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>shaped work indicates what not to do. It tells the team where to stop. There’s a specific appetite—the amount of time the team is allowed to spend on the project. Completing the project within that fixed amount of time requires limiting the scope and leaving specific things out (
&lt;a href="https://read.readwise.io/read/01gs0844yyh61ycz9dzcy3f2xs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Shaping is a closed-door, creative process. You might be alone sketching on paper or in front of a whiteboard with a close collaborator. There’ll be rough diagrams in front of you that nobody outside the room would be able to interpret. When working with a collaborator, you move fast, speak frankly and jump from one promising position to another. It’s that kind of private, rough, early work. (
&lt;a href="https://read.readwise.io/read/01gs08pwhjh29qd5h6exedm90n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can’t really schedule shaping work because, by its very nature, unshaped work is risky and unknown. For that reason we have two separate tracks: one for shaping, one for building. During any six week cycle, the teams are building work that’s been previously shaped and the shapers are working on what the teams might potentially build in a future cycle. Work on the shaping track is kept private and not shared with the wider team until the commitment
26 (
&lt;a href="https://read.readwise.io/read/01gs08r64pxb8bwzaq4t6b1vrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>has been made to bet on it. That gives the shapers the option to put work-in-progress on the shelf or drop it when it’s not working out. (
&lt;a href="https://read.readwise.io/read/01gs08r5qd4hsgmgyyqz261ska" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[basecamp.com]]
title: &amp;ldquo;Shape-Up&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="shape-up-3">Shape-Up&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article3.5c705a01b476.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[basecamp.com]]&lt;/li>
&lt;li>Full Title: Shape-Up&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://basecamp.com/shapeup/shape-up.pdf" rel="noopener">https://basecamp.com/shapeup/shape-up.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>The way a team works has an enormous influence on what it can do. The process, the methods, the practices, the approach, the discipline, the trust, the communication style, the pace. The way—the how—is foundational and fundamental. (
&lt;a href="https://read.readwise.io/read/01gre7kv9bzj0q5hqxvv3931vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>focus on “hammering” the scope to fit within a given time budget was born under these constraints. (
&lt;a href="https://read.readwise.io/read/01gre7qxyqbhgenxe8ks3kfmwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>in six-week cycles. Six weeks is long enough to build something meaningful start-to-finish and short enough that everyone can feel the deadline looming from the start, so they use the time wisely. The (
&lt;a href="https://read.readwise.io/read/01gre7vtjxpcj5agbm71xsz5wv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we shape the work before giving it to a team. A small senior group works in parallel to the cycle teams. They define the key elements of a solution before we consider a project ready to bet on. Projects are defined at the right level of abstraction: concrete enough that the teams know what to do, yet abstract enough that they have room to work out the interesting details themselves. (
&lt;a href="https://read.readwise.io/read/01gre7x4nwmdegdr9yzf7960b6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>14 (
&lt;a href="https://read.readwise.io/read/01gre7xpypxzyqmwmhxznx85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>appetite. Instead of asking how much time it will take to do some work, we ask: How much time do we want to spend? How much is this idea worth? This is the task of shaping: narrowing down the problem and designing the outline of a solution that fits within the constraints of our appetite. (
&lt;a href="https://read.readwise.io/read/01gre7xrpjam85z5by8p85rvqk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we give full responsibility to a small integrated team of designers and programmers. They define their own tasks, make adjustments to the scope, and work together to build vertical slices of the product one at a time. (
&lt;a href="https://read.readwise.io/read/01gre7yr6wz7hrph5q431cx0gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When teams are more autonomous, senior people can spend less time managing them. With less time spent on management, senior people can shape up better projects. When projects are better shaped, teams have clearer boundaries and so can work more autonomously. (
&lt;a href="https://read.readwise.io/read/01gre82mjb23vtt4n78z5tqn43" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At every step of the process we target a specific risk: the risk of not shipping on time. (
&lt;a href="https://read.readwise.io/read/01gre867pa57xb4bfg6k6wzk77" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Improving your discovery process should come after regaining your ability to ship. You can have the best strategy in the world, but if you can’t act on it, what good does it do? (
&lt;a href="https://read.readwise.io/read/01gre84dt3aqyw36ghr8skxxq5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We reduce risk in the planning process by capping our bets to six weeks. If a project runs over, by default it doesn’t get an extension. This “circuit breaker” ensures that we don’t invest multiples of the original appetite on a concept that needs rethinking first. (
&lt;a href="https://read.readwise.io/read/01gre85xex8h27bxef9vdkqbm1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we reduce risk in the building process by integrating design and programming early. Instead of building lots of disconnected parts and hoping they’ll fit together in the 11th hour, we build one meaningful piece of the work end-to-end early on and then repeat. The team sequences the work from the most unknown to the least worrisome pieces and learns what works and what doesn’t by integrating as soon as possible. (
&lt;a href="https://read.readwise.io/read/01gre87cdpvsvf66xhbexzscwn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When we shape the work, we need to do it at the right level of abstraction: not too vague and not too concrete. Product managers often err on one of these two extremes. (
&lt;a href="https://read.readwise.io/read/01gre8fmgc1pmfgnckqvnnbkyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Over-specifying the design also leads to estimation errors. Counterintuitive as it may seem, the more specific the work is, the harder it can be to estimate. (
&lt;a href="https://read.readwise.io/read/01gre8gabx7bwh55q3cqm3dsym" rel="noopener">View Highlight&lt;/a>)
&lt;ul>
&lt;li>Note: This might be one of the major flaws of waterfall&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>When the scope isn’t variable, the team can’t reconsider a design decision that is turning out to cost more than it’s worth. (
&lt;a href="https://read.readwise.io/read/01gre8hxpzf8xrzzk6b8g5vbvw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>projects that are too vague don’t work either. When a project is defined in a few words, nobody knows what it means. (
&lt;a href="https://read.readwise.io/read/01gre8p97p4jbpkjkjcan2vjb1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Team members don’t have enough information to make trade-offs. They don’t know what to include or leave out (
&lt;a href="https://read.readwise.io/read/01gre8pqy5menm7ewnf8rc3cy8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>under-specified projects naturally grow out of control because there’s no boundary to define what’s out of scope. (
&lt;a href="https://read.readwise.io/read/01gre8q1dxck6g3mf5xbd96bba" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Work in the shaping stage is rough. Everyone can tell by looking at it that it’s unfinished. They can see the open spaces where their contributions will go. Work that’s too fine, too early commits
24 (
&lt;a href="https://read.readwise.io/read/01gs082s5vnn56g601jmt1de9v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>everyone to the wrong details. Designers and programmers need room to apply their own judgement and expertise when they roll up their sleeves and discover all the real trade-offs that emerge. (
&lt;a href="https://read.readwise.io/read/01gs082vgw6h7gb6vmq3fttex1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Despite being rough and unfinished, shaped work has been thought through. All the main elements of the solution are there at the macro level and they connect together. (
&lt;a href="https://read.readwise.io/read/01gs083af3z422a77hfmcp1fcw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>shaped work indicates what not to do. It tells the team where to stop. There’s a specific appetite—the amount of time the team is allowed to spend on the project. Completing the project within that fixed amount of time requires limiting the scope and leaving specific things out (
&lt;a href="https://read.readwise.io/read/01gs0844yyh61ycz9dzcy3f2xs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Shaping is a closed-door, creative process. You might be alone sketching on paper or in front of a whiteboard with a close collaborator. There’ll be rough diagrams in front of you that nobody outside the room would be able to interpret. When working with a collaborator, you move fast, speak frankly and jump from one promising position to another. It’s that kind of private, rough, early work. (
&lt;a href="https://read.readwise.io/read/01gs08pwhjh29qd5h6exedm90n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can’t really schedule shaping work because, by its very nature, unshaped work is risky and unknown. For that reason we have two separate tracks: one for shaping, one for building. During any six week cycle, the teams are building work that’s been previously shaped and the shapers are working on what the teams might potentially build in a future cycle. Work on the shaping track is kept private and not shared with the wider team until the commitment
26 (
&lt;a href="https://read.readwise.io/read/01gs08r64pxb8bwzaq4t6b1vrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>has been made to bet on it. That gives the shapers the option to put work-in-progress on the shelf or drop it when it’s not working out. (
&lt;a href="https://read.readwise.io/read/01gs08r5qd4hsgmgyyqz261ska" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Share Your Data Insights to Engage Your Colleagues</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Share-Your-Data-Insights-to-Engage-Your-Colleagues/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Share-Your-Data-Insights-to-Engage-Your-Colleagues/</guid><description>&lt;h1 id="share-your-data-insights-to-engage-your-colleagues">Share Your Data Insights to Engage Your Colleagues&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/08/Share-Data-Insights-2.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Paige Berry]]&lt;/li>
&lt;li>Full Title: Share Your Data Insights to Engage Your Colleagues&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/" rel="noopener">https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Proactively sharing data insights broadly with the people in our organizations encourages engagement and collaboration, brings additional visibility to the data team, and provides a way to work in partnership with others in the company to increase data literacy (
&lt;a href="https://read.readwise.io/read/01grw480sx2qv0bqfdj3b91x21" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when asked to do an analysis for the marketing team, we share the results with everyone to give other folks in the company information they can synthesize and use to inform their own work. (
&lt;a href="https://read.readwise.io/read/01grw4p32rc37gmd23w9m0edrp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Broadly sharing these insights, both those that come from answering stakeholder questions and those discovered when exploring the data on our own, can be beneficial in a variety of ways: (
&lt;a href="https://read.readwise.io/read/01grw4pefx3ep8mzz7mmmdm2ak" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Helping folks understand a more comprehensive universe of questions that can be answered by our data (
&lt;a href="https://read.readwise.io/read/01grw4pma8dvf2vbhrteparvq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teaching others in our company about how to interpret data (
&lt;a href="https://read.readwise.io/read/01grw4ptc4a0wyn8df5yfb6gfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Serving as an entry point to existing reporting (
&lt;a href="https://read.readwise.io/read/01grw4q6fdedg7jctnda222kj9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Making the data team more visible and showing the range of the data team’s skills, far beyond a simple data pull (
&lt;a href="https://read.readwise.io/read/01grw4qv55y9fv8cz4m98v43zr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we have a Slack channel made for proactively sharing insights, called #internal-stats-n-graphs (
&lt;a href="https://read.readwise.io/read/01grw4qz0r33dq6t86bsna4e5j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of the data analysts and analytics engineers on the Data Team aim to develop an insight weekly, then we schedule out who will post in the channel each day (
&lt;a href="https://read.readwise.io/read/01grw4rmxq7y6b1ecs0kfgxxys" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Anyone from the company can post in the channel, which keeps it lively and adds to the collaborative spirit. (
&lt;a href="https://read.readwise.io/read/01grw4rzrrzp7gykfs7q4sesah" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Those conversations can yield great ideas for future explorations, cross-functional connections that lead to valuable partnerships, opportunities to educate about data interpretation best practices, and ways for us on the data team to learn about aspects of the business from subject matter experts that can help us refine our explorations. (
&lt;a href="https://read.readwise.io/read/01grw4sq3n2qekgxnz5w3vpv66" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Paige Berry]]
title: &amp;ldquo;Share Your Data Insights to Engage Your Colleagues&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="share-your-data-insights-to-engage-your-colleagues-1">Share Your Data Insights to Engage Your Colleagues&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/08/Share-Data-Insights-2.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Paige Berry]]&lt;/li>
&lt;li>Full Title: Share Your Data Insights to Engage Your Colleagues&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/" rel="noopener">https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Proactively sharing data insights broadly with the people in our organizations encourages engagement and collaboration, brings additional visibility to the data team, and provides a way to work in partnership with others in the company to increase data literacy (
&lt;a href="https://read.readwise.io/read/01grw480sx2qv0bqfdj3b91x21" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when asked to do an analysis for the marketing team, we share the results with everyone to give other folks in the company information they can synthesize and use to inform their own work. (
&lt;a href="https://read.readwise.io/read/01grw4p32rc37gmd23w9m0edrp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Broadly sharing these insights, both those that come from answering stakeholder questions and those discovered when exploring the data on our own, can be beneficial in a variety of ways: (
&lt;a href="https://read.readwise.io/read/01grw4pefx3ep8mzz7mmmdm2ak" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Helping folks understand a more comprehensive universe of questions that can be answered by our data (
&lt;a href="https://read.readwise.io/read/01grw4pma8dvf2vbhrteparvq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teaching others in our company about how to interpret data (
&lt;a href="https://read.readwise.io/read/01grw4ptc4a0wyn8df5yfb6gfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Serving as an entry point to existing reporting (
&lt;a href="https://read.readwise.io/read/01grw4q6fdedg7jctnda222kj9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Making the data team more visible and showing the range of the data team’s skills, far beyond a simple data pull (
&lt;a href="https://read.readwise.io/read/01grw4qv55y9fv8cz4m98v43zr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we have a Slack channel made for proactively sharing insights, called #internal-stats-n-graphs (
&lt;a href="https://read.readwise.io/read/01grw4qz0r33dq6t86bsna4e5j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of the data analysts and analytics engineers on the Data Team aim to develop an insight weekly, then we schedule out who will post in the channel each day (
&lt;a href="https://read.readwise.io/read/01grw4rmxq7y6b1ecs0kfgxxys" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Anyone from the company can post in the channel, which keeps it lively and adds to the collaborative spirit. (
&lt;a href="https://read.readwise.io/read/01grw4rzrrzp7gykfs7q4sesah" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Those conversations can yield great ideas for future explorations, cross-functional connections that lead to valuable partnerships, opportunities to educate about data interpretation best practices, and ways for us on the data team to learn about aspects of the business from subject matter experts that can help us refine our explorations. (
&lt;a href="https://read.readwise.io/read/01grw4sq3n2qekgxnz5w3vpv66" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Paige Berry]]
title: &amp;ldquo;Share Your Data Insights to Engage Your Colleagues&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="share-your-data-insights-to-engage-your-colleagues-2">Share Your Data Insights to Engage Your Colleagues&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/08/Share-Data-Insights-2.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Paige Berry]]&lt;/li>
&lt;li>Full Title: Share Your Data Insights to Engage Your Colleagues&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/" rel="noopener">https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Proactively sharing data insights broadly with the people in our organizations encourages engagement and collaboration, brings additional visibility to the data team, and provides a way to work in partnership with others in the company to increase data literacy (
&lt;a href="https://read.readwise.io/read/01grw480sx2qv0bqfdj3b91x21" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when asked to do an analysis for the marketing team, we share the results with everyone to give other folks in the company information they can synthesize and use to inform their own work. (
&lt;a href="https://read.readwise.io/read/01grw4p32rc37gmd23w9m0edrp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Broadly sharing these insights, both those that come from answering stakeholder questions and those discovered when exploring the data on our own, can be beneficial in a variety of ways: (
&lt;a href="https://read.readwise.io/read/01grw4pefx3ep8mzz7mmmdm2ak" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Helping folks understand a more comprehensive universe of questions that can be answered by our data (
&lt;a href="https://read.readwise.io/read/01grw4pma8dvf2vbhrteparvq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teaching others in our company about how to interpret data (
&lt;a href="https://read.readwise.io/read/01grw4ptc4a0wyn8df5yfb6gfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Serving as an entry point to existing reporting (
&lt;a href="https://read.readwise.io/read/01grw4q6fdedg7jctnda222kj9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Making the data team more visible and showing the range of the data team’s skills, far beyond a simple data pull (
&lt;a href="https://read.readwise.io/read/01grw4qv55y9fv8cz4m98v43zr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we have a Slack channel made for proactively sharing insights, called #internal-stats-n-graphs (
&lt;a href="https://read.readwise.io/read/01grw4qz0r33dq6t86bsna4e5j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of the data analysts and analytics engineers on the Data Team aim to develop an insight weekly, then we schedule out who will post in the channel each day (
&lt;a href="https://read.readwise.io/read/01grw4rmxq7y6b1ecs0kfgxxys" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Anyone from the company can post in the channel, which keeps it lively and adds to the collaborative spirit. (
&lt;a href="https://read.readwise.io/read/01grw4rzrrzp7gykfs7q4sesah" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Those conversations can yield great ideas for future explorations, cross-functional connections that lead to valuable partnerships, opportunities to educate about data interpretation best practices, and ways for us on the data team to learn about aspects of the business from subject matter experts that can help us refine our explorations. (
&lt;a href="https://read.readwise.io/read/01grw4sq3n2qekgxnz5w3vpv66" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Paige Berry]]
title: &amp;ldquo;Share Your Data Insights to Engage Your Colleagues&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="share-your-data-insights-to-engage-your-colleagues-3">Share Your Data Insights to Engage Your Colleagues&lt;/h1>
&lt;p>
&lt;img src="https://locallyoptimistic.com/wp-content/uploads/2021/08/Share-Data-Insights-2.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Paige Berry]]&lt;/li>
&lt;li>Full Title: Share Your Data Insights to Engage Your Colleagues&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/" rel="noopener">https://locallyoptimistic.com/post/share-your-data-insights-to-engage-your-colleagues/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Proactively sharing data insights broadly with the people in our organizations encourages engagement and collaboration, brings additional visibility to the data team, and provides a way to work in partnership with others in the company to increase data literacy (
&lt;a href="https://read.readwise.io/read/01grw480sx2qv0bqfdj3b91x21" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when asked to do an analysis for the marketing team, we share the results with everyone to give other folks in the company information they can synthesize and use to inform their own work. (
&lt;a href="https://read.readwise.io/read/01grw4p32rc37gmd23w9m0edrp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Broadly sharing these insights, both those that come from answering stakeholder questions and those discovered when exploring the data on our own, can be beneficial in a variety of ways: (
&lt;a href="https://read.readwise.io/read/01grw4pefx3ep8mzz7mmmdm2ak" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Helping folks understand a more comprehensive universe of questions that can be answered by our data (
&lt;a href="https://read.readwise.io/read/01grw4pma8dvf2vbhrteparvq6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teaching others in our company about how to interpret data (
&lt;a href="https://read.readwise.io/read/01grw4ptc4a0wyn8df5yfb6gfx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Serving as an entry point to existing reporting (
&lt;a href="https://read.readwise.io/read/01grw4q6fdedg7jctnda222kj9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Making the data team more visible and showing the range of the data team’s skills, far beyond a simple data pull (
&lt;a href="https://read.readwise.io/read/01grw4qv55y9fv8cz4m98v43zr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we have a Slack channel made for proactively sharing insights, called #internal-stats-n-graphs (
&lt;a href="https://read.readwise.io/read/01grw4qz0r33dq6t86bsna4e5j" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Each of the data analysts and analytics engineers on the Data Team aim to develop an insight weekly, then we schedule out who will post in the channel each day (
&lt;a href="https://read.readwise.io/read/01grw4rmxq7y6b1ecs0kfgxxys" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Anyone from the company can post in the channel, which keeps it lively and adds to the collaborative spirit. (
&lt;a href="https://read.readwise.io/read/01grw4rzrrzp7gykfs7q4sesah" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Those conversations can yield great ideas for future explorations, cross-functional connections that lead to valuable partnerships, opportunities to educate about data interpretation best practices, and ways for us on the data team to learn about aspects of the business from subject matter experts that can help us refine our explorations. (
&lt;a href="https://read.readwise.io/read/01grw4sq3n2qekgxnz5w3vpv66" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Should You Measure the Value of a Data Team?</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Should-You-Measure-the-Value-of-a-Data-Team/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Should-You-Measure-the-Value-of-a-Data-Team/</guid><description>&lt;h1 id="should-you-measure-the-value-of-a-data-team">Should You Measure the Value of a Data Team?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1030/1*ZHv9ptUWuCMMPljdoMAhSQ.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Anna Geller]]&lt;/li>
&lt;li>Full Title: Should You Measure the Value of a Data Team?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a" rel="noopener">https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>the work of data teams is inherently
&lt;a href="https://benn.substack.com/p/chasing-ghosts" rel="noopener">unmeasurable&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6ewbgbdnn59b3jsj6qega" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most data teams work as a support function. They help other teams make decisions and operate more efficiently, but their involvement in value creation is &lt;strong>indirect&lt;/strong>. You can’t directly quantify (&lt;em>especially in advance&lt;/em>) the impact of a new table, dashboard, or
&lt;a href="https://docs.prefect.io/concepts/flows/" rel="noopener">pipeline&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6fxksdxtxjc3h7wnmspnk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data teams often don’t get credit for their work, not because they do a poor job, but because the company culture doesn’t value data work regardless of its quality or quantity. (
&lt;a href="https://read.readwise.io/read/01gre6gd154nfx670b96axrv8s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead of searching for the perfect metric, data teams need to
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">slowly elbow their way in&lt;/a> by continuously solving business problems, earning trust from stakeholders, and gradually improving culture and processes. (
&lt;a href="https://read.readwise.io/read/01gre6gxg0xh2gv5ywheeckrk2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">let your stakeholders tell your ROI story&lt;/a>. Other departments should estimate how much value the data team delivered to them. (
&lt;a href="https://read.readwise.io/read/01gre6kz6hjcyerg4azpszb127" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they can help indirectly by improving &lt;em>processes&lt;/em> and &lt;em>operational efficiency&lt;/em>, saving &lt;em>time&lt;/em> or infrastructure &lt;em>costs&lt;/em>, and gaining more &lt;em>trust&lt;/em> in data and your work. By first writing down what each side expects, you can clarify with stakeholders how data work contributes to &lt;strong>incremental process changes&lt;/strong> that couldn’t have happened without the data team’s involvement. (
&lt;a href="https://read.readwise.io/read/01gre6wdsrg4st52wmzevpptct" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One metric that might help in such situations is the
&lt;a href="https://benn.substack.com/p/method-for-measuring-analytical-work" rel="noopener">&lt;strong>time-to-decision&lt;/strong> framework&lt;/a> proposed by Benn Stancil. The framework is simple: the performance of a data team is measured by how quickly decisions are made. The quicker, the better you are performing (
&lt;a href="https://read.readwise.io/read/01gre6prd5xxyqd4td6jtj85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Another business-oriented measurement is to
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">&lt;strong>tie data objectives to&lt;/strong> the company’s &lt;strong>OKRs&lt;/strong>&lt;/a> if it’s possible to align those objectives. This approach makes it clearer how the data team’s work impacts functional outcomes. (
&lt;a href="https://read.readwise.io/read/01gre6qqje2k81tj3m3ab5q1gz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the senior leadership should value your team’s work without having to prove it, but if you need to prove it, be ready for it. Show, don’t tell. Show what your team delivered and how it solved business problems in the past. Show the impact of incremental process changes that wouldn’t have happened without this team’s involvement. Show what you changed for the better — how money and time were saved and how operational efficiency improved. And whatever metric you choose, iterate on it — don’t let
&lt;a href="http://prefect.io/" rel="noopener">perfect&lt;/a> be the enemy of good. (
&lt;a href="https://read.readwise.io/read/01gre6xy9g35y6cecwn54z08xx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Anna Geller]]
title: &amp;ldquo;Should You Measure the Value of a Data Team?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="should-you-measure-the-value-of-a-data-team-1">Should You Measure the Value of a Data Team?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1030/1*ZHv9ptUWuCMMPljdoMAhSQ.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Anna Geller]]&lt;/li>
&lt;li>Full Title: Should You Measure the Value of a Data Team?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a" rel="noopener">https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>the work of data teams is inherently
&lt;a href="https://benn.substack.com/p/chasing-ghosts" rel="noopener">unmeasurable&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6ewbgbdnn59b3jsj6qega" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most data teams work as a support function. They help other teams make decisions and operate more efficiently, but their involvement in value creation is &lt;strong>indirect&lt;/strong>. You can’t directly quantify (&lt;em>especially in advance&lt;/em>) the impact of a new table, dashboard, or
&lt;a href="https://docs.prefect.io/concepts/flows/" rel="noopener">pipeline&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6fxksdxtxjc3h7wnmspnk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data teams often don’t get credit for their work, not because they do a poor job, but because the company culture doesn’t value data work regardless of its quality or quantity. (
&lt;a href="https://read.readwise.io/read/01gre6gd154nfx670b96axrv8s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead of searching for the perfect metric, data teams need to
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">slowly elbow their way in&lt;/a> by continuously solving business problems, earning trust from stakeholders, and gradually improving culture and processes. (
&lt;a href="https://read.readwise.io/read/01gre6gxg0xh2gv5ywheeckrk2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">let your stakeholders tell your ROI story&lt;/a>. Other departments should estimate how much value the data team delivered to them. (
&lt;a href="https://read.readwise.io/read/01gre6kz6hjcyerg4azpszb127" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they can help indirectly by improving &lt;em>processes&lt;/em> and &lt;em>operational efficiency&lt;/em>, saving &lt;em>time&lt;/em> or infrastructure &lt;em>costs&lt;/em>, and gaining more &lt;em>trust&lt;/em> in data and your work. By first writing down what each side expects, you can clarify with stakeholders how data work contributes to &lt;strong>incremental process changes&lt;/strong> that couldn’t have happened without the data team’s involvement. (
&lt;a href="https://read.readwise.io/read/01gre6wdsrg4st52wmzevpptct" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One metric that might help in such situations is the
&lt;a href="https://benn.substack.com/p/method-for-measuring-analytical-work" rel="noopener">&lt;strong>time-to-decision&lt;/strong> framework&lt;/a> proposed by Benn Stancil. The framework is simple: the performance of a data team is measured by how quickly decisions are made. The quicker, the better you are performing (
&lt;a href="https://read.readwise.io/read/01gre6prd5xxyqd4td6jtj85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Another business-oriented measurement is to
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">&lt;strong>tie data objectives to&lt;/strong> the company’s &lt;strong>OKRs&lt;/strong>&lt;/a> if it’s possible to align those objectives. This approach makes it clearer how the data team’s work impacts functional outcomes. (
&lt;a href="https://read.readwise.io/read/01gre6qqje2k81tj3m3ab5q1gz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the senior leadership should value your team’s work without having to prove it, but if you need to prove it, be ready for it. Show, don’t tell. Show what your team delivered and how it solved business problems in the past. Show the impact of incremental process changes that wouldn’t have happened without this team’s involvement. Show what you changed for the better — how money and time were saved and how operational efficiency improved. And whatever metric you choose, iterate on it — don’t let
&lt;a href="http://prefect.io/" rel="noopener">perfect&lt;/a> be the enemy of good. (
&lt;a href="https://read.readwise.io/read/01gre6xy9g35y6cecwn54z08xx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Anna Geller]]
title: &amp;ldquo;Should You Measure the Value of a Data Team?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="should-you-measure-the-value-of-a-data-team-2">Should You Measure the Value of a Data Team?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1030/1*ZHv9ptUWuCMMPljdoMAhSQ.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Anna Geller]]&lt;/li>
&lt;li>Full Title: Should You Measure the Value of a Data Team?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a" rel="noopener">https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>the work of data teams is inherently
&lt;a href="https://benn.substack.com/p/chasing-ghosts" rel="noopener">unmeasurable&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6ewbgbdnn59b3jsj6qega" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most data teams work as a support function. They help other teams make decisions and operate more efficiently, but their involvement in value creation is &lt;strong>indirect&lt;/strong>. You can’t directly quantify (&lt;em>especially in advance&lt;/em>) the impact of a new table, dashboard, or
&lt;a href="https://docs.prefect.io/concepts/flows/" rel="noopener">pipeline&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6fxksdxtxjc3h7wnmspnk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data teams often don’t get credit for their work, not because they do a poor job, but because the company culture doesn’t value data work regardless of its quality or quantity. (
&lt;a href="https://read.readwise.io/read/01gre6gd154nfx670b96axrv8s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead of searching for the perfect metric, data teams need to
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">slowly elbow their way in&lt;/a> by continuously solving business problems, earning trust from stakeholders, and gradually improving culture and processes. (
&lt;a href="https://read.readwise.io/read/01gre6gxg0xh2gv5ywheeckrk2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">let your stakeholders tell your ROI story&lt;/a>. Other departments should estimate how much value the data team delivered to them. (
&lt;a href="https://read.readwise.io/read/01gre6kz6hjcyerg4azpszb127" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they can help indirectly by improving &lt;em>processes&lt;/em> and &lt;em>operational efficiency&lt;/em>, saving &lt;em>time&lt;/em> or infrastructure &lt;em>costs&lt;/em>, and gaining more &lt;em>trust&lt;/em> in data and your work. By first writing down what each side expects, you can clarify with stakeholders how data work contributes to &lt;strong>incremental process changes&lt;/strong> that couldn’t have happened without the data team’s involvement. (
&lt;a href="https://read.readwise.io/read/01gre6wdsrg4st52wmzevpptct" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One metric that might help in such situations is the
&lt;a href="https://benn.substack.com/p/method-for-measuring-analytical-work" rel="noopener">&lt;strong>time-to-decision&lt;/strong> framework&lt;/a> proposed by Benn Stancil. The framework is simple: the performance of a data team is measured by how quickly decisions are made. The quicker, the better you are performing (
&lt;a href="https://read.readwise.io/read/01gre6prd5xxyqd4td6jtj85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Another business-oriented measurement is to
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">&lt;strong>tie data objectives to&lt;/strong> the company’s &lt;strong>OKRs&lt;/strong>&lt;/a> if it’s possible to align those objectives. This approach makes it clearer how the data team’s work impacts functional outcomes. (
&lt;a href="https://read.readwise.io/read/01gre6qqje2k81tj3m3ab5q1gz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the senior leadership should value your team’s work without having to prove it, but if you need to prove it, be ready for it. Show, don’t tell. Show what your team delivered and how it solved business problems in the past. Show the impact of incremental process changes that wouldn’t have happened without this team’s involvement. Show what you changed for the better — how money and time were saved and how operational efficiency improved. And whatever metric you choose, iterate on it — don’t let
&lt;a href="http://prefect.io/" rel="noopener">perfect&lt;/a> be the enemy of good. (
&lt;a href="https://read.readwise.io/read/01gre6xy9g35y6cecwn54z08xx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Anna Geller]]
title: &amp;ldquo;Should You Measure the Value of a Data Team?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="should-you-measure-the-value-of-a-data-team-3">Should You Measure the Value of a Data Team?&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1030/1*ZHv9ptUWuCMMPljdoMAhSQ.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Anna Geller]]&lt;/li>
&lt;li>Full Title: Should You Measure the Value of a Data Team?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a" rel="noopener">https://medium.com/the-prefect-blog/should-you-measure-the-value-of-a-data-team-95c447f28d4a&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>the work of data teams is inherently
&lt;a href="https://benn.substack.com/p/chasing-ghosts" rel="noopener">unmeasurable&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6ewbgbdnn59b3jsj6qega" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most data teams work as a support function. They help other teams make decisions and operate more efficiently, but their involvement in value creation is &lt;strong>indirect&lt;/strong>. You can’t directly quantify (&lt;em>especially in advance&lt;/em>) the impact of a new table, dashboard, or
&lt;a href="https://docs.prefect.io/concepts/flows/" rel="noopener">pipeline&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gre6fxksdxtxjc3h7wnmspnk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data teams often don’t get credit for their work, not because they do a poor job, but because the company culture doesn’t value data work regardless of its quality or quantity. (
&lt;a href="https://read.readwise.io/read/01gre6gd154nfx670b96axrv8s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Instead of searching for the perfect metric, data teams need to
&lt;a href="https://wrongbutuseful.substack.com/p/elbows-of-data" rel="noopener">slowly elbow their way in&lt;/a> by continuously solving business problems, earning trust from stakeholders, and gradually improving culture and processes. (
&lt;a href="https://read.readwise.io/read/01gre6gxg0xh2gv5ywheeckrk2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">let your stakeholders tell your ROI story&lt;/a>. Other departments should estimate how much value the data team delivered to them. (
&lt;a href="https://read.readwise.io/read/01gre6kz6hjcyerg4azpszb127" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they can help indirectly by improving &lt;em>processes&lt;/em> and &lt;em>operational efficiency&lt;/em>, saving &lt;em>time&lt;/em> or infrastructure &lt;em>costs&lt;/em>, and gaining more &lt;em>trust&lt;/em> in data and your work. By first writing down what each side expects, you can clarify with stakeholders how data work contributes to &lt;strong>incremental process changes&lt;/strong> that couldn’t have happened without the data team’s involvement. (
&lt;a href="https://read.readwise.io/read/01gre6wdsrg4st52wmzevpptct" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One metric that might help in such situations is the
&lt;a href="https://benn.substack.com/p/method-for-measuring-analytical-work" rel="noopener">&lt;strong>time-to-decision&lt;/strong> framework&lt;/a> proposed by Benn Stancil. The framework is simple: the performance of a data team is measured by how quickly decisions are made. The quicker, the better you are performing (
&lt;a href="https://read.readwise.io/read/01gre6prd5xxyqd4td6jtj85gq" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Another business-oriented measurement is to
&lt;a href="https://hex.tech/blog/data-team-roi/" rel="noopener">&lt;strong>tie data objectives to&lt;/strong> the company’s &lt;strong>OKRs&lt;/strong>&lt;/a> if it’s possible to align those objectives. This approach makes it clearer how the data team’s work impacts functional outcomes. (
&lt;a href="https://read.readwise.io/read/01gre6qqje2k81tj3m3ab5q1gz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the senior leadership should value your team’s work without having to prove it, but if you need to prove it, be ready for it. Show, don’t tell. Show what your team delivered and how it solved business problems in the past. Show the impact of incremental process changes that wouldn’t have happened without this team’s involvement. Show what you changed for the better — how money and time were saved and how operational efficiency improved. And whatever metric you choose, iterate on it — don’t let
&lt;a href="http://prefect.io/" rel="noopener">perfect&lt;/a> be the enemy of good. (
&lt;a href="https://read.readwise.io/read/01gre6xy9g35y6cecwn54z08xx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Simpson&amp;#39;s Paradox and Existential Terror</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Simpsons-Paradox-and-Existential-Terror/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Simpsons-Paradox-and-Existential-Terror/</guid><description>&lt;h1 id="simpsons-paradox-and-existential-terror">Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F015fed92-9e5b-4196-8a60-b47f9e42cfb0_573x435.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vera Wilde]]&lt;/li>
&lt;li>Full Title: Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wildetruth.substack.com/p/simpsons-paradox-and-existential" rel="noopener">https://wildetruth.substack.com/p/simpsons-paradox-and-existential&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Simpson’s paradox explains why an effect can disappear or reverse when data from different groups are combined without accounting for a confound or confounder — a third variable that influences both independent (or intervention or exposure) and dependent (or outcome) variables. (
&lt;a href="https://read.readwise.io/read/01gqnkhpbr1d8301eqeaea31na" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Simpson’s success was prefiguring contemporary statistics reform efforts by emphasizing the need for qualitative knowledge — and not just expert knowledge in the traditional sense, but also, we might say, common sense — to play a central role in statistical analysis. (
&lt;a href="https://read.readwise.io/read/01gqnkp2qgwzbvazaxh6vcx71g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So now we have three problems in talking about Simpson’s paradox: (1) it’s not Simpson’s, in the sense that he wasn’t the first to describe confounding, (2) there’s no paradox, in the sense that you should be thinking about causality early and often when doing statistics, and (3) Simpson’s example was inadvertently showing something closer to the numeric phenomenon of noncollapsibility, a failure of subgroups with high proportions to make simple averages in the aggregate, and not the causal phenomena of confounding that he thought he was talking abou (
&lt;a href="https://read.readwise.io/read/01gqnkswb206b940tpr7f3y61e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s widely recognized that all models omit variables (
&lt;a href="https://read.readwise.io/read/01gqnkv12ghgqtvq779hy89fm6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires understanding a group of related concepts starting with &lt;em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">separation&lt;/a> (d as in dependence; see also “&lt;em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">separation without fears&lt;/a>”), its opposite *d-*connection, and how and why to combine graphs and probabilities to draw conditional independence in a special type of causal logic drawing called
&lt;a href="https://www.cmu.edu/dietrich/philosophy/docs/scheines/introtocausalinference.pdf" rel="noopener">Directed Acyclic Graphs&lt;/a> ( (
&lt;a href="https://read.readwise.io/read/01gqnmj0kry71tw3sqxw7w9an2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmk826s0dmqhymfhz4mqvs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmxamagv61s3cca31ngfr6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>then there’s a beautiful irony in all this: Simpson’s main point — story drives statistics — is getting lost in dressing up science as “objective” when it’s not. (
&lt;a href="https://read.readwise.io/read/01gqnms8fwtqsw9mf2wgctz022" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Vera Wilde]]
title: &amp;ldquo;Simpson's Paradox and Existential Terror&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="simpsons-paradox-and-existential-terror-1">Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F015fed92-9e5b-4196-8a60-b47f9e42cfb0_573x435.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vera Wilde]]&lt;/li>
&lt;li>Full Title: Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wildetruth.substack.com/p/simpsons-paradox-and-existential" rel="noopener">https://wildetruth.substack.com/p/simpsons-paradox-and-existential&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Simpson’s paradox explains why an effect can disappear or reverse when data from different groups are combined without accounting for a confound or confounder — a third variable that influences both independent (or intervention or exposure) and dependent (or outcome) variables. (
&lt;a href="https://read.readwise.io/read/01gqnkhpbr1d8301eqeaea31na" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Simpson’s success was prefiguring contemporary statistics reform efforts by emphasizing the need for qualitative knowledge — and not just expert knowledge in the traditional sense, but also, we might say, common sense — to play a central role in statistical analysis. (
&lt;a href="https://read.readwise.io/read/01gqnkp2qgwzbvazaxh6vcx71g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So now we have three problems in talking about Simpson’s paradox: (1) it’s not Simpson’s, in the sense that he wasn’t the first to describe confounding, (2) there’s no paradox, in the sense that you should be thinking about causality early and often when doing statistics, and (3) Simpson’s example was inadvertently showing something closer to the numeric phenomenon of noncollapsibility, a failure of subgroups with high proportions to make simple averages in the aggregate, and not the causal phenomena of confounding that he thought he was talking abou (
&lt;a href="https://read.readwise.io/read/01gqnkswb206b940tpr7f3y61e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s widely recognized that all models omit variables (
&lt;a href="https://read.readwise.io/read/01gqnkv12ghgqtvq779hy89fm6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires understanding a group of related concepts starting with &lt;em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">separation&lt;/a> (d as in dependence; see also “&lt;em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">separation without fears&lt;/a>”), its opposite *d-*connection, and how and why to combine graphs and probabilities to draw conditional independence in a special type of causal logic drawing called
&lt;a href="https://www.cmu.edu/dietrich/philosophy/docs/scheines/introtocausalinference.pdf" rel="noopener">Directed Acyclic Graphs&lt;/a> ( (
&lt;a href="https://read.readwise.io/read/01gqnmj0kry71tw3sqxw7w9an2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmk826s0dmqhymfhz4mqvs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmxamagv61s3cca31ngfr6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>then there’s a beautiful irony in all this: Simpson’s main point — story drives statistics — is getting lost in dressing up science as “objective” when it’s not. (
&lt;a href="https://read.readwise.io/read/01gqnms8fwtqsw9mf2wgctz022" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Vera Wilde]]
title: &amp;ldquo;Simpson's Paradox and Existential Terror&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="simpsons-paradox-and-existential-terror-2">Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F015fed92-9e5b-4196-8a60-b47f9e42cfb0_573x435.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vera Wilde]]&lt;/li>
&lt;li>Full Title: Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wildetruth.substack.com/p/simpsons-paradox-and-existential" rel="noopener">https://wildetruth.substack.com/p/simpsons-paradox-and-existential&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Simpson’s paradox explains why an effect can disappear or reverse when data from different groups are combined without accounting for a confound or confounder — a third variable that influences both independent (or intervention or exposure) and dependent (or outcome) variables. (
&lt;a href="https://read.readwise.io/read/01gqnkhpbr1d8301eqeaea31na" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Simpson’s success was prefiguring contemporary statistics reform efforts by emphasizing the need for qualitative knowledge — and not just expert knowledge in the traditional sense, but also, we might say, common sense — to play a central role in statistical analysis. (
&lt;a href="https://read.readwise.io/read/01gqnkp2qgwzbvazaxh6vcx71g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So now we have three problems in talking about Simpson’s paradox: (1) it’s not Simpson’s, in the sense that he wasn’t the first to describe confounding, (2) there’s no paradox, in the sense that you should be thinking about causality early and often when doing statistics, and (3) Simpson’s example was inadvertently showing something closer to the numeric phenomenon of noncollapsibility, a failure of subgroups with high proportions to make simple averages in the aggregate, and not the causal phenomena of confounding that he thought he was talking abou (
&lt;a href="https://read.readwise.io/read/01gqnkswb206b940tpr7f3y61e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s widely recognized that all models omit variables (
&lt;a href="https://read.readwise.io/read/01gqnkv12ghgqtvq779hy89fm6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires understanding a group of related concepts starting with &lt;em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">separation&lt;/a> (d as in dependence; see also “&lt;em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">separation without fears&lt;/a>”), its opposite *d-*connection, and how and why to combine graphs and probabilities to draw conditional independence in a special type of causal logic drawing called
&lt;a href="https://www.cmu.edu/dietrich/philosophy/docs/scheines/introtocausalinference.pdf" rel="noopener">Directed Acyclic Graphs&lt;/a> ( (
&lt;a href="https://read.readwise.io/read/01gqnmj0kry71tw3sqxw7w9an2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmk826s0dmqhymfhz4mqvs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmxamagv61s3cca31ngfr6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>then there’s a beautiful irony in all this: Simpson’s main point — story drives statistics — is getting lost in dressing up science as “objective” when it’s not. (
&lt;a href="https://read.readwise.io/read/01gqnms8fwtqsw9mf2wgctz022" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Vera Wilde]]
title: &amp;ldquo;Simpson's Paradox and Existential Terror&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="simpsons-paradox-and-existential-terror-3">Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F015fed92-9e5b-4196-8a60-b47f9e42cfb0_573x435.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vera Wilde]]&lt;/li>
&lt;li>Full Title: Simpson&amp;rsquo;s Paradox and Existential Terror&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://wildetruth.substack.com/p/simpsons-paradox-and-existential" rel="noopener">https://wildetruth.substack.com/p/simpsons-paradox-and-existential&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Simpson’s paradox explains why an effect can disappear or reverse when data from different groups are combined without accounting for a confound or confounder — a third variable that influences both independent (or intervention or exposure) and dependent (or outcome) variables. (
&lt;a href="https://read.readwise.io/read/01gqnkhpbr1d8301eqeaea31na" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Simpson’s success was prefiguring contemporary statistics reform efforts by emphasizing the need for qualitative knowledge — and not just expert knowledge in the traditional sense, but also, we might say, common sense — to play a central role in statistical analysis. (
&lt;a href="https://read.readwise.io/read/01gqnkp2qgwzbvazaxh6vcx71g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So now we have three problems in talking about Simpson’s paradox: (1) it’s not Simpson’s, in the sense that he wasn’t the first to describe confounding, (2) there’s no paradox, in the sense that you should be thinking about causality early and often when doing statistics, and (3) Simpson’s example was inadvertently showing something closer to the numeric phenomenon of noncollapsibility, a failure of subgroups with high proportions to make simple averages in the aggregate, and not the causal phenomena of confounding that he thought he was talking abou (
&lt;a href="https://read.readwise.io/read/01gqnkswb206b940tpr7f3y61e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s widely recognized that all models omit variables (
&lt;a href="https://read.readwise.io/read/01gqnkv12ghgqtvq779hy89fm6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires understanding a group of related concepts starting with &lt;em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="https://www.andrew.cmu.edu/user/scheines/scheines.006/tutor/d-sep.html" rel="noopener">separation&lt;/a> (d as in dependence; see also “&lt;em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">d-&lt;/a>&lt;/em>
&lt;a href="http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation-is-a-criterion,ness%22-or-%22separation%22" rel="noopener">separation without fears&lt;/a>”), its opposite *d-*connection, and how and why to combine graphs and probabilities to draw conditional independence in a special type of causal logic drawing called
&lt;a href="https://www.cmu.edu/dietrich/philosophy/docs/scheines/introtocausalinference.pdf" rel="noopener">Directed Acyclic Graphs&lt;/a> ( (
&lt;a href="https://read.readwise.io/read/01gqnmj0kry71tw3sqxw7w9an2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmk826s0dmqhymfhz4mqvs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>when you hear “Simpson’s paradox,” you should think — “D’OH! Is this the numeric problem of noncollapsibility, the causal problem of simple confounding, or another confound problem, like collider bias?” — (
&lt;a href="https://read.readwise.io/read/01gqnmxamagv61s3cca31ngfr6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>then there’s a beautiful irony in all this: Simpson’s main point — story drives statistics — is getting lost in dressing up science as “objective” when it’s not. (
&lt;a href="https://read.readwise.io/read/01gqnms8fwtqsw9mf2wgctz022" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Sizing Engineering Teams.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Sizing-Engineering-Teams./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Sizing-Engineering-Teams./</guid><description>&lt;h1 id="sizing-engineering-teams">Sizing Engineering Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/sizing-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Sizing Engineering Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/sizing-engineering-teams/" rel="noopener">https://lethain.com/sizing-engineering-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>the fundamental challenge of organizational design is sizing teams. You’ll find yourself sizing teams
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">during reorganizations&lt;/a>, to accommodate growth from hiring, and when considering how to support new projects (
&lt;a href="https://read.readwise.io/read/01grskc88pzmm10tanw50stj25" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Keep innovation and maintenance together&lt;/em>. A frequent practice is to spin up a new team to team to innovate while existing teams are bogged down in maintenance. I’ve historically done this myself, but I’ve moved towards
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">innovating within existing teams&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01grsknfxts2h69pfjamgt31bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Teams should be six to eight during steady state.
• To create a new team, grow an existing team to eight to ten, and then bud into two teams of four or five.
• Never create empty teams.
• Never leave managers supporting more than eight folks. (
&lt;a href="https://read.readwise.io/read/01grskp4dqwmha3q9wasm9gemz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Sizing Engineering Teams.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="sizing-engineering-teams-1">Sizing Engineering Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/sizing-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Sizing Engineering Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/sizing-engineering-teams/" rel="noopener">https://lethain.com/sizing-engineering-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>the fundamental challenge of organizational design is sizing teams. You’ll find yourself sizing teams
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">during reorganizations&lt;/a>, to accommodate growth from hiring, and when considering how to support new projects (
&lt;a href="https://read.readwise.io/read/01grskc88pzmm10tanw50stj25" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Keep innovation and maintenance together&lt;/em>. A frequent practice is to spin up a new team to team to innovate while existing teams are bogged down in maintenance. I’ve historically done this myself, but I’ve moved towards
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">innovating within existing teams&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01grsknfxts2h69pfjamgt31bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Teams should be six to eight during steady state.
• To create a new team, grow an existing team to eight to ten, and then bud into two teams of four or five.
• Never create empty teams.
• Never leave managers supporting more than eight folks. (
&lt;a href="https://read.readwise.io/read/01grskp4dqwmha3q9wasm9gemz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Sizing Engineering Teams.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="sizing-engineering-teams-2">Sizing Engineering Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/sizing-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Sizing Engineering Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/sizing-engineering-teams/" rel="noopener">https://lethain.com/sizing-engineering-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>the fundamental challenge of organizational design is sizing teams. You’ll find yourself sizing teams
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">during reorganizations&lt;/a>, to accommodate growth from hiring, and when considering how to support new projects (
&lt;a href="https://read.readwise.io/read/01grskc88pzmm10tanw50stj25" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Keep innovation and maintenance together&lt;/em>. A frequent practice is to spin up a new team to team to innovate while existing teams are bogged down in maintenance. I’ve historically done this myself, but I’ve moved towards
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">innovating within existing teams&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01grsknfxts2h69pfjamgt31bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Teams should be six to eight during steady state.
• To create a new team, grow an existing team to eight to ten, and then bud into two teams of four or five.
• Never create empty teams.
• Never leave managers supporting more than eight folks. (
&lt;a href="https://read.readwise.io/read/01grskp4dqwmha3q9wasm9gemz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Sizing Engineering Teams.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="sizing-engineering-teams-3">Sizing Engineering Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/sizing-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Sizing Engineering Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/sizing-engineering-teams/" rel="noopener">https://lethain.com/sizing-engineering-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>the fundamental challenge of organizational design is sizing teams. You’ll find yourself sizing teams
&lt;a href="https://lethain.com/running-an-engineering-reorg/" rel="noopener">during reorganizations&lt;/a>, to accommodate growth from hiring, and when considering how to support new projects (
&lt;a href="https://read.readwise.io/read/01grskc88pzmm10tanw50stj25" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>Keep innovation and maintenance together&lt;/em>. A frequent practice is to spin up a new team to team to innovate while existing teams are bogged down in maintenance. I’ve historically done this myself, but I’ve moved towards
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">innovating within existing teams&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01grsknfxts2h69pfjamgt31bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Teams should be six to eight during steady state.
• To create a new team, grow an existing team to eight to ten, and then bud into two teams of four or five.
• Never create empty teams.
• Never leave managers supporting more than eight folks. (
&lt;a href="https://read.readwise.io/read/01grskp4dqwmha3q9wasm9gemz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Staying on the Path to High Performing Teams.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Staying-on-the-Path-to-High-Performing-Teams./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Staying-on-the-Path-to-High-Performing-Teams./</guid><description>&lt;h1 id="staying-on-the-path-to-high-performing-teams">Staying on the Path to High Performing Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/durable-excellent-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Staying on the Path to High Performing Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">https://lethain.com/durably-excellent-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>In order to prioritize hiring for scenarios where it’ll do the most good, over the past year I’ve developed a loose framework for reasoning about what a given team needs to increase performance. (
&lt;a href="https://read.readwise.io/read/01grsmgzzm1ffm5m98wkj65et1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms4ybgf85f88mdwqprx6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms55c4q1kydnfkkv9ar4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teams want to climb from &lt;em>falling behind&lt;/em> to &lt;em>innovation&lt;/em>, while entropy drags you backwards. (
&lt;a href="https://read.readwise.io/read/01grsmnq0a1qhex3ha5p9na9g8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>falling behind&lt;/strong>, the system fix is to hire more people until the team moves into treading water. Provide tactical support by setting expectations with users, beating the drum around the easy wins you can find, and injecting optimism. (
&lt;a href="https://read.readwise.io/read/01grsmrfp5k2mwax3kxmxcvp98" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>treading water&lt;/strong>, the system fix is to add process to consolidate the team’s efforts to finish more things and reduce concurrent work until they’re able to begin repaying debt (
&lt;a href="https://read.readwise.io/read/01grsmtwpjy57v1zt36q0ndh36" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>repaying debt&lt;/strong>, the system fix is to add time. Everything is already working, you just need to find space for the compounding value of paying down technical debt to grow. (
&lt;a href="https://read.readwise.io/read/01grsmvmeevmhhd00y5s83p1bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Especially for a team that started out falling behind and has reached repaying debt, your stakeholders are probably antsy waiting for the team to start delivering new stuff, and your obligation is to prevent that impatience from causing a backslide! (
&lt;a href="https://read.readwise.io/read/01grsmx19kvmyrv42nhbzz478n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>because you’ve nominally reached the end of the continuum, but there is still a system fix! In this case, it’s to maintain enough slack in your team’s schedule that the team can build quality into their work, and operating continuously in innovation, (
&lt;a href="https://read.readwise.io/read/01grsmz97jg20ac6q1vc94k2vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each constraint, prioritize one team at a time. If most teams are &lt;em>falling behind&lt;/em>, then hire onto one team until it’s staffed enough to &lt;em>tread water&lt;/em>, and only then move to the next. While this is true for all constraints, it’s particularly important for hiring. (
&lt;a href="https://read.readwise.io/read/01grsn255qxp25fb65k3yq0vbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding new folks to a team disrupts that team’s gelling process, so I’ve found it much easier to have rapid growth periods &lt;em>for any given team&lt;/em> followed by consolidation/gelling periods where the team gels. The organization will never stop growing, but each team will (
&lt;a href="https://read.readwise.io/read/01grsn2tw53c8t12fq0bgq8gnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Staying on the Path to High Performing Teams.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="staying-on-the-path-to-high-performing-teams-1">Staying on the Path to High Performing Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/durable-excellent-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Staying on the Path to High Performing Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">https://lethain.com/durably-excellent-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>In order to prioritize hiring for scenarios where it’ll do the most good, over the past year I’ve developed a loose framework for reasoning about what a given team needs to increase performance. (
&lt;a href="https://read.readwise.io/read/01grsmgzzm1ffm5m98wkj65et1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms4ybgf85f88mdwqprx6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms55c4q1kydnfkkv9ar4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teams want to climb from &lt;em>falling behind&lt;/em> to &lt;em>innovation&lt;/em>, while entropy drags you backwards. (
&lt;a href="https://read.readwise.io/read/01grsmnq0a1qhex3ha5p9na9g8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>falling behind&lt;/strong>, the system fix is to hire more people until the team moves into treading water. Provide tactical support by setting expectations with users, beating the drum around the easy wins you can find, and injecting optimism. (
&lt;a href="https://read.readwise.io/read/01grsmrfp5k2mwax3kxmxcvp98" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>treading water&lt;/strong>, the system fix is to add process to consolidate the team’s efforts to finish more things and reduce concurrent work until they’re able to begin repaying debt (
&lt;a href="https://read.readwise.io/read/01grsmtwpjy57v1zt36q0ndh36" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>repaying debt&lt;/strong>, the system fix is to add time. Everything is already working, you just need to find space for the compounding value of paying down technical debt to grow. (
&lt;a href="https://read.readwise.io/read/01grsmvmeevmhhd00y5s83p1bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Especially for a team that started out falling behind and has reached repaying debt, your stakeholders are probably antsy waiting for the team to start delivering new stuff, and your obligation is to prevent that impatience from causing a backslide! (
&lt;a href="https://read.readwise.io/read/01grsmx19kvmyrv42nhbzz478n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>because you’ve nominally reached the end of the continuum, but there is still a system fix! In this case, it’s to maintain enough slack in your team’s schedule that the team can build quality into their work, and operating continuously in innovation, (
&lt;a href="https://read.readwise.io/read/01grsmz97jg20ac6q1vc94k2vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each constraint, prioritize one team at a time. If most teams are &lt;em>falling behind&lt;/em>, then hire onto one team until it’s staffed enough to &lt;em>tread water&lt;/em>, and only then move to the next. While this is true for all constraints, it’s particularly important for hiring. (
&lt;a href="https://read.readwise.io/read/01grsn255qxp25fb65k3yq0vbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding new folks to a team disrupts that team’s gelling process, so I’ve found it much easier to have rapid growth periods &lt;em>for any given team&lt;/em> followed by consolidation/gelling periods where the team gels. The organization will never stop growing, but each team will (
&lt;a href="https://read.readwise.io/read/01grsn2tw53c8t12fq0bgq8gnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Staying on the Path to High Performing Teams.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="staying-on-the-path-to-high-performing-teams-2">Staying on the Path to High Performing Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/durable-excellent-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Staying on the Path to High Performing Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">https://lethain.com/durably-excellent-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>In order to prioritize hiring for scenarios where it’ll do the most good, over the past year I’ve developed a loose framework for reasoning about what a given team needs to increase performance. (
&lt;a href="https://read.readwise.io/read/01grsmgzzm1ffm5m98wkj65et1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms4ybgf85f88mdwqprx6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms55c4q1kydnfkkv9ar4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teams want to climb from &lt;em>falling behind&lt;/em> to &lt;em>innovation&lt;/em>, while entropy drags you backwards. (
&lt;a href="https://read.readwise.io/read/01grsmnq0a1qhex3ha5p9na9g8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>falling behind&lt;/strong>, the system fix is to hire more people until the team moves into treading water. Provide tactical support by setting expectations with users, beating the drum around the easy wins you can find, and injecting optimism. (
&lt;a href="https://read.readwise.io/read/01grsmrfp5k2mwax3kxmxcvp98" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>treading water&lt;/strong>, the system fix is to add process to consolidate the team’s efforts to finish more things and reduce concurrent work until they’re able to begin repaying debt (
&lt;a href="https://read.readwise.io/read/01grsmtwpjy57v1zt36q0ndh36" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>repaying debt&lt;/strong>, the system fix is to add time. Everything is already working, you just need to find space for the compounding value of paying down technical debt to grow. (
&lt;a href="https://read.readwise.io/read/01grsmvmeevmhhd00y5s83p1bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Especially for a team that started out falling behind and has reached repaying debt, your stakeholders are probably antsy waiting for the team to start delivering new stuff, and your obligation is to prevent that impatience from causing a backslide! (
&lt;a href="https://read.readwise.io/read/01grsmx19kvmyrv42nhbzz478n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>because you’ve nominally reached the end of the continuum, but there is still a system fix! In this case, it’s to maintain enough slack in your team’s schedule that the team can build quality into their work, and operating continuously in innovation, (
&lt;a href="https://read.readwise.io/read/01grsmz97jg20ac6q1vc94k2vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each constraint, prioritize one team at a time. If most teams are &lt;em>falling behind&lt;/em>, then hire onto one team until it’s staffed enough to &lt;em>tread water&lt;/em>, and only then move to the next. While this is true for all constraints, it’s particularly important for hiring. (
&lt;a href="https://read.readwise.io/read/01grsn255qxp25fb65k3yq0vbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding new folks to a team disrupts that team’s gelling process, so I’ve found it much easier to have rapid growth periods &lt;em>for any given team&lt;/em> followed by consolidation/gelling periods where the team gels. The organization will never stop growing, but each team will (
&lt;a href="https://read.readwise.io/read/01grsn2tw53c8t12fq0bgq8gnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Staying on the Path to High Performing Teams.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="staying-on-the-path-to-high-performing-teams-3">Staying on the Path to High Performing Teams.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/blog/2018/durable-excellent-teams-hero.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Staying on the Path to High Performing Teams.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/durably-excellent-teams/" rel="noopener">https://lethain.com/durably-excellent-teams/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>In order to prioritize hiring for scenarios where it’ll do the most good, over the past year I’ve developed a loose framework for reasoning about what a given team needs to increase performance. (
&lt;a href="https://read.readwise.io/read/01grsmgzzm1ffm5m98wkj65et1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms4ybgf85f88mdwqprx6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://lethain.com/static/blog/2018/4-stages-of-team.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01grsmms55c4q1kydnfkkv9ar4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Teams want to climb from &lt;em>falling behind&lt;/em> to &lt;em>innovation&lt;/em>, while entropy drags you backwards. (
&lt;a href="https://read.readwise.io/read/01grsmnq0a1qhex3ha5p9na9g8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>falling behind&lt;/strong>, the system fix is to hire more people until the team moves into treading water. Provide tactical support by setting expectations with users, beating the drum around the easy wins you can find, and injecting optimism. (
&lt;a href="https://read.readwise.io/read/01grsmrfp5k2mwax3kxmxcvp98" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>treading water&lt;/strong>, the system fix is to add process to consolidate the team’s efforts to finish more things and reduce concurrent work until they’re able to begin repaying debt (
&lt;a href="https://read.readwise.io/read/01grsmtwpjy57v1zt36q0ndh36" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When &lt;strong>repaying debt&lt;/strong>, the system fix is to add time. Everything is already working, you just need to find space for the compounding value of paying down technical debt to grow. (
&lt;a href="https://read.readwise.io/read/01grsmvmeevmhhd00y5s83p1bm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Especially for a team that started out falling behind and has reached repaying debt, your stakeholders are probably antsy waiting for the team to start delivering new stuff, and your obligation is to prevent that impatience from causing a backslide! (
&lt;a href="https://read.readwise.io/read/01grsmx19kvmyrv42nhbzz478n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>because you’ve nominally reached the end of the continuum, but there is still a system fix! In this case, it’s to maintain enough slack in your team’s schedule that the team can build quality into their work, and operating continuously in innovation, (
&lt;a href="https://read.readwise.io/read/01grsmz97jg20ac6q1vc94k2vv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each constraint, prioritize one team at a time. If most teams are &lt;em>falling behind&lt;/em>, then hire onto one team until it’s staffed enough to &lt;em>tread water&lt;/em>, and only then move to the next. While this is true for all constraints, it’s particularly important for hiring. (
&lt;a href="https://read.readwise.io/read/01grsn255qxp25fb65k3yq0vbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Adding new folks to a team disrupts that team’s gelling process, so I’ve found it much easier to have rapid growth periods &lt;em>for any given team&lt;/em> followed by consolidation/gelling periods where the team gels. The organization will never stop growing, but each team will (
&lt;a href="https://read.readwise.io/read/01grsn2tw53c8t12fq0bgq8gnr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Talk Abstract:</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Talk-Abstract/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Talk-Abstract/</guid><description>&lt;h1 id="talk-abstract">Talk Abstract:&lt;/h1>
&lt;p>
&lt;img src="http://static1.squarespace.com/static/5a05ececd55b4165f250f032/t/5cc9ed1ec830253749518ae4/1556737311165/boat-1297042_1280&amp;#43;%281%29.png?format=1500w" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[No Idea Blog]]&lt;/li>
&lt;li>Full Title: Talk Abstract:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Glue work refers to the less glamorous, less-promotable work that is necessary to make a team successful. It can include onboarding new people and making them productive faster, improving processes to make customers happy, and filling the gap between a project that succeeds and one that fails. It often requires technical leadership skills and can be career-limiting if left unconscious.&lt;/li>
&lt;li>URL:
&lt;a href="https://noidea.dog/glue" rel="noopener">https://noidea.dog/glue&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting. It can push people into less technical roles and even out of the industry. (
&lt;a href="https://read.readwise.io/read/01gryr90zaf4vnn457884yrygm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Like noticing when other people in the team are blocked and helping them out. Or reviewing design documents and noticing what&amp;rsquo;s being handwaved or what&amp;rsquo;s inconsistent. Or onboarding the new people and making them productive faster. Or improving processes to make customers happy. (
&lt;a href="https://read.readwise.io/read/01gryra63gaq73kbp7mbf9dg8x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing glue work too early can be &lt;strong>career limiting&lt;/strong>, or even push people out of the industry.
It&amp;rsquo;s ironic. We lose good engineers because they happen to &lt;strong>also be good at other skills we need.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gryrbcpd4575e0bwe909yer4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>want to be clear that I&amp;rsquo;m not saying 100% of your work needs to be promotable work. It&amp;rsquo;s good to build auxiliary skills and expand your horizons, and it&amp;rsquo;s important for everyone to do their fair share of taking out the garbage. But a large percentage of your work should be the thing you&amp;rsquo;re evaluated on. (
&lt;a href="https://read.readwise.io/read/01gryrrshbvjyj89khvnf8zb3c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Non-promotable work is one of those &amp;ldquo;one person&amp;rsquo;s trash is another&amp;rsquo;s treasure&amp;rdquo; things. Like, if an engineer organises an offsite, that&amp;rsquo;s non-promotable work, but a people manager can maybe claim it&amp;rsquo;s part of their job to do team-building. If an event coordinator does it, it&amp;rsquo;s probably their core job. (
&lt;a href="https://read.readwise.io/read/01grysfmdpz6nre0z5cxmyjs8p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I advise people to choose deliberately. Choose a role that you&amp;rsquo;ll feel successful and happy and proud to say you do, and that will teach you skills you want. Do a job you’re excited by. You will learn to get good at it by doing it. I feel like we don&amp;rsquo;t admit it often enough enough that most of the time, we won&amp;rsquo;t do a job well on day one. The vast majority of our learning happens on the job. (
&lt;a href="https://read.readwise.io/read/01gryskan5a6j22f1c9s3ye5pc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>junior. Taking a step away from a more technical role closes doors. It&amp;rsquo;s not fair, but our industry biases are set up so that you really need to have a solid engineering resume before you take a non-engineering role (
&lt;a href="https://read.readwise.io/read/01gryszccsbsn0pbz11q9sqnw1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>industry. I&amp;rsquo;ve seen some look back at engineer jobs and discover that they also can&amp;rsquo;t get hired at the level of developer they used to be, even if it was quite recent. As if the skills they had have evaporated. (
&lt;a href="https://read.readwise.io/read/01gryt0xw9c07a3g976s2167vz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re ever tempted to tell someone they&amp;rsquo;re not technical enough, well, first of all just don’t. But be really specific about what you need them to know. (
&lt;a href="https://read.readwise.io/read/01gryt2emdaqda6r79vyrj7gke" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People expect a lead to do a ton of glue. (
&lt;a href="https://read.readwise.io/read/01gryt5phrzdr6grp1jah18sjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A job title saves time and energy that we don’t need to spend putting our credentials on the table (
&lt;a href="https://read.readwise.io/read/01gryt6za3wbmb9g73verw32ka" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re a senior person, please, show the junior people in your organisation that you&amp;rsquo;re learning and how you&amp;rsquo;re doing it. Be public about what you&amp;rsquo;re learning. (
&lt;a href="https://read.readwise.io/read/01grytcf39xa8gnpb6zvmnwecd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So make it clear that it&amp;rsquo;s okay &amp;ndash; and normal &amp;ndash; to learn at work, during work hours. (
&lt;a href="https://read.readwise.io/read/01grytcxvbvw2v03j2a6mjc84g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Managers: If your job ladder doesn&amp;rsquo;t require that your senior people have glue work skills, think about how you&amp;rsquo;re expecting that work to get done. (
&lt;a href="https://read.readwise.io/read/01grytfjqb7tbmb6ssr64j99t9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[No Idea Blog]]
title: &amp;ldquo;Talk Abstract:&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="talk-abstract-1">Talk Abstract:&lt;/h1>
&lt;p>
&lt;img src="http://static1.squarespace.com/static/5a05ececd55b4165f250f032/t/5cc9ed1ec830253749518ae4/1556737311165/boat-1297042_1280&amp;#43;%281%29.png?format=1500w" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[No Idea Blog]]&lt;/li>
&lt;li>Full Title: Talk Abstract:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Glue work refers to the less glamorous, less-promotable work that is necessary to make a team successful. It can include onboarding new people and making them productive faster, improving processes to make customers happy, and filling the gap between a project that succeeds and one that fails. It often requires technical leadership skills and can be career-limiting if left unconscious.&lt;/li>
&lt;li>URL:
&lt;a href="https://noidea.dog/glue" rel="noopener">https://noidea.dog/glue&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting. It can push people into less technical roles and even out of the industry. (
&lt;a href="https://read.readwise.io/read/01gryr90zaf4vnn457884yrygm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Like noticing when other people in the team are blocked and helping them out. Or reviewing design documents and noticing what&amp;rsquo;s being handwaved or what&amp;rsquo;s inconsistent. Or onboarding the new people and making them productive faster. Or improving processes to make customers happy. (
&lt;a href="https://read.readwise.io/read/01gryra63gaq73kbp7mbf9dg8x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing glue work too early can be &lt;strong>career limiting&lt;/strong>, or even push people out of the industry.
It&amp;rsquo;s ironic. We lose good engineers because they happen to &lt;strong>also be good at other skills we need.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gryrbcpd4575e0bwe909yer4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>want to be clear that I&amp;rsquo;m not saying 100% of your work needs to be promotable work. It&amp;rsquo;s good to build auxiliary skills and expand your horizons, and it&amp;rsquo;s important for everyone to do their fair share of taking out the garbage. But a large percentage of your work should be the thing you&amp;rsquo;re evaluated on. (
&lt;a href="https://read.readwise.io/read/01gryrrshbvjyj89khvnf8zb3c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Non-promotable work is one of those &amp;ldquo;one person&amp;rsquo;s trash is another&amp;rsquo;s treasure&amp;rdquo; things. Like, if an engineer organises an offsite, that&amp;rsquo;s non-promotable work, but a people manager can maybe claim it&amp;rsquo;s part of their job to do team-building. If an event coordinator does it, it&amp;rsquo;s probably their core job. (
&lt;a href="https://read.readwise.io/read/01grysfmdpz6nre0z5cxmyjs8p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I advise people to choose deliberately. Choose a role that you&amp;rsquo;ll feel successful and happy and proud to say you do, and that will teach you skills you want. Do a job you’re excited by. You will learn to get good at it by doing it. I feel like we don&amp;rsquo;t admit it often enough enough that most of the time, we won&amp;rsquo;t do a job well on day one. The vast majority of our learning happens on the job. (
&lt;a href="https://read.readwise.io/read/01gryskan5a6j22f1c9s3ye5pc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>junior. Taking a step away from a more technical role closes doors. It&amp;rsquo;s not fair, but our industry biases are set up so that you really need to have a solid engineering resume before you take a non-engineering role (
&lt;a href="https://read.readwise.io/read/01gryszccsbsn0pbz11q9sqnw1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>industry. I&amp;rsquo;ve seen some look back at engineer jobs and discover that they also can&amp;rsquo;t get hired at the level of developer they used to be, even if it was quite recent. As if the skills they had have evaporated. (
&lt;a href="https://read.readwise.io/read/01gryt0xw9c07a3g976s2167vz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re ever tempted to tell someone they&amp;rsquo;re not technical enough, well, first of all just don’t. But be really specific about what you need them to know. (
&lt;a href="https://read.readwise.io/read/01gryt2emdaqda6r79vyrj7gke" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People expect a lead to do a ton of glue. (
&lt;a href="https://read.readwise.io/read/01gryt5phrzdr6grp1jah18sjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A job title saves time and energy that we don’t need to spend putting our credentials on the table (
&lt;a href="https://read.readwise.io/read/01gryt6za3wbmb9g73verw32ka" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re a senior person, please, show the junior people in your organisation that you&amp;rsquo;re learning and how you&amp;rsquo;re doing it. Be public about what you&amp;rsquo;re learning. (
&lt;a href="https://read.readwise.io/read/01grytcf39xa8gnpb6zvmnwecd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So make it clear that it&amp;rsquo;s okay &amp;ndash; and normal &amp;ndash; to learn at work, during work hours. (
&lt;a href="https://read.readwise.io/read/01grytcxvbvw2v03j2a6mjc84g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Managers: If your job ladder doesn&amp;rsquo;t require that your senior people have glue work skills, think about how you&amp;rsquo;re expecting that work to get done. (
&lt;a href="https://read.readwise.io/read/01grytfjqb7tbmb6ssr64j99t9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[No Idea Blog]]
title: &amp;ldquo;Talk Abstract:&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="talk-abstract-2">Talk Abstract:&lt;/h1>
&lt;p>
&lt;img src="http://static1.squarespace.com/static/5a05ececd55b4165f250f032/t/5cc9ed1ec830253749518ae4/1556737311165/boat-1297042_1280&amp;#43;%281%29.png?format=1500w" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[No Idea Blog]]&lt;/li>
&lt;li>Full Title: Talk Abstract:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Glue work refers to the less glamorous, less-promotable work that is necessary to make a team successful. It can include onboarding new people and making them productive faster, improving processes to make customers happy, and filling the gap between a project that succeeds and one that fails. It often requires technical leadership skills and can be career-limiting if left unconscious.&lt;/li>
&lt;li>URL:
&lt;a href="https://noidea.dog/glue" rel="noopener">https://noidea.dog/glue&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting. It can push people into less technical roles and even out of the industry. (
&lt;a href="https://read.readwise.io/read/01gryr90zaf4vnn457884yrygm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Like noticing when other people in the team are blocked and helping them out. Or reviewing design documents and noticing what&amp;rsquo;s being handwaved or what&amp;rsquo;s inconsistent. Or onboarding the new people and making them productive faster. Or improving processes to make customers happy. (
&lt;a href="https://read.readwise.io/read/01gryra63gaq73kbp7mbf9dg8x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing glue work too early can be &lt;strong>career limiting&lt;/strong>, or even push people out of the industry.
It&amp;rsquo;s ironic. We lose good engineers because they happen to &lt;strong>also be good at other skills we need.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gryrbcpd4575e0bwe909yer4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>want to be clear that I&amp;rsquo;m not saying 100% of your work needs to be promotable work. It&amp;rsquo;s good to build auxiliary skills and expand your horizons, and it&amp;rsquo;s important for everyone to do their fair share of taking out the garbage. But a large percentage of your work should be the thing you&amp;rsquo;re evaluated on. (
&lt;a href="https://read.readwise.io/read/01gryrrshbvjyj89khvnf8zb3c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Non-promotable work is one of those &amp;ldquo;one person&amp;rsquo;s trash is another&amp;rsquo;s treasure&amp;rdquo; things. Like, if an engineer organises an offsite, that&amp;rsquo;s non-promotable work, but a people manager can maybe claim it&amp;rsquo;s part of their job to do team-building. If an event coordinator does it, it&amp;rsquo;s probably their core job. (
&lt;a href="https://read.readwise.io/read/01grysfmdpz6nre0z5cxmyjs8p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I advise people to choose deliberately. Choose a role that you&amp;rsquo;ll feel successful and happy and proud to say you do, and that will teach you skills you want. Do a job you’re excited by. You will learn to get good at it by doing it. I feel like we don&amp;rsquo;t admit it often enough enough that most of the time, we won&amp;rsquo;t do a job well on day one. The vast majority of our learning happens on the job. (
&lt;a href="https://read.readwise.io/read/01gryskan5a6j22f1c9s3ye5pc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>junior. Taking a step away from a more technical role closes doors. It&amp;rsquo;s not fair, but our industry biases are set up so that you really need to have a solid engineering resume before you take a non-engineering role (
&lt;a href="https://read.readwise.io/read/01gryszccsbsn0pbz11q9sqnw1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>industry. I&amp;rsquo;ve seen some look back at engineer jobs and discover that they also can&amp;rsquo;t get hired at the level of developer they used to be, even if it was quite recent. As if the skills they had have evaporated. (
&lt;a href="https://read.readwise.io/read/01gryt0xw9c07a3g976s2167vz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re ever tempted to tell someone they&amp;rsquo;re not technical enough, well, first of all just don’t. But be really specific about what you need them to know. (
&lt;a href="https://read.readwise.io/read/01gryt2emdaqda6r79vyrj7gke" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People expect a lead to do a ton of glue. (
&lt;a href="https://read.readwise.io/read/01gryt5phrzdr6grp1jah18sjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A job title saves time and energy that we don’t need to spend putting our credentials on the table (
&lt;a href="https://read.readwise.io/read/01gryt6za3wbmb9g73verw32ka" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re a senior person, please, show the junior people in your organisation that you&amp;rsquo;re learning and how you&amp;rsquo;re doing it. Be public about what you&amp;rsquo;re learning. (
&lt;a href="https://read.readwise.io/read/01grytcf39xa8gnpb6zvmnwecd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So make it clear that it&amp;rsquo;s okay &amp;ndash; and normal &amp;ndash; to learn at work, during work hours. (
&lt;a href="https://read.readwise.io/read/01grytcxvbvw2v03j2a6mjc84g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Managers: If your job ladder doesn&amp;rsquo;t require that your senior people have glue work skills, think about how you&amp;rsquo;re expecting that work to get done. (
&lt;a href="https://read.readwise.io/read/01grytfjqb7tbmb6ssr64j99t9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[No Idea Blog]]
title: &amp;ldquo;Talk Abstract:&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="talk-abstract-3">Talk Abstract:&lt;/h1>
&lt;p>
&lt;img src="http://static1.squarespace.com/static/5a05ececd55b4165f250f032/t/5cc9ed1ec830253749518ae4/1556737311165/boat-1297042_1280&amp;#43;%281%29.png?format=1500w" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[No Idea Blog]]&lt;/li>
&lt;li>Full Title: Talk Abstract:&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Glue work refers to the less glamorous, less-promotable work that is necessary to make a team successful. It can include onboarding new people and making them productive faster, improving processes to make customers happy, and filling the gap between a project that succeeds and one that fails. It often requires technical leadership skills and can be career-limiting if left unconscious.&lt;/li>
&lt;li>URL:
&lt;a href="https://noidea.dog/glue" rel="noopener">https://noidea.dog/glue&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting. It can push people into less technical roles and even out of the industry. (
&lt;a href="https://read.readwise.io/read/01gryr90zaf4vnn457884yrygm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Like noticing when other people in the team are blocked and helping them out. Or reviewing design documents and noticing what&amp;rsquo;s being handwaved or what&amp;rsquo;s inconsistent. Or onboarding the new people and making them productive faster. Or improving processes to make customers happy. (
&lt;a href="https://read.readwise.io/read/01gryra63gaq73kbp7mbf9dg8x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing glue work too early can be &lt;strong>career limiting&lt;/strong>, or even push people out of the industry.
It&amp;rsquo;s ironic. We lose good engineers because they happen to &lt;strong>also be good at other skills we need.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gryrbcpd4575e0bwe909yer4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>want to be clear that I&amp;rsquo;m not saying 100% of your work needs to be promotable work. It&amp;rsquo;s good to build auxiliary skills and expand your horizons, and it&amp;rsquo;s important for everyone to do their fair share of taking out the garbage. But a large percentage of your work should be the thing you&amp;rsquo;re evaluated on. (
&lt;a href="https://read.readwise.io/read/01gryrrshbvjyj89khvnf8zb3c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Non-promotable work is one of those &amp;ldquo;one person&amp;rsquo;s trash is another&amp;rsquo;s treasure&amp;rdquo; things. Like, if an engineer organises an offsite, that&amp;rsquo;s non-promotable work, but a people manager can maybe claim it&amp;rsquo;s part of their job to do team-building. If an event coordinator does it, it&amp;rsquo;s probably their core job. (
&lt;a href="https://read.readwise.io/read/01grysfmdpz6nre0z5cxmyjs8p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I advise people to choose deliberately. Choose a role that you&amp;rsquo;ll feel successful and happy and proud to say you do, and that will teach you skills you want. Do a job you’re excited by. You will learn to get good at it by doing it. I feel like we don&amp;rsquo;t admit it often enough enough that most of the time, we won&amp;rsquo;t do a job well on day one. The vast majority of our learning happens on the job. (
&lt;a href="https://read.readwise.io/read/01gryskan5a6j22f1c9s3ye5pc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>junior. Taking a step away from a more technical role closes doors. It&amp;rsquo;s not fair, but our industry biases are set up so that you really need to have a solid engineering resume before you take a non-engineering role (
&lt;a href="https://read.readwise.io/read/01gryszccsbsn0pbz11q9sqnw1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>industry. I&amp;rsquo;ve seen some look back at engineer jobs and discover that they also can&amp;rsquo;t get hired at the level of developer they used to be, even if it was quite recent. As if the skills they had have evaporated. (
&lt;a href="https://read.readwise.io/read/01gryt0xw9c07a3g976s2167vz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re ever tempted to tell someone they&amp;rsquo;re not technical enough, well, first of all just don’t. But be really specific about what you need them to know. (
&lt;a href="https://read.readwise.io/read/01gryt2emdaqda6r79vyrj7gke" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>People expect a lead to do a ton of glue. (
&lt;a href="https://read.readwise.io/read/01gryt5phrzdr6grp1jah18sjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A job title saves time and energy that we don’t need to spend putting our credentials on the table (
&lt;a href="https://read.readwise.io/read/01gryt6za3wbmb9g73verw32ka" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you&amp;rsquo;re a senior person, please, show the junior people in your organisation that you&amp;rsquo;re learning and how you&amp;rsquo;re doing it. Be public about what you&amp;rsquo;re learning. (
&lt;a href="https://read.readwise.io/read/01grytcf39xa8gnpb6zvmnwecd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>So make it clear that it&amp;rsquo;s okay &amp;ndash; and normal &amp;ndash; to learn at work, during work hours. (
&lt;a href="https://read.readwise.io/read/01grytcxvbvw2v03j2a6mjc84g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Managers: If your job ladder doesn&amp;rsquo;t require that your senior people have glue work skills, think about how you&amp;rsquo;re expecting that work to get done. (
&lt;a href="https://read.readwise.io/read/01grytfjqb7tbmb6ssr64j99t9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Team Topology for Machine Learning</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Team-Topology-for-Machine-Learning/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Team-Topology-for-Machine-Learning/</guid><description>&lt;h1 id="team-topology-for-machine-learning">Team Topology for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*VcGdfLg0pDBXqZiNxPyrPQ.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Team Topology for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This posts deals with an adaptation of
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> to ML applications. In order to break the monolyth in smaller subsystems the book identifies team boundaries based on the cognitive load capacity of teams.
ML topologies:
&lt;ul>
&lt;li>Stream-aligned ML teams: Develop and manage ML applications for end-users. The scope of the team is determined by the cognitive load of the team. For instance, a recommender system solution might not vary much for residential and not residential assets, so a slightly larger team might deal with both. However, the recommender system might be very different for idealista users vs real estate agencies, requiring two different teams.&lt;/li>
&lt;li>Data/infrastructure subsystem teams: Data and infrastructure teams are different breads buy they are both specialist subsystem teams. These teams ensure data and infra management policy are centralized.&lt;/li>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">A platform is more than just software and APIs — it is documentation, consulting, support, evangelism, templates, and guidelines
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;a href="https://martinfowler.com/articles/talk-about-platforms.html" rel="noopener">What I talk about when I talk about platforms&lt;/a>
&lt;ul>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;li>ML Enabling Teams: Internal coaches of stream-aligned ML teams so that they can adopt missing capabilities or use the data platform.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3" rel="noopener">https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> pushes the idea of team-sized software. It stems from
&lt;a href="https://en.wikipedia.org/wiki/Conway%27s_law" rel="noopener">Conway’s Law&lt;/a> that states an organization will produce a system design following the organization’s communication structure. (
&lt;a href="https://read.readwise.io/read/01gs3nn5k2yx36hzrqt1rycxb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Based on this idea, the book defines an alternate approach to identify team boundaries based on specific types of four teams, namely, &lt;em>stream-aligned&lt;/em>, &lt;em>complicated subsystem&lt;/em>, &lt;em>platform&lt;/em>, and &lt;em>enabling&lt;/em> teams. (
&lt;a href="https://read.readwise.io/read/01gs3nnhv826ypybpx83t1h7g4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Misbah Uddin]]
title: &amp;ldquo;Team Topology for Machine Learning&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="team-topology-for-machine-learning-1">Team Topology for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*VcGdfLg0pDBXqZiNxPyrPQ.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Team Topology for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This posts deals with an adaptation of
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> to ML applications. In order to break the monolyth in smaller subsystems the book identifies team boundaries based on the cognitive load capacity of teams.
ML topologies:
&lt;ul>
&lt;li>Stream-aligned ML teams: Develop and manage ML applications for end-users. The scope of the team is determined by the cognitive load of the team. For instance, a recommender system solution might not vary much for residential and not residential assets, so a slightly larger team might deal with both. However, the recommender system might be very different for idealista users vs real estate agencies, requiring two different teams.&lt;/li>
&lt;li>Data/infrastructure subsystem teams: Data and infrastructure teams are different breads buy they are both specialist subsystem teams. These teams ensure data and infra management policy are centralized.&lt;/li>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">A platform is more than just software and APIs — it is documentation, consulting, support, evangelism, templates, and guidelines
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;a href="https://martinfowler.com/articles/talk-about-platforms.html" rel="noopener">What I talk about when I talk about platforms&lt;/a>
&lt;ul>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;li>ML Enabling Teams: Internal coaches of stream-aligned ML teams so that they can adopt missing capabilities or use the data platform.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3" rel="noopener">https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> pushes the idea of team-sized software. It stems from
&lt;a href="https://en.wikipedia.org/wiki/Conway%27s_law" rel="noopener">Conway’s Law&lt;/a> that states an organization will produce a system design following the organization’s communication structure. (
&lt;a href="https://read.readwise.io/read/01gs3nn5k2yx36hzrqt1rycxb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Based on this idea, the book defines an alternate approach to identify team boundaries based on specific types of four teams, namely, &lt;em>stream-aligned&lt;/em>, &lt;em>complicated subsystem&lt;/em>, &lt;em>platform&lt;/em>, and &lt;em>enabling&lt;/em> teams. (
&lt;a href="https://read.readwise.io/read/01gs3nnhv826ypybpx83t1h7g4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Misbah Uddin]]
title: &amp;ldquo;Team Topology for Machine Learning&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="team-topology-for-machine-learning-2">Team Topology for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*VcGdfLg0pDBXqZiNxPyrPQ.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Team Topology for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This posts deals with an adaptation of
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> to ML applications. In order to break the monolyth in smaller subsystems the book identifies team boundaries based on the cognitive load capacity of teams.
ML topologies:
&lt;ul>
&lt;li>Stream-aligned ML teams: Develop and manage ML applications for end-users. The scope of the team is determined by the cognitive load of the team. For instance, a recommender system solution might not vary much for residential and not residential assets, so a slightly larger team might deal with both. However, the recommender system might be very different for idealista users vs real estate agencies, requiring two different teams.&lt;/li>
&lt;li>Data/infrastructure subsystem teams: Data and infrastructure teams are different breads buy they are both specialist subsystem teams. These teams ensure data and infra management policy are centralized.&lt;/li>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">A platform is more than just software and APIs — it is documentation, consulting, support, evangelism, templates, and guidelines
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;a href="https://martinfowler.com/articles/talk-about-platforms.html" rel="noopener">What I talk about when I talk about platforms&lt;/a>
&lt;ul>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;li>ML Enabling Teams: Internal coaches of stream-aligned ML teams so that they can adopt missing capabilities or use the data platform.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3" rel="noopener">https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> pushes the idea of team-sized software. It stems from
&lt;a href="https://en.wikipedia.org/wiki/Conway%27s_law" rel="noopener">Conway’s Law&lt;/a> that states an organization will produce a system design following the organization’s communication structure. (
&lt;a href="https://read.readwise.io/read/01gs3nn5k2yx36hzrqt1rycxb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Based on this idea, the book defines an alternate approach to identify team boundaries based on specific types of four teams, namely, &lt;em>stream-aligned&lt;/em>, &lt;em>complicated subsystem&lt;/em>, &lt;em>platform&lt;/em>, and &lt;em>enabling&lt;/em> teams. (
&lt;a href="https://read.readwise.io/read/01gs3nnhv826ypybpx83t1h7g4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Misbah Uddin]]
title: &amp;ldquo;Team Topology for Machine Learning&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="team-topology-for-machine-learning-3">Team Topology for Machine Learning&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/1*VcGdfLg0pDBXqZiNxPyrPQ.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Misbah Uddin]]&lt;/li>
&lt;li>Full Title: Team Topology for Machine Learning&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: This posts deals with an adaptation of
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> to ML applications. In order to break the monolyth in smaller subsystems the book identifies team boundaries based on the cognitive load capacity of teams.
ML topologies:
&lt;ul>
&lt;li>Stream-aligned ML teams: Develop and manage ML applications for end-users. The scope of the team is determined by the cognitive load of the team. For instance, a recommender system solution might not vary much for residential and not residential assets, so a slightly larger team might deal with both. However, the recommender system might be very different for idealista users vs real estate agencies, requiring two different teams.&lt;/li>
&lt;li>Data/infrastructure subsystem teams: Data and infrastructure teams are different breads buy they are both specialist subsystem teams. These teams ensure data and infra management policy are centralized.&lt;/li>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">A platform is more than just software and APIs — it is documentation, consulting, support, evangelism, templates, and guidelines
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>
&lt;a href="https://martinfowler.com/articles/talk-about-platforms.html" rel="noopener">What I talk about when I talk about platforms&lt;/a>
&lt;ul>
&lt;li>ML Platform teams: Develop end-to-end ML platforms so that stream-aligned ML teams do not have to worry about low-level management and communication between ML artifacts.&lt;/li>
&lt;li>ML Enabling Teams: Internal coaches of stream-aligned ML teams so that they can adopt missing capabilities or use the data platform.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>URL:
&lt;a href="https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3" rel="noopener">https://towardsdatascience.com/team-topology-for-machine-learning-45bddba626e3&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>
&lt;a href="https://teamtopologies.com/book" rel="noopener">Team Topology&lt;/a> pushes the idea of team-sized software. It stems from
&lt;a href="https://en.wikipedia.org/wiki/Conway%27s_law" rel="noopener">Conway’s Law&lt;/a> that states an organization will produce a system design following the organization’s communication structure. (
&lt;a href="https://read.readwise.io/read/01gs3nn5k2yx36hzrqt1rycxb6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Based on this idea, the book defines an alternate approach to identify team boundaries based on specific types of four teams, namely, &lt;em>stream-aligned&lt;/em>, &lt;em>complicated subsystem&lt;/em>, &lt;em>platform&lt;/em>, and &lt;em>enabling&lt;/em> teams. (
&lt;a href="https://read.readwise.io/read/01gs3nnhv826ypybpx83t1h7g4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>The Art of Pushback for Data Product Managers and Leaders</title><link>https://pelayoarbues.github.io/literature-notes/Articles/The-Art-of-Pushback-for-Data-Product-Managers-and-Leaders/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/The-Art-of-Pushback-for-Data-Product-Managers-and-Leaders/</guid><description>&lt;h1 id="the-art-of-pushback-for-data-product-managers-and-leaders">The Art of Pushback for Data Product Managers and Leaders&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/22f8cce1-7dc2-48c4-a327-4449260281c6_1200x630.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vin Vashishta]]&lt;/li>
&lt;li>Full Title: The Art of Pushback for Data Product Managers and Leaders&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product" rel="noopener">https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Prioritization is a critical Data Product Manager and Data Team Leader function. They protect the data team from being pulled in several directions and allow them to focus on high-value work. (
&lt;a href="https://read.readwise.io/read/01gqzqxawwyq5jyw6k91h0j5sa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing someone a favor is worth the negative impact to build a strong relationship with our customers and users. That’s a critical behavior for coalition building, creating momentum and support for data initiatives in the long run. (
&lt;a href="https://read.readwise.io/read/01gqzqy05rgz8qs9wfdjqgdks9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>strategies to deal with those requests.
&lt;ol>
&lt;li>Have a single resource (a rotation where each person on the data team takes a week) dedicated to fielding these requests.&lt;/li>
&lt;li>Setting aside a single day each week to manage these requests. (
&lt;a href="https://read.readwise.io/read/01gqzqynwdm3g90mjvbz6hbftf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Vin Vashishta]]
title: &amp;ldquo;The Art of Pushback for Data Product Managers and Leaders&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-art-of-pushback-for-data-product-managers-and-leaders-1">The Art of Pushback for Data Product Managers and Leaders&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/22f8cce1-7dc2-48c4-a327-4449260281c6_1200x630.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vin Vashishta]]&lt;/li>
&lt;li>Full Title: The Art of Pushback for Data Product Managers and Leaders&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product" rel="noopener">https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Prioritization is a critical Data Product Manager and Data Team Leader function. They protect the data team from being pulled in several directions and allow them to focus on high-value work. (
&lt;a href="https://read.readwise.io/read/01gqzqxawwyq5jyw6k91h0j5sa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing someone a favor is worth the negative impact to build a strong relationship with our customers and users. That’s a critical behavior for coalition building, creating momentum and support for data initiatives in the long run. (
&lt;a href="https://read.readwise.io/read/01gqzqy05rgz8qs9wfdjqgdks9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>strategies to deal with those requests.
&lt;ol>
&lt;li>Have a single resource (a rotation where each person on the data team takes a week) dedicated to fielding these requests.&lt;/li>
&lt;li>Setting aside a single day each week to manage these requests. (
&lt;a href="https://read.readwise.io/read/01gqzqynwdm3g90mjvbz6hbftf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Vin Vashishta]]
title: &amp;ldquo;The Art of Pushback for Data Product Managers and Leaders&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-art-of-pushback-for-data-product-managers-and-leaders-2">The Art of Pushback for Data Product Managers and Leaders&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/22f8cce1-7dc2-48c4-a327-4449260281c6_1200x630.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vin Vashishta]]&lt;/li>
&lt;li>Full Title: The Art of Pushback for Data Product Managers and Leaders&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product" rel="noopener">https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Prioritization is a critical Data Product Manager and Data Team Leader function. They protect the data team from being pulled in several directions and allow them to focus on high-value work. (
&lt;a href="https://read.readwise.io/read/01gqzqxawwyq5jyw6k91h0j5sa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing someone a favor is worth the negative impact to build a strong relationship with our customers and users. That’s a critical behavior for coalition building, creating momentum and support for data initiatives in the long run. (
&lt;a href="https://read.readwise.io/read/01gqzqy05rgz8qs9wfdjqgdks9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>strategies to deal with those requests.
&lt;ol>
&lt;li>Have a single resource (a rotation where each person on the data team takes a week) dedicated to fielding these requests.&lt;/li>
&lt;li>Setting aside a single day each week to manage these requests. (
&lt;a href="https://read.readwise.io/read/01gqzqynwdm3g90mjvbz6hbftf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Vin Vashishta]]
title: &amp;ldquo;The Art of Pushback for Data Product Managers and Leaders&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-art-of-pushback-for-data-product-managers-and-leaders-3">The Art of Pushback for Data Product Managers and Leaders&lt;/h1>
&lt;p>
&lt;img src="https://substack-post-media.s3.amazonaws.com/public/images/22f8cce1-7dc2-48c4-a327-4449260281c6_1200x630.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Vin Vashishta]]&lt;/li>
&lt;li>Full Title: The Art of Pushback for Data Product Managers and Leaders&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product" rel="noopener">https://vinvashishta.substack.com/p/the-art-of-pushback-for-data-product&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Prioritization is a critical Data Product Manager and Data Team Leader function. They protect the data team from being pulled in several directions and allow them to focus on high-value work. (
&lt;a href="https://read.readwise.io/read/01gqzqxawwyq5jyw6k91h0j5sa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>doing someone a favor is worth the negative impact to build a strong relationship with our customers and users. That’s a critical behavior for coalition building, creating momentum and support for data initiatives in the long run. (
&lt;a href="https://read.readwise.io/read/01gqzqy05rgz8qs9wfdjqgdks9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>strategies to deal with those requests.
&lt;ol>
&lt;li>Have a single resource (a rotation where each person on the data team takes a week) dedicated to fielding these requests.&lt;/li>
&lt;li>Setting aside a single day each week to manage these requests. (
&lt;a href="https://read.readwise.io/read/01gqzqynwdm3g90mjvbz6hbftf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul></description></item><item><title>The Enlightenment Trap</title><link>https://pelayoarbues.github.io/literature-notes/Articles/The-Enlightenment-Trap/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/The-Enlightenment-Trap/</guid><description>&lt;h1 id="the-enlightenment-trap">The Enlightenment Trap&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3da270f-a2f2-48ee-994a-498c072607a5_1178x606.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Kurt Gray]]&lt;/li>
&lt;li>Full Title: The Enlightenment Trap&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;amp;utm_campaign=Causas-y-Azares&amp;amp;utm_medium=email&amp;amp;utm_source=Revue-newsletter" rel="noopener">https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;utm_campaign=Causas%20y%20Azares&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>The problem is not with humility itself, but with what happens to our minds when we see ourselves as intellectually humble. We call this problem &amp;ldquo;The Enlightenment Trap,” (
&lt;a href="https://read.readwise.io/read/01gs91b3kkchctbtj1d5g0qhmz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his book “
&lt;a href="https://www.amazon.com/dp/B073TJBYTB/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Enlightenment Now&lt;/a>,” Stephen Pinker emphasized that the recognition of the fallibility and limits of our perspective was a central feature of the 17th-century enlightenment revolution. (
&lt;a href="https://read.readwise.io/read/01gs91cc1cv0wr2screryxsa4s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap is the idea that humility**,** although initially reducing your biases, can trap you into another kind of bias—self-conceit. And while a bit of self-flattery might not be the end of the world, pride and prejudice are connected, as Jane Austin long ago recognized. (
&lt;a href="https://read.readwise.io/read/01gs91em5z7exbmsg7x5qbzk57" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first step in the enlightenment trap is a good step: you begin to recognize just how much you don’t know, and you become more humble. As time goes on, you qualify more of your statements with: “I could be totally wrong about this,” but you also begin to think: “Wow, I am so intellectually humble!” When other people fail to make these admissions of humility, you start to see others as not humble, as flawed thinkers. You (
&lt;a href="https://read.readwise.io/read/01gs91h4pj59r3jf12dt9kyhfp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>those people who are apparently more humble—and more accepting of other people’s beliefs—may actually be prejudiced against more people. The authors of this paper speculate that the reason intellectually humble people are so prejudiced is because they develop a group identity surrounding their humility, and this leads them to dislike anyone who isn’t in their ingroup— (
&lt;a href="https://read.readwise.io/read/01gs91jmq48a1c78fpbnnejh7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap—the tendency to become intolerant toward dogmatic people as one becomes intellectually humble—is easy to fall into, and tough to climb out of (
&lt;a href="https://read.readwise.io/read/01gs91q4n6vektffn0ps2edchx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Kurt Gray]]
title: &amp;ldquo;The Enlightenment Trap&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-enlightenment-trap-1">The Enlightenment Trap&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3da270f-a2f2-48ee-994a-498c072607a5_1178x606.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Kurt Gray]]&lt;/li>
&lt;li>Full Title: The Enlightenment Trap&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;amp;utm_campaign=Causas-y-Azares&amp;amp;utm_medium=email&amp;amp;utm_source=Revue-newsletter" rel="noopener">https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;utm_campaign=Causas%20y%20Azares&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>The problem is not with humility itself, but with what happens to our minds when we see ourselves as intellectually humble. We call this problem &amp;ldquo;The Enlightenment Trap,” (
&lt;a href="https://read.readwise.io/read/01gs91b3kkchctbtj1d5g0qhmz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his book “
&lt;a href="https://www.amazon.com/dp/B073TJBYTB/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Enlightenment Now&lt;/a>,” Stephen Pinker emphasized that the recognition of the fallibility and limits of our perspective was a central feature of the 17th-century enlightenment revolution. (
&lt;a href="https://read.readwise.io/read/01gs91cc1cv0wr2screryxsa4s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap is the idea that humility**,** although initially reducing your biases, can trap you into another kind of bias—self-conceit. And while a bit of self-flattery might not be the end of the world, pride and prejudice are connected, as Jane Austin long ago recognized. (
&lt;a href="https://read.readwise.io/read/01gs91em5z7exbmsg7x5qbzk57" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first step in the enlightenment trap is a good step: you begin to recognize just how much you don’t know, and you become more humble. As time goes on, you qualify more of your statements with: “I could be totally wrong about this,” but you also begin to think: “Wow, I am so intellectually humble!” When other people fail to make these admissions of humility, you start to see others as not humble, as flawed thinkers. You (
&lt;a href="https://read.readwise.io/read/01gs91h4pj59r3jf12dt9kyhfp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>those people who are apparently more humble—and more accepting of other people’s beliefs—may actually be prejudiced against more people. The authors of this paper speculate that the reason intellectually humble people are so prejudiced is because they develop a group identity surrounding their humility, and this leads them to dislike anyone who isn’t in their ingroup— (
&lt;a href="https://read.readwise.io/read/01gs91jmq48a1c78fpbnnejh7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap—the tendency to become intolerant toward dogmatic people as one becomes intellectually humble—is easy to fall into, and tough to climb out of (
&lt;a href="https://read.readwise.io/read/01gs91q4n6vektffn0ps2edchx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Kurt Gray]]
title: &amp;ldquo;The Enlightenment Trap&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-enlightenment-trap-2">The Enlightenment Trap&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3da270f-a2f2-48ee-994a-498c072607a5_1178x606.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Kurt Gray]]&lt;/li>
&lt;li>Full Title: The Enlightenment Trap&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;amp;utm_campaign=Causas-y-Azares&amp;amp;utm_medium=email&amp;amp;utm_source=Revue-newsletter" rel="noopener">https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;utm_campaign=Causas%20y%20Azares&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>The problem is not with humility itself, but with what happens to our minds when we see ourselves as intellectually humble. We call this problem &amp;ldquo;The Enlightenment Trap,” (
&lt;a href="https://read.readwise.io/read/01gs91b3kkchctbtj1d5g0qhmz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his book “
&lt;a href="https://www.amazon.com/dp/B073TJBYTB/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Enlightenment Now&lt;/a>,” Stephen Pinker emphasized that the recognition of the fallibility and limits of our perspective was a central feature of the 17th-century enlightenment revolution. (
&lt;a href="https://read.readwise.io/read/01gs91cc1cv0wr2screryxsa4s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap is the idea that humility**,** although initially reducing your biases, can trap you into another kind of bias—self-conceit. And while a bit of self-flattery might not be the end of the world, pride and prejudice are connected, as Jane Austin long ago recognized. (
&lt;a href="https://read.readwise.io/read/01gs91em5z7exbmsg7x5qbzk57" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first step in the enlightenment trap is a good step: you begin to recognize just how much you don’t know, and you become more humble. As time goes on, you qualify more of your statements with: “I could be totally wrong about this,” but you also begin to think: “Wow, I am so intellectually humble!” When other people fail to make these admissions of humility, you start to see others as not humble, as flawed thinkers. You (
&lt;a href="https://read.readwise.io/read/01gs91h4pj59r3jf12dt9kyhfp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>those people who are apparently more humble—and more accepting of other people’s beliefs—may actually be prejudiced against more people. The authors of this paper speculate that the reason intellectually humble people are so prejudiced is because they develop a group identity surrounding their humility, and this leads them to dislike anyone who isn’t in their ingroup— (
&lt;a href="https://read.readwise.io/read/01gs91jmq48a1c78fpbnnejh7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap—the tendency to become intolerant toward dogmatic people as one becomes intellectually humble—is easy to fall into, and tough to climb out of (
&lt;a href="https://read.readwise.io/read/01gs91q4n6vektffn0ps2edchx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Kurt Gray]]
title: &amp;ldquo;The Enlightenment Trap&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-enlightenment-trap-3">The Enlightenment Trap&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb3da270f-a2f2-48ee-994a-498c072607a5_1178x606.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Kurt Gray]]&lt;/li>
&lt;li>Full Title: The Enlightenment Trap&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;amp;utm_campaign=Causas-y-Azares&amp;amp;utm_medium=email&amp;amp;utm_source=Revue-newsletter" rel="noopener">https://moralunderstanding.substack.com/p/the-enlightenment-trap-047?s=r&amp;utm_campaign=Causas%20y%20Azares&amp;utm_medium=email&amp;utm_source=Revue%20newsletter&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>The problem is not with humility itself, but with what happens to our minds when we see ourselves as intellectually humble. We call this problem &amp;ldquo;The Enlightenment Trap,” (
&lt;a href="https://read.readwise.io/read/01gs91b3kkchctbtj1d5g0qhmz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>In his book “
&lt;a href="https://www.amazon.com/dp/B073TJBYTB/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Enlightenment Now&lt;/a>,” Stephen Pinker emphasized that the recognition of the fallibility and limits of our perspective was a central feature of the 17th-century enlightenment revolution. (
&lt;a href="https://read.readwise.io/read/01gs91cc1cv0wr2screryxsa4s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap is the idea that humility**,** although initially reducing your biases, can trap you into another kind of bias—self-conceit. And while a bit of self-flattery might not be the end of the world, pride and prejudice are connected, as Jane Austin long ago recognized. (
&lt;a href="https://read.readwise.io/read/01gs91em5z7exbmsg7x5qbzk57" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The first step in the enlightenment trap is a good step: you begin to recognize just how much you don’t know, and you become more humble. As time goes on, you qualify more of your statements with: “I could be totally wrong about this,” but you also begin to think: “Wow, I am so intellectually humble!” When other people fail to make these admissions of humility, you start to see others as not humble, as flawed thinkers. You (
&lt;a href="https://read.readwise.io/read/01gs91h4pj59r3jf12dt9kyhfp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>those people who are apparently more humble—and more accepting of other people’s beliefs—may actually be prejudiced against more people. The authors of this paper speculate that the reason intellectually humble people are so prejudiced is because they develop a group identity surrounding their humility, and this leads them to dislike anyone who isn’t in their ingroup— (
&lt;a href="https://read.readwise.io/read/01gs91jmq48a1c78fpbnnejh7t" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The enlightenment trap—the tendency to become intolerant toward dogmatic people as one becomes intellectually humble—is easy to fall into, and tough to climb out of (
&lt;a href="https://read.readwise.io/read/01gs91q4n6vektffn0ps2edchx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>The Hidden Costs of Complexity in Data Science</title><link>https://pelayoarbues.github.io/literature-notes/Articles/The-Hidden-Costs-of-Complexity-in-Data-Science/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/The-Hidden-Costs-of-Complexity-in-Data-Science/</guid><description>&lt;h1 id="the-hidden-costs-of-complexity-in-data-science">The Hidden Costs of Complexity in Data Science&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/0*lfnwjqsG3PNpcPNt" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[Chris Walsh]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: The Hidden Costs of Complexity in Data Science&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: Loved the example comparing Sherman and Tiger tanks.
You should start a project by setting a complexity limit guided by:&lt;/p>
&lt;ul>
&lt;li>What is the minimum required accuracy of the model?&lt;/li>
&lt;li>Will this project require some sort of scaling?&lt;/li>
&lt;li>How much resources are available for the project&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb" rel="noopener">https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>It’s not an unfamiliar problem in other disciplines. Engineers have dealt with analogous problems for decades. In World War II, the US designed Sherman tank used highly interchangeable parts. If one tank was knocked out, parts could be taken from another [1]. The Sherman was a relatively simple machine, if it was damaged in battle it could be quickly repaired in the field [2].
On the other hand, Germany designed the Tiger. The Tiger was powerful, precise and complicated [2]. It was a tank as finely tuned as a Swiss watch. Allied forces deeply feared a fully operational Tiger. The problem was, how do you keep a Tiger running? Precision engineering means customization, of parts and knowledge. If you want to fix a Tiger, you need Tiger specific parts. If you want to fix a Tiger, you need Tiger specific expertise. (
&lt;a href="https://read.readwise.io/read/01gs3nkqekderq68cn0k20kynb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Sherman is the data science model built with little customization. Its developer continually monitoring the costs of complexity. Its parts are recognizable, interpretable and fixable for our colleagues. It is built efficiently and gets the job done with the appropriate level of accuracy. (
&lt;a href="https://read.readwise.io/read/01gs3nm4yfm8ryspxxj27b0g07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Tiger is that data science model, so often built with great passion, whose developer was blind to the costs of complexity. It is an incredible machine, when it works. Its precision means it will break. When it breaks only a very small group of people will be capable of fixing it. (
&lt;a href="https://read.readwise.io/read/01gs3nmmdd2hp7m8cz40cw4y4c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Chris Walsh]]
title: &amp;ldquo;The Hidden Costs of Complexity in Data Science&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-hidden-costs-of-complexity-in-data-science-1">The Hidden Costs of Complexity in Data Science&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/0*lfnwjqsG3PNpcPNt" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[Chris Walsh]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: The Hidden Costs of Complexity in Data Science&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: Loved the example comparing Sherman and Tiger tanks.
You should start a project by setting a complexity limit guided by:&lt;/p>
&lt;ul>
&lt;li>What is the minimum required accuracy of the model?&lt;/li>
&lt;li>Will this project require some sort of scaling?&lt;/li>
&lt;li>How much resources are available for the project&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb" rel="noopener">https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>It’s not an unfamiliar problem in other disciplines. Engineers have dealt with analogous problems for decades. In World War II, the US designed Sherman tank used highly interchangeable parts. If one tank was knocked out, parts could be taken from another [1]. The Sherman was a relatively simple machine, if it was damaged in battle it could be quickly repaired in the field [2].
On the other hand, Germany designed the Tiger. The Tiger was powerful, precise and complicated [2]. It was a tank as finely tuned as a Swiss watch. Allied forces deeply feared a fully operational Tiger. The problem was, how do you keep a Tiger running? Precision engineering means customization, of parts and knowledge. If you want to fix a Tiger, you need Tiger specific parts. If you want to fix a Tiger, you need Tiger specific expertise. (
&lt;a href="https://read.readwise.io/read/01gs3nkqekderq68cn0k20kynb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Sherman is the data science model built with little customization. Its developer continually monitoring the costs of complexity. Its parts are recognizable, interpretable and fixable for our colleagues. It is built efficiently and gets the job done with the appropriate level of accuracy. (
&lt;a href="https://read.readwise.io/read/01gs3nm4yfm8ryspxxj27b0g07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Tiger is that data science model, so often built with great passion, whose developer was blind to the costs of complexity. It is an incredible machine, when it works. Its precision means it will break. When it breaks only a very small group of people will be capable of fixing it. (
&lt;a href="https://read.readwise.io/read/01gs3nmmdd2hp7m8cz40cw4y4c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Chris Walsh]]
title: &amp;ldquo;The Hidden Costs of Complexity in Data Science&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-hidden-costs-of-complexity-in-data-science-2">The Hidden Costs of Complexity in Data Science&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/0*lfnwjqsG3PNpcPNt" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[Chris Walsh]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: The Hidden Costs of Complexity in Data Science&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: Loved the example comparing Sherman and Tiger tanks.
You should start a project by setting a complexity limit guided by:&lt;/p>
&lt;ul>
&lt;li>What is the minimum required accuracy of the model?&lt;/li>
&lt;li>Will this project require some sort of scaling?&lt;/li>
&lt;li>How much resources are available for the project&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb" rel="noopener">https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>It’s not an unfamiliar problem in other disciplines. Engineers have dealt with analogous problems for decades. In World War II, the US designed Sherman tank used highly interchangeable parts. If one tank was knocked out, parts could be taken from another [1]. The Sherman was a relatively simple machine, if it was damaged in battle it could be quickly repaired in the field [2].
On the other hand, Germany designed the Tiger. The Tiger was powerful, precise and complicated [2]. It was a tank as finely tuned as a Swiss watch. Allied forces deeply feared a fully operational Tiger. The problem was, how do you keep a Tiger running? Precision engineering means customization, of parts and knowledge. If you want to fix a Tiger, you need Tiger specific parts. If you want to fix a Tiger, you need Tiger specific expertise. (
&lt;a href="https://read.readwise.io/read/01gs3nkqekderq68cn0k20kynb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Sherman is the data science model built with little customization. Its developer continually monitoring the costs of complexity. Its parts are recognizable, interpretable and fixable for our colleagues. It is built efficiently and gets the job done with the appropriate level of accuracy. (
&lt;a href="https://read.readwise.io/read/01gs3nm4yfm8ryspxxj27b0g07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Tiger is that data science model, so often built with great passion, whose developer was blind to the costs of complexity. It is an incredible machine, when it works. Its precision means it will break. When it breaks only a very small group of people will be capable of fixing it. (
&lt;a href="https://read.readwise.io/read/01gs3nmmdd2hp7m8cz40cw4y4c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Chris Walsh]]
title: &amp;ldquo;The Hidden Costs of Complexity in Data Science&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-hidden-costs-of-complexity-in-data-science-3">The Hidden Costs of Complexity in Data Science&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1200/0*lfnwjqsG3PNpcPNt" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Author: [[Chris Walsh]]&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Full Title: The Hidden Costs of Complexity in Data Science&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Category: #articles&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Document Note: Loved the example comparing Sherman and Tiger tanks.
You should start a project by setting a complexity limit guided by:&lt;/p>
&lt;ul>
&lt;li>What is the minimum required accuracy of the model?&lt;/li>
&lt;li>Will this project require some sort of scaling?&lt;/li>
&lt;li>How much resources are available for the project&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>URL:
&lt;a href="https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb" rel="noopener">https://towardsdatascience.com/the-hidden-costs-of-complexity-in-data-science-6b5958117bfb&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>It’s not an unfamiliar problem in other disciplines. Engineers have dealt with analogous problems for decades. In World War II, the US designed Sherman tank used highly interchangeable parts. If one tank was knocked out, parts could be taken from another [1]. The Sherman was a relatively simple machine, if it was damaged in battle it could be quickly repaired in the field [2].
On the other hand, Germany designed the Tiger. The Tiger was powerful, precise and complicated [2]. It was a tank as finely tuned as a Swiss watch. Allied forces deeply feared a fully operational Tiger. The problem was, how do you keep a Tiger running? Precision engineering means customization, of parts and knowledge. If you want to fix a Tiger, you need Tiger specific parts. If you want to fix a Tiger, you need Tiger specific expertise. (
&lt;a href="https://read.readwise.io/read/01gs3nkqekderq68cn0k20kynb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Sherman is the data science model built with little customization. Its developer continually monitoring the costs of complexity. Its parts are recognizable, interpretable and fixable for our colleagues. It is built efficiently and gets the job done with the appropriate level of accuracy. (
&lt;a href="https://read.readwise.io/read/01gs3nm4yfm8ryspxxj27b0g07" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Tiger is that data science model, so often built with great passion, whose developer was blind to the costs of complexity. It is an incredible machine, when it works. Its precision means it will break. When it breaks only a very small group of people will be capable of fixing it. (
&lt;a href="https://read.readwise.io/read/01gs3nmmdd2hp7m8cz40cw4y4c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>The Illustrated Transformer</title><link>https://pelayoarbues.github.io/literature-notes/Articles/The-Illustrated-Transformer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/The-Illustrated-Transformer/</guid><description>&lt;h1 id="the-illustrated-transformer">The Illustrated Transformer&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: The Illustrated Transformer&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/illustrated-transformer/" rel="noopener">https://jalammar.github.io/illustrated-transformer/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>we will look at &lt;strong>The Transformer&lt;/strong> – a model that uses attention to boost the speed with which these models can be trained. (
&lt;a href="https://read.readwise.io/read/01gr3qfpcx17bqn1wcn3nejn4e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/the_transformer_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ffd9t46h1q3f8d4mnqtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fhhy22e1gh06yr8937x2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number. (
&lt;a href="https://read.readwise.io/read/01gr3qk5rmh11jv8tv46g88tj0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f9jzt5sdzyb5ypzdf2yj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers: (
&lt;a href="https://read.readwise.io/read/01gr3qrd7fxt1ac4aax6454rbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/Transformer_encoder.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fbszx7j24ha1e5p8zg9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. (
&lt;a href="https://read.readwise.io/read/01gr3qw4a7944kyzwreqytcgxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position. (
&lt;a href="https://read.readwise.io/read/01gr3qz3249x4007d6d1x8xfw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">seq2seq models&lt;/a>). (
&lt;a href="https://read.readwise.io/read/01gr3qzm559wjvn64wt6dy58h6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As is the case in NLP applications in general, we begin by turning each input word into a vector using an
&lt;a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca" rel="noopener">embedding algorithm&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr43bvwwr560weacv3m72s65" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below (
&lt;a href="https://read.readwise.io/read/01gr43d82ec8nqmyx1ekqz4vsy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder. (
&lt;a href="https://read.readwise.io/read/01gr43dgprrxmmp295nfatw7b8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f6g9wexr7kmntykvhkqx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer. (
&lt;a href="https://read.readwise.io/read/01gr43e1e3sr81vmzed7k31t8c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder. (
&lt;a href="https://read.readwise.io/read/01gr43eta1s6v2v9pdpyatfym1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f21wkg3842np67vch8mj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.
Say the following sentence is an input sentence we want to translate:
”&lt;code>The animal didn't cross the street because it was too tired&lt;/code>”
What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm. (
&lt;a href="https://read.readwise.io/read/01gr43g439emrv0ppc47107xe6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”. (
&lt;a href="https://read.readwise.io/read/01gr43gfpbp5215vsfmma0fs0e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word. (
&lt;a href="https://read.readwise.io/read/01gr43gpw4bc4n7f112ta03hft" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. (
&lt;a href="https://read.readwise.io/read/01gr43h3k8ahj564hz5njbse37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>first step&lt;/strong> in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process. (
&lt;a href="https://read.readwise.io/read/01gr43j1j705y3zjy6nrp5ns5v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant. (
&lt;a href="https://read.readwise.io/read/01gr43jkm0z72sfsdp5262dmsw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What are the “query”, “key”, and “value” vectors?
They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.
The &lt;strong>second step&lt;/strong> in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position. (
&lt;a href="https://read.readwise.io/read/01gr43kds63qrdqsk5tw2dhknp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2. (
&lt;a href="https://read.readwise.io/read/01gr43ksg4fqem6rse31ga8gav" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43kvr3434ae2v73chyhv9e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>third and fourth steps&lt;/strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1. (
&lt;a href="https://read.readwise.io/read/01gr43mggpdphmyfpht1a6s0cy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention_softmax.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rg7bw2v9aw5a2hr2f2f8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>his softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word. (
&lt;a href="https://read.readwise.io/read/01gr43n1q3mav0cybysjmsbkt9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>fifth step&lt;/strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example) (
&lt;a href="https://read.readwise.io/read/01gr43natm8kn4nej6xgepqh08" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>sixth step&lt;/strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word). (
&lt;a href="https://read.readwise.io/read/01gr43r0r605atfm28k8d0qxwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-output.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rjb5qjeebyfdqcaftnz2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level. (
&lt;a href="https://read.readwise.io/read/01gr43r88wb5xxryx9qmqenvgz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Matrix Calculation of Self-Attention
&lt;strong>The first step&lt;/strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV). (
&lt;a href="https://read.readwise.io/read/01gr43s12mtkh4d0g4pvc8m0w5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ry83pv2qkve5h59a8yw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Finally&lt;/strong>, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer.
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ssjaecxkvwnz37dejpyy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways:
&lt;ol>
&lt;li>It expands the model’s ability to focus on different positions. Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the actual word itself. If we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, it would be useful to know which word “it” refers to. (
&lt;a href="https://read.readwise.io/read/01gr43tgjwvw3dkd7fjx70q6by" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>It gives the attention layer multiple “representation subspaces”. As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace. (
&lt;a href="https://read.readwise.io/read/01gr43tvg1gt8wkthajz0f75w2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_qkv.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v18wvm97ydchy62d2fg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>f we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_z.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v47h8vhrd36nkabghtxk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.
How do we do that? We concat the matrices then multiply them by an additional weights matrix WO.
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43vh72mghvq1ez0345p7tn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place (
&lt;a href="https://read.readwise.io/read/01gr43vw9h0v6s4ys2pk44e428" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43wyr08hq72r7ntkn6jya2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_2.png" width="auto" alt="" />
As we encode the word &amp;ldquo;it&amp;rdquo;, one attention head is focusing most on &amp;ldquo;the animal&amp;rdquo;, while another is focusing on &amp;ldquo;tired&amp;rdquo; &amp;ndash; in a sense, the model&amp;rsquo;s representation of the word &amp;ldquo;it&amp;rdquo; bakes in some of the representation of both &amp;ldquo;animal&amp;rdquo; and &amp;ldquo;tired&amp;rdquo;.
If we add all the attention heads to the picture, however, things can be harder to interpret:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43yat77cam7ysnc577vh70" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence.
To address this, the transformer adds a vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr43yyj61gv31j0syr73xyga" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png" width="auto" alt="" />
To give the model a sense of the order of the words, we add positional encoding vectors &amp;ndash; the values of which follow a specific pattern.
If we assumed the embedding has a dimensionality of 4, the actual positional encodings would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_example.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43znch1bsfjnb2b928qek7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a
&lt;a href="https://arxiv.org/abs/1607.06450" rel="noopener">layer-normalization&lt;/a> step.
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr440f4v2m98ewn3esstkrv8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png" width="auto" alt="" />
This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4413g6rgtjkqb5vw6brsbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together.
The encoder start by processing the input sequence. The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence: (
&lt;a href="https://read.readwise.io/read/01gr441fp3bt80av1s3zq5df63" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_1.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr441tgtwqrtp61jmjh4gr26" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The following steps repeat the process until a special symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4422r1a9ggxktc1bjvk6qf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The self attention layers in the decoder operate in a slightly different way than the one in the encoder:
In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to &lt;code>-inf&lt;/code>) before the softmax step in the self-attention calculation.
The “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack. (
&lt;a href="https://read.readwise.io/read/01gr442gq9g1s6t401zvnszsbg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.
The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.
Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.
The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step. (
&lt;a href="https://read.readwise.io/read/01gr4436kday4y5drby2w9f7tc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.
During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.
To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “&lt;eos>” (short for ‘end of sentence’)). (
&lt;a href="https://read.readwise.io/read/01gr443x9f8v1vp5wr32c61w5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/vocabulary.png" width="auto" alt="" />
The output vocabulary of our model is created in the preprocessing phase before we even begin training. (
&lt;a href="https://read.readwise.io/read/01gr444rwtqjn4t79nrm00egbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector: (
&lt;a href="https://read.readwise.io/read/01gr444akq9ps9fbk8fbx68zxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/one-hot-vocabulary-example.png" width="auto" alt="" />
Example: one-hot encoding of our output vocabulary (
&lt;a href="https://read.readwise.io/read/01gr444ptpa7ancdtj89zmjjd6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Loss Function
Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”.
What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet.
&lt;img src="https://jalammar.github.io/images/t/transformer_logits_output_and_label.png" width="auto" alt="" />
Since the model&amp;rsquo;s parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word. We can compare it with the actual output, then tweak all the model&amp;rsquo;s weights using backpropagation to make the output closer to the desired output. (
&lt;a href="https://read.readwise.io/read/01gr445m67n0aw8x514vrk2xb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where:
• Each probability distribution is represented by a vector of width vocab_size (6 in our toy example, but more realistically a number like 30,000 or 50,000)
• The first probability distribution has the highest probability at the cell associated with the word “i”
• The second probability distribution has the highest probability at the cell associated with the word “am”
• And so on, until the fifth output distribution indicates ‘&lt;code>&amp;lt;end of sentence&amp;gt;&lt;/code>’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.
&lt;img src="https://jalammar.github.io/images/t/output_target_probability_distributions.png" width="auto" alt="" />
The targeted probability distributions we&amp;rsquo;ll train our model against in the training example for one sample sentence. (
&lt;a href="https://read.readwise.io/read/01gr446q3wegn465g7kjqfk962" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Jay Alammar]]
title: &amp;ldquo;The Illustrated Transformer&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-illustrated-transformer-1">The Illustrated Transformer&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: The Illustrated Transformer&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/illustrated-transformer/" rel="noopener">https://jalammar.github.io/illustrated-transformer/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>we will look at &lt;strong>The Transformer&lt;/strong> – a model that uses attention to boost the speed with which these models can be trained. (
&lt;a href="https://read.readwise.io/read/01gr3qfpcx17bqn1wcn3nejn4e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/the_transformer_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ffd9t46h1q3f8d4mnqtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fhhy22e1gh06yr8937x2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number. (
&lt;a href="https://read.readwise.io/read/01gr3qk5rmh11jv8tv46g88tj0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f9jzt5sdzyb5ypzdf2yj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers: (
&lt;a href="https://read.readwise.io/read/01gr3qrd7fxt1ac4aax6454rbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/Transformer_encoder.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fbszx7j24ha1e5p8zg9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. (
&lt;a href="https://read.readwise.io/read/01gr3qw4a7944kyzwreqytcgxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position. (
&lt;a href="https://read.readwise.io/read/01gr3qz3249x4007d6d1x8xfw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">seq2seq models&lt;/a>). (
&lt;a href="https://read.readwise.io/read/01gr3qzm559wjvn64wt6dy58h6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As is the case in NLP applications in general, we begin by turning each input word into a vector using an
&lt;a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca" rel="noopener">embedding algorithm&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr43bvwwr560weacv3m72s65" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below (
&lt;a href="https://read.readwise.io/read/01gr43d82ec8nqmyx1ekqz4vsy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder. (
&lt;a href="https://read.readwise.io/read/01gr43dgprrxmmp295nfatw7b8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f6g9wexr7kmntykvhkqx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer. (
&lt;a href="https://read.readwise.io/read/01gr43e1e3sr81vmzed7k31t8c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder. (
&lt;a href="https://read.readwise.io/read/01gr43eta1s6v2v9pdpyatfym1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f21wkg3842np67vch8mj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.
Say the following sentence is an input sentence we want to translate:
”&lt;code>The animal didn't cross the street because it was too tired&lt;/code>”
What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm. (
&lt;a href="https://read.readwise.io/read/01gr43g439emrv0ppc47107xe6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”. (
&lt;a href="https://read.readwise.io/read/01gr43gfpbp5215vsfmma0fs0e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word. (
&lt;a href="https://read.readwise.io/read/01gr43gpw4bc4n7f112ta03hft" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. (
&lt;a href="https://read.readwise.io/read/01gr43h3k8ahj564hz5njbse37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>first step&lt;/strong> in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process. (
&lt;a href="https://read.readwise.io/read/01gr43j1j705y3zjy6nrp5ns5v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant. (
&lt;a href="https://read.readwise.io/read/01gr43jkm0z72sfsdp5262dmsw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What are the “query”, “key”, and “value” vectors?
They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.
The &lt;strong>second step&lt;/strong> in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position. (
&lt;a href="https://read.readwise.io/read/01gr43kds63qrdqsk5tw2dhknp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2. (
&lt;a href="https://read.readwise.io/read/01gr43ksg4fqem6rse31ga8gav" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43kvr3434ae2v73chyhv9e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>third and fourth steps&lt;/strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1. (
&lt;a href="https://read.readwise.io/read/01gr43mggpdphmyfpht1a6s0cy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention_softmax.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rg7bw2v9aw5a2hr2f2f8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>his softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word. (
&lt;a href="https://read.readwise.io/read/01gr43n1q3mav0cybysjmsbkt9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>fifth step&lt;/strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example) (
&lt;a href="https://read.readwise.io/read/01gr43natm8kn4nej6xgepqh08" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>sixth step&lt;/strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word). (
&lt;a href="https://read.readwise.io/read/01gr43r0r605atfm28k8d0qxwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-output.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rjb5qjeebyfdqcaftnz2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level. (
&lt;a href="https://read.readwise.io/read/01gr43r88wb5xxryx9qmqenvgz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Matrix Calculation of Self-Attention
&lt;strong>The first step&lt;/strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV). (
&lt;a href="https://read.readwise.io/read/01gr43s12mtkh4d0g4pvc8m0w5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ry83pv2qkve5h59a8yw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Finally&lt;/strong>, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer.
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ssjaecxkvwnz37dejpyy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways:
&lt;ol>
&lt;li>It expands the model’s ability to focus on different positions. Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the actual word itself. If we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, it would be useful to know which word “it” refers to. (
&lt;a href="https://read.readwise.io/read/01gr43tgjwvw3dkd7fjx70q6by" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>It gives the attention layer multiple “representation subspaces”. As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace. (
&lt;a href="https://read.readwise.io/read/01gr43tvg1gt8wkthajz0f75w2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_qkv.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v18wvm97ydchy62d2fg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>f we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_z.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v47h8vhrd36nkabghtxk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.
How do we do that? We concat the matrices then multiply them by an additional weights matrix WO.
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43vh72mghvq1ez0345p7tn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place (
&lt;a href="https://read.readwise.io/read/01gr43vw9h0v6s4ys2pk44e428" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43wyr08hq72r7ntkn6jya2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_2.png" width="auto" alt="" />
As we encode the word &amp;ldquo;it&amp;rdquo;, one attention head is focusing most on &amp;ldquo;the animal&amp;rdquo;, while another is focusing on &amp;ldquo;tired&amp;rdquo; &amp;ndash; in a sense, the model&amp;rsquo;s representation of the word &amp;ldquo;it&amp;rdquo; bakes in some of the representation of both &amp;ldquo;animal&amp;rdquo; and &amp;ldquo;tired&amp;rdquo;.
If we add all the attention heads to the picture, however, things can be harder to interpret:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43yat77cam7ysnc577vh70" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence.
To address this, the transformer adds a vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr43yyj61gv31j0syr73xyga" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png" width="auto" alt="" />
To give the model a sense of the order of the words, we add positional encoding vectors &amp;ndash; the values of which follow a specific pattern.
If we assumed the embedding has a dimensionality of 4, the actual positional encodings would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_example.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43znch1bsfjnb2b928qek7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a
&lt;a href="https://arxiv.org/abs/1607.06450" rel="noopener">layer-normalization&lt;/a> step.
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr440f4v2m98ewn3esstkrv8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png" width="auto" alt="" />
This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4413g6rgtjkqb5vw6brsbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together.
The encoder start by processing the input sequence. The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence: (
&lt;a href="https://read.readwise.io/read/01gr441fp3bt80av1s3zq5df63" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_1.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr441tgtwqrtp61jmjh4gr26" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The following steps repeat the process until a special symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4422r1a9ggxktc1bjvk6qf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The self attention layers in the decoder operate in a slightly different way than the one in the encoder:
In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to &lt;code>-inf&lt;/code>) before the softmax step in the self-attention calculation.
The “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack. (
&lt;a href="https://read.readwise.io/read/01gr442gq9g1s6t401zvnszsbg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.
The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.
Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.
The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step. (
&lt;a href="https://read.readwise.io/read/01gr4436kday4y5drby2w9f7tc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.
During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.
To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “&lt;eos>” (short for ‘end of sentence’)). (
&lt;a href="https://read.readwise.io/read/01gr443x9f8v1vp5wr32c61w5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/vocabulary.png" width="auto" alt="" />
The output vocabulary of our model is created in the preprocessing phase before we even begin training. (
&lt;a href="https://read.readwise.io/read/01gr444rwtqjn4t79nrm00egbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector: (
&lt;a href="https://read.readwise.io/read/01gr444akq9ps9fbk8fbx68zxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/one-hot-vocabulary-example.png" width="auto" alt="" />
Example: one-hot encoding of our output vocabulary (
&lt;a href="https://read.readwise.io/read/01gr444ptpa7ancdtj89zmjjd6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Loss Function
Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”.
What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet.
&lt;img src="https://jalammar.github.io/images/t/transformer_logits_output_and_label.png" width="auto" alt="" />
Since the model&amp;rsquo;s parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word. We can compare it with the actual output, then tweak all the model&amp;rsquo;s weights using backpropagation to make the output closer to the desired output. (
&lt;a href="https://read.readwise.io/read/01gr445m67n0aw8x514vrk2xb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where:
• Each probability distribution is represented by a vector of width vocab_size (6 in our toy example, but more realistically a number like 30,000 or 50,000)
• The first probability distribution has the highest probability at the cell associated with the word “i”
• The second probability distribution has the highest probability at the cell associated with the word “am”
• And so on, until the fifth output distribution indicates ‘&lt;code>&amp;lt;end of sentence&amp;gt;&lt;/code>’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.
&lt;img src="https://jalammar.github.io/images/t/output_target_probability_distributions.png" width="auto" alt="" />
The targeted probability distributions we&amp;rsquo;ll train our model against in the training example for one sample sentence. (
&lt;a href="https://read.readwise.io/read/01gr446q3wegn465g7kjqfk962" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Jay Alammar]]
title: &amp;ldquo;The Illustrated Transformer&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-illustrated-transformer-2">The Illustrated Transformer&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: The Illustrated Transformer&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/illustrated-transformer/" rel="noopener">https://jalammar.github.io/illustrated-transformer/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>we will look at &lt;strong>The Transformer&lt;/strong> – a model that uses attention to boost the speed with which these models can be trained. (
&lt;a href="https://read.readwise.io/read/01gr3qfpcx17bqn1wcn3nejn4e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/the_transformer_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ffd9t46h1q3f8d4mnqtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fhhy22e1gh06yr8937x2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number. (
&lt;a href="https://read.readwise.io/read/01gr3qk5rmh11jv8tv46g88tj0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f9jzt5sdzyb5ypzdf2yj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers: (
&lt;a href="https://read.readwise.io/read/01gr3qrd7fxt1ac4aax6454rbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/Transformer_encoder.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fbszx7j24ha1e5p8zg9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. (
&lt;a href="https://read.readwise.io/read/01gr3qw4a7944kyzwreqytcgxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position. (
&lt;a href="https://read.readwise.io/read/01gr3qz3249x4007d6d1x8xfw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">seq2seq models&lt;/a>). (
&lt;a href="https://read.readwise.io/read/01gr3qzm559wjvn64wt6dy58h6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As is the case in NLP applications in general, we begin by turning each input word into a vector using an
&lt;a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca" rel="noopener">embedding algorithm&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr43bvwwr560weacv3m72s65" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below (
&lt;a href="https://read.readwise.io/read/01gr43d82ec8nqmyx1ekqz4vsy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder. (
&lt;a href="https://read.readwise.io/read/01gr43dgprrxmmp295nfatw7b8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f6g9wexr7kmntykvhkqx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer. (
&lt;a href="https://read.readwise.io/read/01gr43e1e3sr81vmzed7k31t8c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder. (
&lt;a href="https://read.readwise.io/read/01gr43eta1s6v2v9pdpyatfym1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f21wkg3842np67vch8mj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.
Say the following sentence is an input sentence we want to translate:
”&lt;code>The animal didn't cross the street because it was too tired&lt;/code>”
What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm. (
&lt;a href="https://read.readwise.io/read/01gr43g439emrv0ppc47107xe6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”. (
&lt;a href="https://read.readwise.io/read/01gr43gfpbp5215vsfmma0fs0e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word. (
&lt;a href="https://read.readwise.io/read/01gr43gpw4bc4n7f112ta03hft" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. (
&lt;a href="https://read.readwise.io/read/01gr43h3k8ahj564hz5njbse37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>first step&lt;/strong> in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process. (
&lt;a href="https://read.readwise.io/read/01gr43j1j705y3zjy6nrp5ns5v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant. (
&lt;a href="https://read.readwise.io/read/01gr43jkm0z72sfsdp5262dmsw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What are the “query”, “key”, and “value” vectors?
They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.
The &lt;strong>second step&lt;/strong> in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position. (
&lt;a href="https://read.readwise.io/read/01gr43kds63qrdqsk5tw2dhknp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2. (
&lt;a href="https://read.readwise.io/read/01gr43ksg4fqem6rse31ga8gav" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43kvr3434ae2v73chyhv9e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>third and fourth steps&lt;/strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1. (
&lt;a href="https://read.readwise.io/read/01gr43mggpdphmyfpht1a6s0cy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention_softmax.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rg7bw2v9aw5a2hr2f2f8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>his softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word. (
&lt;a href="https://read.readwise.io/read/01gr43n1q3mav0cybysjmsbkt9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>fifth step&lt;/strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example) (
&lt;a href="https://read.readwise.io/read/01gr43natm8kn4nej6xgepqh08" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>sixth step&lt;/strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word). (
&lt;a href="https://read.readwise.io/read/01gr43r0r605atfm28k8d0qxwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-output.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rjb5qjeebyfdqcaftnz2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level. (
&lt;a href="https://read.readwise.io/read/01gr43r88wb5xxryx9qmqenvgz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Matrix Calculation of Self-Attention
&lt;strong>The first step&lt;/strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV). (
&lt;a href="https://read.readwise.io/read/01gr43s12mtkh4d0g4pvc8m0w5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ry83pv2qkve5h59a8yw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Finally&lt;/strong>, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer.
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ssjaecxkvwnz37dejpyy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways:
&lt;ol>
&lt;li>It expands the model’s ability to focus on different positions. Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the actual word itself. If we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, it would be useful to know which word “it” refers to. (
&lt;a href="https://read.readwise.io/read/01gr43tgjwvw3dkd7fjx70q6by" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>It gives the attention layer multiple “representation subspaces”. As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace. (
&lt;a href="https://read.readwise.io/read/01gr43tvg1gt8wkthajz0f75w2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_qkv.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v18wvm97ydchy62d2fg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>f we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_z.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v47h8vhrd36nkabghtxk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.
How do we do that? We concat the matrices then multiply them by an additional weights matrix WO.
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43vh72mghvq1ez0345p7tn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place (
&lt;a href="https://read.readwise.io/read/01gr43vw9h0v6s4ys2pk44e428" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43wyr08hq72r7ntkn6jya2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_2.png" width="auto" alt="" />
As we encode the word &amp;ldquo;it&amp;rdquo;, one attention head is focusing most on &amp;ldquo;the animal&amp;rdquo;, while another is focusing on &amp;ldquo;tired&amp;rdquo; &amp;ndash; in a sense, the model&amp;rsquo;s representation of the word &amp;ldquo;it&amp;rdquo; bakes in some of the representation of both &amp;ldquo;animal&amp;rdquo; and &amp;ldquo;tired&amp;rdquo;.
If we add all the attention heads to the picture, however, things can be harder to interpret:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43yat77cam7ysnc577vh70" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence.
To address this, the transformer adds a vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr43yyj61gv31j0syr73xyga" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png" width="auto" alt="" />
To give the model a sense of the order of the words, we add positional encoding vectors &amp;ndash; the values of which follow a specific pattern.
If we assumed the embedding has a dimensionality of 4, the actual positional encodings would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_example.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43znch1bsfjnb2b928qek7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a
&lt;a href="https://arxiv.org/abs/1607.06450" rel="noopener">layer-normalization&lt;/a> step.
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr440f4v2m98ewn3esstkrv8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png" width="auto" alt="" />
This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4413g6rgtjkqb5vw6brsbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together.
The encoder start by processing the input sequence. The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence: (
&lt;a href="https://read.readwise.io/read/01gr441fp3bt80av1s3zq5df63" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_1.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr441tgtwqrtp61jmjh4gr26" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The following steps repeat the process until a special symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4422r1a9ggxktc1bjvk6qf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The self attention layers in the decoder operate in a slightly different way than the one in the encoder:
In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to &lt;code>-inf&lt;/code>) before the softmax step in the self-attention calculation.
The “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack. (
&lt;a href="https://read.readwise.io/read/01gr442gq9g1s6t401zvnszsbg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.
The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.
Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.
The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step. (
&lt;a href="https://read.readwise.io/read/01gr4436kday4y5drby2w9f7tc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.
During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.
To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “&lt;eos>” (short for ‘end of sentence’)). (
&lt;a href="https://read.readwise.io/read/01gr443x9f8v1vp5wr32c61w5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/vocabulary.png" width="auto" alt="" />
The output vocabulary of our model is created in the preprocessing phase before we even begin training. (
&lt;a href="https://read.readwise.io/read/01gr444rwtqjn4t79nrm00egbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector: (
&lt;a href="https://read.readwise.io/read/01gr444akq9ps9fbk8fbx68zxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/one-hot-vocabulary-example.png" width="auto" alt="" />
Example: one-hot encoding of our output vocabulary (
&lt;a href="https://read.readwise.io/read/01gr444ptpa7ancdtj89zmjjd6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Loss Function
Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”.
What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet.
&lt;img src="https://jalammar.github.io/images/t/transformer_logits_output_and_label.png" width="auto" alt="" />
Since the model&amp;rsquo;s parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word. We can compare it with the actual output, then tweak all the model&amp;rsquo;s weights using backpropagation to make the output closer to the desired output. (
&lt;a href="https://read.readwise.io/read/01gr445m67n0aw8x514vrk2xb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where:
• Each probability distribution is represented by a vector of width vocab_size (6 in our toy example, but more realistically a number like 30,000 or 50,000)
• The first probability distribution has the highest probability at the cell associated with the word “i”
• The second probability distribution has the highest probability at the cell associated with the word “am”
• And so on, until the fifth output distribution indicates ‘&lt;code>&amp;lt;end of sentence&amp;gt;&lt;/code>’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.
&lt;img src="https://jalammar.github.io/images/t/output_target_probability_distributions.png" width="auto" alt="" />
The targeted probability distributions we&amp;rsquo;ll train our model against in the training example for one sample sentence. (
&lt;a href="https://read.readwise.io/read/01gr446q3wegn465g7kjqfk962" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Jay Alammar]]
title: &amp;ldquo;The Illustrated Transformer&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="the-illustrated-transformer-3">The Illustrated Transformer&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: The Illustrated Transformer&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/illustrated-transformer/" rel="noopener">https://jalammar.github.io/illustrated-transformer/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>we will look at &lt;strong>The Transformer&lt;/strong> – a model that uses attention to boost the speed with which these models can be trained. (
&lt;a href="https://read.readwise.io/read/01gr3qfpcx17bqn1wcn3nejn4e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/the_transformer_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ffd9t46h1q3f8d4mnqtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fhhy22e1gh06yr8937x2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number. (
&lt;a href="https://read.readwise.io/read/01gr3qk5rmh11jv8tv46g88tj0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f9jzt5sdzyb5ypzdf2yj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers: (
&lt;a href="https://read.readwise.io/read/01gr3qrd7fxt1ac4aax6454rbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/Transformer_encoder.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43fbszx7j24ha1e5p8zg9d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. (
&lt;a href="https://read.readwise.io/read/01gr3qw4a7944kyzwreqytcgxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position. (
&lt;a href="https://read.readwise.io/read/01gr3qz3249x4007d6d1x8xfw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">seq2seq models&lt;/a>). (
&lt;a href="https://read.readwise.io/read/01gr3qzm559wjvn64wt6dy58h6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As is the case in NLP applications in general, we begin by turning each input word into a vector using an
&lt;a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca" rel="noopener">embedding algorithm&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr43bvwwr560weacv3m72s65" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below (
&lt;a href="https://read.readwise.io/read/01gr43d82ec8nqmyx1ekqz4vsy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder. (
&lt;a href="https://read.readwise.io/read/01gr43dgprrxmmp295nfatw7b8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f6g9wexr7kmntykvhkqx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer. (
&lt;a href="https://read.readwise.io/read/01gr43e1e3sr81vmzed7k31t8c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder. (
&lt;a href="https://read.readwise.io/read/01gr43eta1s6v2v9pdpyatfym1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43f21wkg3842np67vch8mj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.
Say the following sentence is an input sentence we want to translate:
”&lt;code>The animal didn't cross the street because it was too tired&lt;/code>”
What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm. (
&lt;a href="https://read.readwise.io/read/01gr43g439emrv0ppc47107xe6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”. (
&lt;a href="https://read.readwise.io/read/01gr43gfpbp5215vsfmma0fs0e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word. (
&lt;a href="https://read.readwise.io/read/01gr43gpw4bc4n7f112ta03hft" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing. (
&lt;a href="https://read.readwise.io/read/01gr43h3k8ahj564hz5njbse37" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>first step&lt;/strong> in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process. (
&lt;a href="https://read.readwise.io/read/01gr43j1j705y3zjy6nrp5ns5v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant. (
&lt;a href="https://read.readwise.io/read/01gr43jkm0z72sfsdp5262dmsw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What are the “query”, “key”, and “value” vectors?
They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.
The &lt;strong>second step&lt;/strong> in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position. (
&lt;a href="https://read.readwise.io/read/01gr43kds63qrdqsk5tw2dhknp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2. (
&lt;a href="https://read.readwise.io/read/01gr43ksg4fqem6rse31ga8gav" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43kvr3434ae2v73chyhv9e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>third and fourth steps&lt;/strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1. (
&lt;a href="https://read.readwise.io/read/01gr43mggpdphmyfpht1a6s0cy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention_softmax.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rg7bw2v9aw5a2hr2f2f8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>his softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word. (
&lt;a href="https://read.readwise.io/read/01gr43n1q3mav0cybysjmsbkt9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>fifth step&lt;/strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example) (
&lt;a href="https://read.readwise.io/read/01gr43natm8kn4nej6xgepqh08" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;strong>sixth step&lt;/strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word). (
&lt;a href="https://read.readwise.io/read/01gr43r0r605atfm28k8d0qxwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-output.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43rjb5qjeebyfdqcaftnz2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level. (
&lt;a href="https://read.readwise.io/read/01gr43r88wb5xxryx9qmqenvgz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Matrix Calculation of Self-Attention
&lt;strong>The first step&lt;/strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV). (
&lt;a href="https://read.readwise.io/read/01gr43s12mtkh4d0g4pvc8m0w5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ry83pv2qkve5h59a8yw7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Finally&lt;/strong>, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer.
&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43ssjaecxkvwnz37dejpyy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways:
&lt;ol>
&lt;li>It expands the model’s ability to focus on different positions. Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the actual word itself. If we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, it would be useful to know which word “it” refers to. (
&lt;a href="https://read.readwise.io/read/01gr43tgjwvw3dkd7fjx70q6by" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>It gives the attention layer multiple “representation subspaces”. As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace. (
&lt;a href="https://read.readwise.io/read/01gr43tvg1gt8wkthajz0f75w2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_qkv.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v18wvm97ydchy62d2fg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>f we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_z.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43v47h8vhrd36nkabghtxk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.
How do we do that? We concat the matrices then multiply them by an additional weights matrix WO.
&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43vh72mghvq1ez0345p7tn" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place (
&lt;a href="https://read.readwise.io/read/01gr43vw9h0v6s4ys2pk44e428" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43wyr08hq72r7ntkn6jya2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_2.png" width="auto" alt="" />
As we encode the word &amp;ldquo;it&amp;rdquo;, one attention head is focusing most on &amp;ldquo;the animal&amp;rdquo;, while another is focusing on &amp;ldquo;tired&amp;rdquo; &amp;ndash; in a sense, the model&amp;rsquo;s representation of the word &amp;ldquo;it&amp;rdquo; bakes in some of the representation of both &amp;ldquo;animal&amp;rdquo; and &amp;ldquo;tired&amp;rdquo;.
If we add all the attention heads to the picture, however, things can be harder to interpret:
&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43yat77cam7ysnc577vh70" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence.
To address this, the transformer adds a vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr43yyj61gv31j0syr73xyga" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png" width="auto" alt="" />
To give the model a sense of the order of the words, we add positional encoding vectors &amp;ndash; the values of which follow a specific pattern.
If we assumed the embedding has a dimensionality of 4, the actual positional encodings would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_example.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr43znch1bsfjnb2b928qek7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a
&lt;a href="https://arxiv.org/abs/1607.06450" rel="noopener">layer-normalization&lt;/a> step.
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr440f4v2m98ewn3esstkrv8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png" width="auto" alt="" />
This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:
&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4413g6rgtjkqb5vw6brsbw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together.
The encoder start by processing the input sequence. The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence: (
&lt;a href="https://read.readwise.io/read/01gr441fp3bt80av1s3zq5df63" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_1.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr441tgtwqrtp61jmjh4gr26" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The following steps repeat the process until a special symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.
&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr4422r1a9ggxktc1bjvk6qf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The self attention layers in the decoder operate in a slightly different way than the one in the encoder:
In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to &lt;code>-inf&lt;/code>) before the softmax step in the self-attention calculation.
The “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack. (
&lt;a href="https://read.readwise.io/read/01gr442gq9g1s6t401zvnszsbg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.
The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.
Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.
The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step. (
&lt;a href="https://read.readwise.io/read/01gr4436kday4y5drby2w9f7tc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.
During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.
To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “&lt;eos>” (short for ‘end of sentence’)). (
&lt;a href="https://read.readwise.io/read/01gr443x9f8v1vp5wr32c61w5n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/vocabulary.png" width="auto" alt="" />
The output vocabulary of our model is created in the preprocessing phase before we even begin training. (
&lt;a href="https://read.readwise.io/read/01gr444rwtqjn4t79nrm00egbd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector: (
&lt;a href="https://read.readwise.io/read/01gr444akq9ps9fbk8fbx68zxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://jalammar.github.io/images/t/one-hot-vocabulary-example.png" width="auto" alt="" />
Example: one-hot encoding of our output vocabulary (
&lt;a href="https://read.readwise.io/read/01gr444ptpa7ancdtj89zmjjd6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Loss Function
Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”.
What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet.
&lt;img src="https://jalammar.github.io/images/t/transformer_logits_output_and_label.png" width="auto" alt="" />
Since the model&amp;rsquo;s parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word. We can compare it with the actual output, then tweak all the model&amp;rsquo;s weights using backpropagation to make the output closer to the desired output. (
&lt;a href="https://read.readwise.io/read/01gr445m67n0aw8x514vrk2xb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where:
• Each probability distribution is represented by a vector of width vocab_size (6 in our toy example, but more realistically a number like 30,000 or 50,000)
• The first probability distribution has the highest probability at the cell associated with the word “i”
• The second probability distribution has the highest probability at the cell associated with the word “am”
• And so on, until the fifth output distribution indicates ‘&lt;code>&amp;lt;end of sentence&amp;gt;&lt;/code>’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.
&lt;img src="https://jalammar.github.io/images/t/output_target_probability_distributions.png" width="auto" alt="" />
The targeted probability distributions we&amp;rsquo;ll train our model against in the training example for one sample sentence. (
&lt;a href="https://read.readwise.io/read/01gr446q3wegn465g7kjqfk962" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Thinking Place</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Thinking-Place/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Thinking-Place/</guid><description>&lt;h1 id="thinking-place">Thinking Place&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[thinkingplace.org]]&lt;/li>
&lt;li>Full Title: Thinking Place&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="http://thinkingplace.org/wittgenstein/" rel="noopener">http://thinkingplace.org/wittgenstein/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>The word Wittgenstein used for ‘thought’ in this context was Denkbewegungen which variously translates as ‘thought movements’, ‘thought-ways’ or ‘paths of thought’: (
&lt;a href="https://read.readwise.io/read/01gs6avw5zcb4a6dk1x5cgfydm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I am reminded here that Wittgenstein states in &lt;em>&lt;strong>Philosophical Investigations&lt;/strong>&lt;/em> that ‘a ‘signpost’ has a guiding function. It is not coercive. Its guiding function rests upon a custom which establishes a practice for its use – ‘a rule stands there like a signpost’ (Wittgenstein, 85). (
&lt;a href="https://read.readwise.io/read/01gs6ay2qzps1c9szbn7dpmxkz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[thinkingplace.org]]
title: &amp;ldquo;Thinking Place&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="thinking-place-1">Thinking Place&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[thinkingplace.org]]&lt;/li>
&lt;li>Full Title: Thinking Place&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="http://thinkingplace.org/wittgenstein/" rel="noopener">http://thinkingplace.org/wittgenstein/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>The word Wittgenstein used for ‘thought’ in this context was Denkbewegungen which variously translates as ‘thought movements’, ‘thought-ways’ or ‘paths of thought’: (
&lt;a href="https://read.readwise.io/read/01gs6avw5zcb4a6dk1x5cgfydm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I am reminded here that Wittgenstein states in &lt;em>&lt;strong>Philosophical Investigations&lt;/strong>&lt;/em> that ‘a ‘signpost’ has a guiding function. It is not coercive. Its guiding function rests upon a custom which establishes a practice for its use – ‘a rule stands there like a signpost’ (Wittgenstein, 85). (
&lt;a href="https://read.readwise.io/read/01gs6ay2qzps1c9szbn7dpmxkz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[thinkingplace.org]]
title: &amp;ldquo;Thinking Place&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="thinking-place-2">Thinking Place&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[thinkingplace.org]]&lt;/li>
&lt;li>Full Title: Thinking Place&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="http://thinkingplace.org/wittgenstein/" rel="noopener">http://thinkingplace.org/wittgenstein/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>The word Wittgenstein used for ‘thought’ in this context was Denkbewegungen which variously translates as ‘thought movements’, ‘thought-ways’ or ‘paths of thought’: (
&lt;a href="https://read.readwise.io/read/01gs6avw5zcb4a6dk1x5cgfydm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I am reminded here that Wittgenstein states in &lt;em>&lt;strong>Philosophical Investigations&lt;/strong>&lt;/em> that ‘a ‘signpost’ has a guiding function. It is not coercive. Its guiding function rests upon a custom which establishes a practice for its use – ‘a rule stands there like a signpost’ (Wittgenstein, 85). (
&lt;a href="https://read.readwise.io/read/01gs6ay2qzps1c9szbn7dpmxkz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[thinkingplace.org]]
title: &amp;ldquo;Thinking Place&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="thinking-place-3">Thinking Place&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article4.6bc1851654a0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[thinkingplace.org]]&lt;/li>
&lt;li>Full Title: Thinking Place&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="http://thinkingplace.org/wittgenstein/" rel="noopener">http://thinkingplace.org/wittgenstein/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>The word Wittgenstein used for ‘thought’ in this context was Denkbewegungen which variously translates as ‘thought movements’, ‘thought-ways’ or ‘paths of thought’: (
&lt;a href="https://read.readwise.io/read/01gs6avw5zcb4a6dk1x5cgfydm" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I am reminded here that Wittgenstein states in &lt;em>&lt;strong>Philosophical Investigations&lt;/strong>&lt;/em> that ‘a ‘signpost’ has a guiding function. It is not coercive. Its guiding function rests upon a custom which establishes a practice for its use – ‘a rule stands there like a signpost’ (Wittgenstein, 85). (
&lt;a href="https://read.readwise.io/read/01gs6ay2qzps1c9szbn7dpmxkz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Too Many Meetings Is Not Your Problem</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Too-Many-Meetings-Is-Not-Your-Problem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Too-Many-Meetings-Is-Not-Your-Problem/</guid><description>&lt;h1 id="too-many-meetings-is-not-your-problem">Too Many Meetings Is Not Your Problem&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1024/1*xq9Xfbdd2XCUe4j6wDpqeg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Judd Antin]]&lt;/li>
&lt;li>Full Title: Too Many Meetings Is Not Your Problem&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Improving meeting hygiene is not the solution to too many meetings. The cure is to invest in great process&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c" rel="noopener">https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Meetings are a symptom, not the disease. (
&lt;a href="https://read.readwise.io/read/01grf73n9pwjvhxah333b6vabg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of broken process. We use meetings as a crutch, a fallback. When we don’t know how to get work done, or we’re not willing to invest in a process that will actually advance the goal, we schedule meetings. (
&lt;a href="https://read.readwise.io/read/01grf76jm5pq83kc0agjmt9brr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our seat at the table starts to matter more than getting something done when we’re sitting there. (
&lt;a href="https://read.readwise.io/read/01grf77b8a500n5nbd72hmf08n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of not knowing what our jobs are. (
&lt;a href="https://read.readwise.io/read/01grf79xfsdrc0g2fw3sm7rwfy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I said no to meetings that I thought I didn’t need to be at, or which I thought would be a waste of time. I killed all the meetings I thought I was attending for status reasons (
&lt;a href="https://read.readwise.io/read/01grf84dxkh0gt0nysjd5m0jp1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Removing meetings wasn’t disconnecting, it was the beginning of treating the underlying disease. I had time to think, design, and contribute more. I had time to unblock people who needed me. I was still in meetings over half of the time, but I was more focused and prepared in the meetings that remained. And I was able to spend more time connecting. (
&lt;a href="https://read.readwise.io/read/01grf84z9cg40nah32kytzexnw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>eliminating half of my meetings was a leadership effectiveness strategy. (
&lt;a href="https://read.readwise.io/read/01grf85aghcv0g8m6zh0x1963d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Great process is lightweight, efficient, and adaptable. Too much is bad but not enough is worse. You need things like clear planning processes and well organized product development and design process that include all functions. And you need program managers (PgM, DpM, TpM, OMGpM) whose major job is to take care of this stuff. A great program manager can measure their worth in meetings removed. (
&lt;a href="https://read.readwise.io/read/01grfa4kf2y9t7tw519xt7gyfg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Meetings are full of wasted time.&lt;/strong> The (
&lt;a href="https://read.readwise.io/read/01grfa50051t58cj77ch6vme81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are for real-time conversations that yield more efficient progress than we could do any other way. (
&lt;a href="https://read.readwise.io/read/01grfa5mp8tv1yyphr21v73vjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do the hardest part right away. Slam it right down on the table, 5 minutes in. I’ve been in so many hour-long meetings that filled up the first 55 minutes with BS, only to finally get to the thing we &lt;em>really&lt;/em> needed to decide in the last 5. Why didn’t we start by discussing that? No one knows. Then we ran out of time. And scheduled another meeting. (
&lt;a href="https://read.readwise.io/read/01grfa7edhemg21ekbn5ktwtwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You must document what happened in a meeting, then tell everyone. If a meeting yielded a decision, but no one told the people who needed to know, was there even a meeting? (
&lt;a href="https://read.readwise.io/read/01grfac4v0sngtjgvxsr6bczjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>No matter what, I want to remind you that, with few exceptions, your job is not to be in meetings. Your job is to make progress (
&lt;a href="https://read.readwise.io/read/01grfajdc8zbcs4fnypjacp36d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Judd Antin]]
title: &amp;ldquo;Too Many Meetings Is Not Your Problem&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="too-many-meetings-is-not-your-problem-1">Too Many Meetings Is Not Your Problem&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1024/1*xq9Xfbdd2XCUe4j6wDpqeg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Judd Antin]]&lt;/li>
&lt;li>Full Title: Too Many Meetings Is Not Your Problem&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Improving meeting hygiene is not the solution to too many meetings. The cure is to invest in great process&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c" rel="noopener">https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Meetings are a symptom, not the disease. (
&lt;a href="https://read.readwise.io/read/01grf73n9pwjvhxah333b6vabg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of broken process. We use meetings as a crutch, a fallback. When we don’t know how to get work done, or we’re not willing to invest in a process that will actually advance the goal, we schedule meetings. (
&lt;a href="https://read.readwise.io/read/01grf76jm5pq83kc0agjmt9brr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our seat at the table starts to matter more than getting something done when we’re sitting there. (
&lt;a href="https://read.readwise.io/read/01grf77b8a500n5nbd72hmf08n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of not knowing what our jobs are. (
&lt;a href="https://read.readwise.io/read/01grf79xfsdrc0g2fw3sm7rwfy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I said no to meetings that I thought I didn’t need to be at, or which I thought would be a waste of time. I killed all the meetings I thought I was attending for status reasons (
&lt;a href="https://read.readwise.io/read/01grf84dxkh0gt0nysjd5m0jp1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Removing meetings wasn’t disconnecting, it was the beginning of treating the underlying disease. I had time to think, design, and contribute more. I had time to unblock people who needed me. I was still in meetings over half of the time, but I was more focused and prepared in the meetings that remained. And I was able to spend more time connecting. (
&lt;a href="https://read.readwise.io/read/01grf84z9cg40nah32kytzexnw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>eliminating half of my meetings was a leadership effectiveness strategy. (
&lt;a href="https://read.readwise.io/read/01grf85aghcv0g8m6zh0x1963d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Great process is lightweight, efficient, and adaptable. Too much is bad but not enough is worse. You need things like clear planning processes and well organized product development and design process that include all functions. And you need program managers (PgM, DpM, TpM, OMGpM) whose major job is to take care of this stuff. A great program manager can measure their worth in meetings removed. (
&lt;a href="https://read.readwise.io/read/01grfa4kf2y9t7tw519xt7gyfg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Meetings are full of wasted time.&lt;/strong> The (
&lt;a href="https://read.readwise.io/read/01grfa50051t58cj77ch6vme81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are for real-time conversations that yield more efficient progress than we could do any other way. (
&lt;a href="https://read.readwise.io/read/01grfa5mp8tv1yyphr21v73vjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do the hardest part right away. Slam it right down on the table, 5 minutes in. I’ve been in so many hour-long meetings that filled up the first 55 minutes with BS, only to finally get to the thing we &lt;em>really&lt;/em> needed to decide in the last 5. Why didn’t we start by discussing that? No one knows. Then we ran out of time. And scheduled another meeting. (
&lt;a href="https://read.readwise.io/read/01grfa7edhemg21ekbn5ktwtwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You must document what happened in a meeting, then tell everyone. If a meeting yielded a decision, but no one told the people who needed to know, was there even a meeting? (
&lt;a href="https://read.readwise.io/read/01grfac4v0sngtjgvxsr6bczjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>No matter what, I want to remind you that, with few exceptions, your job is not to be in meetings. Your job is to make progress (
&lt;a href="https://read.readwise.io/read/01grfajdc8zbcs4fnypjacp36d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Judd Antin]]
title: &amp;ldquo;Too Many Meetings Is Not Your Problem&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="too-many-meetings-is-not-your-problem-2">Too Many Meetings Is Not Your Problem&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1024/1*xq9Xfbdd2XCUe4j6wDpqeg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Judd Antin]]&lt;/li>
&lt;li>Full Title: Too Many Meetings Is Not Your Problem&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Improving meeting hygiene is not the solution to too many meetings. The cure is to invest in great process&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c" rel="noopener">https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Meetings are a symptom, not the disease. (
&lt;a href="https://read.readwise.io/read/01grf73n9pwjvhxah333b6vabg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of broken process. We use meetings as a crutch, a fallback. When we don’t know how to get work done, or we’re not willing to invest in a process that will actually advance the goal, we schedule meetings. (
&lt;a href="https://read.readwise.io/read/01grf76jm5pq83kc0agjmt9brr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our seat at the table starts to matter more than getting something done when we’re sitting there. (
&lt;a href="https://read.readwise.io/read/01grf77b8a500n5nbd72hmf08n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of not knowing what our jobs are. (
&lt;a href="https://read.readwise.io/read/01grf79xfsdrc0g2fw3sm7rwfy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I said no to meetings that I thought I didn’t need to be at, or which I thought would be a waste of time. I killed all the meetings I thought I was attending for status reasons (
&lt;a href="https://read.readwise.io/read/01grf84dxkh0gt0nysjd5m0jp1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Removing meetings wasn’t disconnecting, it was the beginning of treating the underlying disease. I had time to think, design, and contribute more. I had time to unblock people who needed me. I was still in meetings over half of the time, but I was more focused and prepared in the meetings that remained. And I was able to spend more time connecting. (
&lt;a href="https://read.readwise.io/read/01grf84z9cg40nah32kytzexnw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>eliminating half of my meetings was a leadership effectiveness strategy. (
&lt;a href="https://read.readwise.io/read/01grf85aghcv0g8m6zh0x1963d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Great process is lightweight, efficient, and adaptable. Too much is bad but not enough is worse. You need things like clear planning processes and well organized product development and design process that include all functions. And you need program managers (PgM, DpM, TpM, OMGpM) whose major job is to take care of this stuff. A great program manager can measure their worth in meetings removed. (
&lt;a href="https://read.readwise.io/read/01grfa4kf2y9t7tw519xt7gyfg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Meetings are full of wasted time.&lt;/strong> The (
&lt;a href="https://read.readwise.io/read/01grfa50051t58cj77ch6vme81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are for real-time conversations that yield more efficient progress than we could do any other way. (
&lt;a href="https://read.readwise.io/read/01grfa5mp8tv1yyphr21v73vjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do the hardest part right away. Slam it right down on the table, 5 minutes in. I’ve been in so many hour-long meetings that filled up the first 55 minutes with BS, only to finally get to the thing we &lt;em>really&lt;/em> needed to decide in the last 5. Why didn’t we start by discussing that? No one knows. Then we ran out of time. And scheduled another meeting. (
&lt;a href="https://read.readwise.io/read/01grfa7edhemg21ekbn5ktwtwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You must document what happened in a meeting, then tell everyone. If a meeting yielded a decision, but no one told the people who needed to know, was there even a meeting? (
&lt;a href="https://read.readwise.io/read/01grfac4v0sngtjgvxsr6bczjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>No matter what, I want to remind you that, with few exceptions, your job is not to be in meetings. Your job is to make progress (
&lt;a href="https://read.readwise.io/read/01grfajdc8zbcs4fnypjacp36d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Judd Antin]]
title: &amp;ldquo;Too Many Meetings Is Not Your Problem&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="too-many-meetings-is-not-your-problem-3">Too Many Meetings Is Not Your Problem&lt;/h1>
&lt;p>
&lt;img src="https://miro.medium.com/max/1024/1*xq9Xfbdd2XCUe4j6wDpqeg.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Judd Antin]]&lt;/li>
&lt;li>Full Title: Too Many Meetings Is Not Your Problem&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Improving meeting hygiene is not the solution to too many meetings. The cure is to invest in great process&lt;/li>
&lt;li>URL:
&lt;a href="https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c" rel="noopener">https://medium.com/onebigthought/too-many-meetings-is-not-your-problem-7eafa7ae477c&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Meetings are a symptom, not the disease. (
&lt;a href="https://read.readwise.io/read/01grf73n9pwjvhxah333b6vabg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of broken process. We use meetings as a crutch, a fallback. When we don’t know how to get work done, or we’re not willing to invest in a process that will actually advance the goal, we schedule meetings. (
&lt;a href="https://read.readwise.io/read/01grf76jm5pq83kc0agjmt9brr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our seat at the table starts to matter more than getting something done when we’re sitting there. (
&lt;a href="https://read.readwise.io/read/01grf77b8a500n5nbd72hmf08n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are a symptom of not knowing what our jobs are. (
&lt;a href="https://read.readwise.io/read/01grf79xfsdrc0g2fw3sm7rwfy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I said no to meetings that I thought I didn’t need to be at, or which I thought would be a waste of time. I killed all the meetings I thought I was attending for status reasons (
&lt;a href="https://read.readwise.io/read/01grf84dxkh0gt0nysjd5m0jp1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Removing meetings wasn’t disconnecting, it was the beginning of treating the underlying disease. I had time to think, design, and contribute more. I had time to unblock people who needed me. I was still in meetings over half of the time, but I was more focused and prepared in the meetings that remained. And I was able to spend more time connecting. (
&lt;a href="https://read.readwise.io/read/01grf84z9cg40nah32kytzexnw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>eliminating half of my meetings was a leadership effectiveness strategy. (
&lt;a href="https://read.readwise.io/read/01grf85aghcv0g8m6zh0x1963d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Great process is lightweight, efficient, and adaptable. Too much is bad but not enough is worse. You need things like clear planning processes and well organized product development and design process that include all functions. And you need program managers (PgM, DpM, TpM, OMGpM) whose major job is to take care of this stuff. A great program manager can measure their worth in meetings removed. (
&lt;a href="https://read.readwise.io/read/01grfa4kf2y9t7tw519xt7gyfg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>Meetings are full of wasted time.&lt;/strong> The (
&lt;a href="https://read.readwise.io/read/01grfa50051t58cj77ch6vme81" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Meetings are for real-time conversations that yield more efficient progress than we could do any other way. (
&lt;a href="https://read.readwise.io/read/01grfa5mp8tv1yyphr21v73vjk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do the hardest part right away. Slam it right down on the table, 5 minutes in. I’ve been in so many hour-long meetings that filled up the first 55 minutes with BS, only to finally get to the thing we &lt;em>really&lt;/em> needed to decide in the last 5. Why didn’t we start by discussing that? No one knows. Then we ran out of time. And scheduled another meeting. (
&lt;a href="https://read.readwise.io/read/01grfa7edhemg21ekbn5ktwtwc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You must document what happened in a meeting, then tell everyone. If a meeting yielded a decision, but no one told the people who needed to know, was there even a meeting? (
&lt;a href="https://read.readwise.io/read/01grfac4v0sngtjgvxsr6bczjr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>No matter what, I want to remind you that, with few exceptions, your job is not to be in meetings. Your job is to make progress (
&lt;a href="https://read.readwise.io/read/01grfajdc8zbcs4fnypjacp36d" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Toolformer: LMs can teach themselves to use tools</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Toolformer-LMs-can-teach-themselves-to-use-tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Toolformer-LMs-can-teach-themselves-to-use-tools/</guid><description>&lt;h1 id="toolformer-lms-can-teach-themselves-to-use-tools">Toolformer: LMs can teach themselves to use tools&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[arxiv.org]]&lt;/li>
&lt;li>Full Title: Toolformer: LMs can teach themselves to use tools&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://arxiv.org/pdf/2302.04761v1.pdf" rel="noopener">https://arxiv.org/pdf/2302.04761v1.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Toolformer: Language Models Can Teach Themselves to Use Tools (
&lt;a href="https://read.readwise.io/read/01gs56zjwr4x67myv3mm7x66k9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we show that
LMs can teach themselves to use external tools
via simple APIs (
&lt;a href="https://read.readwise.io/read/01gs55kwd9kr4vas1cdfwhs26p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Toolformer, a model
trained to decide which APIs to call, when to
call them, what arguments to pass, and how to
best incorporate the results into future token
prediction. (
&lt;a href="https://read.readwise.io/read/01gs55m3606zentxqprj1gp7b9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. This is done in a self-supervised
way, requiring nothing more than a handful of
demonstrations for each API. We incorporate
a range of tools, including a calculator, a Q&amp;amp;A
system, a search engine, a translation system,
and a calendar. Toolformer achieves substan-
tially improved zero-shot performance across
a variety of downstream tasks, often competi-
tive with much larger models, without sacriﬁc-
ing its core language modeling abilities. (
&lt;a href="https://read.readwise.io/read/01gs55mpwycfyp44pg4gjc83aj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>, existing ap-
proaches either rely on large amounts of human
annotations (Komeili et al., 2022; Thoppilan et al.,
2022) or limit tool use to task-speciﬁc settings only
(e.g., Gao et al., 2022; Parisi et al., 2022), (
&lt;a href="https://read.readwise.io/read/01gs55pa95z2zj3cpb168ekntk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>limitations include an inability to access
up-to-date information on recent events (
&lt;a href="https://read.readwise.io/read/01gs55n8qrc91eer80fc74w9sj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>tendency to hallucinate
facts ( (
&lt;a href="https://read.readwise.io/read/01gs55nb745dh6nn5gfg88k9pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>difﬁcul-
ties in understanding low-resource languages (
&lt;a href="https://read.readwise.io/read/01gs55ndxva4tqsbw3e9qt4b5y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a lack of mathematical skills to per-
form precise calculations (
&lt;a href="https://read.readwise.io/read/01gs55ngp7a4x9j123mfx7h8rt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) and an
unawareness of the progression of time (
&lt;a href="https://read.readwise.io/read/01gs55nk10e7szqrk6ybnmzfbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The use of tools should be learned in a
self-supervised way without requiring large
amounts of human annotations. (
&lt;a href="https://read.readwise.io/read/01gs55qqchkt3x8ygg1xj5r9p4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The LM should not lose any of its generality
and should be able to decide for itself when
and how to use which tool. (
&lt;a href="https://read.readwise.io/read/01gs55qz0f2332adm14jdjtmq2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our aim is to equip a language model M with the
ability to use different tools by means of API calls.
We require that inputs and outputs for each API
can be represented as text sequences. This allows
seamless insertion of API calls into any given text,
using special tokens to mark the start and end of
each such call. (
&lt;a href="https://read.readwise.io/read/01gs56404drd4dzfjjj903bs74" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>using large LMs with in-
context learning (Brown et al., 2020) to generate
entire datasets from scratch (
&lt;a href="https://read.readwise.io/read/01gs5627sh3h78gknv00rwshbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Given just a handful of human-written examples
of how an API can be used, we let a LM annotate
a huge language modeling dataset with potential
API calls. We then use a self-supervised loss to
determine which of these API calls actually help
the model in predicting future tokens. Finally, we
ﬁnetune the LM itself on the API calls that it con-
siders useful. (
&lt;a href="https://read.readwise.io/read/01gs562vsakc7e6gm4tkvz0mh2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a next step, we execute
all API calls generated by M to obtain the corre-
sponding results. How this is done depends entirely
on the API itself – for example, it can involve call-
ing another neural network, executing a Python
script or using a retrieval system to perform search
over a large corpus (
&lt;a href="https://read.readwise.io/read/01gs5651fp2zbjy5s11ykxtfxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each API, we write a
prompt P(x) that encourages the LM to anno-
tate an example x = x1, . . . , xn with API calls. (
&lt;a href="https://read.readwise.io/read/01gs564marcfgazs5b5j98hch2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Model Finetuning After sampling and ﬁltering
calls for all APIs, we ﬁnally merge the remaining
API calls and interleave them with the original
inputs (
&lt;a href="https://read.readwise.io/read/01gs565q74k49z4vr8xkm484jt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One such limi-
tation is the inability of Toolformer to use tools in a
chain (i.e., using the output of one tool as an input
for another tool). This is due to the fact that API
calls for each tool are generated independently; as a
consequence, there are no examples of chained tool
use in the ﬁnetuning dataset (
&lt;a href="https://read.readwise.io/read/01gs567xjvjtxnzbkz1py92r28" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we found models
trained with Toolformer to often be sensitive to the
exact wording of their input when deciding whether
or not to call an API; this is perhaps unsurprising
given that LMs are known to be very sensitive to
the prompt they are provided with in both zero-
and few-shot settings (
&lt;a href="https://read.readwise.io/read/01gs568afsvrq89wf0zcx1c268" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[arxiv.org]]
title: &amp;ldquo;Toolformer: LMs can teach themselves to use tools&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="toolformer-lms-can-teach-themselves-to-use-tools-1">Toolformer: LMs can teach themselves to use tools&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[arxiv.org]]&lt;/li>
&lt;li>Full Title: Toolformer: LMs can teach themselves to use tools&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://arxiv.org/pdf/2302.04761v1.pdf" rel="noopener">https://arxiv.org/pdf/2302.04761v1.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Toolformer: Language Models Can Teach Themselves to Use Tools (
&lt;a href="https://read.readwise.io/read/01gs56zjwr4x67myv3mm7x66k9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we show that
LMs can teach themselves to use external tools
via simple APIs (
&lt;a href="https://read.readwise.io/read/01gs55kwd9kr4vas1cdfwhs26p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Toolformer, a model
trained to decide which APIs to call, when to
call them, what arguments to pass, and how to
best incorporate the results into future token
prediction. (
&lt;a href="https://read.readwise.io/read/01gs55m3606zentxqprj1gp7b9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. This is done in a self-supervised
way, requiring nothing more than a handful of
demonstrations for each API. We incorporate
a range of tools, including a calculator, a Q&amp;amp;A
system, a search engine, a translation system,
and a calendar. Toolformer achieves substan-
tially improved zero-shot performance across
a variety of downstream tasks, often competi-
tive with much larger models, without sacriﬁc-
ing its core language modeling abilities. (
&lt;a href="https://read.readwise.io/read/01gs55mpwycfyp44pg4gjc83aj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>, existing ap-
proaches either rely on large amounts of human
annotations (Komeili et al., 2022; Thoppilan et al.,
2022) or limit tool use to task-speciﬁc settings only
(e.g., Gao et al., 2022; Parisi et al., 2022), (
&lt;a href="https://read.readwise.io/read/01gs55pa95z2zj3cpb168ekntk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>limitations include an inability to access
up-to-date information on recent events (
&lt;a href="https://read.readwise.io/read/01gs55n8qrc91eer80fc74w9sj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>tendency to hallucinate
facts ( (
&lt;a href="https://read.readwise.io/read/01gs55nb745dh6nn5gfg88k9pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>difﬁcul-
ties in understanding low-resource languages (
&lt;a href="https://read.readwise.io/read/01gs55ndxva4tqsbw3e9qt4b5y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a lack of mathematical skills to per-
form precise calculations (
&lt;a href="https://read.readwise.io/read/01gs55ngp7a4x9j123mfx7h8rt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) and an
unawareness of the progression of time (
&lt;a href="https://read.readwise.io/read/01gs55nk10e7szqrk6ybnmzfbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The use of tools should be learned in a
self-supervised way without requiring large
amounts of human annotations. (
&lt;a href="https://read.readwise.io/read/01gs55qqchkt3x8ygg1xj5r9p4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The LM should not lose any of its generality
and should be able to decide for itself when
and how to use which tool. (
&lt;a href="https://read.readwise.io/read/01gs55qz0f2332adm14jdjtmq2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our aim is to equip a language model M with the
ability to use different tools by means of API calls.
We require that inputs and outputs for each API
can be represented as text sequences. This allows
seamless insertion of API calls into any given text,
using special tokens to mark the start and end of
each such call. (
&lt;a href="https://read.readwise.io/read/01gs56404drd4dzfjjj903bs74" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>using large LMs with in-
context learning (Brown et al., 2020) to generate
entire datasets from scratch (
&lt;a href="https://read.readwise.io/read/01gs5627sh3h78gknv00rwshbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Given just a handful of human-written examples
of how an API can be used, we let a LM annotate
a huge language modeling dataset with potential
API calls. We then use a self-supervised loss to
determine which of these API calls actually help
the model in predicting future tokens. Finally, we
ﬁnetune the LM itself on the API calls that it con-
siders useful. (
&lt;a href="https://read.readwise.io/read/01gs562vsakc7e6gm4tkvz0mh2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a next step, we execute
all API calls generated by M to obtain the corre-
sponding results. How this is done depends entirely
on the API itself – for example, it can involve call-
ing another neural network, executing a Python
script or using a retrieval system to perform search
over a large corpus (
&lt;a href="https://read.readwise.io/read/01gs5651fp2zbjy5s11ykxtfxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each API, we write a
prompt P(x) that encourages the LM to anno-
tate an example x = x1, . . . , xn with API calls. (
&lt;a href="https://read.readwise.io/read/01gs564marcfgazs5b5j98hch2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Model Finetuning After sampling and ﬁltering
calls for all APIs, we ﬁnally merge the remaining
API calls and interleave them with the original
inputs (
&lt;a href="https://read.readwise.io/read/01gs565q74k49z4vr8xkm484jt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One such limi-
tation is the inability of Toolformer to use tools in a
chain (i.e., using the output of one tool as an input
for another tool). This is due to the fact that API
calls for each tool are generated independently; as a
consequence, there are no examples of chained tool
use in the ﬁnetuning dataset (
&lt;a href="https://read.readwise.io/read/01gs567xjvjtxnzbkz1py92r28" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we found models
trained with Toolformer to often be sensitive to the
exact wording of their input when deciding whether
or not to call an API; this is perhaps unsurprising
given that LMs are known to be very sensitive to
the prompt they are provided with in both zero-
and few-shot settings (
&lt;a href="https://read.readwise.io/read/01gs568afsvrq89wf0zcx1c268" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[arxiv.org]]
title: &amp;ldquo;Toolformer: LMs can teach themselves to use tools&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="toolformer-lms-can-teach-themselves-to-use-tools-2">Toolformer: LMs can teach themselves to use tools&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[arxiv.org]]&lt;/li>
&lt;li>Full Title: Toolformer: LMs can teach themselves to use tools&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://arxiv.org/pdf/2302.04761v1.pdf" rel="noopener">https://arxiv.org/pdf/2302.04761v1.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Toolformer: Language Models Can Teach Themselves to Use Tools (
&lt;a href="https://read.readwise.io/read/01gs56zjwr4x67myv3mm7x66k9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we show that
LMs can teach themselves to use external tools
via simple APIs (
&lt;a href="https://read.readwise.io/read/01gs55kwd9kr4vas1cdfwhs26p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Toolformer, a model
trained to decide which APIs to call, when to
call them, what arguments to pass, and how to
best incorporate the results into future token
prediction. (
&lt;a href="https://read.readwise.io/read/01gs55m3606zentxqprj1gp7b9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. This is done in a self-supervised
way, requiring nothing more than a handful of
demonstrations for each API. We incorporate
a range of tools, including a calculator, a Q&amp;amp;A
system, a search engine, a translation system,
and a calendar. Toolformer achieves substan-
tially improved zero-shot performance across
a variety of downstream tasks, often competi-
tive with much larger models, without sacriﬁc-
ing its core language modeling abilities. (
&lt;a href="https://read.readwise.io/read/01gs55mpwycfyp44pg4gjc83aj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>, existing ap-
proaches either rely on large amounts of human
annotations (Komeili et al., 2022; Thoppilan et al.,
2022) or limit tool use to task-speciﬁc settings only
(e.g., Gao et al., 2022; Parisi et al., 2022), (
&lt;a href="https://read.readwise.io/read/01gs55pa95z2zj3cpb168ekntk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>limitations include an inability to access
up-to-date information on recent events (
&lt;a href="https://read.readwise.io/read/01gs55n8qrc91eer80fc74w9sj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>tendency to hallucinate
facts ( (
&lt;a href="https://read.readwise.io/read/01gs55nb745dh6nn5gfg88k9pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>difﬁcul-
ties in understanding low-resource languages (
&lt;a href="https://read.readwise.io/read/01gs55ndxva4tqsbw3e9qt4b5y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a lack of mathematical skills to per-
form precise calculations (
&lt;a href="https://read.readwise.io/read/01gs55ngp7a4x9j123mfx7h8rt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) and an
unawareness of the progression of time (
&lt;a href="https://read.readwise.io/read/01gs55nk10e7szqrk6ybnmzfbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The use of tools should be learned in a
self-supervised way without requiring large
amounts of human annotations. (
&lt;a href="https://read.readwise.io/read/01gs55qqchkt3x8ygg1xj5r9p4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The LM should not lose any of its generality
and should be able to decide for itself when
and how to use which tool. (
&lt;a href="https://read.readwise.io/read/01gs55qz0f2332adm14jdjtmq2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our aim is to equip a language model M with the
ability to use different tools by means of API calls.
We require that inputs and outputs for each API
can be represented as text sequences. This allows
seamless insertion of API calls into any given text,
using special tokens to mark the start and end of
each such call. (
&lt;a href="https://read.readwise.io/read/01gs56404drd4dzfjjj903bs74" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>using large LMs with in-
context learning (Brown et al., 2020) to generate
entire datasets from scratch (
&lt;a href="https://read.readwise.io/read/01gs5627sh3h78gknv00rwshbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Given just a handful of human-written examples
of how an API can be used, we let a LM annotate
a huge language modeling dataset with potential
API calls. We then use a self-supervised loss to
determine which of these API calls actually help
the model in predicting future tokens. Finally, we
ﬁnetune the LM itself on the API calls that it con-
siders useful. (
&lt;a href="https://read.readwise.io/read/01gs562vsakc7e6gm4tkvz0mh2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a next step, we execute
all API calls generated by M to obtain the corre-
sponding results. How this is done depends entirely
on the API itself – for example, it can involve call-
ing another neural network, executing a Python
script or using a retrieval system to perform search
over a large corpus (
&lt;a href="https://read.readwise.io/read/01gs5651fp2zbjy5s11ykxtfxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each API, we write a
prompt P(x) that encourages the LM to anno-
tate an example x = x1, . . . , xn with API calls. (
&lt;a href="https://read.readwise.io/read/01gs564marcfgazs5b5j98hch2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Model Finetuning After sampling and ﬁltering
calls for all APIs, we ﬁnally merge the remaining
API calls and interleave them with the original
inputs (
&lt;a href="https://read.readwise.io/read/01gs565q74k49z4vr8xkm484jt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One such limi-
tation is the inability of Toolformer to use tools in a
chain (i.e., using the output of one tool as an input
for another tool). This is due to the fact that API
calls for each tool are generated independently; as a
consequence, there are no examples of chained tool
use in the ﬁnetuning dataset (
&lt;a href="https://read.readwise.io/read/01gs567xjvjtxnzbkz1py92r28" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we found models
trained with Toolformer to often be sensitive to the
exact wording of their input when deciding whether
or not to call an API; this is perhaps unsurprising
given that LMs are known to be very sensitive to
the prompt they are provided with in both zero-
and few-shot settings (
&lt;a href="https://read.readwise.io/read/01gs568afsvrq89wf0zcx1c268" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[arxiv.org]]
title: &amp;ldquo;Toolformer: LMs can teach themselves to use tools&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="toolformer-lms-can-teach-themselves-to-use-tools-3">Toolformer: LMs can teach themselves to use tools&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[arxiv.org]]&lt;/li>
&lt;li>Full Title: Toolformer: LMs can teach themselves to use tools&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://arxiv.org/pdf/2302.04761v1.pdf" rel="noopener">https://arxiv.org/pdf/2302.04761v1.pdf&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Toolformer: Language Models Can Teach Themselves to Use Tools (
&lt;a href="https://read.readwise.io/read/01gs56zjwr4x67myv3mm7x66k9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we show that
LMs can teach themselves to use external tools
via simple APIs (
&lt;a href="https://read.readwise.io/read/01gs55kwd9kr4vas1cdfwhs26p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Toolformer, a model
trained to decide which APIs to call, when to
call them, what arguments to pass, and how to
best incorporate the results into future token
prediction. (
&lt;a href="https://read.readwise.io/read/01gs55m3606zentxqprj1gp7b9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. This is done in a self-supervised
way, requiring nothing more than a handful of
demonstrations for each API. We incorporate
a range of tools, including a calculator, a Q&amp;amp;A
system, a search engine, a translation system,
and a calendar. Toolformer achieves substan-
tially improved zero-shot performance across
a variety of downstream tasks, often competi-
tive with much larger models, without sacriﬁc-
ing its core language modeling abilities. (
&lt;a href="https://read.readwise.io/read/01gs55mpwycfyp44pg4gjc83aj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>, existing ap-
proaches either rely on large amounts of human
annotations (Komeili et al., 2022; Thoppilan et al.,
2022) or limit tool use to task-speciﬁc settings only
(e.g., Gao et al., 2022; Parisi et al., 2022), (
&lt;a href="https://read.readwise.io/read/01gs55pa95z2zj3cpb168ekntk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>limitations include an inability to access
up-to-date information on recent events (
&lt;a href="https://read.readwise.io/read/01gs55n8qrc91eer80fc74w9sj" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>tendency to hallucinate
facts ( (
&lt;a href="https://read.readwise.io/read/01gs55nb745dh6nn5gfg88k9pb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>difﬁcul-
ties in understanding low-resource languages (
&lt;a href="https://read.readwise.io/read/01gs55ndxva4tqsbw3e9qt4b5y" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a lack of mathematical skills to per-
form precise calculations (
&lt;a href="https://read.readwise.io/read/01gs55ngp7a4x9j123mfx7h8rt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>) and an
unawareness of the progression of time (
&lt;a href="https://read.readwise.io/read/01gs55nk10e7szqrk6ybnmzfbk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The use of tools should be learned in a
self-supervised way without requiring large
amounts of human annotations. (
&lt;a href="https://read.readwise.io/read/01gs55qqchkt3x8ygg1xj5r9p4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The LM should not lose any of its generality
and should be able to decide for itself when
and how to use which tool. (
&lt;a href="https://read.readwise.io/read/01gs55qz0f2332adm14jdjtmq2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Our aim is to equip a language model M with the
ability to use different tools by means of API calls.
We require that inputs and outputs for each API
can be represented as text sequences. This allows
seamless insertion of API calls into any given text,
using special tokens to mark the start and end of
each such call. (
&lt;a href="https://read.readwise.io/read/01gs56404drd4dzfjjj903bs74" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>using large LMs with in-
context learning (Brown et al., 2020) to generate
entire datasets from scratch (
&lt;a href="https://read.readwise.io/read/01gs5627sh3h78gknv00rwshbc" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Given just a handful of human-written examples
of how an API can be used, we let a LM annotate
a huge language modeling dataset with potential
API calls. We then use a self-supervised loss to
determine which of these API calls actually help
the model in predicting future tokens. Finally, we
ﬁnetune the LM itself on the API calls that it con-
siders useful. (
&lt;a href="https://read.readwise.io/read/01gs562vsakc7e6gm4tkvz0mh2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>As a next step, we execute
all API calls generated by M to obtain the corre-
sponding results. How this is done depends entirely
on the API itself – for example, it can involve call-
ing another neural network, executing a Python
script or using a retrieval system to perform search
over a large corpus (
&lt;a href="https://read.readwise.io/read/01gs5651fp2zbjy5s11ykxtfxy" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For each API, we write a
prompt P(x) that encourages the LM to anno-
tate an example x = x1, . . . , xn with API calls. (
&lt;a href="https://read.readwise.io/read/01gs564marcfgazs5b5j98hch2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Model Finetuning After sampling and ﬁltering
calls for all APIs, we ﬁnally merge the remaining
API calls and interleave them with the original
inputs (
&lt;a href="https://read.readwise.io/read/01gs565q74k49z4vr8xkm484jt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>One such limi-
tation is the inability of Toolformer to use tools in a
chain (i.e., using the output of one tool as an input
for another tool). This is due to the fact that API
calls for each tool are generated independently; as a
consequence, there are no examples of chained tool
use in the ﬁnetuning dataset (
&lt;a href="https://read.readwise.io/read/01gs567xjvjtxnzbkz1py92r28" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we found models
trained with Toolformer to often be sensitive to the
exact wording of their input when deciding whether
or not to call an API; this is perhaps unsurprising
given that LMs are known to be very sensitive to
the prompt they are provided with in both zero-
and few-shot settings (
&lt;a href="https://read.readwise.io/read/01gs568afsvrq89wf0zcx1c268" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Transformer Models: An Introduction and Catalog</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Transformer-Models-An-Introduction-and-Catalog/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Transformer-Models-An-Introduction-and-Catalog/</guid><description>&lt;h1 id="transformer-models-an-introduction-and-catalog">Transformer Models: An Introduction and Catalog&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[AI, software, tech, and people, not in that order&amp;hellip; by X]]&lt;/li>
&lt;li>Full Title: Transformer Models: An Introduction and Catalog&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/" rel="noopener">https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Transformers are a class of deep learning models that are defined by some architectural traits. They were first introduced in the now famous
&lt;a href="https://arxiv.org/abs/1706.03762" rel="noopener">Attention is All you Need&lt;/a> paper by Google researchers in 2017 (the paper has accumulated a whooping 38k citations in only 5 years) and associated
&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" rel="noopener">blog post&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr3n6ernt5z0vternwwjdav3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Transformer architecture is a specific instance of the
&lt;a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/" rel="noopener">encoder-decoder models&lt;/a> that had become popular just over the 2–3 years prior. Up until that point however, attention was just one of the mechanisms used by these models, which were mostly based on LSTM (Long Short Term Memory) and other RNN (Recurrent Neural Networks) variations. The key insight of the Transformers paper was that, as the title implies, attention could be used as the only mechanism to derive dependencies between input and output. (
&lt;a href="https://read.readwise.io/read/01gr3n6gp4ett44parxp9atn9b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://amatriain.net/blog/images/02-02.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr3n6mt148859yrdd70hcsxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A generic encoder/decoder architecture is made up of two models. The encoder takes the input and encodes it into a fixed-length vector. The decoder takes that vector and decodes it into the output sequence. The encoder and decoder are jointly trained to minimize the conditional log-likelihood. Once trained the encoder/decoder can generate an output given an input sequence or can score a pair of input/output sequences. (
&lt;a href="https://read.readwise.io/read/01gr3n8nw20y7ajxcesdrghgcx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>n the case of the original Transformer architecture, both encoder and decoder had 6 identical layers. In each of those 6 layers the Encoder has two sub layers: a multi-head attention layer, and a simple feed forward network. Each sublayer has a residual connection and a layer normalization. The output size of the Encoder is 512. The Decoder adds a third sublayer, which is another multi-head attention layer over the output of the Encoder. Besides, the other multi-head layer in the decoder is masked to prevent attention to subsequent positions. (
&lt;a href="https://read.readwise.io/read/01gr3n9m9h1r1hft2s4e6qjns5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>t is clear from the description above that the only “exotic” elements of the model architecture are the multi-headed attention, but, as described above, that is where the whole power of the model lies (
&lt;a href="https://read.readwise.io/read/01gr3nap0873cpqq76ag1wrpky" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention function is a mapping between a query and a set of key-value pairs to an output. (
&lt;a href="https://read.readwise.io/read/01gr3nbj85qnq00xc34bd6h9wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Transformers use multi-headed attention, which is a parallel computation of a specific attention function called scaled dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr3nbwyt3ess4zefya12acg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[AI, software, tech, and people, not in that order&amp;hellip; by X]]
title: &amp;ldquo;Transformer Models: An Introduction and Catalog&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="transformer-models-an-introduction-and-catalog-1">Transformer Models: An Introduction and Catalog&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[AI, software, tech, and people, not in that order&amp;hellip; by X]]&lt;/li>
&lt;li>Full Title: Transformer Models: An Introduction and Catalog&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/" rel="noopener">https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Transformers are a class of deep learning models that are defined by some architectural traits. They were first introduced in the now famous
&lt;a href="https://arxiv.org/abs/1706.03762" rel="noopener">Attention is All you Need&lt;/a> paper by Google researchers in 2017 (the paper has accumulated a whooping 38k citations in only 5 years) and associated
&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" rel="noopener">blog post&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr3n6ernt5z0vternwwjdav3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Transformer architecture is a specific instance of the
&lt;a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/" rel="noopener">encoder-decoder models&lt;/a> that had become popular just over the 2–3 years prior. Up until that point however, attention was just one of the mechanisms used by these models, which were mostly based on LSTM (Long Short Term Memory) and other RNN (Recurrent Neural Networks) variations. The key insight of the Transformers paper was that, as the title implies, attention could be used as the only mechanism to derive dependencies between input and output. (
&lt;a href="https://read.readwise.io/read/01gr3n6gp4ett44parxp9atn9b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://amatriain.net/blog/images/02-02.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr3n6mt148859yrdd70hcsxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A generic encoder/decoder architecture is made up of two models. The encoder takes the input and encodes it into a fixed-length vector. The decoder takes that vector and decodes it into the output sequence. The encoder and decoder are jointly trained to minimize the conditional log-likelihood. Once trained the encoder/decoder can generate an output given an input sequence or can score a pair of input/output sequences. (
&lt;a href="https://read.readwise.io/read/01gr3n8nw20y7ajxcesdrghgcx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>n the case of the original Transformer architecture, both encoder and decoder had 6 identical layers. In each of those 6 layers the Encoder has two sub layers: a multi-head attention layer, and a simple feed forward network. Each sublayer has a residual connection and a layer normalization. The output size of the Encoder is 512. The Decoder adds a third sublayer, which is another multi-head attention layer over the output of the Encoder. Besides, the other multi-head layer in the decoder is masked to prevent attention to subsequent positions. (
&lt;a href="https://read.readwise.io/read/01gr3n9m9h1r1hft2s4e6qjns5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>t is clear from the description above that the only “exotic” elements of the model architecture are the multi-headed attention, but, as described above, that is where the whole power of the model lies (
&lt;a href="https://read.readwise.io/read/01gr3nap0873cpqq76ag1wrpky" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention function is a mapping between a query and a set of key-value pairs to an output. (
&lt;a href="https://read.readwise.io/read/01gr3nbj85qnq00xc34bd6h9wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Transformers use multi-headed attention, which is a parallel computation of a specific attention function called scaled dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr3nbwyt3ess4zefya12acg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[AI, software, tech, and people, not in that order&amp;hellip; by X]]
title: &amp;ldquo;Transformer Models: An Introduction and Catalog&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="transformer-models-an-introduction-and-catalog-2">Transformer Models: An Introduction and Catalog&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[AI, software, tech, and people, not in that order&amp;hellip; by X]]&lt;/li>
&lt;li>Full Title: Transformer Models: An Introduction and Catalog&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/" rel="noopener">https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Transformers are a class of deep learning models that are defined by some architectural traits. They were first introduced in the now famous
&lt;a href="https://arxiv.org/abs/1706.03762" rel="noopener">Attention is All you Need&lt;/a> paper by Google researchers in 2017 (the paper has accumulated a whooping 38k citations in only 5 years) and associated
&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" rel="noopener">blog post&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr3n6ernt5z0vternwwjdav3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Transformer architecture is a specific instance of the
&lt;a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/" rel="noopener">encoder-decoder models&lt;/a> that had become popular just over the 2–3 years prior. Up until that point however, attention was just one of the mechanisms used by these models, which were mostly based on LSTM (Long Short Term Memory) and other RNN (Recurrent Neural Networks) variations. The key insight of the Transformers paper was that, as the title implies, attention could be used as the only mechanism to derive dependencies between input and output. (
&lt;a href="https://read.readwise.io/read/01gr3n6gp4ett44parxp9atn9b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://amatriain.net/blog/images/02-02.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr3n6mt148859yrdd70hcsxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A generic encoder/decoder architecture is made up of two models. The encoder takes the input and encodes it into a fixed-length vector. The decoder takes that vector and decodes it into the output sequence. The encoder and decoder are jointly trained to minimize the conditional log-likelihood. Once trained the encoder/decoder can generate an output given an input sequence or can score a pair of input/output sequences. (
&lt;a href="https://read.readwise.io/read/01gr3n8nw20y7ajxcesdrghgcx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>n the case of the original Transformer architecture, both encoder and decoder had 6 identical layers. In each of those 6 layers the Encoder has two sub layers: a multi-head attention layer, and a simple feed forward network. Each sublayer has a residual connection and a layer normalization. The output size of the Encoder is 512. The Decoder adds a third sublayer, which is another multi-head attention layer over the output of the Encoder. Besides, the other multi-head layer in the decoder is masked to prevent attention to subsequent positions. (
&lt;a href="https://read.readwise.io/read/01gr3n9m9h1r1hft2s4e6qjns5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>t is clear from the description above that the only “exotic” elements of the model architecture are the multi-headed attention, but, as described above, that is where the whole power of the model lies (
&lt;a href="https://read.readwise.io/read/01gr3nap0873cpqq76ag1wrpky" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention function is a mapping between a query and a set of key-value pairs to an output. (
&lt;a href="https://read.readwise.io/read/01gr3nbj85qnq00xc34bd6h9wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Transformers use multi-headed attention, which is a parallel computation of a specific attention function called scaled dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr3nbwyt3ess4zefya12acg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[AI, software, tech, and people, not in that order&amp;hellip; by X]]
title: &amp;ldquo;Transformer Models: An Introduction and Catalog&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="transformer-models-an-introduction-and-catalog-3">Transformer Models: An Introduction and Catalog&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article0.00998d930354.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[AI, software, tech, and people, not in that order&amp;hellip; by X]]&lt;/li>
&lt;li>Full Title: Transformer Models: An Introduction and Catalog&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/" rel="noopener">https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Transformers are a class of deep learning models that are defined by some architectural traits. They were first introduced in the now famous
&lt;a href="https://arxiv.org/abs/1706.03762" rel="noopener">Attention is All you Need&lt;/a> paper by Google researchers in 2017 (the paper has accumulated a whooping 38k citations in only 5 years) and associated
&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html" rel="noopener">blog post&lt;/a>. (
&lt;a href="https://read.readwise.io/read/01gr3n6ernt5z0vternwwjdav3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The Transformer architecture is a specific instance of the
&lt;a href="https://machinelearningmastery.com/encoder-decoder-long-short-term-memory-networks/" rel="noopener">encoder-decoder models&lt;/a> that had become popular just over the 2–3 years prior. Up until that point however, attention was just one of the mechanisms used by these models, which were mostly based on LSTM (Long Short Term Memory) and other RNN (Recurrent Neural Networks) variations. The key insight of the Transformers paper was that, as the title implies, attention could be used as the only mechanism to derive dependencies between input and output. (
&lt;a href="https://read.readwise.io/read/01gr3n6gp4ett44parxp9atn9b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://amatriain.net/blog/images/02-02.png" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gr3n6mt148859yrdd70hcsxf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A generic encoder/decoder architecture is made up of two models. The encoder takes the input and encodes it into a fixed-length vector. The decoder takes that vector and decodes it into the output sequence. The encoder and decoder are jointly trained to minimize the conditional log-likelihood. Once trained the encoder/decoder can generate an output given an input sequence or can score a pair of input/output sequences. (
&lt;a href="https://read.readwise.io/read/01gr3n8nw20y7ajxcesdrghgcx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>n the case of the original Transformer architecture, both encoder and decoder had 6 identical layers. In each of those 6 layers the Encoder has two sub layers: a multi-head attention layer, and a simple feed forward network. Each sublayer has a residual connection and a layer normalization. The output size of the Encoder is 512. The Decoder adds a third sublayer, which is another multi-head attention layer over the output of the Encoder. Besides, the other multi-head layer in the decoder is masked to prevent attention to subsequent positions. (
&lt;a href="https://read.readwise.io/read/01gr3n9m9h1r1hft2s4e6qjns5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>t is clear from the description above that the only “exotic” elements of the model architecture are the multi-headed attention, but, as described above, that is where the whole power of the model lies (
&lt;a href="https://read.readwise.io/read/01gr3nap0873cpqq76ag1wrpky" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention function is a mapping between a query and a set of key-value pairs to an output. (
&lt;a href="https://read.readwise.io/read/01gr3nbj85qnq00xc34bd6h9wr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Transformers use multi-headed attention, which is a parallel computation of a specific attention function called scaled dot-product attention. (
&lt;a href="https://read.readwise.io/read/01gr3nbwyt3ess4zefya12acg7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Visualizing a Neural Machine Translation Model</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Visualizing-a-Neural-Machine-Translation-Model/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Visualizing-a-Neural-Machine-Translation-Model/</guid><description>&lt;h1 id="visualizing-a-neural-machine-translation-model">Visualizing a Neural Machine Translation Model&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: Visualizing a Neural Machine Translation Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sequence-to-sequence models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning (
&lt;a href="https://read.readwise.io/read/01gr3nv5vttyncanrptep48jnz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A sequence-to-sequence model is a model that takes a sequence of items (words, letters, features of an images…etc) and outputs another sequence of items. (
&lt;a href="https://read.readwise.io/read/01gr3njgkdgd6y9frntw9jxhf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under the hood, the model is composed of an encoder and a decoder.
The encoder processes each item in the input sequence, it compiles the information it captures into a vector (called the context). After processing the entire input sequence, the encoder sends the context over to the decoder, which begins producing the output sequence item by item. (
&lt;a href="https://read.readwise.io/read/01gr3nm5vg4dnv831j7dqytxrw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context is a vector (an array of numbers, basically) in the case of machine translation. The encoder and decoder tend to both be recurrent neural networks (
&lt;a href="https://read.readwise.io/read/01gr3nmy39nha0ggw7mnkf0pa5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can set the size of the context vector when you set up your model. It is basically the number of hidden units in the encoder RNN. These visualizations show a vector of size 4, but in real world applications the context vector would be of a size like 256, 512, or 1024. (
&lt;a href="https://read.readwise.io/read/01gr3nnhctxxw7npj11y72x88w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>RNN takes two inputs at each time step: an input (in the case of the encoder, one word from the input sentence), and a hidden state. The word, however, needs to be represented by a vector. To transform a word into a vector, we turn to the class of methods called “
&lt;a href="https://machinelearningmastery.com/what-are-word-embeddings/" rel="noopener">word embedding&lt;/a>” algorithms. (
&lt;a href="https://read.readwise.io/read/01gr3nphycgsrkr71be5r59p9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The next RNN step takes the second input vector and hidden state #1 to create the output of that time step. (
&lt;a href="https://read.readwise.io/read/01gr3pdrygrfvtjz0eh0ysd8q7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>each pulse for the encoder or decoder is that RNN processing its inputs and generating an output for that time step. Since the encoder and decoder are both RNNs, each time step one of the RNNs does some processing, it updates its hidden state based on its inputs and previous inputs it has seen (
&lt;a href="https://read.readwise.io/read/01gr3pgaqdtpdzq394war17qy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice how the last hidden state is actually the context we pass along to the decoder. (
&lt;a href="https://read.readwise.io/read/01gr3pgh3tjyzyyttfv3gzbdkh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder also maintains a hidden state that it passes from one time step to the next (
&lt;a href="https://read.readwise.io/read/01gr3ph1qrd5mfrcgxf931r1n1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context vector turned out to be a bottleneck for these types of models. It made it challenging for the models to deal with long sentences. A solution was proposed in
&lt;a href="https://arxiv.org/abs/1409.0473" rel="noopener">Bahdanau et al., 2014&lt;/a> and
&lt;a href="https://arxiv.org/abs/1508.04025" rel="noopener">Luong et al., 2015&lt;/a>. These papers introduced and refined a technique called “Attention”, which highly improved the quality of machine translation systems. (
&lt;a href="https://read.readwise.io/read/01gr3pjqrvpfw11cff1zanafyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Attention allows the model to focus on the relevant parts of the input sequence as needed. (
&lt;a href="https://read.readwise.io/read/01gr3pmn7ntadgvqb3hwjnzf9g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At time step 7, the attention mechanism enables the decoder to focus on the word &amp;ldquo;étudiant&amp;rdquo; (&amp;ldquo;student&amp;rdquo; in french) before it generates the English translation. This ability to amplify the signal from the relevant part of the input sequence makes attention models produce better results than models without attention. (
&lt;a href="https://read.readwise.io/read/01gr3pq25bkrqfpk9rb9pszx6p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention model differs from a classic sequence-to-sequence model in two main ways:
First, the encoder passes a lot more data to the decoder. Instead of passing the last hidden state of the encoding stage, the encoder passes &lt;em>all&lt;/em> the hidden states to the decoder: (
&lt;a href="https://read.readwise.io/read/01gr3prcswwfmn6r2cv56e7jew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Jay Alammar]]
title: &amp;ldquo;Visualizing a Neural Machine Translation Model&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="visualizing-a-neural-machine-translation-model-1">Visualizing a Neural Machine Translation Model&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: Visualizing a Neural Machine Translation Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sequence-to-sequence models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning (
&lt;a href="https://read.readwise.io/read/01gr3nv5vttyncanrptep48jnz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A sequence-to-sequence model is a model that takes a sequence of items (words, letters, features of an images…etc) and outputs another sequence of items. (
&lt;a href="https://read.readwise.io/read/01gr3njgkdgd6y9frntw9jxhf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under the hood, the model is composed of an encoder and a decoder.
The encoder processes each item in the input sequence, it compiles the information it captures into a vector (called the context). After processing the entire input sequence, the encoder sends the context over to the decoder, which begins producing the output sequence item by item. (
&lt;a href="https://read.readwise.io/read/01gr3nm5vg4dnv831j7dqytxrw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context is a vector (an array of numbers, basically) in the case of machine translation. The encoder and decoder tend to both be recurrent neural networks (
&lt;a href="https://read.readwise.io/read/01gr3nmy39nha0ggw7mnkf0pa5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can set the size of the context vector when you set up your model. It is basically the number of hidden units in the encoder RNN. These visualizations show a vector of size 4, but in real world applications the context vector would be of a size like 256, 512, or 1024. (
&lt;a href="https://read.readwise.io/read/01gr3nnhctxxw7npj11y72x88w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>RNN takes two inputs at each time step: an input (in the case of the encoder, one word from the input sentence), and a hidden state. The word, however, needs to be represented by a vector. To transform a word into a vector, we turn to the class of methods called “
&lt;a href="https://machinelearningmastery.com/what-are-word-embeddings/" rel="noopener">word embedding&lt;/a>” algorithms. (
&lt;a href="https://read.readwise.io/read/01gr3nphycgsrkr71be5r59p9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The next RNN step takes the second input vector and hidden state #1 to create the output of that time step. (
&lt;a href="https://read.readwise.io/read/01gr3pdrygrfvtjz0eh0ysd8q7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>each pulse for the encoder or decoder is that RNN processing its inputs and generating an output for that time step. Since the encoder and decoder are both RNNs, each time step one of the RNNs does some processing, it updates its hidden state based on its inputs and previous inputs it has seen (
&lt;a href="https://read.readwise.io/read/01gr3pgaqdtpdzq394war17qy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice how the last hidden state is actually the context we pass along to the decoder. (
&lt;a href="https://read.readwise.io/read/01gr3pgh3tjyzyyttfv3gzbdkh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder also maintains a hidden state that it passes from one time step to the next (
&lt;a href="https://read.readwise.io/read/01gr3ph1qrd5mfrcgxf931r1n1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context vector turned out to be a bottleneck for these types of models. It made it challenging for the models to deal with long sentences. A solution was proposed in
&lt;a href="https://arxiv.org/abs/1409.0473" rel="noopener">Bahdanau et al., 2014&lt;/a> and
&lt;a href="https://arxiv.org/abs/1508.04025" rel="noopener">Luong et al., 2015&lt;/a>. These papers introduced and refined a technique called “Attention”, which highly improved the quality of machine translation systems. (
&lt;a href="https://read.readwise.io/read/01gr3pjqrvpfw11cff1zanafyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Attention allows the model to focus on the relevant parts of the input sequence as needed. (
&lt;a href="https://read.readwise.io/read/01gr3pmn7ntadgvqb3hwjnzf9g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At time step 7, the attention mechanism enables the decoder to focus on the word &amp;ldquo;étudiant&amp;rdquo; (&amp;ldquo;student&amp;rdquo; in french) before it generates the English translation. This ability to amplify the signal from the relevant part of the input sequence makes attention models produce better results than models without attention. (
&lt;a href="https://read.readwise.io/read/01gr3pq25bkrqfpk9rb9pszx6p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention model differs from a classic sequence-to-sequence model in two main ways:
First, the encoder passes a lot more data to the decoder. Instead of passing the last hidden state of the encoding stage, the encoder passes &lt;em>all&lt;/em> the hidden states to the decoder: (
&lt;a href="https://read.readwise.io/read/01gr3prcswwfmn6r2cv56e7jew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Jay Alammar]]
title: &amp;ldquo;Visualizing a Neural Machine Translation Model&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="visualizing-a-neural-machine-translation-model-2">Visualizing a Neural Machine Translation Model&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: Visualizing a Neural Machine Translation Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sequence-to-sequence models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning (
&lt;a href="https://read.readwise.io/read/01gr3nv5vttyncanrptep48jnz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A sequence-to-sequence model is a model that takes a sequence of items (words, letters, features of an images…etc) and outputs another sequence of items. (
&lt;a href="https://read.readwise.io/read/01gr3njgkdgd6y9frntw9jxhf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under the hood, the model is composed of an encoder and a decoder.
The encoder processes each item in the input sequence, it compiles the information it captures into a vector (called the context). After processing the entire input sequence, the encoder sends the context over to the decoder, which begins producing the output sequence item by item. (
&lt;a href="https://read.readwise.io/read/01gr3nm5vg4dnv831j7dqytxrw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context is a vector (an array of numbers, basically) in the case of machine translation. The encoder and decoder tend to both be recurrent neural networks (
&lt;a href="https://read.readwise.io/read/01gr3nmy39nha0ggw7mnkf0pa5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can set the size of the context vector when you set up your model. It is basically the number of hidden units in the encoder RNN. These visualizations show a vector of size 4, but in real world applications the context vector would be of a size like 256, 512, or 1024. (
&lt;a href="https://read.readwise.io/read/01gr3nnhctxxw7npj11y72x88w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>RNN takes two inputs at each time step: an input (in the case of the encoder, one word from the input sentence), and a hidden state. The word, however, needs to be represented by a vector. To transform a word into a vector, we turn to the class of methods called “
&lt;a href="https://machinelearningmastery.com/what-are-word-embeddings/" rel="noopener">word embedding&lt;/a>” algorithms. (
&lt;a href="https://read.readwise.io/read/01gr3nphycgsrkr71be5r59p9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The next RNN step takes the second input vector and hidden state #1 to create the output of that time step. (
&lt;a href="https://read.readwise.io/read/01gr3pdrygrfvtjz0eh0ysd8q7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>each pulse for the encoder or decoder is that RNN processing its inputs and generating an output for that time step. Since the encoder and decoder are both RNNs, each time step one of the RNNs does some processing, it updates its hidden state based on its inputs and previous inputs it has seen (
&lt;a href="https://read.readwise.io/read/01gr3pgaqdtpdzq394war17qy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice how the last hidden state is actually the context we pass along to the decoder. (
&lt;a href="https://read.readwise.io/read/01gr3pgh3tjyzyyttfv3gzbdkh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder also maintains a hidden state that it passes from one time step to the next (
&lt;a href="https://read.readwise.io/read/01gr3ph1qrd5mfrcgxf931r1n1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context vector turned out to be a bottleneck for these types of models. It made it challenging for the models to deal with long sentences. A solution was proposed in
&lt;a href="https://arxiv.org/abs/1409.0473" rel="noopener">Bahdanau et al., 2014&lt;/a> and
&lt;a href="https://arxiv.org/abs/1508.04025" rel="noopener">Luong et al., 2015&lt;/a>. These papers introduced and refined a technique called “Attention”, which highly improved the quality of machine translation systems. (
&lt;a href="https://read.readwise.io/read/01gr3pjqrvpfw11cff1zanafyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Attention allows the model to focus on the relevant parts of the input sequence as needed. (
&lt;a href="https://read.readwise.io/read/01gr3pmn7ntadgvqb3hwjnzf9g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At time step 7, the attention mechanism enables the decoder to focus on the word &amp;ldquo;étudiant&amp;rdquo; (&amp;ldquo;student&amp;rdquo; in french) before it generates the English translation. This ability to amplify the signal from the relevant part of the input sequence makes attention models produce better results than models without attention. (
&lt;a href="https://read.readwise.io/read/01gr3pq25bkrqfpk9rb9pszx6p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention model differs from a classic sequence-to-sequence model in two main ways:
First, the encoder passes a lot more data to the decoder. Instead of passing the last hidden state of the encoding stage, the encoder passes &lt;em>all&lt;/em> the hidden states to the decoder: (
&lt;a href="https://read.readwise.io/read/01gr3prcswwfmn6r2cv56e7jew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Jay Alammar]]
title: &amp;ldquo;Visualizing a Neural Machine Translation Model&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="visualizing-a-neural-machine-translation-model-3">Visualizing a Neural Machine Translation Model&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Jay Alammar]]&lt;/li>
&lt;li>Full Title: Visualizing a Neural Machine Translation Model&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener">https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Sequence-to-sequence models are deep learning models that have achieved a lot of success in tasks like machine translation, text summarization, and image captioning (
&lt;a href="https://read.readwise.io/read/01gr3nv5vttyncanrptep48jnz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>A sequence-to-sequence model is a model that takes a sequence of items (words, letters, features of an images…etc) and outputs another sequence of items. (
&lt;a href="https://read.readwise.io/read/01gr3njgkdgd6y9frntw9jxhf1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under the hood, the model is composed of an encoder and a decoder.
The encoder processes each item in the input sequence, it compiles the information it captures into a vector (called the context). After processing the entire input sequence, the encoder sends the context over to the decoder, which begins producing the output sequence item by item. (
&lt;a href="https://read.readwise.io/read/01gr3nm5vg4dnv831j7dqytxrw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context is a vector (an array of numbers, basically) in the case of machine translation. The encoder and decoder tend to both be recurrent neural networks (
&lt;a href="https://read.readwise.io/read/01gr3nmy39nha0ggw7mnkf0pa5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>You can set the size of the context vector when you set up your model. It is basically the number of hidden units in the encoder RNN. These visualizations show a vector of size 4, but in real world applications the context vector would be of a size like 256, 512, or 1024. (
&lt;a href="https://read.readwise.io/read/01gr3nnhctxxw7npj11y72x88w" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>RNN takes two inputs at each time step: an input (in the case of the encoder, one word from the input sentence), and a hidden state. The word, however, needs to be represented by a vector. To transform a word into a vector, we turn to the class of methods called “
&lt;a href="https://machinelearningmastery.com/what-are-word-embeddings/" rel="noopener">word embedding&lt;/a>” algorithms. (
&lt;a href="https://read.readwise.io/read/01gr3nphycgsrkr71be5r59p9a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The next RNN step takes the second input vector and hidden state #1 to create the output of that time step. (
&lt;a href="https://read.readwise.io/read/01gr3pdrygrfvtjz0eh0ysd8q7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>each pulse for the encoder or decoder is that RNN processing its inputs and generating an output for that time step. Since the encoder and decoder are both RNNs, each time step one of the RNNs does some processing, it updates its hidden state based on its inputs and previous inputs it has seen (
&lt;a href="https://read.readwise.io/read/01gr3pgaqdtpdzq394war17qy2" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Notice how the last hidden state is actually the context we pass along to the decoder. (
&lt;a href="https://read.readwise.io/read/01gr3pgh3tjyzyyttfv3gzbdkh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The decoder also maintains a hidden state that it passes from one time step to the next (
&lt;a href="https://read.readwise.io/read/01gr3ph1qrd5mfrcgxf931r1n1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The context vector turned out to be a bottleneck for these types of models. It made it challenging for the models to deal with long sentences. A solution was proposed in
&lt;a href="https://arxiv.org/abs/1409.0473" rel="noopener">Bahdanau et al., 2014&lt;/a> and
&lt;a href="https://arxiv.org/abs/1508.04025" rel="noopener">Luong et al., 2015&lt;/a>. These papers introduced and refined a technique called “Attention”, which highly improved the quality of machine translation systems. (
&lt;a href="https://read.readwise.io/read/01gr3pjqrvpfw11cff1zanafyg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Attention allows the model to focus on the relevant parts of the input sequence as needed. (
&lt;a href="https://read.readwise.io/read/01gr3pmn7ntadgvqb3hwjnzf9g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>At time step 7, the attention mechanism enables the decoder to focus on the word &amp;ldquo;étudiant&amp;rdquo; (&amp;ldquo;student&amp;rdquo; in french) before it generates the English translation. This ability to amplify the signal from the relevant part of the input sequence makes attention models produce better results than models without attention. (
&lt;a href="https://read.readwise.io/read/01gr3pq25bkrqfpk9rb9pszx6p" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An attention model differs from a classic sequence-to-sequence model in two main ways:
First, the encoder passes a lot more data to the decoder. Instead of passing the last hidden state of the encoding stage, the encoder passes &lt;em>all&lt;/em> the hidden states to the decoder: (
&lt;a href="https://read.readwise.io/read/01gr3prcswwfmn6r2cv56e7jew" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Want to Improve Your Memory? Try These Unexpected Tips.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Want-to-Improve-Your-Memory-Try-These-Unexpected-Tips./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Want-to-Improve-Your-Memory-Try-These-Unexpected-Tips./</guid><description>&lt;h1 id="want-to-improve-your-memory-try-these-unexpected-tips">Want to Improve Your Memory? Try These Unexpected Tips.&lt;/h1>
&lt;p>
&lt;img src="https://cdn.vox-cdn.com/thumbor/7c2x61QOmsFTksAaeQFvqduIUwE=/167x0:2834x2000/1310x983/cdn.vox-cdn.com/uploads/chorus_image/image/71826126/memory02.0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Allie Volpe]]&lt;/li>
&lt;li>Full Title: Want to Improve Your Memory? Try These Unexpected Tips.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips" rel="noopener">https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>PLR technique: pause, link, and rehearse. (
&lt;a href="https://read.readwise.io/read/01gqzgpzqmdzy6s4gsggks7nb9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put meetings in your phone’s calendar (be detailed about who you’re meeting, where, and why) and make sure alerts are turned on, set reminders, and take photos of events to refer to later. “Go back to those pictures,” Ranganath says. Don’t just take a photo and let it languish in your camera roll forever. “Anything you can do to revisit unique moments will bring back all sorts of other stuff.” (
&lt;a href="https://read.readwise.io/read/01gqzgqs8s9szts0cgnfbnj96k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis assigns vivid images to whatever he’s trying to remember, be it a number or an address. Maybe if you don’t want to forget to grab cheese at the grocery store, imagine a giant, incredibly stinky hunk of fromage. Dellis will sometimes pinch himself or say a unique mantra when putting down his keys so he’ll remember the bizarre thing he did in the moment. (
&lt;a href="https://read.readwise.io/read/01gqzgt5kye498bhw8rna6wyq1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But if you study or reflect on things you want to remember, the more likely these memories will be strengthened, Schacter says. Again, looking at images or videos you took from a particularly enjoyable dinner with friends is a way to better commit these events to memory. (
&lt;a href="https://read.readwise.io/read/01gqzgts7rmya3db4zteaktwt6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis recommends spending five minutes before bed recalling what happened that day. Did you see a beautiful sunset? Did your kid have a funny retort to a simple question? Did you eat something delicious? Replay small but lovely occurrences you’d like to savor. “The more you do that, over time you realize you’ll actually be able to remember more details of your life (
&lt;a href="https://read.readwise.io/read/01gqzgvdsgx6pcqanqng538t7k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Allie Volpe]]
title: &amp;ldquo;Want to Improve Your Memory? Try These Unexpected Tips.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="want-to-improve-your-memory-try-these-unexpected-tips-1">Want to Improve Your Memory? Try These Unexpected Tips.&lt;/h1>
&lt;p>
&lt;img src="https://cdn.vox-cdn.com/thumbor/7c2x61QOmsFTksAaeQFvqduIUwE=/167x0:2834x2000/1310x983/cdn.vox-cdn.com/uploads/chorus_image/image/71826126/memory02.0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Allie Volpe]]&lt;/li>
&lt;li>Full Title: Want to Improve Your Memory? Try These Unexpected Tips.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips" rel="noopener">https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>PLR technique: pause, link, and rehearse. (
&lt;a href="https://read.readwise.io/read/01gqzgpzqmdzy6s4gsggks7nb9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put meetings in your phone’s calendar (be detailed about who you’re meeting, where, and why) and make sure alerts are turned on, set reminders, and take photos of events to refer to later. “Go back to those pictures,” Ranganath says. Don’t just take a photo and let it languish in your camera roll forever. “Anything you can do to revisit unique moments will bring back all sorts of other stuff.” (
&lt;a href="https://read.readwise.io/read/01gqzgqs8s9szts0cgnfbnj96k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis assigns vivid images to whatever he’s trying to remember, be it a number or an address. Maybe if you don’t want to forget to grab cheese at the grocery store, imagine a giant, incredibly stinky hunk of fromage. Dellis will sometimes pinch himself or say a unique mantra when putting down his keys so he’ll remember the bizarre thing he did in the moment. (
&lt;a href="https://read.readwise.io/read/01gqzgt5kye498bhw8rna6wyq1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But if you study or reflect on things you want to remember, the more likely these memories will be strengthened, Schacter says. Again, looking at images or videos you took from a particularly enjoyable dinner with friends is a way to better commit these events to memory. (
&lt;a href="https://read.readwise.io/read/01gqzgts7rmya3db4zteaktwt6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis recommends spending five minutes before bed recalling what happened that day. Did you see a beautiful sunset? Did your kid have a funny retort to a simple question? Did you eat something delicious? Replay small but lovely occurrences you’d like to savor. “The more you do that, over time you realize you’ll actually be able to remember more details of your life (
&lt;a href="https://read.readwise.io/read/01gqzgvdsgx6pcqanqng538t7k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Allie Volpe]]
title: &amp;ldquo;Want to Improve Your Memory? Try These Unexpected Tips.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="want-to-improve-your-memory-try-these-unexpected-tips-2">Want to Improve Your Memory? Try These Unexpected Tips.&lt;/h1>
&lt;p>
&lt;img src="https://cdn.vox-cdn.com/thumbor/7c2x61QOmsFTksAaeQFvqduIUwE=/167x0:2834x2000/1310x983/cdn.vox-cdn.com/uploads/chorus_image/image/71826126/memory02.0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Allie Volpe]]&lt;/li>
&lt;li>Full Title: Want to Improve Your Memory? Try These Unexpected Tips.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips" rel="noopener">https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>PLR technique: pause, link, and rehearse. (
&lt;a href="https://read.readwise.io/read/01gqzgpzqmdzy6s4gsggks7nb9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put meetings in your phone’s calendar (be detailed about who you’re meeting, where, and why) and make sure alerts are turned on, set reminders, and take photos of events to refer to later. “Go back to those pictures,” Ranganath says. Don’t just take a photo and let it languish in your camera roll forever. “Anything you can do to revisit unique moments will bring back all sorts of other stuff.” (
&lt;a href="https://read.readwise.io/read/01gqzgqs8s9szts0cgnfbnj96k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis assigns vivid images to whatever he’s trying to remember, be it a number or an address. Maybe if you don’t want to forget to grab cheese at the grocery store, imagine a giant, incredibly stinky hunk of fromage. Dellis will sometimes pinch himself or say a unique mantra when putting down his keys so he’ll remember the bizarre thing he did in the moment. (
&lt;a href="https://read.readwise.io/read/01gqzgt5kye498bhw8rna6wyq1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But if you study or reflect on things you want to remember, the more likely these memories will be strengthened, Schacter says. Again, looking at images or videos you took from a particularly enjoyable dinner with friends is a way to better commit these events to memory. (
&lt;a href="https://read.readwise.io/read/01gqzgts7rmya3db4zteaktwt6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis recommends spending five minutes before bed recalling what happened that day. Did you see a beautiful sunset? Did your kid have a funny retort to a simple question? Did you eat something delicious? Replay small but lovely occurrences you’d like to savor. “The more you do that, over time you realize you’ll actually be able to remember more details of your life (
&lt;a href="https://read.readwise.io/read/01gqzgvdsgx6pcqanqng538t7k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Allie Volpe]]
title: &amp;ldquo;Want to Improve Your Memory? Try These Unexpected Tips.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="want-to-improve-your-memory-try-these-unexpected-tips-3">Want to Improve Your Memory? Try These Unexpected Tips.&lt;/h1>
&lt;p>
&lt;img src="https://cdn.vox-cdn.com/thumbor/7c2x61QOmsFTksAaeQFvqduIUwE=/167x0:2834x2000/1310x983/cdn.vox-cdn.com/uploads/chorus_image/image/71826126/memory02.0.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Allie Volpe]]&lt;/li>
&lt;li>Full Title: Want to Improve Your Memory? Try These Unexpected Tips.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips" rel="noopener">https://www.vox.com/even-better/23537229/improve-your-memory-concentration-tips&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>PLR technique: pause, link, and rehearse. (
&lt;a href="https://read.readwise.io/read/01gqzgpzqmdzy6s4gsggks7nb9" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put meetings in your phone’s calendar (be detailed about who you’re meeting, where, and why) and make sure alerts are turned on, set reminders, and take photos of events to refer to later. “Go back to those pictures,” Ranganath says. Don’t just take a photo and let it languish in your camera roll forever. “Anything you can do to revisit unique moments will bring back all sorts of other stuff.” (
&lt;a href="https://read.readwise.io/read/01gqzgqs8s9szts0cgnfbnj96k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis assigns vivid images to whatever he’s trying to remember, be it a number or an address. Maybe if you don’t want to forget to grab cheese at the grocery store, imagine a giant, incredibly stinky hunk of fromage. Dellis will sometimes pinch himself or say a unique mantra when putting down his keys so he’ll remember the bizarre thing he did in the moment. (
&lt;a href="https://read.readwise.io/read/01gqzgt5kye498bhw8rna6wyq1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But if you study or reflect on things you want to remember, the more likely these memories will be strengthened, Schacter says. Again, looking at images or videos you took from a particularly enjoyable dinner with friends is a way to better commit these events to memory. (
&lt;a href="https://read.readwise.io/read/01gqzgts7rmya3db4zteaktwt6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Dellis recommends spending five minutes before bed recalling what happened that day. Did you see a beautiful sunset? Did your kid have a funny retort to a simple question? Did you eat something delicious? Replay small but lovely occurrences you’d like to savor. “The more you do that, over time you realize you’ll actually be able to remember more details of your life (
&lt;a href="https://read.readwise.io/read/01gqzgvdsgx6pcqanqng538t7k" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>What Are Word and Sentence Embeddings?</title><link>https://pelayoarbues.github.io/literature-notes/Articles/What-Are-Word-and-Sentence-Embeddings/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/What-Are-Word-and-Sentence-Embeddings/</guid><description>&lt;h1 id="what-are-word-and-sentence-embeddings">What Are Word and Sentence Embeddings?&lt;/h1>
&lt;p>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Luis Serrano]]&lt;/li>
&lt;li>Full Title: What Are Word and Sentence Embeddings?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;amp;utm_medium=paidsocial&amp;amp;utm_campaign=contentpromotion_retargeting_site&amp;amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty" rel="noopener">https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;utm_medium=paidsocial&amp;utm_campaign=contentpromotion_retargeting_site&amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>An assignment of words to numbers is called a &lt;em>word embedding&lt;/em>. We can think of a word embedding as an assignment of &lt;em>scores&lt;/em> to the words, with some nice properties ( (
&lt;a href="https://read.readwise.io/read/01gqqw5kjbt63d24h22x9z9shr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77n8peqnna90dhxa0yr4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77pg83nqv249n4geqfsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And what are the numbers we are assigning to each word? Simply the horizontal and vertical coordinates of the location of the word (
&lt;a href="https://read.readwise.io/read/01gqqw7306pcef7dadk7jwa10v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>properties that a nice word embedding should have:
&lt;ol>
&lt;li>Words that are similar should correspond to points that are close by (or equivalently, to scores that are similar).&lt;/li>
&lt;li>Words that are different should correspond to points that are far away (or equivalently, to scores that are significantly different). (
&lt;a href="https://read.readwise.io/read/01gqqw7p89nvv67b5nsv09ttz7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>There is something more to these word embeddings, and it is that they don’t only capture word similarity, but they also capture other properties of the language. In language, words can be combined to get more complicated concepts. In mathematics, numbers can be added or subtracted to get other numbers. Could we build a word embedding that captures relations between words, as relations between numbers? (
&lt;a href="https://read.readwise.io/read/01gqqw8b9k95jxtv87nhs89219" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9xnp6wam8m6fe3pewgr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9ye9va8mc185vxyh44b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The analogy “A puppy is to a dog like a calf is to a cow” can be translated into “The path from the word puppy to the word dog is the same as the path from the word calf to the word cow”. The analogy “A dog is to a cow like a puppy is to a calf” is also captured in this rectangle (
&lt;a href="https://read.readwise.io/read/01gqqwj85kpr6s0maystb7j6tg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The main property of word embeddings that is in effect here is that the two axes (vertical and horizontal) represent different things. If you look carefully, moving towards the right turns the puppy into a dog, and the calf into a cow, which is an increase in &lt;em>age&lt;/em>. Likewise, moving upwards turns a puppy into a calf and a dog into a cow, which is an increase in the &lt;em>size&lt;/em> of the animal. It seems that this embedding is understanding that the words in it have two main properties, or features: age and size. Furthermore, it seems that the embedding is locating age in the horizontal axis and size in the vertical axis. (
&lt;a href="https://read.readwise.io/read/01gqqwqne86n0epfjcz2srzky4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>good word embedding would be able to capture not only age and size, but also many more features of the words. Since each feature is one new axis, or coordinate, then a good embedding must have many more than two coordinates assigned to every word. The cohere embedding, for example, has 4096 coordinates associated with each word. (
&lt;a href="https://read.readwise.io/read/01gqqwrbbk8mfpbqsxmtyhghtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. A sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, in a coherent way. By coherent, I mean that it satisfies similar properties as a word embedding. For instance, similar sentences are assigned to similar vectors, different sentences are assigned to different vectors, and most importantly, each of the coordinates of the vector identifies some (whether clear or obscure) property of the sentence. (
&lt;a href="https://read.readwise.io/read/01gqqwvja8bdxv1crf6p8wtz09" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Luis Serrano]]
title: &amp;ldquo;What Are Word and Sentence Embeddings?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-are-word-and-sentence-embeddings-1">What Are Word and Sentence Embeddings?&lt;/h1>
&lt;p>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Luis Serrano]]&lt;/li>
&lt;li>Full Title: What Are Word and Sentence Embeddings?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;amp;utm_medium=paidsocial&amp;amp;utm_campaign=contentpromotion_retargeting_site&amp;amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty" rel="noopener">https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;utm_medium=paidsocial&amp;utm_campaign=contentpromotion_retargeting_site&amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>An assignment of words to numbers is called a &lt;em>word embedding&lt;/em>. We can think of a word embedding as an assignment of &lt;em>scores&lt;/em> to the words, with some nice properties ( (
&lt;a href="https://read.readwise.io/read/01gqqw5kjbt63d24h22x9z9shr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77n8peqnna90dhxa0yr4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77pg83nqv249n4geqfsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And what are the numbers we are assigning to each word? Simply the horizontal and vertical coordinates of the location of the word (
&lt;a href="https://read.readwise.io/read/01gqqw7306pcef7dadk7jwa10v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>properties that a nice word embedding should have:
&lt;ol>
&lt;li>Words that are similar should correspond to points that are close by (or equivalently, to scores that are similar).&lt;/li>
&lt;li>Words that are different should correspond to points that are far away (or equivalently, to scores that are significantly different). (
&lt;a href="https://read.readwise.io/read/01gqqw7p89nvv67b5nsv09ttz7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>There is something more to these word embeddings, and it is that they don’t only capture word similarity, but they also capture other properties of the language. In language, words can be combined to get more complicated concepts. In mathematics, numbers can be added or subtracted to get other numbers. Could we build a word embedding that captures relations between words, as relations between numbers? (
&lt;a href="https://read.readwise.io/read/01gqqw8b9k95jxtv87nhs89219" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9xnp6wam8m6fe3pewgr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9ye9va8mc185vxyh44b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The analogy “A puppy is to a dog like a calf is to a cow” can be translated into “The path from the word puppy to the word dog is the same as the path from the word calf to the word cow”. The analogy “A dog is to a cow like a puppy is to a calf” is also captured in this rectangle (
&lt;a href="https://read.readwise.io/read/01gqqwj85kpr6s0maystb7j6tg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The main property of word embeddings that is in effect here is that the two axes (vertical and horizontal) represent different things. If you look carefully, moving towards the right turns the puppy into a dog, and the calf into a cow, which is an increase in &lt;em>age&lt;/em>. Likewise, moving upwards turns a puppy into a calf and a dog into a cow, which is an increase in the &lt;em>size&lt;/em> of the animal. It seems that this embedding is understanding that the words in it have two main properties, or features: age and size. Furthermore, it seems that the embedding is locating age in the horizontal axis and size in the vertical axis. (
&lt;a href="https://read.readwise.io/read/01gqqwqne86n0epfjcz2srzky4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>good word embedding would be able to capture not only age and size, but also many more features of the words. Since each feature is one new axis, or coordinate, then a good embedding must have many more than two coordinates assigned to every word. The cohere embedding, for example, has 4096 coordinates associated with each word. (
&lt;a href="https://read.readwise.io/read/01gqqwrbbk8mfpbqsxmtyhghtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. A sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, in a coherent way. By coherent, I mean that it satisfies similar properties as a word embedding. For instance, similar sentences are assigned to similar vectors, different sentences are assigned to different vectors, and most importantly, each of the coordinates of the vector identifies some (whether clear or obscure) property of the sentence. (
&lt;a href="https://read.readwise.io/read/01gqqwvja8bdxv1crf6p8wtz09" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Luis Serrano]]
title: &amp;ldquo;What Are Word and Sentence Embeddings?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-are-word-and-sentence-embeddings-2">What Are Word and Sentence Embeddings?&lt;/h1>
&lt;p>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Luis Serrano]]&lt;/li>
&lt;li>Full Title: What Are Word and Sentence Embeddings?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;amp;utm_medium=paidsocial&amp;amp;utm_campaign=contentpromotion_retargeting_site&amp;amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty" rel="noopener">https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;utm_medium=paidsocial&amp;utm_campaign=contentpromotion_retargeting_site&amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>An assignment of words to numbers is called a &lt;em>word embedding&lt;/em>. We can think of a word embedding as an assignment of &lt;em>scores&lt;/em> to the words, with some nice properties ( (
&lt;a href="https://read.readwise.io/read/01gqqw5kjbt63d24h22x9z9shr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77n8peqnna90dhxa0yr4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77pg83nqv249n4geqfsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And what are the numbers we are assigning to each word? Simply the horizontal and vertical coordinates of the location of the word (
&lt;a href="https://read.readwise.io/read/01gqqw7306pcef7dadk7jwa10v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>properties that a nice word embedding should have:
&lt;ol>
&lt;li>Words that are similar should correspond to points that are close by (or equivalently, to scores that are similar).&lt;/li>
&lt;li>Words that are different should correspond to points that are far away (or equivalently, to scores that are significantly different). (
&lt;a href="https://read.readwise.io/read/01gqqw7p89nvv67b5nsv09ttz7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>There is something more to these word embeddings, and it is that they don’t only capture word similarity, but they also capture other properties of the language. In language, words can be combined to get more complicated concepts. In mathematics, numbers can be added or subtracted to get other numbers. Could we build a word embedding that captures relations between words, as relations between numbers? (
&lt;a href="https://read.readwise.io/read/01gqqw8b9k95jxtv87nhs89219" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9xnp6wam8m6fe3pewgr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9ye9va8mc185vxyh44b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The analogy “A puppy is to a dog like a calf is to a cow” can be translated into “The path from the word puppy to the word dog is the same as the path from the word calf to the word cow”. The analogy “A dog is to a cow like a puppy is to a calf” is also captured in this rectangle (
&lt;a href="https://read.readwise.io/read/01gqqwj85kpr6s0maystb7j6tg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The main property of word embeddings that is in effect here is that the two axes (vertical and horizontal) represent different things. If you look carefully, moving towards the right turns the puppy into a dog, and the calf into a cow, which is an increase in &lt;em>age&lt;/em>. Likewise, moving upwards turns a puppy into a calf and a dog into a cow, which is an increase in the &lt;em>size&lt;/em> of the animal. It seems that this embedding is understanding that the words in it have two main properties, or features: age and size. Furthermore, it seems that the embedding is locating age in the horizontal axis and size in the vertical axis. (
&lt;a href="https://read.readwise.io/read/01gqqwqne86n0epfjcz2srzky4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>good word embedding would be able to capture not only age and size, but also many more features of the words. Since each feature is one new axis, or coordinate, then a good embedding must have many more than two coordinates assigned to every word. The cohere embedding, for example, has 4096 coordinates associated with each word. (
&lt;a href="https://read.readwise.io/read/01gqqwrbbk8mfpbqsxmtyhghtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. A sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, in a coherent way. By coherent, I mean that it satisfies similar properties as a word embedding. For instance, similar sentences are assigned to similar vectors, different sentences are assigned to different vectors, and most importantly, each of the coordinates of the vector identifies some (whether clear or obscure) property of the sentence. (
&lt;a href="https://read.readwise.io/read/01gqqwvja8bdxv1crf6p8wtz09" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Luis Serrano]]
title: &amp;ldquo;What Are Word and Sentence Embeddings?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-are-word-and-sentence-embeddings-3">What Are Word and Sentence Embeddings?&lt;/h1>
&lt;p>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/1.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Luis Serrano]]&lt;/li>
&lt;li>Full Title: What Are Word and Sentence Embeddings?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;amp;utm_medium=paidsocial&amp;amp;utm_campaign=contentpromotion_retargeting_site&amp;amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty" rel="noopener">https://txt.cohere.ai/sentence-word-embeddings/?utm_source=twitter&amp;utm_medium=paidsocial&amp;utm_campaign=contentpromotion_retargeting_site&amp;twclid=21m5p3ikfn1n6k1x1nhi1ul8ty&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>An assignment of words to numbers is called a &lt;em>word embedding&lt;/em>. We can think of a word embedding as an assignment of &lt;em>scores&lt;/em> to the words, with some nice properties ( (
&lt;a href="https://read.readwise.io/read/01gqqw5kjbt63d24h22x9z9shr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77n8peqnna90dhxa0yr4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/2023/01/Vis-1.1-1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqw77pg83nqv249n4geqfsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And what are the numbers we are assigning to each word? Simply the horizontal and vertical coordinates of the location of the word (
&lt;a href="https://read.readwise.io/read/01gqqw7306pcef7dadk7jwa10v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>properties that a nice word embedding should have:
&lt;ol>
&lt;li>Words that are similar should correspond to points that are close by (or equivalently, to scores that are similar).&lt;/li>
&lt;li>Words that are different should correspond to points that are far away (or equivalently, to scores that are significantly different). (
&lt;a href="https://read.readwise.io/read/01gqqw7p89nvv67b5nsv09ttz7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>There is something more to these word embeddings, and it is that they don’t only capture word similarity, but they also capture other properties of the language. In language, words can be combined to get more complicated concepts. In mathematics, numbers can be added or subtracted to get other numbers. Could we build a word embedding that captures relations between words, as relations between numbers? (
&lt;a href="https://read.readwise.io/read/01gqqw8b9k95jxtv87nhs89219" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9xnp6wam8m6fe3pewgr" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;img src="https://txt.cohere.ai/content/images/size/w2400/2023/01/Vis-2.1.jpg" width="auto" alt="" /> (
&lt;a href="https://read.readwise.io/read/01gqqwj9ye9va8mc185vxyh44b" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The analogy “A puppy is to a dog like a calf is to a cow” can be translated into “The path from the word puppy to the word dog is the same as the path from the word calf to the word cow”. The analogy “A dog is to a cow like a puppy is to a calf” is also captured in this rectangle (
&lt;a href="https://read.readwise.io/read/01gqqwj85kpr6s0maystb7j6tg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The main property of word embeddings that is in effect here is that the two axes (vertical and horizontal) represent different things. If you look carefully, moving towards the right turns the puppy into a dog, and the calf into a cow, which is an increase in &lt;em>age&lt;/em>. Likewise, moving upwards turns a puppy into a calf and a dog into a cow, which is an increase in the &lt;em>size&lt;/em> of the animal. It seems that this embedding is understanding that the words in it have two main properties, or features: age and size. Furthermore, it seems that the embedding is locating age in the horizontal axis and size in the vertical axis. (
&lt;a href="https://read.readwise.io/read/01gqqwqne86n0epfjcz2srzky4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>good word embedding would be able to capture not only age and size, but also many more features of the words. Since each feature is one new axis, or coordinate, then a good embedding must have many more than two coordinates assigned to every word. The cohere embedding, for example, has 4096 coordinates associated with each word. (
&lt;a href="https://read.readwise.io/read/01gqqwrbbk8mfpbqsxmtyhghtb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>. A sentence embedding is just like a word embedding, except it associates every sentence with a vector full of numbers, in a coherent way. By coherent, I mean that it satisfies similar properties as a word embedding. For instance, similar sentences are assigned to similar vectors, different sentences are assigned to different vectors, and most importantly, each of the coordinates of the vector identifies some (whether clear or obscure) property of the sentence. (
&lt;a href="https://read.readwise.io/read/01gqqwvja8bdxv1crf6p8wtz09" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>What I Do Before a Data Science Project to Ensure Success</title><link>https://pelayoarbues.github.io/literature-notes/Articles/What-I-Do-Before-a-Data-Science-Project-to-Ensure-Success/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/What-I-Do-Before-a-Data-Science-Project-to-Ensure-Success/</guid><description>&lt;h1 id="what-i-do-before-a-data-science-project-to-ensure-success">What I Do Before a Data Science Project to Ensure Success&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/ideal-data-science-workflow.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[eugeneyan.com]]&lt;/li>
&lt;li>Full Title: What I Do Before a Data Science Project to Ensure Success&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager" rel="noopener">https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>First, Draw The Map To The Destination (One-Pager)
The map covers the intent, desired outcome, deliverable, and constraints. (
&lt;a href="https://read.readwise.io/read/01gqqv431az1h7ewqhayqwy2ne" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Intent (Why?)
What’s the problem we’re trying to solve, or the opportunity we want to gain from? How will customers benefit? &lt;em>Why&lt;/em> are we doing this, and &lt;em>why&lt;/em> is it important? (
&lt;a href="https://read.readwise.io/read/01gqqv4a4pvrf9vxa699rqhprg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Management is doing things right; leadership is doing the right things.” - Peter Drucker (
&lt;a href="https://read.readwise.io/read/01gqqv4hdmekgf30nmbb39a6m6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But, by taking the time to think through the problem and intent, we might realise that, hey, maybe we don’t need to fix it after all. (
&lt;a href="https://read.readwise.io/read/01gqqv4x33hv6db37nkwd2ctrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have the intent, we can discuss how success looks like. How well should we solve this problem? How do we measure it? In data science, this is usually a business metric such as conversion, savings from fraud reduction, net promoter score, etc. (
&lt;a href="https://read.readwise.io/read/01gqqv5gr6134s6j3wjeb0st5x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Specifying the desired outcome, in quantifiable terms, prevents us from falling into the trap of chasing a moving target. (
&lt;a href="https://read.readwise.io/read/01gqqv6b867t3pwd6vt38xjjk1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Solving a problem to 95% could take 3-4x the effort of solving to 90%; solving to 99% might take 10-100x more. (
&lt;a href="https://read.readwise.io/read/01gqqv6pmnpzyvbvc1wvt9zdc5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can design a deliverable that meets the intent and desired outcome. How should we solve this problem? The solution should be designed to meet the intent and desired outcome, keeping in mind the need to integrate with the existing system. (
&lt;a href="https://read.readwise.io/read/01gqqv7370g0gq3s43402p6dn3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>e-commerce platform has the intent of improving how customers discover and purchase products. To achieve this, should we improve search? Or recommendations? Or email campaigns? If it’s a recommender, how will we deploy it? (
&lt;a href="https://read.readwise.io/read/01gqqv7f3mznfp9vyn1dht7a16" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This doesn’t have to be especially detailed; for now, we don’t need the full architecture and specs. But it’s useful to have a rough sketch to get upfront buy-in from the business, product, and tech teams (
&lt;a href="https://read.readwise.io/read/01gqqv8mysz7s0xdarcnh4ye69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How &lt;em>not&lt;/em> to solve a problem is often more important than how to solve it. Unfortunately, this doesn’t get addressed enough. (
&lt;a href="https://read.readwise.io/read/01gqqvb5gaekkk4q99gpwtvt2e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Providing teams with boundaries and constraints counterintuitively leads to greater creativity and freedom. Without constraints, we don’t know what we cannot do. (
&lt;a href="https://read.readwise.io/read/01gqqvdmxvq01q7m9xfz6yzyta" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Constraints drive innovation and force focus. Instead of trying to remove them, use them to your advantage.” (
&lt;a href="https://read.readwise.io/read/01gqqvfbjwzcf77wk1chc642ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We write the intent, desired outcome, deliverable, and constraints in simple language on a single-paged document. This can be shared to stakeholders for their review, feedback, and buy-in. (
&lt;a href="https://read.readwise.io/read/01gqqvfna7vqsse7bg262jjs8h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires a certain amount of discipline from stakeholders. After all, the work comes at no cost to them. There’s nothing stopping them from changing their minds halfway through the project. (
&lt;a href="https://read.readwise.io/read/01gqqvg2g9rhn16e9n4vnqdyey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most projects start with a solution, then come up with estimates for each component and the overall design. (
&lt;a href="https://read.readwise.io/read/01gqqvk6xgj43mky36dtx6z4rd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I tend to do the opposite. Given a budget (read: time-box), how can we design a solution that fits? The intent and desired outcome determine the time-box, and the time-box determines the solution design. This is how Basecamp does it too—they have different
&lt;a href="https://basecamp.com/shapeup/1.5-chapter-06#ingredient-2-appetite" rel="noopener">appetite&lt;/a> for various problems, and scope the solutions accordingly. (
&lt;a href="https://read.readwise.io/read/01gqqvkhd2w3teftgc6y5hhsf6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The time-box will vary across the project stages. At the start, when we’re still exploring and uncertainty is high, we’ll want tighter time-boxes to limit wild goose chases. (
&lt;a href="https://read.readwise.io/read/01gqqvmh5wgk8zff8p1zy3c46a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>feasibility assessment&lt;/strong>. With our existing data and technology, are we able to solve the problem? If so, to what extent? In this stage, we aim for a quick and dirty investigation. I usually time-box this at 1-2 weeks. (
&lt;a href="https://read.readwise.io/read/01gqqvmypq0e71g7khczbc0tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After determining feasibility, we proceed with a &lt;strong>proof of concept&lt;/strong> (POC). In this stage, we &lt;em>hack&lt;/em> together a prototype to assess if our solution is technically achievable. Ideally, we also test the integration points with upstream data providers and downstream consumers. Can we meet the technical constraints (e.g., latency, throughput)? Is model performance satisfactory? This usually takes a month or two. (
&lt;a href="https://read.readwise.io/read/01gqqvq07vrkf3f5gbdgy0bcs0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We’ll want to time-box this too. An overly generous timeline can lead to non-essential features being squeezed in and never-ending development—without actually deploying it, no one benefits from it. This usually takes 3-6 months, including infra, job orchestration, testing, monitoring, documentation, etc. (
&lt;a href="https://read.readwise.io/read/01gqqvqfe9tqzqgsaphad7mssf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Having the one-pager and time-box improves a project’s chances of success. Usually, it’s sufficient. Nonetheless, it can be helpful to &lt;strong>break it down&lt;/strong>, especially if it involves unfamiliar data or technology. (
&lt;a href="https://read.readwise.io/read/01gqqw13n8btrm10ddeegqt3fk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the breakdown indicates which components are harder to implement or more at risk—these usually involve things we’ve not done before. We want to front-load the &lt;em>risk&lt;/em> and start with these &lt;em>scary&lt;/em> bits first (
&lt;a href="https://read.readwise.io/read/01gqqw1pce7bm7metr0z6eh1m4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When breaking it down, I often consult seniors with more expertise and experience. They usually have better intuition on potential gotchas and blockers that deserve more attention. (
&lt;a href="https://read.readwise.io/read/01gqqw1yppnv89h54gxa2b93j8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[eugeneyan.com]]
title: &amp;ldquo;What I Do Before a Data Science Project to Ensure Success&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-i-do-before-a-data-science-project-to-ensure-success-1">What I Do Before a Data Science Project to Ensure Success&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/ideal-data-science-workflow.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[eugeneyan.com]]&lt;/li>
&lt;li>Full Title: What I Do Before a Data Science Project to Ensure Success&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager" rel="noopener">https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>First, Draw The Map To The Destination (One-Pager)
The map covers the intent, desired outcome, deliverable, and constraints. (
&lt;a href="https://read.readwise.io/read/01gqqv431az1h7ewqhayqwy2ne" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Intent (Why?)
What’s the problem we’re trying to solve, or the opportunity we want to gain from? How will customers benefit? &lt;em>Why&lt;/em> are we doing this, and &lt;em>why&lt;/em> is it important? (
&lt;a href="https://read.readwise.io/read/01gqqv4a4pvrf9vxa699rqhprg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Management is doing things right; leadership is doing the right things.” - Peter Drucker (
&lt;a href="https://read.readwise.io/read/01gqqv4hdmekgf30nmbb39a6m6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But, by taking the time to think through the problem and intent, we might realise that, hey, maybe we don’t need to fix it after all. (
&lt;a href="https://read.readwise.io/read/01gqqv4x33hv6db37nkwd2ctrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have the intent, we can discuss how success looks like. How well should we solve this problem? How do we measure it? In data science, this is usually a business metric such as conversion, savings from fraud reduction, net promoter score, etc. (
&lt;a href="https://read.readwise.io/read/01gqqv5gr6134s6j3wjeb0st5x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Specifying the desired outcome, in quantifiable terms, prevents us from falling into the trap of chasing a moving target. (
&lt;a href="https://read.readwise.io/read/01gqqv6b867t3pwd6vt38xjjk1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Solving a problem to 95% could take 3-4x the effort of solving to 90%; solving to 99% might take 10-100x more. (
&lt;a href="https://read.readwise.io/read/01gqqv6pmnpzyvbvc1wvt9zdc5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can design a deliverable that meets the intent and desired outcome. How should we solve this problem? The solution should be designed to meet the intent and desired outcome, keeping in mind the need to integrate with the existing system. (
&lt;a href="https://read.readwise.io/read/01gqqv7370g0gq3s43402p6dn3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>e-commerce platform has the intent of improving how customers discover and purchase products. To achieve this, should we improve search? Or recommendations? Or email campaigns? If it’s a recommender, how will we deploy it? (
&lt;a href="https://read.readwise.io/read/01gqqv7f3mznfp9vyn1dht7a16" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This doesn’t have to be especially detailed; for now, we don’t need the full architecture and specs. But it’s useful to have a rough sketch to get upfront buy-in from the business, product, and tech teams (
&lt;a href="https://read.readwise.io/read/01gqqv8mysz7s0xdarcnh4ye69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How &lt;em>not&lt;/em> to solve a problem is often more important than how to solve it. Unfortunately, this doesn’t get addressed enough. (
&lt;a href="https://read.readwise.io/read/01gqqvb5gaekkk4q99gpwtvt2e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Providing teams with boundaries and constraints counterintuitively leads to greater creativity and freedom. Without constraints, we don’t know what we cannot do. (
&lt;a href="https://read.readwise.io/read/01gqqvdmxvq01q7m9xfz6yzyta" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Constraints drive innovation and force focus. Instead of trying to remove them, use them to your advantage.” (
&lt;a href="https://read.readwise.io/read/01gqqvfbjwzcf77wk1chc642ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We write the intent, desired outcome, deliverable, and constraints in simple language on a single-paged document. This can be shared to stakeholders for their review, feedback, and buy-in. (
&lt;a href="https://read.readwise.io/read/01gqqvfna7vqsse7bg262jjs8h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires a certain amount of discipline from stakeholders. After all, the work comes at no cost to them. There’s nothing stopping them from changing their minds halfway through the project. (
&lt;a href="https://read.readwise.io/read/01gqqvg2g9rhn16e9n4vnqdyey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most projects start with a solution, then come up with estimates for each component and the overall design. (
&lt;a href="https://read.readwise.io/read/01gqqvk6xgj43mky36dtx6z4rd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I tend to do the opposite. Given a budget (read: time-box), how can we design a solution that fits? The intent and desired outcome determine the time-box, and the time-box determines the solution design. This is how Basecamp does it too—they have different
&lt;a href="https://basecamp.com/shapeup/1.5-chapter-06#ingredient-2-appetite" rel="noopener">appetite&lt;/a> for various problems, and scope the solutions accordingly. (
&lt;a href="https://read.readwise.io/read/01gqqvkhd2w3teftgc6y5hhsf6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The time-box will vary across the project stages. At the start, when we’re still exploring and uncertainty is high, we’ll want tighter time-boxes to limit wild goose chases. (
&lt;a href="https://read.readwise.io/read/01gqqvmh5wgk8zff8p1zy3c46a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>feasibility assessment&lt;/strong>. With our existing data and technology, are we able to solve the problem? If so, to what extent? In this stage, we aim for a quick and dirty investigation. I usually time-box this at 1-2 weeks. (
&lt;a href="https://read.readwise.io/read/01gqqvmypq0e71g7khczbc0tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After determining feasibility, we proceed with a &lt;strong>proof of concept&lt;/strong> (POC). In this stage, we &lt;em>hack&lt;/em> together a prototype to assess if our solution is technically achievable. Ideally, we also test the integration points with upstream data providers and downstream consumers. Can we meet the technical constraints (e.g., latency, throughput)? Is model performance satisfactory? This usually takes a month or two. (
&lt;a href="https://read.readwise.io/read/01gqqvq07vrkf3f5gbdgy0bcs0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We’ll want to time-box this too. An overly generous timeline can lead to non-essential features being squeezed in and never-ending development—without actually deploying it, no one benefits from it. This usually takes 3-6 months, including infra, job orchestration, testing, monitoring, documentation, etc. (
&lt;a href="https://read.readwise.io/read/01gqqvqfe9tqzqgsaphad7mssf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Having the one-pager and time-box improves a project’s chances of success. Usually, it’s sufficient. Nonetheless, it can be helpful to &lt;strong>break it down&lt;/strong>, especially if it involves unfamiliar data or technology. (
&lt;a href="https://read.readwise.io/read/01gqqw13n8btrm10ddeegqt3fk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the breakdown indicates which components are harder to implement or more at risk—these usually involve things we’ve not done before. We want to front-load the &lt;em>risk&lt;/em> and start with these &lt;em>scary&lt;/em> bits first (
&lt;a href="https://read.readwise.io/read/01gqqw1pce7bm7metr0z6eh1m4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When breaking it down, I often consult seniors with more expertise and experience. They usually have better intuition on potential gotchas and blockers that deserve more attention. (
&lt;a href="https://read.readwise.io/read/01gqqw1yppnv89h54gxa2b93j8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[eugeneyan.com]]
title: &amp;ldquo;What I Do Before a Data Science Project to Ensure Success&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-i-do-before-a-data-science-project-to-ensure-success-2">What I Do Before a Data Science Project to Ensure Success&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/ideal-data-science-workflow.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[eugeneyan.com]]&lt;/li>
&lt;li>Full Title: What I Do Before a Data Science Project to Ensure Success&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager" rel="noopener">https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>First, Draw The Map To The Destination (One-Pager)
The map covers the intent, desired outcome, deliverable, and constraints. (
&lt;a href="https://read.readwise.io/read/01gqqv431az1h7ewqhayqwy2ne" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Intent (Why?)
What’s the problem we’re trying to solve, or the opportunity we want to gain from? How will customers benefit? &lt;em>Why&lt;/em> are we doing this, and &lt;em>why&lt;/em> is it important? (
&lt;a href="https://read.readwise.io/read/01gqqv4a4pvrf9vxa699rqhprg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Management is doing things right; leadership is doing the right things.” - Peter Drucker (
&lt;a href="https://read.readwise.io/read/01gqqv4hdmekgf30nmbb39a6m6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But, by taking the time to think through the problem and intent, we might realise that, hey, maybe we don’t need to fix it after all. (
&lt;a href="https://read.readwise.io/read/01gqqv4x33hv6db37nkwd2ctrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have the intent, we can discuss how success looks like. How well should we solve this problem? How do we measure it? In data science, this is usually a business metric such as conversion, savings from fraud reduction, net promoter score, etc. (
&lt;a href="https://read.readwise.io/read/01gqqv5gr6134s6j3wjeb0st5x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Specifying the desired outcome, in quantifiable terms, prevents us from falling into the trap of chasing a moving target. (
&lt;a href="https://read.readwise.io/read/01gqqv6b867t3pwd6vt38xjjk1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Solving a problem to 95% could take 3-4x the effort of solving to 90%; solving to 99% might take 10-100x more. (
&lt;a href="https://read.readwise.io/read/01gqqv6pmnpzyvbvc1wvt9zdc5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can design a deliverable that meets the intent and desired outcome. How should we solve this problem? The solution should be designed to meet the intent and desired outcome, keeping in mind the need to integrate with the existing system. (
&lt;a href="https://read.readwise.io/read/01gqqv7370g0gq3s43402p6dn3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>e-commerce platform has the intent of improving how customers discover and purchase products. To achieve this, should we improve search? Or recommendations? Or email campaigns? If it’s a recommender, how will we deploy it? (
&lt;a href="https://read.readwise.io/read/01gqqv7f3mznfp9vyn1dht7a16" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This doesn’t have to be especially detailed; for now, we don’t need the full architecture and specs. But it’s useful to have a rough sketch to get upfront buy-in from the business, product, and tech teams (
&lt;a href="https://read.readwise.io/read/01gqqv8mysz7s0xdarcnh4ye69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How &lt;em>not&lt;/em> to solve a problem is often more important than how to solve it. Unfortunately, this doesn’t get addressed enough. (
&lt;a href="https://read.readwise.io/read/01gqqvb5gaekkk4q99gpwtvt2e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Providing teams with boundaries and constraints counterintuitively leads to greater creativity and freedom. Without constraints, we don’t know what we cannot do. (
&lt;a href="https://read.readwise.io/read/01gqqvdmxvq01q7m9xfz6yzyta" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Constraints drive innovation and force focus. Instead of trying to remove them, use them to your advantage.” (
&lt;a href="https://read.readwise.io/read/01gqqvfbjwzcf77wk1chc642ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We write the intent, desired outcome, deliverable, and constraints in simple language on a single-paged document. This can be shared to stakeholders for their review, feedback, and buy-in. (
&lt;a href="https://read.readwise.io/read/01gqqvfna7vqsse7bg262jjs8h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires a certain amount of discipline from stakeholders. After all, the work comes at no cost to them. There’s nothing stopping them from changing their minds halfway through the project. (
&lt;a href="https://read.readwise.io/read/01gqqvg2g9rhn16e9n4vnqdyey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most projects start with a solution, then come up with estimates for each component and the overall design. (
&lt;a href="https://read.readwise.io/read/01gqqvk6xgj43mky36dtx6z4rd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I tend to do the opposite. Given a budget (read: time-box), how can we design a solution that fits? The intent and desired outcome determine the time-box, and the time-box determines the solution design. This is how Basecamp does it too—they have different
&lt;a href="https://basecamp.com/shapeup/1.5-chapter-06#ingredient-2-appetite" rel="noopener">appetite&lt;/a> for various problems, and scope the solutions accordingly. (
&lt;a href="https://read.readwise.io/read/01gqqvkhd2w3teftgc6y5hhsf6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The time-box will vary across the project stages. At the start, when we’re still exploring and uncertainty is high, we’ll want tighter time-boxes to limit wild goose chases. (
&lt;a href="https://read.readwise.io/read/01gqqvmh5wgk8zff8p1zy3c46a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>feasibility assessment&lt;/strong>. With our existing data and technology, are we able to solve the problem? If so, to what extent? In this stage, we aim for a quick and dirty investigation. I usually time-box this at 1-2 weeks. (
&lt;a href="https://read.readwise.io/read/01gqqvmypq0e71g7khczbc0tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After determining feasibility, we proceed with a &lt;strong>proof of concept&lt;/strong> (POC). In this stage, we &lt;em>hack&lt;/em> together a prototype to assess if our solution is technically achievable. Ideally, we also test the integration points with upstream data providers and downstream consumers. Can we meet the technical constraints (e.g., latency, throughput)? Is model performance satisfactory? This usually takes a month or two. (
&lt;a href="https://read.readwise.io/read/01gqqvq07vrkf3f5gbdgy0bcs0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We’ll want to time-box this too. An overly generous timeline can lead to non-essential features being squeezed in and never-ending development—without actually deploying it, no one benefits from it. This usually takes 3-6 months, including infra, job orchestration, testing, monitoring, documentation, etc. (
&lt;a href="https://read.readwise.io/read/01gqqvqfe9tqzqgsaphad7mssf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Having the one-pager and time-box improves a project’s chances of success. Usually, it’s sufficient. Nonetheless, it can be helpful to &lt;strong>break it down&lt;/strong>, especially if it involves unfamiliar data or technology. (
&lt;a href="https://read.readwise.io/read/01gqqw13n8btrm10ddeegqt3fk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the breakdown indicates which components are harder to implement or more at risk—these usually involve things we’ve not done before. We want to front-load the &lt;em>risk&lt;/em> and start with these &lt;em>scary&lt;/em> bits first (
&lt;a href="https://read.readwise.io/read/01gqqw1pce7bm7metr0z6eh1m4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When breaking it down, I often consult seniors with more expertise and experience. They usually have better intuition on potential gotchas and blockers that deserve more attention. (
&lt;a href="https://read.readwise.io/read/01gqqw1yppnv89h54gxa2b93j8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[eugeneyan.com]]
title: &amp;ldquo;What I Do Before a Data Science Project to Ensure Success&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-i-do-before-a-data-science-project-to-ensure-success-3">What I Do Before a Data Science Project to Ensure Success&lt;/h1>
&lt;p>
&lt;img src="https://eugeneyan.com/assets/og_image/ideal-data-science-workflow.jpg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[eugeneyan.com]]&lt;/li>
&lt;li>Full Title: What I Do Before a Data Science Project to Ensure Success&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager" rel="noopener">https://eugeneyan.com/writing/what-i-do-before-a-data-science-project-to-ensure-success/#first-draw-the-map-to-the-destination-one-pager&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>First, Draw The Map To The Destination (One-Pager)
The map covers the intent, desired outcome, deliverable, and constraints. (
&lt;a href="https://read.readwise.io/read/01gqqv431az1h7ewqhayqwy2ne" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Intent (Why?)
What’s the problem we’re trying to solve, or the opportunity we want to gain from? How will customers benefit? &lt;em>Why&lt;/em> are we doing this, and &lt;em>why&lt;/em> is it important? (
&lt;a href="https://read.readwise.io/read/01gqqv4a4pvrf9vxa699rqhprg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Management is doing things right; leadership is doing the right things.” - Peter Drucker (
&lt;a href="https://read.readwise.io/read/01gqqv4hdmekgf30nmbb39a6m6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>But, by taking the time to think through the problem and intent, we might realise that, hey, maybe we don’t need to fix it after all. (
&lt;a href="https://read.readwise.io/read/01gqqv4x33hv6db37nkwd2ctrs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Now that we have the intent, we can discuss how success looks like. How well should we solve this problem? How do we measure it? In data science, this is usually a business metric such as conversion, savings from fraud reduction, net promoter score, etc. (
&lt;a href="https://read.readwise.io/read/01gqqv5gr6134s6j3wjeb0st5x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Specifying the desired outcome, in quantifiable terms, prevents us from falling into the trap of chasing a moving target. (
&lt;a href="https://read.readwise.io/read/01gqqv6b867t3pwd6vt38xjjk1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Solving a problem to 95% could take 3-4x the effort of solving to 90%; solving to 99% might take 10-100x more. (
&lt;a href="https://read.readwise.io/read/01gqqv6pmnpzyvbvc1wvt9zdc5" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>we can design a deliverable that meets the intent and desired outcome. How should we solve this problem? The solution should be designed to meet the intent and desired outcome, keeping in mind the need to integrate with the existing system. (
&lt;a href="https://read.readwise.io/read/01gqqv7370g0gq3s43402p6dn3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>e-commerce platform has the intent of improving how customers discover and purchase products. To achieve this, should we improve search? Or recommendations? Or email campaigns? If it’s a recommender, how will we deploy it? (
&lt;a href="https://read.readwise.io/read/01gqqv7f3mznfp9vyn1dht7a16" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This doesn’t have to be especially detailed; for now, we don’t need the full architecture and specs. But it’s useful to have a rough sketch to get upfront buy-in from the business, product, and tech teams (
&lt;a href="https://read.readwise.io/read/01gqqv8mysz7s0xdarcnh4ye69" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>How &lt;em>not&lt;/em> to solve a problem is often more important than how to solve it. Unfortunately, this doesn’t get addressed enough. (
&lt;a href="https://read.readwise.io/read/01gqqvb5gaekkk4q99gpwtvt2e" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Providing teams with boundaries and constraints counterintuitively leads to greater creativity and freedom. Without constraints, we don’t know what we cannot do. (
&lt;a href="https://read.readwise.io/read/01gqqvdmxvq01q7m9xfz6yzyta" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>“Constraints drive innovation and force focus. Instead of trying to remove them, use them to your advantage.” (
&lt;a href="https://read.readwise.io/read/01gqqvfbjwzcf77wk1chc642ar" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We write the intent, desired outcome, deliverable, and constraints in simple language on a single-paged document. This can be shared to stakeholders for their review, feedback, and buy-in. (
&lt;a href="https://read.readwise.io/read/01gqqvfna7vqsse7bg262jjs8h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>This requires a certain amount of discipline from stakeholders. After all, the work comes at no cost to them. There’s nothing stopping them from changing their minds halfway through the project. (
&lt;a href="https://read.readwise.io/read/01gqqvg2g9rhn16e9n4vnqdyey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Most projects start with a solution, then come up with estimates for each component and the overall design. (
&lt;a href="https://read.readwise.io/read/01gqqvk6xgj43mky36dtx6z4rd" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>I tend to do the opposite. Given a budget (read: time-box), how can we design a solution that fits? The intent and desired outcome determine the time-box, and the time-box determines the solution design. This is how Basecamp does it too—they have different
&lt;a href="https://basecamp.com/shapeup/1.5-chapter-06#ingredient-2-appetite" rel="noopener">appetite&lt;/a> for various problems, and scope the solutions accordingly. (
&lt;a href="https://read.readwise.io/read/01gqqvkhd2w3teftgc6y5hhsf6" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The time-box will vary across the project stages. At the start, when we’re still exploring and uncertainty is high, we’ll want tighter time-boxes to limit wild goose chases. (
&lt;a href="https://read.readwise.io/read/01gqqvmh5wgk8zff8p1zy3c46a" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;strong>feasibility assessment&lt;/strong>. With our existing data and technology, are we able to solve the problem? If so, to what extent? In this stage, we aim for a quick and dirty investigation. I usually time-box this at 1-2 weeks. (
&lt;a href="https://read.readwise.io/read/01gqqvmypq0e71g7khczbc0tb3" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>After determining feasibility, we proceed with a &lt;strong>proof of concept&lt;/strong> (POC). In this stage, we &lt;em>hack&lt;/em> together a prototype to assess if our solution is technically achievable. Ideally, we also test the integration points with upstream data providers and downstream consumers. Can we meet the technical constraints (e.g., latency, throughput)? Is model performance satisfactory? This usually takes a month or two. (
&lt;a href="https://read.readwise.io/read/01gqqvq07vrkf3f5gbdgy0bcs0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>We’ll want to time-box this too. An overly generous timeline can lead to non-essential features being squeezed in and never-ending development—without actually deploying it, no one benefits from it. This usually takes 3-6 months, including infra, job orchestration, testing, monitoring, documentation, etc. (
&lt;a href="https://read.readwise.io/read/01gqqvqfe9tqzqgsaphad7mssf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Having the one-pager and time-box improves a project’s chances of success. Usually, it’s sufficient. Nonetheless, it can be helpful to &lt;strong>break it down&lt;/strong>, especially if it involves unfamiliar data or technology. (
&lt;a href="https://read.readwise.io/read/01gqqw13n8btrm10ddeegqt3fk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>the breakdown indicates which components are harder to implement or more at risk—these usually involve things we’ve not done before. We want to front-load the &lt;em>risk&lt;/em> and start with these &lt;em>scary&lt;/em> bits first (
&lt;a href="https://read.readwise.io/read/01gqqw1pce7bm7metr0z6eh1m4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>When breaking it down, I often consult seniors with more expertise and experience. They usually have better intuition on potential gotchas and blockers that deserve more attention. (
&lt;a href="https://read.readwise.io/read/01gqqw1yppnv89h54gxa2b93j8" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>What Is &amp;#34;Data as a Product&amp;#34; Really?</title><link>https://pelayoarbues.github.io/literature-notes/Articles/What-Is-Data-as-a-Product-Really/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/What-Is-Data-as-a-Product-Really/</guid><description>&lt;h1 id="what-is-data-as-a-product-really">What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/h1>
&lt;p>
&lt;img src="https://assets-global.website-files.com/60d9fbbfcd9fcb40bad8aac3/62a38e5a180196a1a760c86c_What-is-data-as-a-product-really.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Parker Rogers]]&lt;/li>
&lt;li>Full Title: What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean" rel="noopener">https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>what matters isn’t necessarily the exact dictionary definition of &lt;em>data as a product&lt;/em>, but rather that data teams work diligently to find processes and systems that help them advocate for the importance of data on a wider, organizational level. (
&lt;a href="https://read.readwise.io/read/01gqcp30nw6a306jxsrds9ns0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Data as a product is about … &lt;strong>key product development principles&lt;/strong>.
• Data as a product is about … &lt;strong>providing data to stakeholders automatically.&lt;/strong>
• Data as a product is about … &lt;strong>applying the principles of product thinking.&lt;/strong>
• Data as a product is about … &lt;strong>all the tools, processes, and people that go into it.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gqcp4c8ckcvhe94wh99hr7fv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is explained as the concept of applying key product development principles (such as identifying and addressing unmet needs, agility, iterability, and reusability) to data projects (
&lt;a href="https://read.readwise.io/read/01gqcphatrm16wwdcezpesm0zh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• The data team can understand and apply the product development principles above.
• The data team has developed &lt;em>point solutions&lt;/em> that solve the specific needs of their stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqcphn5trbtbbjpsn7bv6bqv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once a data team has abstracted the underlying principles of successful &lt;em>point solutions&lt;/em> and reused them to solve an array of business problems, they have achieved &lt;em>data as a product&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gqcpk5rs2tn348dqdg5aj6fw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is about the concept of providing data to stakeholders in an automated fashion to facilitate good decision-making (
&lt;a href="https://read.readwise.io/read/01gqcpkepjdq2saczzjtggz7pg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• DaaS professionals have specific domain expertise (marketing, finance, product, etc.) and are focused on providing insights.
• DaaP professionals are engineers. They are focused on building processes and data pipelines and delivering rows/columns of data to facilitate good decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcpm6t377zd4ddsjm8qahtx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://martinfowler.com/articles/products-over-projects.html" rel="noopener">&lt;em>&lt;strong>Product thinking&lt;/strong>&lt;/em>&lt;/a>&lt;em>:&lt;/em> A mindset that’s outcome-oriented, business-capability aligned, long-lived, and cross-functional with the intention to solve problems and improve business outcomes. Additionally, there should be a focus on discoverability, security, explorability, understandability, trustworthiness, etc (
&lt;a href="https://read.readwise.io/read/01gqcpsk1byfx94cbq0r1wwn9c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Data products&lt;/strong>&lt;/em>: Using “raw data, derived data, [and] algorithms” to automate and/or guide decisions to improve business outcomes (
&lt;a href="https://read.readwise.io/read/01gqcpq8vk03tae65gqm7pmjjf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under this view, every piece of data, the tools used to generate, access, and analyze, are integrated together as one big data product. Any internal tool used to make a decision is a &lt;em>feature&lt;/em> of the data product. (
&lt;a href="https://read.readwise.io/read/01gqcpv565mbbfckxpg222rhz4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they simply call &lt;em>all&lt;/em> company data &lt;em>data as a product&lt;/em>, with the individual tools being &lt;em>features&lt;/em> of &lt;em>data as a product&lt;/em> while other articles are calling the individual &lt;em>features&lt;/em> &lt;em>data as a product.&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqcpw3s28y6k71psct26pwjt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data as a product is the concept of applying key product development principles (Identifying and addressing unmet needs, agility, iterability, and reusability) to data projects. (
&lt;a href="https://read.readwise.io/read/01gqcpxzm92bnjfd22f3myfqtp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Fundamentally, &lt;em>data as a product&lt;/em> is a concept, or methodology, about how data teams can create value in their organizations. The general belief is that applying product management principles to data teams will make data work more valuable and scalable, qualities that have been lacking in the data community for years. (
&lt;a href="https://read.readwise.io/read/01gqcpy92c4ybqjxh3rbqr4r3h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Parker Rogers]]
title: &amp;ldquo;What Is &amp;quot;Data as a Product&amp;quot; Really?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-is-data-as-a-product-really-1">What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/h1>
&lt;p>
&lt;img src="https://assets-global.website-files.com/60d9fbbfcd9fcb40bad8aac3/62a38e5a180196a1a760c86c_What-is-data-as-a-product-really.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Parker Rogers]]&lt;/li>
&lt;li>Full Title: What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean" rel="noopener">https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>what matters isn’t necessarily the exact dictionary definition of &lt;em>data as a product&lt;/em>, but rather that data teams work diligently to find processes and systems that help them advocate for the importance of data on a wider, organizational level. (
&lt;a href="https://read.readwise.io/read/01gqcp30nw6a306jxsrds9ns0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Data as a product is about … &lt;strong>key product development principles&lt;/strong>.
• Data as a product is about … &lt;strong>providing data to stakeholders automatically.&lt;/strong>
• Data as a product is about … &lt;strong>applying the principles of product thinking.&lt;/strong>
• Data as a product is about … &lt;strong>all the tools, processes, and people that go into it.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gqcp4c8ckcvhe94wh99hr7fv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is explained as the concept of applying key product development principles (such as identifying and addressing unmet needs, agility, iterability, and reusability) to data projects (
&lt;a href="https://read.readwise.io/read/01gqcphatrm16wwdcezpesm0zh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• The data team can understand and apply the product development principles above.
• The data team has developed &lt;em>point solutions&lt;/em> that solve the specific needs of their stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqcphn5trbtbbjpsn7bv6bqv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once a data team has abstracted the underlying principles of successful &lt;em>point solutions&lt;/em> and reused them to solve an array of business problems, they have achieved &lt;em>data as a product&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gqcpk5rs2tn348dqdg5aj6fw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is about the concept of providing data to stakeholders in an automated fashion to facilitate good decision-making (
&lt;a href="https://read.readwise.io/read/01gqcpkepjdq2saczzjtggz7pg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• DaaS professionals have specific domain expertise (marketing, finance, product, etc.) and are focused on providing insights.
• DaaP professionals are engineers. They are focused on building processes and data pipelines and delivering rows/columns of data to facilitate good decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcpm6t377zd4ddsjm8qahtx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://martinfowler.com/articles/products-over-projects.html" rel="noopener">&lt;em>&lt;strong>Product thinking&lt;/strong>&lt;/em>&lt;/a>&lt;em>:&lt;/em> A mindset that’s outcome-oriented, business-capability aligned, long-lived, and cross-functional with the intention to solve problems and improve business outcomes. Additionally, there should be a focus on discoverability, security, explorability, understandability, trustworthiness, etc (
&lt;a href="https://read.readwise.io/read/01gqcpsk1byfx94cbq0r1wwn9c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Data products&lt;/strong>&lt;/em>: Using “raw data, derived data, [and] algorithms” to automate and/or guide decisions to improve business outcomes (
&lt;a href="https://read.readwise.io/read/01gqcpq8vk03tae65gqm7pmjjf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under this view, every piece of data, the tools used to generate, access, and analyze, are integrated together as one big data product. Any internal tool used to make a decision is a &lt;em>feature&lt;/em> of the data product. (
&lt;a href="https://read.readwise.io/read/01gqcpv565mbbfckxpg222rhz4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they simply call &lt;em>all&lt;/em> company data &lt;em>data as a product&lt;/em>, with the individual tools being &lt;em>features&lt;/em> of &lt;em>data as a product&lt;/em> while other articles are calling the individual &lt;em>features&lt;/em> &lt;em>data as a product.&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqcpw3s28y6k71psct26pwjt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data as a product is the concept of applying key product development principles (Identifying and addressing unmet needs, agility, iterability, and reusability) to data projects. (
&lt;a href="https://read.readwise.io/read/01gqcpxzm92bnjfd22f3myfqtp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Fundamentally, &lt;em>data as a product&lt;/em> is a concept, or methodology, about how data teams can create value in their organizations. The general belief is that applying product management principles to data teams will make data work more valuable and scalable, qualities that have been lacking in the data community for years. (
&lt;a href="https://read.readwise.io/read/01gqcpy92c4ybqjxh3rbqr4r3h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Parker Rogers]]
title: &amp;ldquo;What Is &amp;quot;Data as a Product&amp;quot; Really?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-is-data-as-a-product-really-2">What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/h1>
&lt;p>
&lt;img src="https://assets-global.website-files.com/60d9fbbfcd9fcb40bad8aac3/62a38e5a180196a1a760c86c_What-is-data-as-a-product-really.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Parker Rogers]]&lt;/li>
&lt;li>Full Title: What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean" rel="noopener">https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>what matters isn’t necessarily the exact dictionary definition of &lt;em>data as a product&lt;/em>, but rather that data teams work diligently to find processes and systems that help them advocate for the importance of data on a wider, organizational level. (
&lt;a href="https://read.readwise.io/read/01gqcp30nw6a306jxsrds9ns0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Data as a product is about … &lt;strong>key product development principles&lt;/strong>.
• Data as a product is about … &lt;strong>providing data to stakeholders automatically.&lt;/strong>
• Data as a product is about … &lt;strong>applying the principles of product thinking.&lt;/strong>
• Data as a product is about … &lt;strong>all the tools, processes, and people that go into it.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gqcp4c8ckcvhe94wh99hr7fv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is explained as the concept of applying key product development principles (such as identifying and addressing unmet needs, agility, iterability, and reusability) to data projects (
&lt;a href="https://read.readwise.io/read/01gqcphatrm16wwdcezpesm0zh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• The data team can understand and apply the product development principles above.
• The data team has developed &lt;em>point solutions&lt;/em> that solve the specific needs of their stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqcphn5trbtbbjpsn7bv6bqv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once a data team has abstracted the underlying principles of successful &lt;em>point solutions&lt;/em> and reused them to solve an array of business problems, they have achieved &lt;em>data as a product&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gqcpk5rs2tn348dqdg5aj6fw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is about the concept of providing data to stakeholders in an automated fashion to facilitate good decision-making (
&lt;a href="https://read.readwise.io/read/01gqcpkepjdq2saczzjtggz7pg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• DaaS professionals have specific domain expertise (marketing, finance, product, etc.) and are focused on providing insights.
• DaaP professionals are engineers. They are focused on building processes and data pipelines and delivering rows/columns of data to facilitate good decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcpm6t377zd4ddsjm8qahtx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://martinfowler.com/articles/products-over-projects.html" rel="noopener">&lt;em>&lt;strong>Product thinking&lt;/strong>&lt;/em>&lt;/a>&lt;em>:&lt;/em> A mindset that’s outcome-oriented, business-capability aligned, long-lived, and cross-functional with the intention to solve problems and improve business outcomes. Additionally, there should be a focus on discoverability, security, explorability, understandability, trustworthiness, etc (
&lt;a href="https://read.readwise.io/read/01gqcpsk1byfx94cbq0r1wwn9c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Data products&lt;/strong>&lt;/em>: Using “raw data, derived data, [and] algorithms” to automate and/or guide decisions to improve business outcomes (
&lt;a href="https://read.readwise.io/read/01gqcpq8vk03tae65gqm7pmjjf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under this view, every piece of data, the tools used to generate, access, and analyze, are integrated together as one big data product. Any internal tool used to make a decision is a &lt;em>feature&lt;/em> of the data product. (
&lt;a href="https://read.readwise.io/read/01gqcpv565mbbfckxpg222rhz4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they simply call &lt;em>all&lt;/em> company data &lt;em>data as a product&lt;/em>, with the individual tools being &lt;em>features&lt;/em> of &lt;em>data as a product&lt;/em> while other articles are calling the individual &lt;em>features&lt;/em> &lt;em>data as a product.&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqcpw3s28y6k71psct26pwjt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data as a product is the concept of applying key product development principles (Identifying and addressing unmet needs, agility, iterability, and reusability) to data projects. (
&lt;a href="https://read.readwise.io/read/01gqcpxzm92bnjfd22f3myfqtp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Fundamentally, &lt;em>data as a product&lt;/em> is a concept, or methodology, about how data teams can create value in their organizations. The general belief is that applying product management principles to data teams will make data work more valuable and scalable, qualities that have been lacking in the data community for years. (
&lt;a href="https://read.readwise.io/read/01gqcpy92c4ybqjxh3rbqr4r3h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Parker Rogers]]
title: &amp;ldquo;What Is &amp;quot;Data as a Product&amp;quot; Really?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="what-is-data-as-a-product-really-3">What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/h1>
&lt;p>
&lt;img src="https://assets-global.website-files.com/60d9fbbfcd9fcb40bad8aac3/62a38e5a180196a1a760c86c_What-is-data-as-a-product-really.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Parker Rogers]]&lt;/li>
&lt;li>Full Title: What Is &amp;ldquo;Data as a Product&amp;rdquo; Really?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean" rel="noopener">https://www.getcensus.com/blog/what-does-data-as-a-product-really-mean&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>what matters isn’t necessarily the exact dictionary definition of &lt;em>data as a product&lt;/em>, but rather that data teams work diligently to find processes and systems that help them advocate for the importance of data on a wider, organizational level. (
&lt;a href="https://read.readwise.io/read/01gqcp30nw6a306jxsrds9ns0x" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• Data as a product is about … &lt;strong>key product development principles&lt;/strong>.
• Data as a product is about … &lt;strong>providing data to stakeholders automatically.&lt;/strong>
• Data as a product is about … &lt;strong>applying the principles of product thinking.&lt;/strong>
• Data as a product is about … &lt;strong>all the tools, processes, and people that go into it.&lt;/strong> (
&lt;a href="https://read.readwise.io/read/01gqcp4c8ckcvhe94wh99hr7fv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is explained as the concept of applying key product development principles (such as identifying and addressing unmet needs, agility, iterability, and reusability) to data projects (
&lt;a href="https://read.readwise.io/read/01gqcphatrm16wwdcezpesm0zh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• The data team can understand and apply the product development principles above.
• The data team has developed &lt;em>point solutions&lt;/em> that solve the specific needs of their stakeholders. (
&lt;a href="https://read.readwise.io/read/01gqcphn5trbtbbjpsn7bv6bqv" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Once a data team has abstracted the underlying principles of successful &lt;em>point solutions&lt;/em> and reused them to solve an array of business problems, they have achieved &lt;em>data as a product&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01gqcpk5rs2tn348dqdg5aj6fw" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>data as a product&lt;/em> is about the concept of providing data to stakeholders in an automated fashion to facilitate good decision-making (
&lt;a href="https://read.readwise.io/read/01gqcpkepjdq2saczzjtggz7pg" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>• DaaS professionals have specific domain expertise (marketing, finance, product, etc.) and are focused on providing insights.
• DaaP professionals are engineers. They are focused on building processes and data pipelines and delivering rows/columns of data to facilitate good decision-making. (
&lt;a href="https://read.readwise.io/read/01gqcpm6t377zd4ddsjm8qahtx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>
&lt;a href="https://martinfowler.com/articles/products-over-projects.html" rel="noopener">&lt;em>&lt;strong>Product thinking&lt;/strong>&lt;/em>&lt;/a>&lt;em>:&lt;/em> A mindset that’s outcome-oriented, business-capability aligned, long-lived, and cross-functional with the intention to solve problems and improve business outcomes. Additionally, there should be a focus on discoverability, security, explorability, understandability, trustworthiness, etc (
&lt;a href="https://read.readwise.io/read/01gqcpsk1byfx94cbq0r1wwn9c" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>&lt;em>&lt;strong>Data products&lt;/strong>&lt;/em>: Using “raw data, derived data, [and] algorithms” to automate and/or guide decisions to improve business outcomes (
&lt;a href="https://read.readwise.io/read/01gqcpq8vk03tae65gqm7pmjjf" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Under this view, every piece of data, the tools used to generate, access, and analyze, are integrated together as one big data product. Any internal tool used to make a decision is a &lt;em>feature&lt;/em> of the data product. (
&lt;a href="https://read.readwise.io/read/01gqcpv565mbbfckxpg222rhz4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>they simply call &lt;em>all&lt;/em> company data &lt;em>data as a product&lt;/em>, with the individual tools being &lt;em>features&lt;/em> of &lt;em>data as a product&lt;/em> while other articles are calling the individual &lt;em>features&lt;/em> &lt;em>data as a product.&lt;/em> (
&lt;a href="https://read.readwise.io/read/01gqcpw3s28y6k71psct26pwjt" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Data as a product is the concept of applying key product development principles (Identifying and addressing unmet needs, agility, iterability, and reusability) to data projects. (
&lt;a href="https://read.readwise.io/read/01gqcpxzm92bnjfd22f3myfqtp" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Fundamentally, &lt;em>data as a product&lt;/em> is a concept, or methodology, about how data teams can create value in their organizations. The general belief is that applying product management principles to data teams will make data work more valuable and scalable, qualities that have been lacking in the data community for years. (
&lt;a href="https://read.readwise.io/read/01gqcpy92c4ybqjxh3rbqr4r3h" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Why-Backlogs-Are-Useless-Why-They-Never-Shrink-and-What-to-Do-Instead/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Why-Backlogs-Are-Useless-Why-They-Never-Shrink-and-What-to-Do-Instead/</guid><description>&lt;h1 id="why-backlogs-are-useless-why-they-never-shrink-and-what-to-do-instead">Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lucasfcosta.com]]&lt;/li>
&lt;li>Full Title: Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html" rel="noopener">https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Backlogs &lt;em>never&lt;/em> shrink. (
&lt;a href="https://read.readwise.io/read/01gs5he241dvcqw5sga298pz06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Important tasks never go into the backlog. We create them, we work on them, and we ship them. (
&lt;a href="https://read.readwise.io/read/01gs5heh4bz19ppj7ew9ec93cz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The truth is, we always know what task is most important, and we work on it until it’s done. Everything else is fluff. (
&lt;a href="https://read.readwise.io/read/01gs5hf3tzdhqzbqpw1x133e13" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Backlogs exist because they’re a great way to avoid difficult conversations and shift blame away from product to engineering. (
&lt;a href="https://read.readwise.io/read/01gs5hg2qb6mkf2x8ysrzk7ssh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s much easier to say “you’ll add it to the backlog,” than to spend an hour explaining why the suggestion is irrelevant. (
&lt;a href="https://read.readwise.io/read/01gs5hn4a23341f8b14sq8qv49" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>product manager’s job is &lt;em>not&lt;/em> to create as many tickets as possible but to &lt;em>delete&lt;/em> as many as they can and avoid unnecessary work at all costs. (
&lt;a href="https://read.readwise.io/read/01gs5hp5rhxm7tw1ms7k4231qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a product manager creating more tasks than its engineers can deliver is also producing waste. (
&lt;a href="https://read.readwise.io/read/01gs5hqmd5ha46ye9wn2sjzt7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way to make a backlog even more harmful is to require engineers to “refine” the tasks there. That way, you’ll be wasting time from product managers &lt;em>and&lt;/em> engineers, (
&lt;a href="https://read.readwise.io/read/01gs5hr7zdng61j6sfeby8jn9s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do not maintain a backlog unless it’s the backlog for your next few weeks of work. (
&lt;a href="https://read.readwise.io/read/01gs5kms7fynmw46929fkpyde4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’d need more than two or three weeks to get rid of everything on your backlog, you’re planning too far ahead, at the wrong level of abstraction. (
&lt;a href="https://read.readwise.io/read/01gs5kn1j5n1yswqjzfjrtz21n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everything further away than two or three works of work should go into a high-level roadmap. You should revisit that roadmap regularly, and product managers should share it with engineers and explain why each item is important (
&lt;a href="https://read.readwise.io/read/01gs5kne440rn1hv4q8bf2cp2q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If a bug’s been in the backlog for more than three months, it’s already a feature. (
&lt;a href="https://read.readwise.io/read/01gs5kp25ahxxmntavqdbqw615" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lucasfcosta.com]]
title: &amp;ldquo;Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="why-backlogs-are-useless-why-they-never-shrink-and-what-to-do-instead-1">Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lucasfcosta.com]]&lt;/li>
&lt;li>Full Title: Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html" rel="noopener">https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Backlogs &lt;em>never&lt;/em> shrink. (
&lt;a href="https://read.readwise.io/read/01gs5he241dvcqw5sga298pz06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Important tasks never go into the backlog. We create them, we work on them, and we ship them. (
&lt;a href="https://read.readwise.io/read/01gs5heh4bz19ppj7ew9ec93cz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The truth is, we always know what task is most important, and we work on it until it’s done. Everything else is fluff. (
&lt;a href="https://read.readwise.io/read/01gs5hf3tzdhqzbqpw1x133e13" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Backlogs exist because they’re a great way to avoid difficult conversations and shift blame away from product to engineering. (
&lt;a href="https://read.readwise.io/read/01gs5hg2qb6mkf2x8ysrzk7ssh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s much easier to say “you’ll add it to the backlog,” than to spend an hour explaining why the suggestion is irrelevant. (
&lt;a href="https://read.readwise.io/read/01gs5hn4a23341f8b14sq8qv49" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>product manager’s job is &lt;em>not&lt;/em> to create as many tickets as possible but to &lt;em>delete&lt;/em> as many as they can and avoid unnecessary work at all costs. (
&lt;a href="https://read.readwise.io/read/01gs5hp5rhxm7tw1ms7k4231qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a product manager creating more tasks than its engineers can deliver is also producing waste. (
&lt;a href="https://read.readwise.io/read/01gs5hqmd5ha46ye9wn2sjzt7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way to make a backlog even more harmful is to require engineers to “refine” the tasks there. That way, you’ll be wasting time from product managers &lt;em>and&lt;/em> engineers, (
&lt;a href="https://read.readwise.io/read/01gs5hr7zdng61j6sfeby8jn9s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do not maintain a backlog unless it’s the backlog for your next few weeks of work. (
&lt;a href="https://read.readwise.io/read/01gs5kms7fynmw46929fkpyde4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’d need more than two or three weeks to get rid of everything on your backlog, you’re planning too far ahead, at the wrong level of abstraction. (
&lt;a href="https://read.readwise.io/read/01gs5kn1j5n1yswqjzfjrtz21n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everything further away than two or three works of work should go into a high-level roadmap. You should revisit that roadmap regularly, and product managers should share it with engineers and explain why each item is important (
&lt;a href="https://read.readwise.io/read/01gs5kne440rn1hv4q8bf2cp2q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If a bug’s been in the backlog for more than three months, it’s already a feature. (
&lt;a href="https://read.readwise.io/read/01gs5kp25ahxxmntavqdbqw615" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lucasfcosta.com]]
title: &amp;ldquo;Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="why-backlogs-are-useless-why-they-never-shrink-and-what-to-do-instead-2">Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lucasfcosta.com]]&lt;/li>
&lt;li>Full Title: Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html" rel="noopener">https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Backlogs &lt;em>never&lt;/em> shrink. (
&lt;a href="https://read.readwise.io/read/01gs5he241dvcqw5sga298pz06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Important tasks never go into the backlog. We create them, we work on them, and we ship them. (
&lt;a href="https://read.readwise.io/read/01gs5heh4bz19ppj7ew9ec93cz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The truth is, we always know what task is most important, and we work on it until it’s done. Everything else is fluff. (
&lt;a href="https://read.readwise.io/read/01gs5hf3tzdhqzbqpw1x133e13" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Backlogs exist because they’re a great way to avoid difficult conversations and shift blame away from product to engineering. (
&lt;a href="https://read.readwise.io/read/01gs5hg2qb6mkf2x8ysrzk7ssh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s much easier to say “you’ll add it to the backlog,” than to spend an hour explaining why the suggestion is irrelevant. (
&lt;a href="https://read.readwise.io/read/01gs5hn4a23341f8b14sq8qv49" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>product manager’s job is &lt;em>not&lt;/em> to create as many tickets as possible but to &lt;em>delete&lt;/em> as many as they can and avoid unnecessary work at all costs. (
&lt;a href="https://read.readwise.io/read/01gs5hp5rhxm7tw1ms7k4231qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a product manager creating more tasks than its engineers can deliver is also producing waste. (
&lt;a href="https://read.readwise.io/read/01gs5hqmd5ha46ye9wn2sjzt7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way to make a backlog even more harmful is to require engineers to “refine” the tasks there. That way, you’ll be wasting time from product managers &lt;em>and&lt;/em> engineers, (
&lt;a href="https://read.readwise.io/read/01gs5hr7zdng61j6sfeby8jn9s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do not maintain a backlog unless it’s the backlog for your next few weeks of work. (
&lt;a href="https://read.readwise.io/read/01gs5kms7fynmw46929fkpyde4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’d need more than two or three weeks to get rid of everything on your backlog, you’re planning too far ahead, at the wrong level of abstraction. (
&lt;a href="https://read.readwise.io/read/01gs5kn1j5n1yswqjzfjrtz21n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everything further away than two or three works of work should go into a high-level roadmap. You should revisit that roadmap regularly, and product managers should share it with engineers and explain why each item is important (
&lt;a href="https://read.readwise.io/read/01gs5kne440rn1hv4q8bf2cp2q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If a bug’s been in the backlog for more than three months, it’s already a feature. (
&lt;a href="https://read.readwise.io/read/01gs5kp25ahxxmntavqdbqw615" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lucasfcosta.com]]
title: &amp;ldquo;Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="why-backlogs-are-useless-why-they-never-shrink-and-what-to-do-instead-3">Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/h1>
&lt;p>
&lt;img src="https://readwise-assets.s3.amazonaws.com/static/images/article1.be68295a7e40.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lucasfcosta.com]]&lt;/li>
&lt;li>Full Title: Why Backlogs Are Useless, Why They Never Shrink, and What to Do Instead&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html" rel="noopener">https://lucasfcosta.com/2023/02/07/backlogs-are-useless.html&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Backlogs &lt;em>never&lt;/em> shrink. (
&lt;a href="https://read.readwise.io/read/01gs5he241dvcqw5sga298pz06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Important tasks never go into the backlog. We create them, we work on them, and we ship them. (
&lt;a href="https://read.readwise.io/read/01gs5heh4bz19ppj7ew9ec93cz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The truth is, we always know what task is most important, and we work on it until it’s done. Everything else is fluff. (
&lt;a href="https://read.readwise.io/read/01gs5hf3tzdhqzbqpw1x133e13" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Backlogs exist because they’re a great way to avoid difficult conversations and shift blame away from product to engineering. (
&lt;a href="https://read.readwise.io/read/01gs5hg2qb6mkf2x8ysrzk7ssh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>it’s much easier to say “you’ll add it to the backlog,” than to spend an hour explaining why the suggestion is irrelevant. (
&lt;a href="https://read.readwise.io/read/01gs5hn4a23341f8b14sq8qv49" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>product manager’s job is &lt;em>not&lt;/em> to create as many tickets as possible but to &lt;em>delete&lt;/em> as many as they can and avoid unnecessary work at all costs. (
&lt;a href="https://read.readwise.io/read/01gs5hp5rhxm7tw1ms7k4231qs" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>a product manager creating more tasks than its engineers can deliver is also producing waste. (
&lt;a href="https://read.readwise.io/read/01gs5hqmd5ha46ye9wn2sjzt7v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The only way to make a backlog even more harmful is to require engineers to “refine” the tasks there. That way, you’ll be wasting time from product managers &lt;em>and&lt;/em> engineers, (
&lt;a href="https://read.readwise.io/read/01gs5hr7zdng61j6sfeby8jn9s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Do not maintain a backlog unless it’s the backlog for your next few weeks of work. (
&lt;a href="https://read.readwise.io/read/01gs5kms7fynmw46929fkpyde4" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If you’d need more than two or three weeks to get rid of everything on your backlog, you’re planning too far ahead, at the wrong level of abstraction. (
&lt;a href="https://read.readwise.io/read/01gs5kn1j5n1yswqjzfjrtz21n" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Everything further away than two or three works of work should go into a high-level roadmap. You should revisit that roadmap regularly, and product managers should share it with engineers and explain why each item is important (
&lt;a href="https://read.readwise.io/read/01gs5kne440rn1hv4q8bf2cp2q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>If a bug’s been in the backlog for more than three months, it’s already a feature. (
&lt;a href="https://read.readwise.io/read/01gs5kp25ahxxmntavqdbqw615" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Why Is “Data Scientist” Such a Controversial Title?</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Why-Is-Data-Scientist-Such-a-Controversial-Title/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Why-Is-Data-Scientist-Such-a-Controversial-Title/</guid><description>&lt;h1 id="why-is-data-scientist-such-a-controversial-title">Why Is “Data Scientist” Such a Controversial Title?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fedc01350-a3b8-42d5-869c-81244aaec134_714x338.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emily Thompson]]&lt;/li>
&lt;li>Full Title: Why Is “Data Scientist” Such a Controversial Title?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: There is no science without data, so data word in Data Science is redundant.
A decade later there is still debate on what the Data Scientist term means. The important part of the role is the science aspect.
There is no data science without data engineering and data infrastructure. There is no gain without planning and investing.
Many data scientists has to build the infrastructure and tools themselves when it does not exist.
ETL work and data quality tasks that validates the data pipeline is also part of the work of a scientist. It is even positive because it makes you learn data appreciation.
Data science integration with product managers is still not consistently integrated. Those PMs able to get the learning expertise of the Data Science teams will have a superpower.&lt;/li>
&lt;li>URL:
&lt;a href="https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_366" rel="noopener">https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_366&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>fter all that, I have to admit that that the term Data Scientist is a generic one that means different things to different people, and the field probably does need to evolve with more specific titles. (
&lt;a href="https://read.readwise.io/read/01gs3nhz0qq3c80wbmjm1xvx6v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Emily Thompson]]
title: &amp;ldquo;Why Is “Data Scientist” Such a Controversial Title?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="why-is-data-scientist-such-a-controversial-title-1">Why Is “Data Scientist” Such a Controversial Title?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fedc01350-a3b8-42d5-869c-81244aaec134_714x338.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emily Thompson]]&lt;/li>
&lt;li>Full Title: Why Is “Data Scientist” Such a Controversial Title?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: There is no science without data, so data word in Data Science is redundant.
A decade later there is still debate on what the Data Scientist term means. The important part of the role is the science aspect.
There is no data science without data engineering and data infrastructure. There is no gain without planning and investing.
Many data scientists has to build the infrastructure and tools themselves when it does not exist.
ETL work and data quality tasks that validates the data pipeline is also part of the work of a scientist. It is even positive because it makes you learn data appreciation.
Data science integration with product managers is still not consistently integrated. Those PMs able to get the learning expertise of the Data Science teams will have a superpower.&lt;/li>
&lt;li>URL:
&lt;a href="https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_366" rel="noopener">https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_366&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>fter all that, I have to admit that that the term Data Scientist is a generic one that means different things to different people, and the field probably does need to evolve with more specific titles. (
&lt;a href="https://read.readwise.io/read/01gs3nhz0qq3c80wbmjm1xvx6v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Emily Thompson]]
title: &amp;ldquo;Why Is “Data Scientist” Such a Controversial Title?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="why-is-data-scientist-such-a-controversial-title-2">Why Is “Data Scientist” Such a Controversial Title?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fedc01350-a3b8-42d5-869c-81244aaec134_714x338.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emily Thompson]]&lt;/li>
&lt;li>Full Title: Why Is “Data Scientist” Such a Controversial Title?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: There is no science without data, so data word in Data Science is redundant.
A decade later there is still debate on what the Data Scientist term means. The important part of the role is the science aspect.
There is no data science without data engineering and data infrastructure. There is no gain without planning and investing.
Many data scientists has to build the infrastructure and tools themselves when it does not exist.
ETL work and data quality tasks that validates the data pipeline is also part of the work of a scientist. It is even positive because it makes you learn data appreciation.
Data science integration with product managers is still not consistently integrated. Those PMs able to get the learning expertise of the Data Science teams will have a superpower.&lt;/li>
&lt;li>URL:
&lt;a href="https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_366" rel="noopener">https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_366&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>fter all that, I have to admit that that the term Data Scientist is a generic one that means different things to different people, and the field probably does need to evolve with more specific titles. (
&lt;a href="https://read.readwise.io/read/01gs3nhz0qq3c80wbmjm1xvx6v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[Emily Thompson]]
title: &amp;ldquo;Why Is “Data Scientist” Such a Controversial Title?&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="why-is-data-scientist-such-a-controversial-title-3">Why Is “Data Scientist” Such a Controversial Title?&lt;/h1>
&lt;p>
&lt;img src="https://substackcdn.com/image/fetch/w_1200,h_600,c_limit,f_jpg,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fedc01350-a3b8-42d5-869c-81244aaec134_714x338.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[Emily Thompson]]&lt;/li>
&lt;li>Full Title: Why Is “Data Scientist” Such a Controversial Title?&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: There is no science without data, so data word in Data Science is redundant.
A decade later there is still debate on what the Data Scientist term means. The important part of the role is the science aspect.
There is no data science without data engineering and data infrastructure. There is no gain without planning and investing.
Many data scientists has to build the infrastructure and tools themselves when it does not exist.
ETL work and data quality tasks that validates the data pipeline is also part of the work of a scientist. It is even positive because it makes you learn data appreciation.
Data science integration with product managers is still not consistently integrated. Those PMs able to get the learning expertise of the Data Science teams will have a superpower.&lt;/li>
&lt;li>URL:
&lt;a href="https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;amp;utm_source=Data_Elixir_366" rel="noopener">https://scientistemily.substack.com/p/save-data-science?utm_campaign=Data_Elixir&amp;utm_source=Data_Elixir_366&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>fter all that, I have to admit that that the term Data Scientist is a generic one that means different things to different people, and the field probably does need to evolve with more specific titles. (
&lt;a href="https://read.readwise.io/read/01gs3nhz0qq3c80wbmjm1xvx6v" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT</title><link>https://pelayoarbues.github.io/literature-notes/Articles/WolframAlpha-as-the-Way-to-Bring-Computational-Knowledge-Superpowers-to-ChatGPT/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/WolframAlpha-as-the-Way-to-Bring-Computational-Knowledge-Superpowers-to-ChatGPT/</guid><description>&lt;h1 id="wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt">Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/h1>
&lt;p>
&lt;img src="https://content.wolfram.com/uploads/sites/43/2023/01/ChatGPT-hero-v4.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stephenwolfram.com]]&lt;/li>
&lt;li>Full Title: Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/" rel="noopener">https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Contents
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#top" rel="noopener">Top&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#chatgpt-and-wolfram%7calpha" rel="noopener">ChatGPT and Wolfram|Alpha&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-basic-example" rel="noopener">A Basic Example&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-few-more-examples" rel="noopener">A Few More Examples&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#the-path-forward" rel="noopener">The Path Forward&lt;/a>
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT (
&lt;a href="https://read.readwise.io/read/01grxsqamrhb8w92df7rxbdvsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For decades there’s been a dichotomy in thinking about AI between “statistical approaches” of the kind ChatGPT uses, and “symbolic approaches” that are in effect the starting point for Wolfram|Alpha. But now—thanks to the success of ChatGPT—as well as all the work we’ve done in making Wolfram|Alpha understand natural language—there’s finally the opportunity to combine these to make something much stronger than either could ever achieve on their own. (
&lt;a href="https://read.readwise.io/read/01grv9x2xegdjzdcg9jzrevhey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>one might think that if one could just go on and “train a big enough network” one would be able to do absolutely anything with it. But it won’t work that way. Fundamental facts about computation—and notably the concept of
&lt;a href="https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility" rel="noopener">computational irreducibility&lt;/a>—make it clear it ultimately can’t. But what’s more relevant is what we’ve seen in the actual history of machine learning. (
&lt;a href="https://read.readwise.io/read/01grva7n2n5xw4rfqcp8fc6t72" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And yes, there’ll be plenty of cases where “raw ChatGPT” can help with people’s writing, make suggestions, or generate text that’s useful for various kinds of documents or interactions. But when it comes to setting up things that have to be perfect, machine learning just isn’t the way to do it—much as humans aren’t either. (
&lt;a href="https://read.readwise.io/read/01grva821x2dtsd7qwbxzktex7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Wolfram|Alpha can communicate with it in what amounts to ChatGPT’s native language—natural language. And Wolfram|Alpha will take care of “adding the formality and precision” when it converts to its native language—Wolfram Language. It’s a very good situation, that I think has great practical potential. (
&lt;a href="https://read.readwise.io/read/01grva9nsnacg93ne9fz5jv07g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What about ChatGPT directly learning Wolfram Language? Well, yes, it could do that, and in fact it’s already started. And in the end I fully expect that something like ChatGPT will be able to
&lt;a href="https://writings.stephenwolfram.com/2015/11/how-should-we-talk-to-ais/" rel="noopener">operate directly in Wolfram Language&lt;/a>, and be very powerful in doing so. (
&lt;a href="https://read.readwise.io/read/01grvaa8w0t11grxx75c9c26t1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stephenwolfram.com]]
title: &amp;ldquo;Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt-1">Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/h1>
&lt;p>
&lt;img src="https://content.wolfram.com/uploads/sites/43/2023/01/ChatGPT-hero-v4.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stephenwolfram.com]]&lt;/li>
&lt;li>Full Title: Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/" rel="noopener">https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Contents
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#top" rel="noopener">Top&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#chatgpt-and-wolfram%7calpha" rel="noopener">ChatGPT and Wolfram|Alpha&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-basic-example" rel="noopener">A Basic Example&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-few-more-examples" rel="noopener">A Few More Examples&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#the-path-forward" rel="noopener">The Path Forward&lt;/a>
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT (
&lt;a href="https://read.readwise.io/read/01grxsqamrhb8w92df7rxbdvsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For decades there’s been a dichotomy in thinking about AI between “statistical approaches” of the kind ChatGPT uses, and “symbolic approaches” that are in effect the starting point for Wolfram|Alpha. But now—thanks to the success of ChatGPT—as well as all the work we’ve done in making Wolfram|Alpha understand natural language—there’s finally the opportunity to combine these to make something much stronger than either could ever achieve on their own. (
&lt;a href="https://read.readwise.io/read/01grv9x2xegdjzdcg9jzrevhey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>one might think that if one could just go on and “train a big enough network” one would be able to do absolutely anything with it. But it won’t work that way. Fundamental facts about computation—and notably the concept of
&lt;a href="https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility" rel="noopener">computational irreducibility&lt;/a>—make it clear it ultimately can’t. But what’s more relevant is what we’ve seen in the actual history of machine learning. (
&lt;a href="https://read.readwise.io/read/01grva7n2n5xw4rfqcp8fc6t72" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And yes, there’ll be plenty of cases where “raw ChatGPT” can help with people’s writing, make suggestions, or generate text that’s useful for various kinds of documents or interactions. But when it comes to setting up things that have to be perfect, machine learning just isn’t the way to do it—much as humans aren’t either. (
&lt;a href="https://read.readwise.io/read/01grva821x2dtsd7qwbxzktex7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Wolfram|Alpha can communicate with it in what amounts to ChatGPT’s native language—natural language. And Wolfram|Alpha will take care of “adding the formality and precision” when it converts to its native language—Wolfram Language. It’s a very good situation, that I think has great practical potential. (
&lt;a href="https://read.readwise.io/read/01grva9nsnacg93ne9fz5jv07g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What about ChatGPT directly learning Wolfram Language? Well, yes, it could do that, and in fact it’s already started. And in the end I fully expect that something like ChatGPT will be able to
&lt;a href="https://writings.stephenwolfram.com/2015/11/how-should-we-talk-to-ais/" rel="noopener">operate directly in Wolfram Language&lt;/a>, and be very powerful in doing so. (
&lt;a href="https://read.readwise.io/read/01grvaa8w0t11grxx75c9c26t1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stephenwolfram.com]]
title: &amp;ldquo;Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt-2">Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/h1>
&lt;p>
&lt;img src="https://content.wolfram.com/uploads/sites/43/2023/01/ChatGPT-hero-v4.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stephenwolfram.com]]&lt;/li>
&lt;li>Full Title: Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/" rel="noopener">https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Contents
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#top" rel="noopener">Top&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#chatgpt-and-wolfram%7calpha" rel="noopener">ChatGPT and Wolfram|Alpha&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-basic-example" rel="noopener">A Basic Example&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-few-more-examples" rel="noopener">A Few More Examples&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#the-path-forward" rel="noopener">The Path Forward&lt;/a>
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT (
&lt;a href="https://read.readwise.io/read/01grxsqamrhb8w92df7rxbdvsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For decades there’s been a dichotomy in thinking about AI between “statistical approaches” of the kind ChatGPT uses, and “symbolic approaches” that are in effect the starting point for Wolfram|Alpha. But now—thanks to the success of ChatGPT—as well as all the work we’ve done in making Wolfram|Alpha understand natural language—there’s finally the opportunity to combine these to make something much stronger than either could ever achieve on their own. (
&lt;a href="https://read.readwise.io/read/01grv9x2xegdjzdcg9jzrevhey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>one might think that if one could just go on and “train a big enough network” one would be able to do absolutely anything with it. But it won’t work that way. Fundamental facts about computation—and notably the concept of
&lt;a href="https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility" rel="noopener">computational irreducibility&lt;/a>—make it clear it ultimately can’t. But what’s more relevant is what we’ve seen in the actual history of machine learning. (
&lt;a href="https://read.readwise.io/read/01grva7n2n5xw4rfqcp8fc6t72" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And yes, there’ll be plenty of cases where “raw ChatGPT” can help with people’s writing, make suggestions, or generate text that’s useful for various kinds of documents or interactions. But when it comes to setting up things that have to be perfect, machine learning just isn’t the way to do it—much as humans aren’t either. (
&lt;a href="https://read.readwise.io/read/01grva821x2dtsd7qwbxzktex7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Wolfram|Alpha can communicate with it in what amounts to ChatGPT’s native language—natural language. And Wolfram|Alpha will take care of “adding the formality and precision” when it converts to its native language—Wolfram Language. It’s a very good situation, that I think has great practical potential. (
&lt;a href="https://read.readwise.io/read/01grva9nsnacg93ne9fz5jv07g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What about ChatGPT directly learning Wolfram Language? Well, yes, it could do that, and in fact it’s already started. And in the end I fully expect that something like ChatGPT will be able to
&lt;a href="https://writings.stephenwolfram.com/2015/11/how-should-we-talk-to-ais/" rel="noopener">operate directly in Wolfram Language&lt;/a>, and be very powerful in doing so. (
&lt;a href="https://read.readwise.io/read/01grvaa8w0t11grxx75c9c26t1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[stephenwolfram.com]]
title: &amp;ldquo;Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt-3">Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/h1>
&lt;p>
&lt;img src="https://content.wolfram.com/uploads/sites/43/2023/01/ChatGPT-hero-v4.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[stephenwolfram.com]]&lt;/li>
&lt;li>Full Title: Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/" rel="noopener">https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Contents
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#top" rel="noopener">Top&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#chatgpt-and-wolfram%7calpha" rel="noopener">ChatGPT and Wolfram|Alpha&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-basic-example" rel="noopener">A Basic Example&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#a-few-more-examples" rel="noopener">A Few More Examples&lt;/a>
•
&lt;a href="https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bring-computational-knowledge-superpowers-to-chatgpt#the-path-forward" rel="noopener">The Path Forward&lt;/a>
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT
Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT (
&lt;a href="https://read.readwise.io/read/01grxsqamrhb8w92df7rxbdvsx" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>For decades there’s been a dichotomy in thinking about AI between “statistical approaches” of the kind ChatGPT uses, and “symbolic approaches” that are in effect the starting point for Wolfram|Alpha. But now—thanks to the success of ChatGPT—as well as all the work we’ve done in making Wolfram|Alpha understand natural language—there’s finally the opportunity to combine these to make something much stronger than either could ever achieve on their own. (
&lt;a href="https://read.readwise.io/read/01grv9x2xegdjzdcg9jzrevhey" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>one might think that if one could just go on and “train a big enough network” one would be able to do absolutely anything with it. But it won’t work that way. Fundamental facts about computation—and notably the concept of
&lt;a href="https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility" rel="noopener">computational irreducibility&lt;/a>—make it clear it ultimately can’t. But what’s more relevant is what we’ve seen in the actual history of machine learning. (
&lt;a href="https://read.readwise.io/read/01grva7n2n5xw4rfqcp8fc6t72" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>And yes, there’ll be plenty of cases where “raw ChatGPT” can help with people’s writing, make suggestions, or generate text that’s useful for various kinds of documents or interactions. But when it comes to setting up things that have to be perfect, machine learning just isn’t the way to do it—much as humans aren’t either. (
&lt;a href="https://read.readwise.io/read/01grva821x2dtsd7qwbxzktex7" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Wolfram|Alpha can communicate with it in what amounts to ChatGPT’s native language—natural language. And Wolfram|Alpha will take care of “adding the formality and precision” when it converts to its native language—Wolfram Language. It’s a very good situation, that I think has great practical potential. (
&lt;a href="https://read.readwise.io/read/01grva9nsnacg93ne9fz5jv07g" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>What about ChatGPT directly learning Wolfram Language? Well, yes, it could do that, and in fact it’s already started. And in the end I fully expect that something like ChatGPT will be able to
&lt;a href="https://writings.stephenwolfram.com/2015/11/how-should-we-talk-to-ais/" rel="noopener">operate directly in Wolfram Language&lt;/a>, and be very powerful in doing so. (
&lt;a href="https://read.readwise.io/read/01grvaa8w0t11grxx75c9c26t1" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Writing Strategies and Visions.</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Writing-Strategies-and-Visions./</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Writing-Strategies-and-Visions./</guid><description>&lt;h1 id="writing-strategies-and-visions">Writing Strategies and Visions.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Writing Strategies and Visions.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/strategies-visions/" rel="noopener">https://lethain.com/strategies-visions/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>A &lt;em>strategy&lt;/em> is an approach to a challenge that recommends specific actions that address the challenge’s constraints.
&lt;a href="https://lethain.com/good-strategy-bad-strategy/" rel="noopener">A structure that I’ve found extremely effective&lt;/a> is described in
&lt;a href="https://www.amazon.com/dp/B004J4WKEC/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Good Strategy, Bad Strategy&lt;/a>, and has three sections: &lt;em>diagnosis&lt;/em>, &lt;em>policies&lt;/em> and &lt;em>actions&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsnfpze4fb7hfdrt2fskhwh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;em>diagnosis&lt;/em> is a theory describing the challenge at hand. It calls out the factors and constraints that define the challenge, and at its core is a very thorough problem statement. (
&lt;a href="https://read.readwise.io/read/01grsnkag6thg68hh2c2sjdffz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The second step is to identify &lt;em>policies&lt;/em> that will be applied to address the challenge. These describe the general approach you’ll take, and are often tradeoffs between two competing goals. (
&lt;a href="https://read.readwise.io/read/01grsnjtqetnz3bm9ny1705kde" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>your diagnosis, you get your &lt;em>actions&lt;/em>. Folks are often comfortable with hard decisions in the abstract, but struggle to translate them into the specific steps to implement them (
&lt;a href="https://read.readwise.io/read/01grsnjm3f8tfwpv6at6knqr0s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An effective vision helps folks think beyond the constraints of their local maxima, and lightly aligns progress without requiring tight centralized coordination. (
&lt;a href="https://read.readwise.io/read/01grsnr1g0n7q9japy9fpq4tm0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put all these pieces together, and you’ve crafted a document that is a guiding hand to align decisions while also creating room for teams to make their own choices and tradeoffs along the way. (
&lt;a href="https://read.readwise.io/read/01grsp16q2jxs6atvs7593hwxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Writing Strategies and Visions.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="writing-strategies-and-visions-1">Writing Strategies and Visions.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Writing Strategies and Visions.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/strategies-visions/" rel="noopener">https://lethain.com/strategies-visions/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>A &lt;em>strategy&lt;/em> is an approach to a challenge that recommends specific actions that address the challenge’s constraints.
&lt;a href="https://lethain.com/good-strategy-bad-strategy/" rel="noopener">A structure that I’ve found extremely effective&lt;/a> is described in
&lt;a href="https://www.amazon.com/dp/B004J4WKEC/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Good Strategy, Bad Strategy&lt;/a>, and has three sections: &lt;em>diagnosis&lt;/em>, &lt;em>policies&lt;/em> and &lt;em>actions&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsnfpze4fb7hfdrt2fskhwh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;em>diagnosis&lt;/em> is a theory describing the challenge at hand. It calls out the factors and constraints that define the challenge, and at its core is a very thorough problem statement. (
&lt;a href="https://read.readwise.io/read/01grsnkag6thg68hh2c2sjdffz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The second step is to identify &lt;em>policies&lt;/em> that will be applied to address the challenge. These describe the general approach you’ll take, and are often tradeoffs between two competing goals. (
&lt;a href="https://read.readwise.io/read/01grsnjtqetnz3bm9ny1705kde" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>your diagnosis, you get your &lt;em>actions&lt;/em>. Folks are often comfortable with hard decisions in the abstract, but struggle to translate them into the specific steps to implement them (
&lt;a href="https://read.readwise.io/read/01grsnjm3f8tfwpv6at6knqr0s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An effective vision helps folks think beyond the constraints of their local maxima, and lightly aligns progress without requiring tight centralized coordination. (
&lt;a href="https://read.readwise.io/read/01grsnr1g0n7q9japy9fpq4tm0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put all these pieces together, and you’ve crafted a document that is a guiding hand to align decisions while also creating room for teams to make their own choices and tradeoffs along the way. (
&lt;a href="https://read.readwise.io/read/01grsp16q2jxs6atvs7593hwxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Writing Strategies and Visions.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="writing-strategies-and-visions-2">Writing Strategies and Visions.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Writing Strategies and Visions.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/strategies-visions/" rel="noopener">https://lethain.com/strategies-visions/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>A &lt;em>strategy&lt;/em> is an approach to a challenge that recommends specific actions that address the challenge’s constraints.
&lt;a href="https://lethain.com/good-strategy-bad-strategy/" rel="noopener">A structure that I’ve found extremely effective&lt;/a> is described in
&lt;a href="https://www.amazon.com/dp/B004J4WKEC/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Good Strategy, Bad Strategy&lt;/a>, and has three sections: &lt;em>diagnosis&lt;/em>, &lt;em>policies&lt;/em> and &lt;em>actions&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsnfpze4fb7hfdrt2fskhwh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;em>diagnosis&lt;/em> is a theory describing the challenge at hand. It calls out the factors and constraints that define the challenge, and at its core is a very thorough problem statement. (
&lt;a href="https://read.readwise.io/read/01grsnkag6thg68hh2c2sjdffz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The second step is to identify &lt;em>policies&lt;/em> that will be applied to address the challenge. These describe the general approach you’ll take, and are often tradeoffs between two competing goals. (
&lt;a href="https://read.readwise.io/read/01grsnjtqetnz3bm9ny1705kde" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>your diagnosis, you get your &lt;em>actions&lt;/em>. Folks are often comfortable with hard decisions in the abstract, but struggle to translate them into the specific steps to implement them (
&lt;a href="https://read.readwise.io/read/01grsnjm3f8tfwpv6at6knqr0s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An effective vision helps folks think beyond the constraints of their local maxima, and lightly aligns progress without requiring tight centralized coordination. (
&lt;a href="https://read.readwise.io/read/01grsnr1g0n7q9japy9fpq4tm0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put all these pieces together, and you’ve crafted a document that is a guiding hand to align decisions while also creating room for teams to make their own choices and tradeoffs along the way. (
&lt;a href="https://read.readwise.io/read/01grsp16q2jxs6atvs7593hwxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[lethain.com]]
title: &amp;ldquo;Writing Strategies and Visions.&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="writing-strategies-and-visions-3">Writing Strategies and Visions.&lt;/h1>
&lt;p>
&lt;img src="https://lethain.com/static/author.png" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[lethain.com]]&lt;/li>
&lt;li>Full Title: Writing Strategies and Visions.&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://lethain.com/strategies-visions/" rel="noopener">https://lethain.com/strategies-visions/&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>A &lt;em>strategy&lt;/em> is an approach to a challenge that recommends specific actions that address the challenge’s constraints.
&lt;a href="https://lethain.com/good-strategy-bad-strategy/" rel="noopener">A structure that I’ve found extremely effective&lt;/a> is described in
&lt;a href="https://www.amazon.com/dp/B004J4WKEC/ref=dp-kindle-redirect?_encoding=UTF8&amp;amp;btkr=1" rel="noopener">Good Strategy, Bad Strategy&lt;/a>, and has three sections: &lt;em>diagnosis&lt;/em>, &lt;em>policies&lt;/em> and &lt;em>actions&lt;/em>. (
&lt;a href="https://read.readwise.io/read/01grsnfpze4fb7hfdrt2fskhwh" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The &lt;em>diagnosis&lt;/em> is a theory describing the challenge at hand. It calls out the factors and constraints that define the challenge, and at its core is a very thorough problem statement. (
&lt;a href="https://read.readwise.io/read/01grsnkag6thg68hh2c2sjdffz" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>The second step is to identify &lt;em>policies&lt;/em> that will be applied to address the challenge. These describe the general approach you’ll take, and are often tradeoffs between two competing goals. (
&lt;a href="https://read.readwise.io/read/01grsnjtqetnz3bm9ny1705kde" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>your diagnosis, you get your &lt;em>actions&lt;/em>. Folks are often comfortable with hard decisions in the abstract, but struggle to translate them into the specific steps to implement them (
&lt;a href="https://read.readwise.io/read/01grsnjm3f8tfwpv6at6knqr0s" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>An effective vision helps folks think beyond the constraints of their local maxima, and lightly aligns progress without requiring tight centralized coordination. (
&lt;a href="https://read.readwise.io/read/01grsnr1g0n7q9japy9fpq4tm0" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Put all these pieces together, and you’ve crafted a document that is a guiding hand to align decisions while also creating room for teams to make their own choices and tradeoffs along the way. (
&lt;a href="https://read.readwise.io/read/01grsp16q2jxs6atvs7593hwxa" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>Your Estimates Suck</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Your-Estimates-Suck/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Your-Estimates-Suck/</guid><description>&lt;h1 id="your-estimates-suck">Your Estimates Suck&lt;/h1>
&lt;p>
&lt;img src="https://world.hey.com/dhh/avatar-20210222112907000000-293866624" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[hey.com]]&lt;/li>
&lt;li>Full Title: Your Estimates Suck&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Humans are unable to get accurate estimates of how long things will take, unless is something that can be accomplished with a cookiecutter. No one is able to estimate 4 or 6 weeks.
Appetite, how much you are willing to spend.
Stop loss. Common in gambling, how much you are willing to lose, spend. Related to sunk costs, it prevents you from taking irrational decisions.
Stick to your guns. Stick to 6 weeks, make it in 6 weeks. Dont bring other 6 weeks.
No one gets everything they want. Accept that fact and that some features will be out. You start building, and it takes longer than you thought. You got to trade concessions, you have to cut features.
It is a repeatable process that allows you to continue ship. You build a lot of stuff and make the products better. But accept that all of them left something in the table.
Nothing will clog down the momentum and motivation of a software development team like not being able to ship. You lose your capacity to ship.
If you practice beeing late you are going to be good at being late. If you practice shipping, you get good at shipping.
If you are unable to ship in time, you don&amp;rsquo;t ship whatever, you cut down scope. And if you have to cut down too much scope, you cancel projects. You dont put more hours. It is important that it is there, it keeps the system integral.
You dont want to be stuck for this one thing, you could be working in something else. It creates a very negative feedback.&lt;/li>
&lt;li>URL:
&lt;a href="https://world.hey.com/dhh/your-estimates-suck-2b9f8445" rel="noopener">https://world.hey.com/dhh/your-estimates-suck-2b9f8445&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Humans are terrible at estimating anything complicated that involves novel attempts at problem solving. (
&lt;a href="https://read.readwise.io/read/01gs3nbsfd3y94antvfvtesf7q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Nothing will clog down the momentum and motivation of a software development team like not being able to ship (
&lt;a href="https://read.readwise.io/read/01gs3nd14p73xsfmndy7x2kxkk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[hey.com]]
title: &amp;ldquo;Your Estimates Suck&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="your-estimates-suck-1">Your Estimates Suck&lt;/h1>
&lt;p>
&lt;img src="https://world.hey.com/dhh/avatar-20210222112907000000-293866624" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[hey.com]]&lt;/li>
&lt;li>Full Title: Your Estimates Suck&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Humans are unable to get accurate estimates of how long things will take, unless is something that can be accomplished with a cookiecutter. No one is able to estimate 4 or 6 weeks.
Appetite, how much you are willing to spend.
Stop loss. Common in gambling, how much you are willing to lose, spend. Related to sunk costs, it prevents you from taking irrational decisions.
Stick to your guns. Stick to 6 weeks, make it in 6 weeks. Dont bring other 6 weeks.
No one gets everything they want. Accept that fact and that some features will be out. You start building, and it takes longer than you thought. You got to trade concessions, you have to cut features.
It is a repeatable process that allows you to continue ship. You build a lot of stuff and make the products better. But accept that all of them left something in the table.
Nothing will clog down the momentum and motivation of a software development team like not being able to ship. You lose your capacity to ship.
If you practice beeing late you are going to be good at being late. If you practice shipping, you get good at shipping.
If you are unable to ship in time, you don&amp;rsquo;t ship whatever, you cut down scope. And if you have to cut down too much scope, you cancel projects. You dont put more hours. It is important that it is there, it keeps the system integral.
You dont want to be stuck for this one thing, you could be working in something else. It creates a very negative feedback.&lt;/li>
&lt;li>URL:
&lt;a href="https://world.hey.com/dhh/your-estimates-suck-2b9f8445" rel="noopener">https://world.hey.com/dhh/your-estimates-suck-2b9f8445&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Humans are terrible at estimating anything complicated that involves novel attempts at problem solving. (
&lt;a href="https://read.readwise.io/read/01gs3nbsfd3y94antvfvtesf7q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Nothing will clog down the momentum and motivation of a software development team like not being able to ship (
&lt;a href="https://read.readwise.io/read/01gs3nd14p73xsfmndy7x2kxkk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[hey.com]]
title: &amp;ldquo;Your Estimates Suck&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="your-estimates-suck-2">Your Estimates Suck&lt;/h1>
&lt;p>
&lt;img src="https://world.hey.com/dhh/avatar-20210222112907000000-293866624" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[hey.com]]&lt;/li>
&lt;li>Full Title: Your Estimates Suck&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Humans are unable to get accurate estimates of how long things will take, unless is something that can be accomplished with a cookiecutter. No one is able to estimate 4 or 6 weeks.
Appetite, how much you are willing to spend.
Stop loss. Common in gambling, how much you are willing to lose, spend. Related to sunk costs, it prevents you from taking irrational decisions.
Stick to your guns. Stick to 6 weeks, make it in 6 weeks. Dont bring other 6 weeks.
No one gets everything they want. Accept that fact and that some features will be out. You start building, and it takes longer than you thought. You got to trade concessions, you have to cut features.
It is a repeatable process that allows you to continue ship. You build a lot of stuff and make the products better. But accept that all of them left something in the table.
Nothing will clog down the momentum and motivation of a software development team like not being able to ship. You lose your capacity to ship.
If you practice beeing late you are going to be good at being late. If you practice shipping, you get good at shipping.
If you are unable to ship in time, you don&amp;rsquo;t ship whatever, you cut down scope. And if you have to cut down too much scope, you cancel projects. You dont put more hours. It is important that it is there, it keeps the system integral.
You dont want to be stuck for this one thing, you could be working in something else. It creates a very negative feedback.&lt;/li>
&lt;li>URL:
&lt;a href="https://world.hey.com/dhh/your-estimates-suck-2b9f8445" rel="noopener">https://world.hey.com/dhh/your-estimates-suck-2b9f8445&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Humans are terrible at estimating anything complicated that involves novel attempts at problem solving. (
&lt;a href="https://read.readwise.io/read/01gs3nbsfd3y94antvfvtesf7q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Nothing will clog down the momentum and motivation of a software development team like not being able to ship (
&lt;a href="https://read.readwise.io/read/01gs3nd14p73xsfmndy7x2kxkk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[hey.com]]
title: &amp;ldquo;Your Estimates Suck&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="your-estimates-suck-3">Your Estimates Suck&lt;/h1>
&lt;p>
&lt;img src="https://world.hey.com/dhh/avatar-20210222112907000000-293866624" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[hey.com]]&lt;/li>
&lt;li>Full Title: Your Estimates Suck&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>Document Note: Humans are unable to get accurate estimates of how long things will take, unless is something that can be accomplished with a cookiecutter. No one is able to estimate 4 or 6 weeks.
Appetite, how much you are willing to spend.
Stop loss. Common in gambling, how much you are willing to lose, spend. Related to sunk costs, it prevents you from taking irrational decisions.
Stick to your guns. Stick to 6 weeks, make it in 6 weeks. Dont bring other 6 weeks.
No one gets everything they want. Accept that fact and that some features will be out. You start building, and it takes longer than you thought. You got to trade concessions, you have to cut features.
It is a repeatable process that allows you to continue ship. You build a lot of stuff and make the products better. But accept that all of them left something in the table.
Nothing will clog down the momentum and motivation of a software development team like not being able to ship. You lose your capacity to ship.
If you practice beeing late you are going to be good at being late. If you practice shipping, you get good at shipping.
If you are unable to ship in time, you don&amp;rsquo;t ship whatever, you cut down scope. And if you have to cut down too much scope, you cancel projects. You dont put more hours. It is important that it is there, it keeps the system integral.
You dont want to be stuck for this one thing, you could be working in something else. It creates a very negative feedback.&lt;/li>
&lt;li>URL:
&lt;a href="https://world.hey.com/dhh/your-estimates-suck-2b9f8445" rel="noopener">https://world.hey.com/dhh/your-estimates-suck-2b9f8445&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Humans are terrible at estimating anything complicated that involves novel attempts at problem solving. (
&lt;a href="https://read.readwise.io/read/01gs3nbsfd3y94antvfvtesf7q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Nothing will clog down the momentum and motivation of a software development team like not being able to ship (
&lt;a href="https://read.readwise.io/read/01gs3nd14p73xsfmndy7x2kxkk" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item><item><title>¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español</title><link>https://pelayoarbues.github.io/literature-notes/Articles/Por-Qu%C3%A9-Los-Salarios-Son-M%C3%A1s-Altos-en-Las-Ciudades-Grandes-La-Importancia-Del-Poder-De-Monopsonio-en-El-Mercado-Laboral-Espa%C3%B1ol/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pelayoarbues.github.io/literature-notes/Articles/Por-Qu%C3%A9-Los-Salarios-Son-M%C3%A1s-Altos-en-Las-Ciudades-Grandes-La-Importancia-Del-Poder-De-Monopsonio-en-El-Mercado-Laboral-Espa%C3%B1ol/</guid><description>&lt;h1 id="por-qué-los-salarios-son-más-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-español">¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/h1>
&lt;p>
&lt;img src="https://nadaesgratis.es/wp-content/uploads/imagen_portada-1-300x200.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[admin]]&lt;/li>
&lt;li>Full Title: ¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol" rel="noopener">https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights">Highlights&lt;/h2>
&lt;ul>
&lt;li>Existen varias explicaciones del origen de la brecha salarial entre ciudades de distinto tamaño. Una de ellas es que las grandes ciudades experimentan &amp;ldquo;
&lt;a href="https://nadaesgratis.es/fran-beltran/las-economias-de-aglomeracion-y-la-distribucion-espacial-de-la-poblacion" rel="noopener">economías de aglomeración&lt;/a>&amp;rdquo;, lo cual significa que las empresas y los trabajadores son más productivos cuando están concentrados en un solo lugar. (
&lt;a href="https://read.readwise.io/read/01grgtncsm5crjkn5jn5752dad" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Una explicación alternativa es que las grandes ciudades atraen y retienen a trabajadores y emprendedores de mayor talento. (
&lt;a href="https://read.readwise.io/read/01grgtntar0ygqcj2zmeseqj06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>en las ciudades grandes hay más empresas y la competencia por los trabajadores es más fuerte. Esto significa que las firmas tienen que ofrecer salarios más altos para retener a sus empleados (
&lt;a href="https://read.readwise.io/read/01grgtqn2by74wpj6hnrx17qpb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las grandes ciudades también suelen tener más competencia entre los empleadores, como se refleja en la menor concentración de empleo (medida con el Índice de Herfindahl-Hirschman, o HHI). Este índice va de 0 (competencia perfecta) a 1 (un solo empleador con control absoluto del mercado, también conocido como monopsonio (
&lt;a href="https://read.readwise.io/read/01grgtrt8c8w8789kzyssxpq9q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[admin]]
title: &amp;ldquo;¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="por-qué-los-salarios-son-más-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-español-1">¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/h1>
&lt;p>
&lt;img src="https://nadaesgratis.es/wp-content/uploads/imagen_portada-1-300x200.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-1">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[admin]]&lt;/li>
&lt;li>Full Title: ¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol" rel="noopener">https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-1">Highlights&lt;/h2>
&lt;ul>
&lt;li>Existen varias explicaciones del origen de la brecha salarial entre ciudades de distinto tamaño. Una de ellas es que las grandes ciudades experimentan &amp;ldquo;
&lt;a href="https://nadaesgratis.es/fran-beltran/las-economias-de-aglomeracion-y-la-distribucion-espacial-de-la-poblacion" rel="noopener">economías de aglomeración&lt;/a>&amp;rdquo;, lo cual significa que las empresas y los trabajadores son más productivos cuando están concentrados en un solo lugar. (
&lt;a href="https://read.readwise.io/read/01grgtncsm5crjkn5jn5752dad" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Una explicación alternativa es que las grandes ciudades atraen y retienen a trabajadores y emprendedores de mayor talento. (
&lt;a href="https://read.readwise.io/read/01grgtntar0ygqcj2zmeseqj06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>en las ciudades grandes hay más empresas y la competencia por los trabajadores es más fuerte. Esto significa que las firmas tienen que ofrecer salarios más altos para retener a sus empleados (
&lt;a href="https://read.readwise.io/read/01grgtqn2by74wpj6hnrx17qpb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las grandes ciudades también suelen tener más competencia entre los empleadores, como se refleja en la menor concentración de empleo (medida con el Índice de Herfindahl-Hirschman, o HHI). Este índice va de 0 (competencia perfecta) a 1 (un solo empleador con control absoluto del mercado, también conocido como monopsonio (
&lt;a href="https://read.readwise.io/read/01grgtrt8c8w8789kzyssxpq9q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[admin]]
title: &amp;ldquo;¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="por-qué-los-salarios-son-más-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-español-2">¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/h1>
&lt;p>
&lt;img src="https://nadaesgratis.es/wp-content/uploads/imagen_portada-1-300x200.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-2">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[admin]]&lt;/li>
&lt;li>Full Title: ¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol" rel="noopener">https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-2">Highlights&lt;/h2>
&lt;ul>
&lt;li>Existen varias explicaciones del origen de la brecha salarial entre ciudades de distinto tamaño. Una de ellas es que las grandes ciudades experimentan &amp;ldquo;
&lt;a href="https://nadaesgratis.es/fran-beltran/las-economias-de-aglomeracion-y-la-distribucion-espacial-de-la-poblacion" rel="noopener">economías de aglomeración&lt;/a>&amp;rdquo;, lo cual significa que las empresas y los trabajadores son más productivos cuando están concentrados en un solo lugar. (
&lt;a href="https://read.readwise.io/read/01grgtncsm5crjkn5jn5752dad" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Una explicación alternativa es que las grandes ciudades atraen y retienen a trabajadores y emprendedores de mayor talento. (
&lt;a href="https://read.readwise.io/read/01grgtntar0ygqcj2zmeseqj06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>en las ciudades grandes hay más empresas y la competencia por los trabajadores es más fuerte. Esto significa que las firmas tienen que ofrecer salarios más altos para retener a sus empleados (
&lt;a href="https://read.readwise.io/read/01grgtqn2by74wpj6hnrx17qpb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las grandes ciudades también suelen tener más competencia entre los empleadores, como se refleja en la menor concentración de empleo (medida con el Índice de Herfindahl-Hirschman, o HHI). Este índice va de 0 (competencia perfecta) a 1 (un solo empleador con control absoluto del mercado, también conocido como monopsonio (
&lt;a href="https://read.readwise.io/read/01grgtrt8c8w8789kzyssxpq9q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>author: [[admin]]
title: &amp;ldquo;¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&amp;rdquo;
tags:&lt;/p>
&lt;ul>
&lt;li>articles&lt;/li>
&lt;li>literature-note&lt;/li>
&lt;/ul>
&lt;hr>
&lt;h1 id="por-qué-los-salarios-son-más-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-español-3">¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/h1>
&lt;p>
&lt;img src="https://nadaesgratis.es/wp-content/uploads/imagen_portada-1-300x200.jpeg" width="auto" alt="rw-book-cover" />&lt;/p>
&lt;h2 id="metadata-3">Metadata&lt;/h2>
&lt;ul>
&lt;li>Author: [[admin]]&lt;/li>
&lt;li>Full Title: ¿Por Qué Los Salarios Son Más Altos en Las Ciudades Grandes? La Importancia Del Poder De Monopsonio en El Mercado Laboral Español&lt;/li>
&lt;li>Category: #articles&lt;/li>
&lt;li>URL:
&lt;a href="https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol" rel="noopener">https://nadaesgratis.es/admin/por-que-los-salarios-son-mas-altos-en-las-ciudades-grandes-la-importancia-del-poder-de-monopsonio-en-el-mercado-laboral-espanol&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="highlights-3">Highlights&lt;/h2>
&lt;ul>
&lt;li>Existen varias explicaciones del origen de la brecha salarial entre ciudades de distinto tamaño. Una de ellas es que las grandes ciudades experimentan &amp;ldquo;
&lt;a href="https://nadaesgratis.es/fran-beltran/las-economias-de-aglomeracion-y-la-distribucion-espacial-de-la-poblacion" rel="noopener">economías de aglomeración&lt;/a>&amp;rdquo;, lo cual significa que las empresas y los trabajadores son más productivos cuando están concentrados en un solo lugar. (
&lt;a href="https://read.readwise.io/read/01grgtncsm5crjkn5jn5752dad" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Una explicación alternativa es que las grandes ciudades atraen y retienen a trabajadores y emprendedores de mayor talento. (
&lt;a href="https://read.readwise.io/read/01grgtntar0ygqcj2zmeseqj06" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>en las ciudades grandes hay más empresas y la competencia por los trabajadores es más fuerte. Esto significa que las firmas tienen que ofrecer salarios más altos para retener a sus empleados (
&lt;a href="https://read.readwise.io/read/01grgtqn2by74wpj6hnrx17qpb" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;li>Las grandes ciudades también suelen tener más competencia entre los empleadores, como se refleja en la menor concentración de empleo (medida con el Índice de Herfindahl-Hirschman, o HHI). Este índice va de 0 (competencia perfecta) a 1 (un solo empleador con control absoluto del mercado, también conocido como monopsonio (
&lt;a href="https://read.readwise.io/read/01grgtrt8c8w8789kzyssxpq9q" rel="noopener">View Highlight&lt;/a>)&lt;/li>
&lt;/ul></description></item></channel></rss>